#!/usr/bin/env python3
"""
HVDC DHL Warehouse ì™„ì „ë³µêµ¬ ë°ì´í„° ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±ê¸°
- ì…ë ¥: HVDC_DHL_Warehouse_ì™„ì „ë³µêµ¬_20250704_125724.xlsx
- ì¶œë ¥: ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ (Excel + Markdown)
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import traceback

class HVDCDHLWarehouseAnalyzer:
    def __init__(self, file_path):
        """ì´ˆê¸°í™”"""
        self.file_path = file_path
        self.df = None
        self.analysis_results = {}
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
    def load_data(self):
        """Excel íŒŒì¼ ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘"""
        try:
            print(f"ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘: {os.path.basename(self.file_path)}")
            self.df = pd.read_excel(self.file_path)
            
            # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
            self.analysis_results['basic_info'] = {
                'file_name': os.path.basename(self.file_path),
                'total_records': len(self.df),
                'total_columns': len(self.df.columns),
                'file_size_mb': round(os.path.getsize(self.file_path) / (1024*1024), 2),
                'analysis_timestamp': self.timestamp
            }
            
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df):,}ê±´, {len(self.df.columns)}ê°œ ì»¬ëŸ¼")
            print(f"ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡: {list(self.df.columns)}")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def analyze_column_structure(self):
        """ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„"""
        try:
            print("ğŸ” ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„ ì¤‘...")
            
            column_analysis = []
            for col in self.df.columns:
                col_info = {
                    'column_name': col,
                    'data_type': str(self.df[col].dtype),
                    'non_null_count': self.df[col].notna().sum(),
                    'null_count': self.df[col].isna().sum(),
                    'null_percentage': round(self.df[col].isna().sum() / len(self.df) * 100, 2),
                    'unique_values': self.df[col].nunique()
                }
                
                # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì˜ ê²½ìš° ì¶”ê°€ í†µê³„
                if pd.api.types.is_numeric_dtype(self.df[col]):
                    col_info.update({
                        'min_value': self.df[col].min(),
                        'max_value': self.df[col].max(),
                        'mean_value': self.df[col].mean(),
                        'std_value': self.df[col].std()
                    })
                
                column_analysis.append(col_info)
            
            self.analysis_results['column_structure'] = column_analysis
            print(f"âœ… ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„ ì™„ë£Œ: {len(column_analysis)}ê°œ ì»¬ëŸ¼")
            
        except Exception as e:
            print(f"âŒ ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def analyze_warehouse_data(self):
        """ì°½ê³  ë°ì´í„° ë¶„ì„"""
        try:
            print("ğŸ¢ ì°½ê³  ë°ì´í„° ë¶„ì„ ì¤‘...")
            
            # ì°½ê³  ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
            warehouse_cols = [col for col in self.df.columns if any(keyword in str(col).upper() 
                           for keyword in ['WAREHOUSE', 'WH', 'DSV', 'AAA', 'HAULER', 'MOSB'])]
            
            print(f"ğŸ” ë°œê²¬ëœ ì°½ê³  ì»¬ëŸ¼: {warehouse_cols}")
            
            warehouse_analysis = {}
            
            for col in warehouse_cols:
                if self.df[col].dtype == 'object':
                    # ë‚ ì§œ ì»¬ëŸ¼ì¸ì§€ í™•ì¸
                    try:
                        pd.to_datetime(self.df[col].dropna().iloc[0])
                        is_date = True
                    except:
                        is_date = False
                    
                    if not is_date:
                        value_counts = self.df[col].value_counts()
                        warehouse_analysis[col] = {
                            'type': 'categorical',
                            'unique_values': len(value_counts),
                            'top_values': value_counts.head(5).to_dict(),
                            'null_count': self.df[col].isna().sum()
                        }
                else:
                    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼
                    warehouse_analysis[col] = {
                        'type': 'numeric',
                        'min': self.df[col].min(),
                        'max': self.df[col].max(),
                        'mean': self.df[col].mean(),
                        'null_count': self.df[col].isna().sum()
                    }
            
            self.analysis_results['warehouse_analysis'] = warehouse_analysis
            print(f"âœ… ì°½ê³  ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {len(warehouse_cols)}ê°œ ì°½ê³  ì»¬ëŸ¼")
            
        except Exception as e:
            print(f"âŒ ì°½ê³  ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def analyze_site_data(self):
        """í˜„ì¥ ë°ì´í„° ë¶„ì„"""
        try:
            print("ğŸ—ï¸ í˜„ì¥ ë°ì´í„° ë¶„ì„ ì¤‘...")
            
            # í˜„ì¥ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
            site_cols = [col for col in self.df.columns if any(keyword in str(col).upper() 
                       for keyword in ['AGI', 'DAS', 'MIR', 'SHU', 'SITE'])]
            
            print(f"ğŸ” ë°œê²¬ëœ í˜„ì¥ ì»¬ëŸ¼: {site_cols}")
            
            site_analysis = {}
            
            for col in site_cols:
                if self.df[col].dtype == 'object':
                    # ë‚ ì§œ ì»¬ëŸ¼ì¸ì§€ í™•ì¸
                    try:
                        pd.to_datetime(self.df[col].dropna().iloc[0])
                        is_date = True
                    except:
                        is_date = False
                    
                    if not is_date:
                        value_counts = self.df[col].value_counts()
                        site_analysis[col] = {
                            'type': 'categorical',
                            'unique_values': len(value_counts),
                            'top_values': value_counts.head(5).to_dict(),
                            'null_count': self.df[col].isna().sum()
                        }
                else:
                    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼
                    site_analysis[col] = {
                        'type': 'numeric',
                        'min': self.df[col].min(),
                        'max': self.df[col].max(),
                        'mean': self.df[col].mean(),
                        'null_count': self.df[col].isna().sum()
                    }
            
            self.analysis_results['site_analysis'] = site_analysis
            print(f"âœ… í˜„ì¥ ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {len(site_cols)}ê°œ í˜„ì¥ ì»¬ëŸ¼")
            
        except Exception as e:
            print(f"âŒ í˜„ì¥ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def analyze_date_patterns(self):
        """ë‚ ì§œ íŒ¨í„´ ë¶„ì„"""
        try:
            print("ğŸ“… ë‚ ì§œ íŒ¨í„´ ë¶„ì„ ì¤‘...")
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸°
            date_cols = []
            for col in self.df.columns:
                if self.df[col].dtype == 'object':
                    try:
                        sample_data = self.df[col].dropna().head(10)
                        if len(sample_data) > 0:
                            pd.to_datetime(sample_data.iloc[0])
                            date_cols.append(col)
                    except:
                        continue
            
            print(f"ğŸ” ë°œê²¬ëœ ë‚ ì§œ ì»¬ëŸ¼: {date_cols}")
            
            date_analysis = {}
            
            for col in date_cols:
                try:
                    date_series = pd.to_datetime(self.df[col], errors='coerce')
                    valid_dates = date_series.dropna()
                    
                    if len(valid_dates) > 0:
                        date_analysis[col] = {
                            'total_records': len(self.df[col]),
                            'valid_dates': len(valid_dates),
                            'null_dates': len(self.df[col]) - len(valid_dates),
                            'date_range': {
                                'start': valid_dates.min().strftime('%Y-%m-%d'),
                                'end': valid_dates.max().strftime('%Y-%m-%d')
                            },
                            'monthly_distribution': valid_dates.dt.to_period('M').value_counts().sort_index().to_dict()
                        }
                except Exception as e:
                    date_analysis[col] = {'error': str(e)}
            
            self.analysis_results['date_analysis'] = date_analysis
            print(f"âœ… ë‚ ì§œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {len(date_cols)}ê°œ ë‚ ì§œ ì»¬ëŸ¼")
            
        except Exception as e:
            print(f"âŒ ë‚ ì§œ íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def analyze_numeric_data(self):
        """ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„"""
        try:
            print("ğŸ“Š ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„ ì¤‘...")
            
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
            print(f"ğŸ” ë°œê²¬ëœ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼: {numeric_cols}")
            
            numeric_analysis = {}
            
            for col in numeric_cols:
                numeric_analysis[col] = {
                    'count': self.df[col].count(),
                    'mean': self.df[col].mean(),
                    'std': self.df[col].std(),
                    'min': self.df[col].min(),
                    'max': self.df[col].max(),
                    'median': self.df[col].median(),
                    'null_count': self.df[col].isna().sum(),
                    'zero_count': (self.df[col] == 0).sum(),
                    'negative_count': (self.df[col] < 0).sum()
                }
            
            self.analysis_results['numeric_analysis'] = numeric_analysis
            print(f"âœ… ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„ ì™„ë£Œ: {len(numeric_cols)}ê°œ ìˆ˜ì¹˜ ì»¬ëŸ¼")
            
        except Exception as e:
            print(f"âŒ ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def generate_summary_statistics(self):
        """ìš”ì•½ í†µê³„ ìƒì„±"""
        try:
            print("ğŸ“ˆ ìš”ì•½ í†µê³„ ìƒì„± ì¤‘...")
            
            # ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
            total_cells = len(self.df) * len(self.df.columns)
            null_cells = self.df.isnull().sum().sum()
            data_quality = {
                'total_cells': total_cells,
                'null_cells': null_cells,
                'data_completeness': round((total_cells - null_cells) / total_cells * 100, 2),
                'duplicate_rows': self.df.duplicated().sum(),
                'unique_rows': len(self.df.drop_duplicates())
            }
            
            # ì»¬ëŸ¼ íƒ€ì…ë³„ ë¶„í¬
            column_types = {
                'numeric': len(self.df.select_dtypes(include=[np.number]).columns),
                'object': len(self.df.select_dtypes(include=['object']).columns),
                'datetime': len(self.df.select_dtypes(include=['datetime']).columns),
                'boolean': len(self.df.select_dtypes(include=['bool']).columns)
            }
            
            self.analysis_results['summary_statistics'] = {
                'data_quality': data_quality,
                'column_types': column_types
            }
            
            print("âœ… ìš”ì•½ í†µê³„ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ìš”ì•½ í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def create_excel_report(self):
        """Excel ë³´ê³ ì„œ ìƒì„±"""
        try:
            print("ğŸ“‹ Excel ë³´ê³ ì„œ ìƒì„± ì¤‘...")
            
            output_file = f"HVDC_DHL_Warehouse_ë¶„ì„ë³´ê³ ì„œ_{self.timestamp}.xlsx"
            
            with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
                # 1. ì›ë³¸ ë°ì´í„°
                self.df.to_excel(writer, sheet_name='ì›ë³¸_ë°ì´í„°', index=False)
                
                # 2. ê¸°ë³¸ ì •ë³´
                basic_info = pd.DataFrame([self.analysis_results['basic_info']])
                basic_info.to_excel(writer, sheet_name='ê¸°ë³¸_ì •ë³´', index=False)
                
                # 3. ì»¬ëŸ¼ êµ¬ì¡°
                column_df = pd.DataFrame(self.analysis_results['column_structure'])
                column_df.to_excel(writer, sheet_name='ì»¬ëŸ¼_êµ¬ì¡°', index=False)
                
                # 4. ì°½ê³  ë¶„ì„
                if 'warehouse_analysis' in self.analysis_results:
                    warehouse_df = pd.DataFrame(self.analysis_results['warehouse_analysis']).T
                    warehouse_df.to_excel(writer, sheet_name='ì°½ê³ _ë¶„ì„')
                
                # 5. í˜„ì¥ ë¶„ì„
                if 'site_analysis' in self.analysis_results:
                    site_df = pd.DataFrame(self.analysis_results['site_analysis']).T
                    site_df.to_excel(writer, sheet_name='í˜„ì¥_ë¶„ì„')
                
                # 6. ë‚ ì§œ ë¶„ì„
                if 'date_analysis' in self.analysis_results:
                    date_df = pd.DataFrame(self.analysis_results['date_analysis']).T
                    date_df.to_excel(writer, sheet_name='ë‚ ì§œ_ë¶„ì„')
                
                # 7. ìˆ˜ì¹˜í˜• ë¶„ì„
                if 'numeric_analysis' in self.analysis_results:
                    numeric_df = pd.DataFrame(self.analysis_results['numeric_analysis']).T
                    numeric_df.to_excel(writer, sheet_name='ìˆ˜ì¹˜í˜•_ë¶„ì„')
                
                # 8. ìš”ì•½ í†µê³„
                if 'summary_statistics' in self.analysis_results:
                    summary_df = pd.DataFrame(self.analysis_results['summary_statistics'])
                    summary_df.to_excel(writer, sheet_name='ìš”ì•½_í†µê³„')
            
            print(f"âœ… Excel ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"âŒ Excel ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
    
    def create_markdown_report(self):
        """Markdown ë³´ê³ ì„œ ìƒì„±"""
        try:
            print("ğŸ“ Markdown ë³´ê³ ì„œ ìƒì„± ì¤‘...")
            
            output_file = f"HVDC_DHL_Warehouse_ë¶„ì„ë³´ê³ ì„œ_{self.timestamp}.md"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# ğŸ”Œ HVDC DHL Warehouse ì™„ì „ë³µêµ¬ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ\n\n")
                f.write(f"**ë¶„ì„ì¼ì‹œ**: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n")
                f.write(f"**ì›ë³¸íŒŒì¼**: {self.analysis_results['basic_info']['file_name']}\n\n")
                
                # ê¸°ë³¸ ì •ë³´
                f.write("## ğŸ“‹ ê¸°ë³¸ ì •ë³´\n\n")
                basic_info = self.analysis_results['basic_info']
                f.write(f"- **ì´ ë ˆì½”ë“œ ìˆ˜**: {basic_info['total_records']:,}ê±´\n")
                f.write(f"- **ì´ ì»¬ëŸ¼ ìˆ˜**: {basic_info['total_columns']}ê°œ\n")
                f.write(f"- **íŒŒì¼ í¬ê¸°**: {basic_info['file_size_mb']}MB\n\n")
                
                # ë°ì´í„° í’ˆì§ˆ
                if 'summary_statistics' in self.analysis_results:
                    f.write("## ğŸ“Š ë°ì´í„° í’ˆì§ˆ\n\n")
                    quality = self.analysis_results['summary_statistics']['data_quality']
                    f.write(f"- **ë°ì´í„° ì™„ì„±ë„**: {quality['data_completeness']}%\n")
                    f.write(f"- **ì¤‘ë³µ í–‰ ìˆ˜**: {quality['duplicate_rows']}ê±´\n")
                    f.write(f"- **ê³ ìœ  í–‰ ìˆ˜**: {quality['unique_rows']}ê±´\n\n")
                
                # ì»¬ëŸ¼ íƒ€ì… ë¶„í¬
                if 'summary_statistics' in self.analysis_results:
                    f.write("## ğŸ—ï¸ ì»¬ëŸ¼ íƒ€ì… ë¶„í¬\n\n")
                    types = self.analysis_results['summary_statistics']['column_types']
                    f.write(f"- **ìˆ˜ì¹˜í˜•**: {types['numeric']}ê°œ\n")
                    f.write(f"- **ë¬¸ìí˜•**: {types['object']}ê°œ\n")
                    f.write(f"- **ë‚ ì§œí˜•**: {types['datetime']}ê°œ\n")
                    f.write(f"- **ë¶ˆë¦°í˜•**: {types['boolean']}ê°œ\n\n")
                
                # ì°½ê³  ë¶„ì„
                if 'warehouse_analysis' in self.analysis_results:
                    f.write("## ğŸ¢ ì°½ê³  ë°ì´í„° ë¶„ì„\n\n")
                    for col, info in self.analysis_results['warehouse_analysis'].items():
                        f.write(f"### {col}\n")
                        f.write(f"- **íƒ€ì…**: {info['type']}\n")
                        if info['type'] == 'categorical':
                            f.write(f"- **ê³ ìœ ê°’ ìˆ˜**: {info['unique_values']}ê°œ\n")
                            f.write(f"- **ìƒìœ„ê°’**: {list(info['top_values'].keys())[:3]}\n")
                        else:
                            f.write(f"- **í‰ê· **: {info['mean']:.2f}\n")
                            f.write(f"- **ë²”ìœ„**: {info['min']:.2f} ~ {info['max']:.2f}\n")
                        f.write(f"- **ê²°ì¸¡ê°’**: {info['null_count']}ê±´\n\n")
                
                # í˜„ì¥ ë¶„ì„
                if 'site_analysis' in self.analysis_results:
                    f.write("## ğŸ—ï¸ í˜„ì¥ ë°ì´í„° ë¶„ì„\n\n")
                    for col, info in self.analysis_results['site_analysis'].items():
                        f.write(f"### {col}\n")
                        f.write(f"- **íƒ€ì…**: {info['type']}\n")
                        if info['type'] == 'categorical':
                            f.write(f"- **ê³ ìœ ê°’ ìˆ˜**: {info['unique_values']}ê°œ\n")
                            f.write(f"- **ìƒìœ„ê°’**: {list(info['top_values'].keys())[:3]}\n")
                        else:
                            f.write(f"- **í‰ê· **: {info['mean']:.2f}\n")
                            f.write(f"- **ë²”ìœ„**: {info['min']:.2f} ~ {info['max']:.2f}\n")
                        f.write(f"- **ê²°ì¸¡ê°’**: {info['null_count']}ê±´\n\n")
                
                # ë‚ ì§œ ë¶„ì„
                if 'date_analysis' in self.analysis_results:
                    f.write("## ğŸ“… ë‚ ì§œ íŒ¨í„´ ë¶„ì„\n\n")
                    for col, info in self.analysis_results['date_analysis'].items():
                        if 'error' not in info:
                            f.write(f"### {col}\n")
                            f.write(f"- **ìœ íš¨ ë‚ ì§œ**: {info['valid_dates']}ê±´\n")
                            f.write(f"- **ê²°ì¸¡ ë‚ ì§œ**: {info['null_dates']}ê±´\n")
                            f.write(f"- **ë‚ ì§œ ë²”ìœ„**: {info['date_range']['start']} ~ {info['date_range']['end']}\n\n")
                
                # ìˆ˜ì¹˜í˜• ë¶„ì„
                if 'numeric_analysis' in self.analysis_results:
                    f.write("## ğŸ“Š ìˆ˜ì¹˜í˜• ë°ì´í„° ë¶„ì„\n\n")
                    for col, info in self.analysis_results['numeric_analysis'].items():
                        f.write(f"### {col}\n")
                        f.write(f"- **í‰ê· **: {info['mean']:.2f}\n")
                        f.write(f"- **í‘œì¤€í¸ì°¨**: {info['std']:.2f}\n")
                        f.write(f"- **ë²”ìœ„**: {info['min']:.2f} ~ {info['max']:.2f}\n")
                        f.write(f"- **ì¤‘ì•™ê°’**: {info['median']:.2f}\n")
                        f.write(f"- **ê²°ì¸¡ê°’**: {info['null_count']}ê±´\n")
                        f.write(f"- **0ê°’**: {info['zero_count']}ê±´\n")
                        f.write(f"- **ìŒìˆ˜**: {info['negative_count']}ê±´\n\n")
                
                f.write("---\n\n")
                f.write("**ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ**\n")
                f.write(f"ìƒì„±ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}\n")
            
            print(f"âœ… Markdown ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_file}")
            return output_file
            
        except Exception as e:
            print(f"âŒ Markdown ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return None
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ HVDC DHL Warehouse ë°ì´í„° ë¶„ì„ ì‹œì‘")
        print("=" * 60)
        
        if not self.load_data():
            return False
        
        self.analyze_column_structure()
        self.analyze_warehouse_data()
        self.analyze_site_data()
        self.analyze_date_patterns()
        self.analyze_numeric_data()
        self.generate_summary_statistics()
        
        excel_file = self.create_excel_report()
        markdown_file = self.create_markdown_report()
        
        print("=" * 60)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        if excel_file:
            print(f"ğŸ“Š Excel ë³´ê³ ì„œ: {excel_file}")
        if markdown_file:
            print(f"ğŸ“ Markdown ë³´ê³ ì„œ: {markdown_file}")
        
        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    file_path = "HVDC_DHL_Warehouse_ì™„ì „ë³µêµ¬_20250704_125724.xlsx"
    
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return
    
    analyzer = HVDCDHLWarehouseAnalyzer(file_path)
    analyzer.run_analysis()

if __name__ == "__main__":
    main() 