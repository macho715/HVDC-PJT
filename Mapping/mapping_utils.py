#!/usr/bin/env python3
"""
HVDC Warehouse í†µí•© ë§¤í•‘ ìœ í‹¸ë¦¬í‹° v2.8.2 (2025-06-29)
Author: MACHO-GPT v3.4-mini â”‚ Samsung C&T Logistics

ë§¤í•‘ ê·œì¹™ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ëœ Storage Type ë¶„ë¥˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
v2.8.2 ì‹ ê·œ ê¸°ëŠ¥: í˜¸í™˜ì„± fallback, lru_cache, circular import ë°©ì§€
ìµœì‹  ì‹¤ì „ ì˜ˆì œ ë° í™•ì¥ ìë™í™” ê¸°ëŠ¥ í¬í•¨.
"""

import json
import pandas as pd
import numpy as np
import re
from pathlib import Path
import logging
from functools import lru_cache

logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”§ v2.8.2 íŒ¨ì¹˜: ì‹ ê·œ ìœ í‹¸ - ê°’ ì •ê·œí™” & ìœ íš¨ì„± ê²€ì‚¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_DOUBLE_SPACE = "\u3000"          # ì „ê° ê³µë°±

# v2.8.2 íŒ¨ì¹˜: ê·œì¹™ íŒŒì¼ ê²½ë¡œ ìƒìˆ˜ ì •ì˜
DEFAULT_RULE = "mapping_rules_v2.8.json"
FALLBACK_RULE = "mapping_rules_v2.6.json"

def clean_value(val) -> str:
    """
    NaN / None / ì „ê°ê³µë°± / ì•ë’¤ ìŠ¤í˜ì´ìŠ¤ë¥¼ ëª¨ë‘ ì œê±°í•œ ë¬¸ìì—´ì„ ë°˜í™˜
    v2.8.1 íŒ¨ì¹˜: ì „ê°ê³µë°±(\u3000) ì²˜ë¦¬ ì¶”ê°€
    """
    if val is None or (isinstance(val, float) and np.isnan(val)) or pd.isna(val):
        return ""
    return str(val).replace(_DOUBLE_SPACE, "").strip()

def is_valid_data(val) -> bool:
    """
    ìœ íš¨í•œ(ë¹„ì–´ ìˆì§€ ì•Šê³  'nan'Â·'none'ì´ ì•„ë‹Œ) ë°ì´í„° ì—¬ë¶€ í™•ì¸
    v2.8.1 íŒ¨ì¹˜: ì „ê°ê³µë°± ì²˜ë¦¬ ë° NaN ì•ˆì „ ê²€ì‚¬
    """
    cleaned = clean_value(val).lower()
    return cleaned not in ("", "nan", "none")

@lru_cache(maxsize=2)
def load_rules(rule_file: str = None) -> dict:
    """
    ë§¤í•‘ ê·œì¹™ íŒŒì¼ ë¡œë“œ (ìºì‹œ ì ìš©)
    v2.8.2 íŒ¨ì¹˜: í˜¸í™˜ì„± fallback + lru_cache ìµœì í™”
    
    Args:
        rule_file: ê·œì¹™ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ DEFAULT_RULE ì‚¬ìš©)
    
    Returns:
        dict: ë¡œë“œëœ ë§¤í•‘ ê·œì¹™
    """
    if rule_file is None:
        rule_file = DEFAULT_RULE
    
    # 1. ê¸°ë³¸ ê·œì¹™ íŒŒì¼ ì‹œë„
    try:
        with open(rule_file, encoding='utf-8') as f:
            rules = json.load(f)
            logger.info(f"âœ… ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {rule_file}")
            return rules
    except Exception as e:
        logger.warning(f"ê¸°ë³¸ ê·œì¹™ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({rule_file}): {e}")
    
    # 2. Fallback ê·œì¹™ íŒŒì¼ ì‹œë„
    if rule_file != FALLBACK_RULE:
        try:
            with open(FALLBACK_RULE, encoding='utf-8') as f:
                rules = json.load(f)
                logger.info(f"âœ… Fallback ê·œì¹™ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {FALLBACK_RULE}")
                return rules
        except Exception as e:
            logger.warning(f"Fallback ê·œì¹™ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({FALLBACK_RULE}): {e}")
    
    # 3. ìµœì¢… fallback: ê¸°ë³¸ê°’ ë°˜í™˜
    logger.error("ëª¨ë“  ë§¤í•‘ ê·œì¹™ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©")
    return {
        'vendor_mappings': {},
        'container_column_groups': {},
        'warehouse_classification': {},
        'field_map': {},
        'property_mappings': {},
        'logistics_flow_definition': {}
    }

# ì „ì—­ ê·œì¹™ ë¡œë“œ (ìºì‹œ ì ìš©)
RULES = load_rules()

VENDOR_MAP = RULES.get('vendor_mappings', {})
CONTAINER_GROUPS = RULES.get('container_column_groups', {})
WAREHOUSE_CLASS = RULES.get('warehouse_classification', {})
FIELD_MAP = RULES.get('field_map', {})
PROPERTY_MAPPINGS = RULES.get('property_mappings', {})
LOGISTICS_FLOW_DEF = RULES.get('logistics_flow_definition', {})

def normalize_code_num(code):
    """HVDC CODE ìˆ«ì ë¶€ë¶„ 0ì œê±° ì •ê·œí™”(ì˜ˆ: 0014, 014, 14 ëª¨ë‘ â†’ 14)"""
    if not isinstance(code, str): 
        code = str(code)
    m = re.search(r'(\d+)$', code)
    return int(m.group(1)) if m else code

def codes_match(code_a, code_b):
    """ì½”ë“œ ë¹„êµ í•¨ìˆ˜ (ì •ê·œí™” ì ìš©)"""
    return normalize_code_num(code_a) == normalize_code_num(code_b)

def is_valid_hvdc_vendor(code3, valid_list=None):
    """ë²¤ë” í•„í„° í•¨ìˆ˜ (HE, SIMë§Œ ìœ íš¨)"""
    if valid_list is None:
        valid_list = ["HE", "SIM"]
    return str(code3).strip().upper() in valid_list

def is_warehouse_code(code, wh_list=None):
    """ì°½ê³  ì½”ë“œ í•„í„° í•¨ìˆ˜"""
    if wh_list is None:
        wh_list = ["DSV OUTDOOR", "DSV INDOOR", "DSV AL MARKAZ", "DSV MZP"]
    return str(code).strip().upper() in [x.upper() for x in wh_list]

class MappingManager:
    """í†µí•© ë§¤í•‘ ê´€ë¦¬ì v2.8.2"""
    
    def __init__(self, mapping_file: str = None):
        """
        v2.8.2 íŒ¨ì¹˜: mapping_file=Noneì´ë©´ DEFAULT_RULE ì‚¬ìš©
        """
        self.mapping_file = mapping_file or DEFAULT_RULE
        self.mapping_rules = self._load_mapping_rules()
        self.warehouse_classification = self.mapping_rules.get("warehouse_classification", {})
        self.logistics_flow_definition = self.mapping_rules.get("logistics_flow_definition", {})
        
    def _load_mapping_rules(self):
        """
        ë§¤í•‘ ê·œì¹™ íŒŒì¼ ë¡œë“œ (í˜¸í™˜ì„± fallback í¬í•¨)
        v2.8.2 íŒ¨ì¹˜: ìºì‹œëœ load_rules() í•¨ìˆ˜ ì¬ì‚¬ìš©
        """
        return load_rules(self.mapping_file)
    
    def classify_storage_type(self, location: str) -> str:
        """Location â†’ Storage Type (Indoor, Outdoor, Site, Pre_Arrival, OffshoreBase)"""
        if not location or pd.isna(location):
            return "Unknown"

        loc = str(location).strip()

        # â‘  Exact match against rule list
        for stype, locs in self.warehouse_classification.items():
            if loc in locs:
                return stype

        # â‘¡ Substring match (case-insensitive)
        loc_lower = loc.lower()
        for stype, locs in self.warehouse_classification.items():
            for pattern in locs:
                if pattern.lower() in loc_lower:
                    return stype

        # â‘¢ NEW: fallback heuristics
        if loc_lower in {"pre arrival", "inbound_pending", "not_yet_received"}:
            return "Pre_Arrival"
        if "mosb" in loc_lower or "offshore" in loc_lower:
            return "OffshoreBase"

        return "Unknown"
    
    def add_storage_type_to_dataframe(self, df: pd.DataFrame, location_col: str = "Location") -> pd.DataFrame:
        """
        DataFrameì— Storage_Type ì»¬ëŸ¼ ì¶”ê°€
        
        Args:
            df: ëŒ€ìƒ DataFrame
            location_col: Location ì»¬ëŸ¼ëª…
            
        Returns:
            pd.DataFrame: Storage_Type ì»¬ëŸ¼ì´ ì¶”ê°€ëœ DataFrame
        """
        if location_col not in df.columns:
            logger.error(f"Location ì»¬ëŸ¼ ì—†ìŒ: {location_col}")
            df['Storage_Type'] = 'Unknown'
            return df
            
        # âœ… Location ê¸°ì¤€ìœ¼ë¡œ Storage_Type ìƒˆë¡œ ìƒì„± (ê¸°ì¡´ ê°’ ë¬´ì‹œ)
        df['Storage_Type'] = df[location_col].apply(self.classify_storage_type)
        
        # ê²€ì¦ ë¡œê·¸
        storage_counts = df['Storage_Type'].value_counts()
        logger.info(f"ğŸ·ï¸ Storage Type ë¶„ë¥˜ ê²°ê³¼: {dict(storage_counts)}")
        
        return df
    
    def validate_mapping(self, df: pd.DataFrame, location_col: str = "Location") -> dict:
        """
        ë§¤í•‘ ê²€ì¦ ë° í†µê³„
        
        Args:
            df: ê²€ì¦í•  DataFrame
            location_col: Location ì»¬ëŸ¼ëª…
            
        Returns:
            dict: ê²€ì¦ ê²°ê³¼
        """
        if location_col not in df.columns:
            return {"error": f"Location ì»¬ëŸ¼ ì—†ìŒ: {location_col}"}
            
        # Storage Typeë³„ ê³ ìœ  Location ëª©ë¡
        validation_result = {}
        
        for storage_type in self.warehouse_classification.keys():
            locations = df[df['Storage_Type'] == storage_type][location_col].unique()
            validation_result[storage_type] = {
                'count': len(df[df['Storage_Type'] == storage_type]),
                'locations': sorted(locations.tolist())
            }
        
        # Unknown íƒ€ì… ê²€ì¦
        unknown_locations = df[df['Storage_Type'] == 'Unknown'][location_col].unique()
        validation_result['Unknown'] = {
            'count': len(df[df['Storage_Type'] == 'Unknown']),
            'locations': sorted(unknown_locations.tolist())
        }
        
        return validation_result
    
    def get_warehouse_locations(self) -> list:
        """ì°½ê³  Location ëª©ë¡ ë°˜í™˜"""
        warehouse_types = ['Indoor', 'Outdoor', 'dangerous_cargo']
        warehouse_locations = []
        
        for storage_type in warehouse_types:
            if storage_type in self.warehouse_classification:
                warehouse_locations.extend(self.warehouse_classification[storage_type])
                
        return warehouse_locations
    
    def get_site_locations(self) -> list:
        """í˜„ì¥ Location ëª©ë¡ ë°˜í™˜"""
        return self.warehouse_classification.get('Site', [])

# â”€â”€ 3ï¸âƒ£ New Utility: calc_flow_code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Insert into logistics_flow_utils.py (new) or mapping_utils.py.
# Calculates 0-4 code per HVDC_Logistics_Flow_Report.md definitions.

def calc_flow_code(record: dict) -> int:
    """Return logistics flow code (int 0-4)."""
    # Code 0: Pre Arrival flag
    status_flag = record.get("Status", "").lower()
    if status_flag in {"pre arrival", "inbound_pending", "not_yet_received"}:
        return 0

    # Start from direct Portâ†’Site
    steps = 1  # Port and Site implicitly present

    # Each intermediate node +1
    if record.get("Warehouse"):
        steps += 1  # WH
    if record.get("OffshoreBase"):
        steps += 1  # MOSB / Offshore Base
    if record.get("ExtraWH"):
        steps += 1  # Additional WH layer

    # Ensure within 1-4
    return min(max(steps, 1), 4)

def add_logistics_flow_code_to_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    DataFrameì— Logistics_Flow_Code ì»¬ëŸ¼ ì¶”ê°€
    v2.8.2 íŒ¨ì¹˜: Circular import ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—° import íŒ¨í„´
    """
    def calculate_flow_code(row):
        # v2.8.2 íŒ¨ì¹˜: FlowCodeCalculatorV2 ì§€ì—° import (í•„ìš”ì‹œ)
        try:
            # from .calc_flow_code_v2 import FlowCodeCalculatorV2
            # calculator = FlowCodeCalculatorV2()
            # return calculator.calculate_route_from_record(dict(row))
            pass
        except ImportError:
            # Fallback to legacy calc_flow_code
            pass
        
        record = {
            "Status": row.get("Status", ""),
            "Warehouse": row.get("Location", "") if classify_storage_type(row.get("Location", "")) in ["Indoor", "Outdoor"] else None,
            "OffshoreBase": row.get("Location", "") if classify_storage_type(row.get("Location", "")) == "OffshoreBase" else None,
            "ExtraWH": None  # ì¶”í›„ í™•ì¥ ê°€ëŠ¥
        }
        return calc_flow_code(record)
    
    df['Logistics_Flow_Code'] = df.apply(calculate_flow_code, axis=1)
    
    # í†µê³„ ë¡œê·¸
    flow_counts = df['Logistics_Flow_Code'].value_counts().sort_index()
    logger.info(f"ğŸš€ ë¬¼ë¥˜ íë¦„ ì½”ë“œ ë¶„í¬: {dict(flow_counts)}")
    
    return df

# ì „ì—­ ë§¤í•‘ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
mapping_manager = MappingManager()

def classify_storage_type(location: str) -> str:
    """í¸ì˜ í•¨ìˆ˜: Locationì„ Storage Typeìœ¼ë¡œ ë¶„ë¥˜"""
    return mapping_manager.classify_storage_type(location)

def add_storage_type_to_dataframe(df: pd.DataFrame, location_col: str = "Location") -> pd.DataFrame:
    """í¸ì˜ í•¨ìˆ˜: DataFrameì— Storage_Type ì»¬ëŸ¼ ì¶”ê°€"""
    return mapping_manager.add_storage_type_to_dataframe(df, location_col)

def normalize_vendor(vendor_name):
    """
    ë²¤ë”ëª… ì •ê·œí™” (mapping_rulesì˜ vendor_mappings ì ìš©)
    
    Args:
        vendor_name: ì›ë³¸ ë²¤ë”ëª…
        
    Returns:
        str: ì •ê·œí™”ëœ ë²¤ë”ëª…
    """
    if pd.isna(vendor_name) or not vendor_name:
        return 'UNKNOWN'
    
    vendor_mappings = mapping_manager.mapping_rules.get('vendor_mappings', {})
    vendor_str = str(vendor_name).strip().upper()
    
    # ë§¤í•‘ ê·œì¹™ì— ë”°ë¥¸ ì •ê·œí™”
    for original, normalized in vendor_mappings.items():
        if vendor_str == original.upper() or vendor_str in original.upper():
            return normalized
    
    return vendor_str

def standardize_container_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì»¨í…Œì´ë„ˆ ì»¬ëŸ¼ í‘œì¤€í™” (mapping_rulesì˜ container_column_groups ì ìš©)
    
    Args:
        df: ëŒ€ìƒ DataFrame
        
    Returns:
        pd.DataFrame: í‘œì¤€í™”ëœ DataFrame
    """
    container_groups = mapping_manager.mapping_rules.get('container_column_groups', {})
    
    # ê° ì»¨í…Œì´ë„ˆ ê·¸ë£¹ë³„ë¡œ í‘œì¤€í™”
    for standard_name, variations in container_groups.items():
        # í•´ë‹¹ ê·¸ë£¹ì˜ ëª¨ë“  ë³€í˜•ì„ ì°¾ì•„ì„œ í‘œì¤€ëª…ìœ¼ë¡œ í†µí•©
        for variation in variations:
            if variation in df.columns:
                # í‘œì¤€ëª… ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
                if standard_name not in df.columns:
                    df[standard_name] = 0
                
                # ê¸°ì¡´ ê°’ë“¤ì„ í‘œì¤€ëª… ì»¬ëŸ¼ì— ì¶”ê°€
                df[standard_name] = df[standard_name] + df[variation].fillna(0)
                
                # ì›ë³¸ ì»¬ëŸ¼ ì‚­ì œ (ì„ íƒì‚¬í•­)
                # df = df.drop(columns=[variation])
    
    return df

# ìµœì‹  ì‹¤ì „ ì˜ˆì œ í•¨ìˆ˜ë“¤ ì¶”ê°€
def normalize_vendor_enhanced(val):
    """ë²¤ë”ëª… í‘œì¤€í™”: SIMENSEâ†’SIM ë“± (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    if pd.isna(val): 
        return 'Unknown'
    sval = str(val).upper()
    return VENDOR_MAP.get(sval, sval)

def standardize_container_columns_enhanced(df):
    """ì»¨í…Œì´ë„ˆ ì»¬ëŸ¼(20FT/40FT ë“±) ê·¸ë£¹í™” (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    for std_col, variants in CONTAINER_GROUPS.items():
        df[std_col] = 0
        for var in variants:
            for col in df.columns:
                if col.replace(" ", "").replace("-", "").upper() == var.replace(" ", "").replace("-", "").upper():
                    df[std_col] += pd.to_numeric(df[col], errors='coerce').fillna(0)
    return df

def add_storage_type_to_dataframe_enhanced(df, col="Category"):
    """ì°½ê³ /í˜„ì¥/ìœ„í—˜ë¬¼ ìë™ ë¶„ë¥˜ (Storage_Type ë¶€ì—¬) (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    def map_type(loc):
        for k, vlist in WAREHOUSE_CLASS.items():
            if str(loc).strip() in vlist:
                return k
        return "Unknown"
    df["Storage_Type"] = df[col].apply(map_type)
    return df

def normalize_location_column(df, location_col='Location'):
    """Location ì»¬ëŸ¼ ì •ê·œí™” (ìµœì‹  ì‹¤ì „ ì˜ˆì œ)"""
    df[location_col] = df[location_col].astype(str).str.strip()
    return df

def get_numeric_fields_from_mapping():
    """mapping_rulesì—ì„œ ìˆ«ìí˜• í•„ë“œ ëª©ë¡ ë°˜í™˜"""
    numeric_fields = []
    for field, props in PROPERTY_MAPPINGS.items():
        if props.get('datatype') in ['xsd:decimal', 'xsd:integer']:
            numeric_fields.append(field)
    return numeric_fields

def get_field_predicate(field_name):
    """í•„ë“œëª…ì— í•´ë‹¹í•˜ëŠ” predicate ë°˜í™˜"""
    return FIELD_MAP.get(field_name, f"has{field_name.replace(' ', '')}")

def validate_dataframe_against_mapping(df):
    """DataFrameì´ mapping_rulesì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦"""
    missing_fields = []
    extra_fields = []
    
    # mapping_rulesì— ì •ì˜ëœ í•„ë“œê°€ DataFrameì— ì—†ëŠ”ì§€ í™•ì¸
    for field in FIELD_MAP.keys():
        if field not in df.columns:
            missing_fields.append(field)
    
    # DataFrameì— ìˆì§€ë§Œ mapping_rulesì— ì •ì˜ë˜ì§€ ì•Šì€ í•„ë“œ í™•ì¸
    for col in df.columns:
        if col not in FIELD_MAP:
            extra_fields.append(col)
    
    return {
        'missing_fields': missing_fields,
        'extra_fields': extra_fields,
        'is_valid': len(missing_fields) == 0
    }

def normalize_flow_code(code):
    """
    Flow Code ì •ê·œí™” í•¨ìˆ˜ (v2.8.3 ì‹ ê·œ)
    ë¹„í‘œì¤€ Flow Code 6 â†’ 3ìœ¼ë¡œ ìë™ ë§¤í•‘
    
    Args:
        code: ì›ë³¸ Flow Code (int ë˜ëŠ” str)
        
    Returns:
        int: ì •ê·œí™”ëœ Flow Code
    """
    try:
        code_int = int(code)
        if code_int == 6:  # ğŸ†• íŒ¨ì¹˜: ë¹„í‘œì¤€ ì½”ë“œ 6 â†’ í‘œì¤€ 3ìœ¼ë¡œ ë§¤í•‘
            logger.info(f"Flow Code ì •ê·œí™”: {code} â†’ 3")
            return 3
        return code_int
    except (ValueError, TypeError):
        logger.warning(f"Flow Code ë³€í™˜ ì‹¤íŒ¨: {code}, ê¸°ë³¸ê°’ 0 ì‚¬ìš©")
        return 0

def apply_validation_rules(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë§¤í•‘ ê·œì¹™ì˜ validation_rulesë¥¼ DataFrameì— ì ìš© (v2.8.3 ì‹ ê·œ)
    
    Args:
        df: ëŒ€ìƒ DataFrame
        
    Returns:
        pd.DataFrame: validation_rules ì ìš©ëœ DataFrame
    """
    df_processed = df.copy()
    validation_rules = RULES.get('automation_features', {}).get('validation_rules', {})
    
    # ğŸ†• íŒ¨ì¹˜: NULL Pkg â†’ 1 ë³´ì •
    if validation_rules.get('null_pkg_to_one', False) and 'Pkg' in df_processed.columns:
        null_count = df_processed['Pkg'].isna().sum()
        if null_count > 0:
            df_processed['Pkg'] = df_processed['Pkg'].fillna(1)
            logger.info(f"NULL Pkg ë³´ì •: {null_count}ê±´ â†’ 1 PKGë¡œ ì„¤ì •")
    
    # ğŸ†• íŒ¨ì¹˜: ì¤‘ë³µ ì œê±°
    dedup_keys = validation_rules.get('dedup_keys', [])
    if dedup_keys and all(key in df_processed.columns for key in dedup_keys):
        original_count = len(df_processed)
        df_processed = df_processed.drop_duplicates(subset=dedup_keys, keep='last')
        removed_count = original_count - len(df_processed)
        if removed_count > 0:
            logger.info(f"ì¤‘ë³µ ì œê±°: {removed_count}ê±´ ì œê±° (ê¸°ì¤€: {dedup_keys})")
    
    # ğŸ†• íŒ¨ì¹˜: Flow Code ì •ê·œí™”
    if 'Flow_Code' in df_processed.columns:
        df_processed['Flow_Code'] = df_processed['Flow_Code'].apply(normalize_flow_code)
    elif 'Logistics Flow Code' in df_processed.columns:
        df_processed['Logistics Flow Code'] = df_processed['Logistics Flow Code'].apply(normalize_flow_code)
    
    # ğŸ†• íŒ¨ì¹˜: OUT íŠ¸ëœì­ì…˜ ë¶€í˜¸ ì²˜ë¦¬ (ì„ íƒì )
    if validation_rules.get('out_negative_pkg', False):
        if 'Transaction_Type' in df_processed.columns and 'Pkg' in df_processed.columns:
            out_mask = df_processed['Transaction_Type'].str.contains('OUT', na=False)
            out_count = out_mask.sum()
            if out_count > 0:
                df_processed.loc[out_mask, 'Pkg'] = df_processed.loc[out_mask, 'Pkg'] * -1
                logger.info(f"OUT ë¶€í˜¸ ì²˜ë¦¬: {out_count}ê±´ ìŒìˆ˜ ë³€í™˜")
        elif 'TxType' in df_processed.columns and 'Pkg' in df_processed.columns:
            out_mask = df_processed['TxType'].str.contains('OUT', na=False)
            out_count = out_mask.sum()
            if out_count > 0:
                df_processed.loc[out_mask, 'Pkg'] = df_processed.loc[out_mask, 'Pkg'] * -1
                logger.info(f"OUT ë¶€í˜¸ ì²˜ë¦¬: {out_count}ê±´ ìŒìˆ˜ ë³€í™˜")
    
    return df_processed 