import pandas as pd
import warnings
import numpy as np
warnings.filterwarnings('ignore')

print('ğŸ” í™”ë¬¼ì´ë ¥ê´€ë¦¬_ì™„ì „í†µí•©_ì°½ê³ í˜„ì¥í¬í•¨.xlsx ìƒì„¸ ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„')
print('=' * 80)

file_path = r'C:\cursor-mcp\HVDC_PJT\MACHO_í†µí•©ê´€ë¦¬_20250702_205301\í™”ë¬¼ì´ë ¥ê´€ë¦¬_ì™„ì „í†µí•©_ì°½ê³ í˜„ì¥í¬í•¨.xlsx'

# ë©”ì¸ ì‹œíŠ¸ ìƒì„¸ ë¶„ì„
print('\nğŸ“Š ë©”ì¸ ì‹œíŠ¸: í™”ë¬¼ì´ë ¥ê´€ë¦¬_í†µí•© - ìƒì„¸ ì»¬ëŸ¼ êµ¬ì¡°')
print('=' * 80)

df_main = pd.read_excel(file_path, sheet_name='í™”ë¬¼ì´ë ¥ê´€ë¦¬_í†µí•©')

print(f'ê¸°ë³¸ ì •ë³´: {len(df_main):,}ê±´ Ã— {len(df_main.columns)}ê°œ ì»¬ëŸ¼')

# ì»¬ëŸ¼ ë¶„ë¥˜
column_categories = {
    'ê¸°ë³¸ì •ë³´': ['no.', 'Shipment Invoice No.', 'Case No.', 'EQ No', 'VENDOR'],
    'HVDCì½”ë“œ': ['HVDC CODE', 'HVDC CODE 1', 'HVDC CODE 2', 'HVDC CODE 3', 'HVDC CODE 4', 'HVDC CODE 5'],
    'í™”ë¬¼ì •ë³´': ['Site', 'Pkg', 'Storage', 'Description', 'L(CM)', 'W(CM)', 'H(CM)', 'CBM', 'N.W(kgs)', 'G.W(kgs)', 'Stack', 'HS Code'],
    'ê°€ê²©ì •ë³´': ['Currency', 'Price'],
    'ìš´ì†¡ì •ë³´': ['Vessel', 'COE', 'POL', 'POD', 'ETD/ATD', 'ETA/ATA'],
    'ì°½ê³ ìœ„ì¹˜': ['DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'DSV MZP', 'MOSB'],
    'í˜„ì¥ìœ„ì¹˜': ['MIR', 'SHU', 'DAS', 'AGI'],
    'ìƒíƒœì •ë³´': ['Status_WAREHOUSE', 'Status_SITE', 'Status_Current', 'Status_Location', 'Status_Storage', 'Status', 'Location'],
    'ì²˜ë¦¬ì •ë³´': ['wh handling', 'site  handling', 'total handling', 'minus', 'final handling'],
    'SQM_Stack': ['SQM', 'Stack_Status'],
    'Flow_Codeì²´ê³„': ['FLOW_CODE', 'WH_HANDLING', 'ROUTE_STRING', 'FLOW_CODE_ì„¤ëª…', 'WH_HANDLING_ì„¤ëª…'],
    'ì‹œê°„ë¶„ì„': ['Status_Location_Date', 'ë„ì°©ì¼ì‹œ', 'ë„ì°©ë…„ì›”', 'ë„ì°©ë…„ë„', 'ë„ì°©ì›”'],
    'ì¶”ê°€ì •ë³´': ['No.', 'Local', 'SERIAL NO.', 'PO. No', 'Bill of Lading', 'AAA  Storage', 'Hauler Indoor', 'Shifting']
}

# ì¹´í…Œê³ ë¦¬ë³„ ì»¬ëŸ¼ ë¶„ì„
for category, expected_cols in column_categories.items():
    print(f'\nğŸ”¹ {category} ì¹´í…Œê³ ë¦¬')
    print('-' * 60)
    
    found_cols = []
    for col in expected_cols:
        if col in df_main.columns:
            found_cols.append(col)
    
    # ì¶”ê°€ë¡œ ë°œê²¬ëœ ì»¬ëŸ¼ë“¤
    additional_cols = []
    for col in df_main.columns:
        if col not in [c for cats in column_categories.values() for c in cats]:
            # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
            if category == 'ì°½ê³ ìœ„ì¹˜' and any(keyword in col for keyword in ['DSV', 'MOSB']):
                additional_cols.append(col)
            elif category == 'í˜„ì¥ìœ„ì¹˜' and any(keyword in col for keyword in ['MIR', 'SHU', 'DAS', 'AGI']):
                additional_cols.append(col)
            elif category == 'ì‹œê°„ë¶„ì„' and any(keyword in col for keyword in ['Date', 'ì¼ì‹œ', 'ë…„ì›”', 'ë…„ë„', 'ì›”']):
                additional_cols.append(col)
            elif category == 'ìƒíƒœì •ë³´' and any(keyword in col for keyword in ['Status', 'Location']):
                additional_cols.append(col)
    
    all_cols = found_cols + additional_cols
    
    if all_cols:
        print(f'ì»¬ëŸ¼ ìˆ˜: {len(all_cols)}ê°œ')
        for col in all_cols:
            completion = df_main[col].notna().sum() / len(df_main) * 100
            unique_count = df_main[col].nunique()
            dtype = str(df_main[col].dtype)
            
            # ìƒ˜í”Œ ë°ì´í„°
            sample_data = df_main[col].dropna().head(2).tolist()
            sample_str = ', '.join([str(x)[:15] for x in sample_data]) if sample_data else 'N/A'
            
            status = 'âœ…' if completion >= 95 else 'ğŸ”¶' if completion >= 70 else 'âŒ'
            
            print(f'{status} {col:<25}: {completion:>6.1f}% | {dtype:<12} | ê³ ìœ ê°’:{unique_count:>4} | ìƒ˜í”Œ: {sample_str}')
    else:
        print('í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì—†ìŒ')

# ë°ì´í„° í’ˆì§ˆ ìš”ì•½
print(f'\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ìš”ì•½')
print('=' * 50)

completion_levels = []
for col in df_main.columns:
    completion = df_main[col].notna().sum() / len(df_main) * 100
    completion_levels.append(completion)

high_quality = sum(1 for x in completion_levels if x >= 95)
medium_quality = sum(1 for x in completion_levels if 70 <= x < 95)
low_quality = sum(1 for x in completion_levels if x < 70)

print(f'â€¢ ê³ í’ˆì§ˆ ì»¬ëŸ¼ (95%+): {high_quality}ê°œ')
print(f'â€¢ ì¤‘í’ˆì§ˆ ì»¬ëŸ¼ (70-95%): {medium_quality}ê°œ')
print(f'â€¢ ì €í’ˆì§ˆ ì»¬ëŸ¼ (70% ë¯¸ë§Œ): {low_quality}ê°œ')

# Flow Code ìƒì„¸ ë¶„ì„
print(f'\nğŸ”„ Flow Code ìƒì„¸ ë¶„ì„')
print('-' * 50)

if 'FLOW_CODE' in df_main.columns:
    flow_analysis = df_main['FLOW_CODE'].value_counts().sort_index()
    flow_descriptions = {
        0: 'Pre Arrival (ì‚¬ì „ ë„ì°©)',
        1: 'Direct Route (Port â†’ Site)',
        2: 'Warehouse Route (Port â†’ WH â†’ Site)',
        3: 'Complex Route (Port â†’ WH â†’ MOSB â†’ Site)',
        4: 'Multi-WH Route (Port â†’ WH â†’ WH â†’ MOSB â†’ Site)'
    }
    
    total_items = len(df_main)
    
    for code, count in flow_analysis.items():
        percentage = count / total_items * 100
        desc = flow_descriptions.get(code, 'Unknown')
        print(f'Code {code}: {count:>5,}ê±´ ({percentage:>5.1f}%) - {desc}')
    
    # WH_HANDLING ë¶„ì„
    if 'WH_HANDLING' in df_main.columns:
        wh_analysis = df_main['WH_HANDLING'].value_counts().sort_index()
        print(f'\nWH_HANDLING ë¶„ì„:')
        wh_descriptions = {
            0: 'No WH (ì°½ê³  ë¯¸ê²½ìœ )',
            1: 'Single WH (1ê°œ ì°½ê³ )',
            2: 'Double WH (2ê°œ ì°½ê³ )',
            3: 'Triple WH (3ê°œ ì°½ê³ )'
        }
        
        for wh, count in wh_analysis.items():
            percentage = count / total_items * 100
            desc = wh_descriptions.get(wh, 'Multiple WH')
            print(f'WH {wh}: {count:>5,}ê±´ ({percentage:>5.1f}%) - {desc}')

# ë‹¤ë¥¸ ì‹œíŠ¸ë“¤ ìš”ì•½ ë¶„ì„
print(f'\nğŸ“‹ ë‹¤ë¥¸ ì‹œíŠ¸ë“¤ ìš”ì•½')
print('=' * 50)

other_sheets = ['FLOWCODE0-4_ë¶„ì„ìš”ì•½', 'ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', 'í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ']

for sheet_name in other_sheets:
    df = pd.read_excel(file_path, sheet_name=sheet_name)
    print(f'\nğŸ”¸ {sheet_name}')
    print(f'   ê·œëª¨: {len(df):,}ê±´ Ã— {len(df.columns)}ê°œ ì»¬ëŸ¼')
    
    if sheet_name == 'FLOWCODE0-4_ë¶„ì„ìš”ì•½':
        print('   ë‚´ìš©: Flow Codeë³„ ê²½ë¡œ ë° ìƒíƒœ ìš”ì•½')
        if 'Flow_Code' in df.columns and 'Description' in df.columns:
            print('   Flow Code ì •ì˜:')
            for idx, row in df.iterrows():
                if pd.notna(row.get('Flow_Code')) and pd.notna(row.get('Description')):
                    print(f'     - {row["Flow_Code"]}: {row["Description"]}')
    
    elif 'ì›”ë³„' in sheet_name:
        print('   ë‚´ìš©: ì›”ë³„ ì…ì¶œê³  ë° ì¬ê³  í˜„í™©')
        # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì°¾ê¸°
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(f'   ìˆ˜ì¹˜ ë°ì´í„° ì»¬ëŸ¼: {len(numeric_cols)}ê°œ')
            for col in numeric_cols[:3]:
                if df[col].notna().sum() > 0:
                    total = df[col].sum()
                    avg = df[col].mean()
                    print(f'     - {col}: ì´ {total:,.0f}, í‰ê·  {avg:.1f}')

print(f'\nğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸')
print('=' * 50)

print('1. ë©”ì¸ ë°ì´í„°ì…‹: 7,573ê±´ì˜ í™”ë¬¼ íŠ¸ëœì­ì…˜')
print('2. ì™„ì „í•œ Flow Code ì²´ê³„: 0-4ê¹Œì§€ 5ë‹¨ê³„ ê²½ë¡œ')
print('3. ìœ„ì¹˜ ì¶”ì : ì°½ê³  5ê°œì†Œ + í˜„ì¥ 4ê°œì†Œ')
print('4. ë²¤ë” êµ¬ì„±: HITACHI 70.6%, SIMENSE 29.4%')
print('5. ê²½ë¡œ ë¶„í¬: ì°½ê³  ê²½ìœ  46.5%, ì§ì†¡ 43.2%')
print('6. ë°ì´í„° í’ˆì§ˆ: 78ê°œ ì»¬ëŸ¼ ì¤‘ 40ê°œê°€ ê³ í’ˆì§ˆ')

print(f'\nğŸ”§ **ì¶”ì²œ ëª…ë ¹ì–´:**')
print('/analyze_integration [í™”ë¬¼ì´ë ¥ê´€ë¦¬ ì™„ì „í†µí•© íŒŒì¼ ë¶„ì„ ì™„ë£Œ]')
print('/extract_kpi [í•µì‹¬ KPI ì§€í‘œ ì¶”ì¶œ ë° ëŒ€ì‹œë³´ë“œ ìƒì„±]')
print('/validate_data [ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ë¬´ê²°ì„± í™•ì¸]') 