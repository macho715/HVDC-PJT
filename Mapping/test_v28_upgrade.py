#!/usr/bin/env python3
"""
HVDC v2.8 ì—…ê·¸ë ˆì´ë“œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Author: MACHO-GPT v3.4-mini â”‚ Samsung C&T Logistics
Purpose: Pre_Arrival, OffshoreBase, logistics_flow_code ê¸°ëŠ¥ ê²€ì¦
"""

import sys
import pandas as pd
import json
from pathlib import Path
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from mapping_utils import (
        MappingManager, 
        classify_storage_type, 
        calc_flow_code,
        add_logistics_flow_code_to_dataframe
    )
except ImportError as e:
    logger.error(f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

def test_v28_json_rules():
    """v2.8 JSON ê·œì¹™ íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª v2.8 JSON ê·œì¹™ íŒŒì¼ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # v2.8 íŒŒì¼ ì¡´ì¬ í™•ì¸
    v28_file = Path("mapping_rules_v2.8.json")
    if not v28_file.exists():
        logger.error("âŒ mapping_rules_v2.8.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        return False
    
    try:
        with open(v28_file, 'r', encoding='utf-8') as f:
            rules = json.load(f)
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = [
            'warehouse_classification', 
            'logistics_flow_definition',
            'v28_features'
        ]
        
        for field in required_fields:
            if field not in rules:
                logger.error(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                return False
        
        # Pre_Arrival, OffshoreBase í™•ì¸
        warehouse_class = rules['warehouse_classification']
        if 'Pre_Arrival' not in warehouse_class:
            logger.error("âŒ Pre_Arrival ë¶„ë¥˜ ëˆ„ë½")
            return False
        
        if 'OffshoreBase' not in warehouse_class:
            logger.error("âŒ OffshoreBase ë¶„ë¥˜ ëˆ„ë½")
            return False
        
        # logistics_flow_definition í™•ì¸
        flow_def = rules['logistics_flow_definition']
        expected_codes = ['0', '1', '2', '3', '4']
        for code in expected_codes:
            if code not in flow_def:
                logger.error(f"âŒ ë¬¼ë¥˜ íë¦„ ì½”ë“œ ëˆ„ë½: {code}")
                return False
        
        logger.info("âœ… v2.8 JSON ê·œì¹™ íŒŒì¼ ê²€ì¦ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ JSON íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

def test_storage_type_classification():
    """ì°½ê³  ë¶„ë¥˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª ì°½ê³  ë¶„ë¥˜ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        # (ì…ë ¥, ì˜ˆìƒ ì¶œë ¥)
        ("PRE ARRIVAL", "Pre_Arrival"),
        ("INBOUND_PENDING", "Pre_Arrival"),
        ("NOT_YET_RECEIVED", "Pre_Arrival"),
        ("MOSB", "OffshoreBase"),
        ("MARINE BASE", "OffshoreBase"),
        ("OFFSHORE BASE", "OffshoreBase"),
        ("DSV Indoor", "Indoor"),
        ("DSV Outdoor", "Outdoor"),
        ("AGI", "Site"),
        ("Unknown Location", "Unknown")
    ]
    
    manager = MappingManager()
    success_count = 0
    
    for location, expected in test_cases:
        result = manager.classify_storage_type(location)
        if result == expected:
            logger.info(f"âœ… {location} â†’ {result}")
            success_count += 1
        else:
            logger.error(f"âŒ {location} â†’ {result} (ì˜ˆìƒ: {expected})")
    
    success_rate = success_count / len(test_cases) * 100
    logger.info(f"ğŸ¯ ì°½ê³  ë¶„ë¥˜ ì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{len(test_cases)})")
    
    return success_rate >= 90

def test_logistics_flow_code():
    """ë¬¼ë¥˜ íë¦„ ì½”ë“œ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª ë¬¼ë¥˜ íë¦„ ì½”ë“œ ê³„ì‚° í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        # (ë ˆì½”ë“œ, ì˜ˆìƒ ì½”ë“œ)
        ({"Status": "PRE ARRIVAL"}, 0),
        ({"Status": "INBOUND_PENDING"}, 0),
        ({"Status": "Active"}, 1),  # Portâ†’Site
        ({"Status": "Active", "Warehouse": "DSV Indoor"}, 2),  # Portâ†’WHâ†’Site
        ({"Status": "Active", "Warehouse": "DSV Indoor", "OffshoreBase": "MOSB"}, 3),  # Portâ†’WHâ†’MOSBâ†’Site
        ({"Status": "Active", "Warehouse": "DSV Indoor", "OffshoreBase": "MOSB", "ExtraWH": "Extra"}, 4),  # 4-step
    ]
    
    success_count = 0
    
    for record, expected in test_cases:
        result = calc_flow_code(record)
        if result == expected:
            logger.info(f"âœ… {record} â†’ Code {result}")
            success_count += 1
        else:
            logger.error(f"âŒ {record} â†’ Code {result} (ì˜ˆìƒ: {expected})")
    
    success_rate = success_count / len(test_cases) * 100
    logger.info(f"ğŸ¯ ë¬¼ë¥˜ íë¦„ ì½”ë“œ ì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{len(test_cases)})")
    
    return success_rate >= 90

def test_dataframe_integration():
    """DataFrame í†µí•© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª DataFrame í†µí•© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame({
        'Case_No': ['HE001', 'HE002', 'HE003', 'HE004', 'HE005'],
        'Location': ['PRE ARRIVAL', 'DSV Indoor', 'MOSB', 'AGI', 'DSV Outdoor'],
        'Status': ['PRE ARRIVAL', 'Active', 'Active', 'Active', 'Active'],
        'Qty': [10, 20, 15, 25, 30],
        'Amount': [1000, 2000, 1500, 2500, 3000]
    })
    
    try:
        # Storage Type ì¶”ê°€
        manager = MappingManager()
        df_with_storage = manager.add_storage_type_to_dataframe(test_data)
        
        logger.info("âœ… Storage Type ì¶”ê°€ ì™„ë£Œ")
        logger.info(f"   Storage Type ë¶„í¬: {df_with_storage['Storage_Type'].value_counts().to_dict()}")
        
        # Logistics Flow Code ì¶”ê°€
        df_complete = add_logistics_flow_code_to_dataframe(df_with_storage)
        
        logger.info("âœ… Logistics Flow Code ì¶”ê°€ ì™„ë£Œ") 
        logger.info(f"   Flow Code ë¶„í¬: {df_complete['Logistics_Flow_Code'].value_counts().to_dict()}")
        
        # ê¸°ë³¸ ê²€ì¦: ì»¬ëŸ¼ì´ ì œëŒ€ë¡œ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
        required_columns = ['Storage_Type', 'Logistics_Flow_Code']
        for col in required_columns:
            if col not in df_complete.columns:
                logger.error(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {col}")
                return False
        
        # ë°ì´í„° íƒ€ì… ê²€ì¦
        if not pd.api.types.is_integer_dtype(df_complete['Logistics_Flow_Code']):
            logger.error("âŒ Logistics_Flow_Codeê°€ ì •ìˆ˜ íƒ€ì…ì´ ì•„ë‹™ë‹ˆë‹¤")
            return False
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        flow_codes = df_complete['Logistics_Flow_Code'].values
        if not all(0 <= code <= 4 for code in flow_codes):
            logger.error("âŒ Flow Code ë²”ìœ„ ì˜¤ë¥˜ (0-4 ë²”ìœ„ ë²—ì–´ë‚¨)")
            return False
        
        # Pre_Arrival ì¼€ì´ìŠ¤ ê²€ì¦
        pre_arrival_rows = df_complete[df_complete['Storage_Type'] == 'Pre_Arrival']
        if not all(pre_arrival_rows['Logistics_Flow_Code'] == 0):
            logger.error("âŒ Pre_Arrival ì•„ì´í…œì˜ Flow Codeê°€ 0ì´ ì•„ë‹™ë‹ˆë‹¤")
            return False
        
        logger.info("âœ… DataFrame í†µí•© ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ìµœì¢… ê²°ê³¼:")
        logger.info(f"   ì´ ë ˆì½”ë“œ: {len(df_complete)}")
        logger.info(f"   Storage Type ë¶„í¬: {df_complete['Storage_Type'].value_counts().to_dict()}")
        logger.info(f"   Flow Code ë¶„í¬: {df_complete['Logistics_Flow_Code'].value_counts().to_dict()}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ DataFrame í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("ğŸš€ HVDC v2.8 ì—…ê·¸ë ˆì´ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    tests = [
        ("JSON ê·œì¹™ íŒŒì¼", test_v28_json_rules),
        ("ì°½ê³  ë¶„ë¥˜ ê¸°ëŠ¥", test_storage_type_classification),
        ("ë¬¼ë¥˜ íë¦„ ì½”ë“œ", test_logistics_flow_code),
        ("DataFrame í†µí•©", test_dataframe_integration)
    ]
    
    results = []
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
        try:
            result = test_func()
            results.append((test_name, result))
            status = "âœ… PASS" if result else "âŒ FAIL"
            logger.info(f"ğŸ“Š {test_name}: {status}")
        except Exception as e:
            logger.error(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            results.append((test_name, False))
    
    # ìµœì¢… ê²°ê³¼
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“Š ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    success_rate = passed / total * 100
    
    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        logger.info(f"   {test_name}: {status}")
    
    logger.info(f"\nğŸ¯ ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}% ({passed}/{total})")
    
    if success_rate >= 90:
        logger.info("ğŸ‰ v2.8 ì—…ê·¸ë ˆì´ë“œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        logger.info("ğŸ”§ **ì¶”ì²œ ëª…ë ¹ì–´:**")
        logger.info("/logi_master [v2.8 Pre_Arrival + OffshoreBase ë§¤í•‘ ì‹œìŠ¤í…œ í™œì„±í™”]")
        logger.info("/switch_mode PRIME [ë¬¼ë¥˜ íë¦„ ì½”ë“œ ìë™ ê³„ì‚° ëª¨ë“œ ì „í™˜]")
        logger.info("/visualize_data [v2.8 í™•ì¥ ê¸°ëŠ¥ ëŒ€ì‹œë³´ë“œ ìƒì„±]")
        return True
    else:
        logger.error("âŒ v2.8 ì—…ê·¸ë ˆì´ë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1) 