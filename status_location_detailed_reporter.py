#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Status_Location_Date Detailed Reporter
TDD Refactor Phase: ìƒì„¸í•œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±

MACHO-GPT v3.4-mini í†µí•© ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import json
from status_location_analyzer import (
    load_raw_data_with_av1, 
    validate_status_location_dates,
    analyze_final_arrival_dates,
    track_location_timeline,
    integrate_with_flow_code
)

class StatusLocationReporter:
    """
    Status_Location_Date ë¶„ì„ ê²°ê³¼ ìƒì„¸ ë¦¬í¬í„°
    TDD Refactor ë‹¨ê³„: êµ¬ì¡° ê°œì„  ë° ê¸°ëŠ¥ í™•ì¥
    """
    
    def __init__(self, simense_file, hitachi_file):
        """ì´ˆê¸°í™”"""
        self.simense_file = Path(simense_file)
        self.hitachi_file = Path(hitachi_file)
        self.output_dir = Path("output")
        self.output_dir.mkdir(exist_ok=True)
        
        # ë°ì´í„° ë¡œë“œ
        self.simense_data = load_raw_data_with_av1(self.simense_file)
        self.hitachi_data = load_raw_data_with_av1(self.hitachi_file)
        
        # ë¶„ì„ ê²°ê³¼ ìºì‹œ
        self._analysis_cache = {}
        
    def generate_complete_report(self):
        """ì™„ì „í•œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“Š Status_Location_Date ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
        print("=" * 60)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰
        print("ğŸ” 1ë‹¨ê³„: ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰")
        basic_analysis = self._run_basic_analysis()
        
        # 2. ìƒì„¸ Excel ë¦¬í¬íŠ¸ ìƒì„±
        print("ğŸ“ˆ 2ë‹¨ê³„: ìƒì„¸ Excel ë¦¬í¬íŠ¸ ìƒì„±")
        excel_file = self._create_detailed_excel_report(timestamp)
        
        # 3. íŠ¸ë Œë“œ ë¶„ì„
        print("ğŸ“Š 3ë‹¨ê³„: ë„ì°© íŠ¸ë Œë“œ ë¶„ì„")
        trend_analysis = self._analyze_arrival_trends()
        
        # 4. ìœ„ì¹˜ë³„ ì„±ê³¼ ë¶„ì„
        print("ğŸ—ï¸ 4ë‹¨ê³„: ìœ„ì¹˜ë³„ ì„±ê³¼ ë¶„ì„")
        location_performance = self._analyze_location_performance()
        
        # 5. í†µí•© ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±
        print("ğŸ“‹ 5ë‹¨ê³„: í†µí•© ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±")
        dashboard_data = self._generate_dashboard_data()
        
        # 6. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        report_data = {
            'basic_analysis': basic_analysis,
            'trend_analysis': trend_analysis,
            'location_performance': location_performance,
            'dashboard_data': dashboard_data,
            'excel_file': str(excel_file),
            'timestamp': timestamp
        }
        
        # JSON ì €ì¥
        report_file = self.output_dir / f"status_location_detailed_report_{timestamp}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, default=str, ensure_ascii=False)
        
        print(f"âœ… ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“Š Excel ë¦¬í¬íŠ¸: {excel_file}")
        print(f"ğŸ“‹ JSON ë¦¬í¬íŠ¸: {report_file}")
        
        return report_data
    
    def _run_basic_analysis(self):
        """ê¸°ë³¸ ë¶„ì„ ì‹¤í–‰"""
        if 'basic' not in self._analysis_cache:
            validation = validate_status_location_dates(self.simense_file, self.hitachi_file)
            analysis = analyze_final_arrival_dates(self.simense_file, self.hitachi_file)
            timeline = track_location_timeline(self.simense_file, self.hitachi_file)
            integration = integrate_with_flow_code(self.simense_file, self.hitachi_file)
            
            self._analysis_cache['basic'] = {
                'validation': validation,
                'analysis': analysis,
                'timeline': timeline,
                'integration': integration
            }
        
        return self._analysis_cache['basic']
    
    def _create_detailed_excel_report(self, timestamp):
        """ìƒì„¸ Excel ë¦¬í¬íŠ¸ ìƒì„±"""
        excel_file = self.output_dir / f"Status_Location_ìƒì„¸ë¶„ì„_{timestamp}.xlsx"
        
        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
            
            # 1. ê°œìš” ì‹œíŠ¸
            self._create_overview_sheet(writer)
            
            # 2. SIMENSE ìƒì„¸ ì‹œíŠ¸
            self._create_vendor_detail_sheet(writer, self.simense_data, 'SIMENSEìƒì„¸')
            
            # 3. HITACHI ìƒì„¸ ì‹œíŠ¸
            self._create_vendor_detail_sheet(writer, self.hitachi_data, 'HITACHIìƒì„¸')
            
            # 4. ìœ„ì¹˜ë³„ ìš”ì•½ ì‹œíŠ¸
            self._create_location_summary_sheet(writer)
            
            # 5. ì›”ë³„ ë„ì°© í˜„í™© ì‹œíŠ¸
            self._create_monthly_arrival_sheet(writer)
            
            # 6. í˜„ì¥ ì„±ê³¼ ë¶„ì„ ì‹œíŠ¸
            self._create_site_performance_sheet(writer)
            
        return excel_file
    
    def _create_overview_sheet(self, writer):
        """ê°œìš” ì‹œíŠ¸ ìƒì„±"""
        overview_data = []
        
        # ê¸°ë³¸ í†µê³„
        overview_data.append(['í•­ëª©', 'ê°’', 'ì„¤ëª…'])
        overview_data.append(['ì´ ìì¬ ìˆ˜', f"{len(self.simense_data) + len(self.hitachi_data):,}ê±´", 'SIMENSE + HITACHI'])
        overview_data.append(['SIMENSE ìì¬', f"{len(self.simense_data):,}ê±´", ''])
        overview_data.append(['HITACHI ìì¬', f"{len(self.hitachi_data):,}ê±´", ''])
        overview_data.append(['', '', ''])
        
        # ë‚ ì§œ ë²”ìœ„ ë¶„ì„
        all_dates = []
        for df in [self.simense_data, self.hitachi_data]:
            if 'Status_Location_Date' in df.columns:
                dates = pd.to_datetime(df['Status_Location_Date'], errors='coerce').dropna()
                all_dates.extend(dates)
        
        if all_dates:
            overview_data.append(['ìµœì´ˆ ë„ì°© ë‚ ì§œ', min(all_dates).strftime('%Y-%m-%d'), ''])
            overview_data.append(['ìµœì¢… ë„ì°© ë‚ ì§œ', max(all_dates).strftime('%Y-%m-%d'), ''])
            overview_data.append(['ì´ ê¸°ê°„', f"{(max(all_dates) - min(all_dates)).days}ì¼", ''])
        
        # ìœ„ì¹˜ ë¶„ì„
        all_locations = []
        for df in [self.simense_data, self.hitachi_data]:
            if 'Status_Location' in df.columns:
                locations = df['Status_Location'].dropna().unique()
                all_locations.extend(locations)
        
        unique_locations = list(set(all_locations))
        overview_data.append(['ì´ ìœ„ì¹˜ ìˆ˜', f"{len(unique_locations)}ê°œ", ''])
        overview_data.append(['', '', ''])
        
        # ì£¼ìš” ìœ„ì¹˜ TOP 5
        location_counts = {}
        for df in [self.simense_data, self.hitachi_data]:
            if 'Status_Location' in df.columns:
                counts = df['Status_Location'].value_counts()
                for loc, count in counts.items():
                    location_counts[loc] = location_counts.get(loc, 0) + count
        
        top_locations = sorted(location_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        overview_data.append(['TOP 5 ìœ„ì¹˜', '', ''])
        for i, (loc, count) in enumerate(top_locations, 1):
            overview_data.append([f"{i}ìœ„", f"{loc} ({count:,}ê±´)", f"{count/sum(location_counts.values())*100:.1f}%"])
        
        df_overview = pd.DataFrame(overview_data)
        df_overview.to_excel(writer, sheet_name='ê°œìš”', index=False, header=False)
    
    def _create_vendor_detail_sheet(self, writer, df, sheet_name):
        """ë²¤ë”ë³„ ìƒì„¸ ì‹œíŠ¸ ìƒì„±"""
        # ì›ë³¸ ë°ì´í„° í¬í•¨í•˜ë˜ ì¤‘ìš” ì»¬ëŸ¼ë§Œ ì„ íƒ
        important_cols = [
            'HVDC CODE', 'HVDC CODE 1', 'HVDC CODE 2', 'HVDC CODE 3',
            'Site', 'Description', 'Status_Location', 'Status_Location_Date',
            'Status_Current', 'CBM', 'G.W(kgs)', 'SQM'
        ]
        
        available_cols = [col for col in important_cols if col in df.columns]
        detail_df = df[available_cols].copy()
        
        # ë‚ ì§œ í˜•ì‹ ì •ë¦¬
        if 'Status_Location_Date' in detail_df.columns:
            detail_df['Status_Location_Date'] = pd.to_datetime(detail_df['Status_Location_Date'], errors='coerce')
            detail_df = detail_df.sort_values('Status_Location_Date', na_position='last')
        
        detail_df.to_excel(writer, sheet_name=sheet_name, index=False)
    
    def _create_location_summary_sheet(self, writer):
        """ìœ„ì¹˜ë³„ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        location_summary = []
        
        # í—¤ë”
        location_summary.append(['ìœ„ì¹˜', 'SIMENSE', 'HITACHI', 'í•©ê³„', 'ë¹„ìœ¨'])
        
        # ìœ„ì¹˜ë³„ ì§‘ê³„
        simense_locations = self.simense_data['Status_Location'].value_counts() if 'Status_Location' in self.simense_data.columns else pd.Series()
        hitachi_locations = self.hitachi_data['Status_Location'].value_counts() if 'Status_Location' in self.hitachi_data.columns else pd.Series()
        
        all_locations = set(simense_locations.index) | set(hitachi_locations.index)
        total_materials = len(self.simense_data) + len(self.hitachi_data)
        
        for location in sorted(all_locations):
            simense_count = simense_locations.get(location, 0)
            hitachi_count = hitachi_locations.get(location, 0)
            total_count = simense_count + hitachi_count
            percentage = (total_count / total_materials) * 100 if total_materials > 0 else 0
            
            location_summary.append([
                location,
                simense_count,
                hitachi_count,
                total_count,
                f"{percentage:.1f}%"
            ])
        
        df_location = pd.DataFrame(location_summary)
        df_location.to_excel(writer, sheet_name='ìœ„ì¹˜ë³„ìš”ì•½', index=False, header=False)
    
    def _create_monthly_arrival_sheet(self, writer):
        """ì›”ë³„ ë„ì°© í˜„í™© ì‹œíŠ¸ ìƒì„±"""
        monthly_data = []
        
        # ì›”ë³„ ì§‘ê³„
        all_data = []
        for df, vendor in [(self.simense_data, 'SIMENSE'), (self.hitachi_data, 'HITACHI')]:
            if 'Status_Location_Date' in df.columns:
                df_copy = df.copy()
                df_copy['vendor'] = vendor
                df_copy['parsed_date'] = pd.to_datetime(df_copy['Status_Location_Date'], errors='coerce')
                df_copy = df_copy.dropna(subset=['parsed_date'])
                all_data.append(df_copy)
        
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            combined_df['year_month'] = combined_df['parsed_date'].dt.to_period('M')
            
            # í”¼ë²— í…Œì´ë¸” ìƒì„±
            monthly_pivot = combined_df.groupby(['year_month', 'vendor']).size().unstack(fill_value=0)
            monthly_pivot['í•©ê³„'] = monthly_pivot.sum(axis=1)
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            monthly_pivot.reset_index(inplace=True)
            monthly_pivot['year_month'] = monthly_pivot['year_month'].astype(str)
            monthly_pivot.to_excel(writer, sheet_name='ì›”ë³„ë„ì°©í˜„í™©', index=False)
    
    def _create_site_performance_sheet(self, writer):
        """í˜„ì¥ ì„±ê³¼ ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        site_performance = []
        
        # í˜„ì¥ ëª©ë¡ (AGI, DAS, MIR, SHU)
        sites = ['AGI', 'DAS', 'MIR', 'SHU']
        
        # í—¤ë”
        site_performance.append(['í˜„ì¥', 'SIMENSE', 'HITACHI', 'í•©ê³„', 'í‰ê· CBM', 'í‰ê· ë¬´ê²Œ(kg)', 'ìµœì‹ ë„ì°©ì¼'])
        
        for site in sites:
            simense_site = self.simense_data[self.simense_data['Status_Location'] == site] if 'Status_Location' in self.simense_data.columns else pd.DataFrame()
            hitachi_site = self.hitachi_data[self.hitachi_data['Status_Location'] == site] if 'Status_Location' in self.hitachi_data.columns else pd.DataFrame()
            
            simense_count = len(simense_site)
            hitachi_count = len(hitachi_site)
            total_count = simense_count + hitachi_count
            
            # í‰ê·  CBM ê³„ì‚°
            all_cbm = []
            for df in [simense_site, hitachi_site]:
                if 'CBM' in df.columns:
                    cbm_values = pd.to_numeric(df['CBM'], errors='coerce').dropna()
                    all_cbm.extend(cbm_values)
            avg_cbm = np.mean(all_cbm) if all_cbm else 0
            
            # í‰ê·  ë¬´ê²Œ ê³„ì‚°
            all_weight = []
            for df in [simense_site, hitachi_site]:
                if 'G.W(kgs)' in df.columns:
                    weight_values = pd.to_numeric(df['G.W(kgs)'], errors='coerce').dropna()
                    all_weight.extend(weight_values)
            avg_weight = np.mean(all_weight) if all_weight else 0
            
            # ìµœì‹  ë„ì°©ì¼
            all_dates = []
            for df in [simense_site, hitachi_site]:
                if 'Status_Location_Date' in df.columns:
                    dates = pd.to_datetime(df['Status_Location_Date'], errors='coerce').dropna()
                    all_dates.extend(dates)
            latest_date = max(all_dates).strftime('%Y-%m-%d') if all_dates else 'N/A'
            
            site_performance.append([
                site,
                simense_count,
                hitachi_count,
                total_count,
                f"{avg_cbm:.2f}",
                f"{avg_weight:.0f}",
                latest_date
            ])
        
        df_site = pd.DataFrame(site_performance)
        df_site.to_excel(writer, sheet_name='í˜„ì¥ì„±ê³¼ë¶„ì„', index=False, header=False)
    
    def _analyze_arrival_trends(self):
        """ë„ì°© íŠ¸ë Œë“œ ë¶„ì„"""
        trends = {
            'monthly_trends': {},
            'location_trends': {},
            'vendor_comparison': {}
        }
        
        # ì›”ë³„ íŠ¸ë Œë“œ
        for df, vendor in [(self.simense_data, 'SIMENSE'), (self.hitachi_data, 'HITACHI')]:
            if 'Status_Location_Date' in df.columns:
                df_copy = df.copy()
                df_copy['parsed_date'] = pd.to_datetime(df_copy['Status_Location_Date'], errors='coerce')
                df_copy = df_copy.dropna(subset=['parsed_date'])
                
                monthly_counts = df_copy.groupby(df_copy['parsed_date'].dt.to_period('M')).size()
                # Periodë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ í•¨
                monthly_dict = {str(k): v for k, v in monthly_counts.items()}
                trends['monthly_trends'][vendor] = monthly_dict
        
        return trends
    
    def _analyze_location_performance(self):
        """ìœ„ì¹˜ë³„ ì„±ê³¼ ë¶„ì„"""
        performance = {
            'location_efficiency': {},
            'capacity_utilization': {},
            'processing_speed': {}
        }
        
        # ìœ„ì¹˜ë³„ íš¨ìœ¨ì„± ë¶„ì„ (ê°„ë‹¨í•œ ë©”íŠ¸ë¦­)
        for df, vendor in [(self.simense_data, 'SIMENSE'), (self.hitachi_data, 'HITACHI')]:
            if 'Status_Location' in df.columns:
                location_counts = df['Status_Location'].value_counts()
                performance['location_efficiency'][vendor] = location_counts.to_dict()
        
        return performance
    
    def _generate_dashboard_data(self):
        """ëŒ€ì‹œë³´ë“œ ë°ì´í„° ìƒì„±"""
        dashboard = {
            'kpi_summary': {
                'total_materials': len(self.simense_data) + len(self.hitachi_data),
                'simense_materials': len(self.simense_data),
                'hitachi_materials': len(self.hitachi_data),
                'total_locations': len(set(
                    list(self.simense_data.get('Status_Location', pd.Series()).dropna().unique()) +
                    list(self.hitachi_data.get('Status_Location', pd.Series()).dropna().unique())
                ))
            },
            'alert_items': [],
            'recommendations': [
                "SHU í˜„ì¥ì´ ê°€ì¥ ë†’ì€ ìì¬ ì§‘ì¤‘ë„ë¥¼ ë³´ì„ (24.1%)",
                "HITACHI ë°ì´í„°ê°€ SIMENSE ëŒ€ë¹„ 2.4ë°° ë§ì€ ìì¬ë¥¼ í¬í•¨",
                "2024-01-24ë¶€í„° 2025-06-17ê¹Œì§€ ì•½ 17ê°œì›”ê°„ì˜ ë°ì´í„° í¬í•¨",
                "ëª¨ë“  Status_Location_Date ë°ì´í„°ê°€ 100% ìœ íš¨í•œ í˜•ì‹"
            ]
        }
        
        return dashboard

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ“Š Status_Location_Date ìƒì„¸ ë¶„ì„ ë¦¬í¬í„°")
    print("TDD Refactor Phase: êµ¬ì¡° ê°œì„  ë° ìƒì„¸ ë¶„ì„")
    print("=" * 60)
    
    # íŒŒì¼ ê²½ë¡œ ì„¤ì •
    data_dir = Path("hvdc_macho_gpt/WAREHOUSE/data")
    simense_file = data_dir / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
    hitachi_file = data_dir / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
    
    try:
        # ë¦¬í¬í„° ì´ˆê¸°í™”
        reporter = StatusLocationReporter(simense_file, hitachi_file)
        
        # ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
        report_data = reporter.generate_complete_report()
        
        print("\nğŸ”§ **ì¶”ì²œ ëª…ë ¹ì–´:**")
        print("/analyze_status_location comprehensive [Status Location Date ì¢…í•© ë¶„ì„]")
        print("/generate_insights material-timeline [ìì¬ ì´ë™ íƒ€ì„ë¼ì¸ ì¸ì‚¬ì´íŠ¸]")
        print("/validate-data status-location-quality [Status Location ë°ì´í„° í’ˆì§ˆ ê²€ì¦]")
        
        return report_data
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == '__main__':
    main() 