#!/usr/bin/env python3
"""
MACHO-GPT v3.4-mini ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ
/generate-validation-report ëª…ë ¹ì–´ êµ¬í˜„

ì…ë ¥:
1. ì²­êµ¬ì„œ ì›ë³¸ íŒŒì¼ (DSV ì›”ë³„ Invoice)
2. ì „ì²´ í™”ë¬¼ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ (HVDC WAREHOUSE_HITACHI(HE) ë“±)

ì¶œë ¥:
1. PDF ìš”ì•½ ë³´ê³ ì„œ (ê²€ì¦ ê²°ê³¼í‘œ í¬í•¨)
2. Excel ìƒì„¸ ê²°ê³¼ (PASS/FAIL êµ¬ë¶„, ê¸ˆì•¡ ì°¨ì´ ë“±)
3. RDF TTL íŒŒì¼ (ì˜¨í†¨ë¡œì§€ íŠ¸ë¦¬í”Œ í˜•íƒœ)
"""

import pandas as pd
import numpy as np
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Tuple, Optional
from pathlib import Path
import os
import re
from dataclasses import dataclass

# RDF ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from rdflib import Graph, Namespace, Literal, URIRef
    from rdflib.namespace import RDF, RDFS, XSD

    RDF_AVAILABLE = True
except ImportError:
    RDF_AVAILABLE = False
    print("âš ï¸ rdflib íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. RDF TTL íŒŒì¼ ìƒì„±ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
import matplotlib.pyplot as plt
import seaborn as sns

# ReportLab ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.platypus import (
        SimpleDocTemplate,
        Paragraph,
        Spacer,
        Table,
        TableStyle,
    )
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.lib import colors

    REPORTLAB_AVAILABLE = True
except ImportError:
    REPORTLAB_AVAILABLE = False
    print("âš ï¸ reportlab íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDF ë³´ê³ ì„œ ìƒì„±ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class ValidationConfig:
    """ê²€ì¦ ì„¤ì •"""

    confidence_threshold: float = 0.95
    amount_tolerance: float = 0.01  # 1% ê¸ˆì•¡ ì˜¤ì°¨ í—ˆìš©
    quantity_tolerance: float = 0.05  # 5% ìˆ˜ëŸ‰ ì˜¤ì°¨ í—ˆìš©
    fanr_compliance_required: bool = True
    moiat_compliance_required: bool = True
    generate_pdf: bool = True
    generate_excel: bool = True
    generate_rdf: bool = True


class ValidationReportGenerator:
    """MACHO-GPT v3.4-mini ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""

    def __init__(self, config: ValidationConfig = None):
        """ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”"""
        self.config = config or ValidationConfig()

        # ë¬¼ë¥˜ ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (RDF ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
        if RDF_AVAILABLE:
            self.LOGI = Namespace("http://macho-gpt.com/ontology/logistics#")
            self.HVDC = Namespace("http://macho-gpt.com/ontology/hvdc#")
            self.FANR = Namespace("http://macho-gpt.com/ontology/fanr#")
        else:
            self.LOGI = None
            self.HVDC = None
            self.FANR = None

        # ê²€ì¦ ê²°ê³¼ ì €ì¥ì†Œ
        self.validation_results = {
            "invoice_validation": {},
            "warehouse_validation": {},
            "cross_validation": {},
            "compliance_validation": {},
            "overall_validation": {},
        }

        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dir = Path("../output/validation_reports")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        logger.info("ğŸ” ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    def generate_validation_report(
        self, invoice_file: str, warehouse_file: str
    ) -> Dict[str, Any]:
        """
        ì¢…í•© ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            invoice_file: ì²­êµ¬ì„œ ì›ë³¸ íŒŒì¼ ê²½ë¡œ
            warehouse_file: í™”ë¬¼ ì…ì¶œê³  ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ

        Returns:
            ê²€ì¦ ê²°ê³¼ ë° ìƒì„±ëœ íŒŒì¼ ê²½ë¡œë“¤
        """
        logger.info("ğŸš€ ì¢…í•© ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        try:
            # 1. íŒŒì¼ ë¡œë“œ ë° ê²€ì¦
            invoice_data = self._load_invoice_data(invoice_file)
            warehouse_data = self._load_warehouse_data(warehouse_file)

            # 2. ê°œë³„ ê²€ì¦ ìˆ˜í–‰
            invoice_validation = self._validate_invoice_data(invoice_data)
            warehouse_validation = self._validate_warehouse_data(warehouse_data)

            # 3. êµì°¨ ê²€ì¦ ìˆ˜í–‰
            cross_validation = self._perform_cross_validation(
                invoice_data, warehouse_data
            )

            # 4. ê·œì • ì¤€ìˆ˜ ê²€ì¦
            compliance_validation = self._validate_compliance(
                invoice_data, warehouse_data
            )

            # 5. ì „ì²´ ê²€ì¦ ê²°ê³¼ í†µí•©
            overall_validation = self._calculate_overall_validation(
                invoice_validation,
                warehouse_validation,
                cross_validation,
                compliance_validation,
            )

            # 6. ë¦¬í¬íŠ¸ íŒŒì¼ ìƒì„±
            generated_files = self._generate_report_files(
                timestamp,
                invoice_validation,
                warehouse_validation,
                cross_validation,
                compliance_validation,
                overall_validation,
            )

            # 7. ê²°ê³¼ ë°˜í™˜
            result = {
                "command": "generate_validation_report",
                "execution_time": datetime.now().isoformat(),
                "input_files": {
                    "invoice_file": invoice_file,
                    "warehouse_file": warehouse_file,
                },
                "validation_results": {
                    "invoice_validation": invoice_validation,
                    "warehouse_validation": warehouse_validation,
                    "cross_validation": cross_validation,
                    "compliance_validation": compliance_validation,
                    "overall_validation": overall_validation,
                },
                "generated_files": generated_files,
                "recommendations": self._generate_recommendations(overall_validation),
                "next_actions": self._suggest_next_actions(overall_validation),
            }

            logger.info(
                f"âœ… ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ - ì „ì²´ ì ìˆ˜: {overall_validation['total_score']:.3f}"
            )
            return result

        except Exception as e:
            logger.error(f"âŒ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._create_error_response(str(e))

    def _load_invoice_data(self, invoice_file: str) -> pd.DataFrame:
        """ì²­êµ¬ì„œ ë°ì´í„° ë¡œë“œ"""
        logger.info(f"ğŸ“„ ì²­êµ¬ì„œ ë°ì´í„° ë¡œë“œ: {invoice_file}")

        try:
            # Excel íŒŒì¼ ë¡œë“œ
            df = pd.read_excel(invoice_file, sheet_name=0)
            logger.info(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
            logger.info(f"ğŸ“‹ ì›ë³¸ ì»¬ëŸ¼ëª…: {list(df.columns)}")

            # ê¸°ë³¸ ë°ì´í„° ê²€ì¦
            required_columns = [
                "Item",
                "Description",
                "Quantity",
                "Unit_Price",
                "Total_Amount",
            ]
            missing_columns = [col for col in required_columns if col not in df.columns]

            if missing_columns:
                logger.warning(f"âš ï¸ ì²­êµ¬ì„œ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
                logger.info(f"ğŸ” ë§¤í•‘ ì „ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")

            # ë°ì´í„° ì •ì œ
            df = self._clean_invoice_data(df)

            # ë§¤í•‘ í›„ í•„ìˆ˜ ì»¬ëŸ¼ ì¬ê²€ì¦
            final_missing = [col for col in required_columns if col not in df.columns]
            if final_missing:
                logger.error(f"âŒ ë§¤í•‘ í›„ì—ë„ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {final_missing}")
                logger.info(f"ğŸ“‹ ìµœì¢… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            else:
                logger.info(f"âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ")

            logger.info(f"âœ… ì²­êµ¬ì„œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê±´")
            return df

        except Exception as e:
            logger.error(f"âŒ ì²­êµ¬ì„œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def _load_warehouse_data(self, warehouse_file: str) -> pd.DataFrame:
        """ì°½ê³  ë°ì´í„° ë¡œë“œ"""
        logger.info(f"ğŸ­ ì°½ê³  ë°ì´í„° ë¡œë“œ: {warehouse_file}")

        try:
            # Excel íŒŒì¼ ë¡œë“œ
            df = pd.read_excel(warehouse_file, sheet_name=0)
            logger.info(f"ğŸ“Š ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")
            logger.info(f"ğŸ“‹ ì›ë³¸ ì»¬ëŸ¼ëª…: {list(df.columns)}")

            # ê¸°ë³¸ ë°ì´í„° ê²€ì¦
            required_columns = ["Item"]
            missing_columns = [col for col in required_columns if col not in df.columns]

            if missing_columns:
                logger.warning(f"âš ï¸ ì°½ê³  ë°ì´í„° í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
                logger.info(f"ğŸ” ë§¤í•‘ ì „ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")

            # ë°ì´í„° ì •ì œ
            df = self._clean_warehouse_data(df)

            # ë§¤í•‘ í›„ í•„ìˆ˜ ì»¬ëŸ¼ ì¬ê²€ì¦
            final_missing = [col for col in required_columns if col not in df.columns]
            if final_missing:
                logger.error(f"âŒ ë§¤í•‘ í›„ì—ë„ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {final_missing}")
                logger.info(f"ğŸ“‹ ìµœì¢… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
            else:
                logger.info(f"âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ë§¤í•‘ ì™„ë£Œ")

            logger.info(f"âœ… ì°½ê³  ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê±´")
            return df

        except Exception as e:
            logger.error(f"âŒ ì°½ê³  ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def _clean_invoice_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì²­êµ¬ì„œ ë°ì´í„° ì •ì œ"""
        df_clean = df.copy()

        # ë””ë²„ê¹…: ì›ë³¸ ì»¬ëŸ¼ëª… ì¶œë ¥
        logger.info(f"ğŸ” ì›ë³¸ ì²­êµ¬ì„œ ì»¬ëŸ¼ëª…: {list(df_clean.columns)}")

        # ì»¬ëŸ¼ëª… í‘œì¤€í™” - í™•ì¥ëœ ë§¤í•‘
        column_mapping = {}

        # Item ê´€ë ¨ ë§¤í•‘
        item_mappings = {
            "Item No": "Item",
            "Item Number": "Item",
            "S No.": "Item",
            "S.No.": "Item",
            "S.No": "Item",
            "No.": "Item",  # ì‹¤ì œ íŒŒì¼ì— ë§ê²Œ ì¶”ê°€
            "Item": "Item",
            "ID": "Item",
            "Case No.": "Item",
            "Case No": "Item",
            "Case_No": "Item",
            "no.": "Item",
            "Number": "Item",
        }

        # Description ê´€ë ¨ ë§¤í•‘
        desc_mappings = {
            "Description": "Description",
            "Desc": "Description",
            "Item Description": "Description",
            "Product Description": "Description",
            "Goods Description": "Description",
            "Details": "Description",
        }

        # Quantity ê´€ë ¨ ë§¤í•‘
        qty_mappings = {
            "Qty": "Quantity",
            "Quantity": "Quantity",
            "QTY": "Quantity",
            "qty": "Quantity",
            "CNTR Unstuffing Q'TY": "Quantity",
            "CNTR Stuffing Q'TY": "Quantity",
            "Container Qty": "Quantity",
            "Package Qty": "Quantity",
            "Units": "Quantity",
            "Count": "Quantity",
        }

        # Unit Price ê´€ë ¨ ë§¤í•‘
        price_mappings = {
            "Unit Price": "Unit_Price",
            "Unit_Price": "Unit_Price",
            "Price": "Unit_Price",
            "Unit Cost": "Unit_Price",
            "Rate": "Unit_Price",
            "Per Unit": "Unit_Price",
            "Price per Unit": "Unit_Price",
            "Unit price_Handling In": "Unit_Price_Handling_In",  # ì‹¤ì œ íŒŒì¼ì— ë§ê²Œ ì¶”ê°€
            "Unit price_Handling out": "Unit_Price_Handling_Out",
            "Unit price_Unstuffing": "Unit_Price_Unstuffing",
            "Unit price_Stuffing": "Unit_Price_Stuffing",
            "Unit price_folk lift": "Unit_Price_Folk_Lift",
            "Unit price_crane": "Unit_Price_Crane",
        }

        # Total Amount ê´€ë ¨ ë§¤í•‘ (AmountëŠ” ë§ˆì§€ë§‰ì— ì²˜ë¦¬í•˜ì—¬ ì¶©ëŒ ë°©ì§€)
        total_mappings = {
            "Total": "Total_Amount",
            "Total Amount": "Total_Amount",
            "Total_Amount": "Total_Amount",
            "Sum": "Total_Amount",
            "Value": "Total_Amount",
            "Cost": "Total_Amount",
            "Invoice Amount": "Total_Amount",
            "Line Total": "Total_Amount",
            "Extended Amount": "Total_Amount",
            "TOTAL": "Total_Amount",  # ì‹¤ì œ íŒŒì¼ì— ë§ê²Œ ì¶”ê°€
        }

        # ë§¤í•‘ ì ìš© (ìš°ì„ ìˆœìœ„ ê³ ë ¤)
        for mapping_dict in [
            item_mappings,
            desc_mappings,
            qty_mappings,
            price_mappings,
            total_mappings,
        ]:
            for old_col, new_col in mapping_dict.items():
                if (
                    old_col in df_clean.columns
                    and new_col not in column_mapping.values()
                ):
                    column_mapping[old_col] = new_col

        # Amount ì»¬ëŸ¼ íŠ¹ë³„ ì²˜ë¦¬ (Quantity vs Total_Amount êµ¬ë¶„)
        if "Amount" in df_clean.columns and "Amount" not in column_mapping:
            # Amountê°€ ì´ë¯¸ ë§¤í•‘ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
            if (
                "Quantity" not in df_clean.columns
                and "Total_Amount" not in df_clean.columns
            ):
                # ë‘˜ ë‹¤ ì—†ëŠ” ê²½ìš°, ë°ì´í„° íƒ€ì…ìœ¼ë¡œ íŒë‹¨
                amount_col = df_clean["Amount"]
                if pd.api.types.is_numeric_dtype(amount_col):
                    # ìˆ«ìì¸ ê²½ìš° Total_Amountë¡œ ë§¤í•‘
                    column_mapping["Amount"] = "Total_Amount"
                else:
                    # ë¬¸ìì—´ì¸ ê²½ìš° Quantityë¡œ ë§¤í•‘
                    column_mapping["Amount"] = "Quantity"
            elif "Quantity" not in df_clean.columns:
                column_mapping["Amount"] = "Quantity"
            elif "Total_Amount" not in df_clean.columns:
                column_mapping["Amount"] = "Total_Amount"

        # Description ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° HVDC CODEë¥¼ Descriptionìœ¼ë¡œ ì‚¬ìš©
        if "Description" not in df_clean.columns and "HVDC CODE" in df_clean.columns:
            column_mapping["HVDC CODE"] = "Description"
            logger.info(f"ğŸ”§ HVDC CODEë¥¼ Descriptionìœ¼ë¡œ ë§¤í•‘")

        # Unit_Price ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ìƒì„±
        if "Unit_Price" not in df_clean.columns:
            logger.info(f"ğŸ”§ Unit_Price ì»¬ëŸ¼ì´ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±")

        logger.info(f"ğŸ”§ ì ìš©ë  ë§¤í•‘: {column_mapping}")

        # ë§¤í•‘ ì ìš©
        df_clean = df_clean.rename(columns=column_mapping)

        # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (Total_Amountê°€ ì¤‘ë³µëœ ê²½ìš°)
        if "Total_Amount" in df_clean.columns:
            # ì²« ë²ˆì§¸ Total_Amount ì»¬ëŸ¼ë§Œ ìœ ì§€
            total_amount_cols = [
                col for col in df_clean.columns if col == "Total_Amount"
            ]
            if len(total_amount_cols) > 1:
                # ì²« ë²ˆì§¸ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì‚­ì œ
                for col in total_amount_cols[1:]:
                    df_clean = df_clean.drop(columns=[col])
                logger.info(f"ğŸ”§ ì¤‘ë³µ Total_Amount ì»¬ëŸ¼ ì œê±° ì™„ë£Œ")

        # Unit_Price ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš° ìƒì„±
        if "Unit_Price" not in df_clean.columns:
            if "Quantity" in df_clean.columns and "Total_Amount" in df_clean.columns:
                # Quantityì™€ Total_Amountê°€ ìˆëŠ” ê²½ìš° ê³„ì‚°
                df_clean["Unit_Price"] = df_clean["Total_Amount"] / df_clean["Quantity"]
                df_clean["Unit_Price"] = df_clean["Unit_Price"].fillna(0)
                logger.info(f"ğŸ”§ Unit_Price ê³„ì‚° ì™„ë£Œ: Total_Amount / Quantity")
            else:
                # ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ìƒì„±
                df_clean["Unit_Price"] = 0
                logger.info(f"ğŸ”§ Unit_Price ê¸°ë³¸ê°’ 0ìœ¼ë¡œ ìƒì„±")
        else:
            logger.info(
                f"ğŸ”§ Unit_Price ì»¬ëŸ¼ì´ ì´ë¯¸ ì¡´ì¬í•¨: {df_clean['Unit_Price'].notna().sum()}ê°œ ìœ íš¨ê°’"
            )

        # ë””ë²„ê¹…: ë§¤í•‘ í›„ ì»¬ëŸ¼ëª… ì¶œë ¥
        logger.info(f"ğŸ”§ ë§¤í•‘ í›„ ì²­êµ¬ì„œ ì»¬ëŸ¼ëª…: {list(df_clean.columns)}")

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ["Item", "Description"]
        missing_required = [
            col for col in required_columns if col not in df_clean.columns
        ]
        if missing_required:
            logger.warning(f"âš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_required}")
            logger.info(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df_clean.columns)}")

        # ìˆ«ì ì»¬ëŸ¼ ì •ì œ
        numeric_columns = ["Quantity", "Unit_Price", "Total_Amount"]
        for col in numeric_columns:
            if col in df_clean.columns:
                df_clean[col] = pd.to_numeric(df_clean[col], errors="coerce")
                logger.info(
                    f"ğŸ“Š {col} ì»¬ëŸ¼ ì •ì œ ì™„ë£Œ: {df_clean[col].notna().sum()}ê°œ ìœ íš¨ê°’"
                )

        # ë¹ˆ ê°’ ì œê±°
        before_clean = len(df_clean)
        df_clean = df_clean.dropna(subset=["Item"])
        after_clean = len(df_clean)
        logger.info(f"ğŸ§¹ ë¹ˆ ê°’ ì œê±°: {before_clean} â†’ {after_clean}ê±´")

        # DataFrame êµ¬ì¡° ìƒì„¸ ì¶œë ¥
        self._debug_dataframe_structure(df_clean, "ì²­êµ¬ì„œ ë°ì´í„°")

        return df_clean

    def _clean_warehouse_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì°½ê³  ë°ì´í„° ì •ì œ"""
        df_clean = df.copy()

        # ë””ë²„ê¹…: ì›ë³¸ ì»¬ëŸ¼ëª… ì¶œë ¥
        logger.info(f"ğŸ” ì›ë³¸ ì°½ê³  ë°ì´í„° ì»¬ëŸ¼ëª…: {list(df_clean.columns)}")

        # ì»¬ëŸ¼ëª… í‘œì¤€í™” - í™•ì¥ëœ ë§¤í•‘
        column_mapping = {}

        # Item ê´€ë ¨ ë§¤í•‘
        item_mappings = {
            "no.": "Item",
            "No.": "Item",
            "Item No": "Item",
            "Item Number": "Item",
            "Item": "Item",
            "ID": "Item",
            "Case No.": "Item",
            "Case No": "Item",
            "Case_No": "Item",
            "S No.": "Item",
            "S.No.": "Item",
            "S.No": "Item",
            "Number": "Item",
            "Reference": "Item",
            "Code": "Item",
        }

        # Description ê´€ë ¨ ë§¤í•‘
        desc_mappings = {
            "Description": "Description",
            "Desc": "Description",
            "Item Description": "Description",
            "Product Description": "Description",
            "Goods Description": "Description",
            "Details": "Description",
            "Name": "Description",
            "Product": "Description",
            "Goods": "Description",
        }

        # ì¶”ê°€ ì°½ê³  ê´€ë ¨ ì»¬ëŸ¼ë“¤
        other_mappings = {
            "Category": "Category",
            "Type": "Type",
            "Vendor": "Vendor",
            "Supplier": "Vendor",
            "Manufacturer": "Vendor",
            "Brand": "Vendor",
            "Date": "Date",
            "Created Date": "Date",
            "Entry Date": "Date",
            "Arrival Date": "Date",
            "Transaction Date": "Date",
            "Timestamp": "Date",
        }

        # ë§¤í•‘ ì ìš© (ìš°ì„ ìˆœìœ„ ê³ ë ¤)
        for mapping_dict in [item_mappings, desc_mappings, other_mappings]:
            for old_col, new_col in mapping_dict.items():
                if (
                    old_col in df_clean.columns
                    and new_col not in column_mapping.values()
                ):
                    column_mapping[old_col] = new_col

        logger.info(f"ğŸ”§ ì ìš©ë  ë§¤í•‘: {column_mapping}")

        # ë§¤í•‘ ì ìš©
        df_clean = df_clean.rename(columns=column_mapping)

        # ë””ë²„ê¹…: ë§¤í•‘ í›„ ì»¬ëŸ¼ëª… ì¶œë ¥
        logger.info(f"ğŸ”§ ë§¤í•‘ í›„ ì°½ê³  ë°ì´í„° ì»¬ëŸ¼ëª…: {list(df_clean.columns)}")

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ["Item"]
        missing_required = [
            col for col in required_columns if col not in df_clean.columns
        ]
        if missing_required:
            logger.warning(f"âš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_required}")
            logger.info(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df_clean.columns)}")

        # ë¹ˆ ê°’ ì œê±°
        before_clean = len(df_clean)
        df_clean = df_clean.dropna(subset=["Item"])
        after_clean = len(df_clean)
        logger.info(f"ğŸ§¹ ë¹ˆ ê°’ ì œê±°: {before_clean} â†’ {after_clean}ê±´")

        # ì°½ê³  ì»¬ëŸ¼ ì‹ë³„ ë° ì¶œë ¥
        warehouse_columns = [
            col
            for col in df_clean.columns
            if any(
                warehouse in col
                for warehouse in [
                    "DSV",
                    "DHL",
                    "AAA",
                    "Hauler",
                    "MOSB",
                    "MIR",
                    "SHU",
                    "DAS",
                    "AGI",
                ]
            )
        ]
        logger.info(f"ğŸ­ ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ ì‹ë³„: {warehouse_columns}")

        # DataFrame êµ¬ì¡° ìƒì„¸ ì¶œë ¥
        self._debug_dataframe_structure(df_clean, "ì°½ê³  ë°ì´í„°")

        return df_clean

    def _debug_dataframe_structure(self, df: pd.DataFrame, data_type: str):
        """DataFrame êµ¬ì¡° ë””ë²„ê¹… ì¶œë ¥"""
        logger.info(f"ğŸ” {data_type} DataFrame êµ¬ì¡° ë¶„ì„:")
        logger.info(f"  ğŸ“Š í¬ê¸°: {df.shape}")
        logger.info(f"  ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}")
        logger.info(f"  ğŸ“ˆ ë°ì´í„° íƒ€ì…:")
        for col in df.columns:
            try:
                dtype = df[col].dtype
                non_null_count = df[col].notna().sum()
                null_count = df[col].isna().sum()
                logger.info(
                    f"    {col}: {dtype} (ìœ íš¨: {non_null_count}, ë¹ˆê°’: {null_count})"
                )
            except Exception as e:
                logger.warning(f"    {col}: ë°ì´í„° íƒ€ì… í™•ì¸ ì‹¤íŒ¨ - {e}")

        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥ (ì²˜ìŒ 3í–‰)
        if len(df) > 0:
            try:
                logger.info(f"  ğŸ“„ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):")
                sample_data = df.head(3).to_dict("records")
                for i, row in enumerate(sample_data):
                    # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì¶œë ¥
                    row_str = str(row)
                    if len(row_str) > 200:  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì¶œë ¥
                        row_str = row_str[:200] + "..."
                    logger.info(f"    í–‰ {i+1}: {row_str}")
            except Exception as e:
                logger.warning(f"  ğŸ“„ ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥ ì‹¤íŒ¨: {e}")

        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if data_type == "ì²­êµ¬ì„œ ë°ì´í„°":
            required_cols = [
                "Item",
                "Description",
                "Quantity",
                "Unit_Price",
                "Total_Amount",
            ]
        else:  # ì°½ê³  ë°ì´í„°
            required_cols = ["Item"]

        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            logger.warning(f"  âš ï¸ ëˆ„ë½ëœ í•„ìˆ˜ ì»¬ëŸ¼: {missing_cols}")
        else:
            logger.info(f"  âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬")

    def _validate_invoice_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ì²­êµ¬ì„œ ë°ì´í„° ê²€ì¦"""
        logger.info("ğŸ” ì²­êµ¬ì„œ ë°ì´í„° ê²€ì¦ ì¤‘...")

        validation_result = {
            "status": "PASS",
            "score": 0.0,
            "checks": {},
            "errors": [],
            "warnings": [],
        }

        total_checks = 0
        passed_checks = 0

        # 1. ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
        total_checks += 1
        if len(df) > 0:
            passed_checks += 1
            validation_result["checks"]["data_structure"] = {
                "status": "PASS",
                "message": "ë°ì´í„° êµ¬ì¡° ì •ìƒ",
            }
        else:
            validation_result["checks"]["data_structure"] = {
                "status": "FAIL",
                "message": "ë¹ˆ ë°ì´í„°",
            }
            validation_result["errors"].append("ë¹ˆ ë°ì´í„°")

        # 2. í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        required_columns = ["Item", "Description"]
        for col in required_columns:
            total_checks += 1
            if col in df.columns:
                passed_checks += 1
                validation_result["checks"][f"column_{col}"] = {
                    "status": "PASS",
                    "message": f"{col} ì»¬ëŸ¼ ì¡´ì¬",
                }
            else:
                validation_result["checks"][f"column_{col}"] = {
                    "status": "FAIL",
                    "message": f"{col} ì»¬ëŸ¼ ëˆ„ë½",
                }
                validation_result["errors"].append(f"{col} ì»¬ëŸ¼ ëˆ„ë½")

        # 3. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        total_checks += 1
        null_count = df["Item"].isnull().sum()
        if null_count == 0:
            passed_checks += 1
            validation_result["checks"]["data_quality"] = {
                "status": "PASS",
                "message": "ë°ì´í„° í’ˆì§ˆ ì–‘í˜¸",
            }
        else:
            validation_result["checks"]["data_quality"] = {
                "status": "WARNING",
                "message": f"{null_count}ê°œ ë¹ˆ ê°’ ë°œê²¬",
            }
            validation_result["warnings"].append(f"{null_count}ê°œ ë¹ˆ ê°’")

        # 4. ê¸ˆì•¡ ê³„ì‚° ê²€ì¦ (ê¸ˆì•¡ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
        if (
            "Quantity" in df.columns
            and "Unit_Price" in df.columns
            and "Total_Amount" in df.columns
        ):
            total_checks += 1
            df["Calculated_Total"] = df["Quantity"] * df["Unit_Price"]
            df["Amount_Difference"] = abs(df["Total_Amount"] - df["Calculated_Total"])

            # 1% ì´ë‚´ ì˜¤ì°¨ í—ˆìš©
            tolerance = df["Total_Amount"] * self.config.amount_tolerance
            accurate_calculations = (df["Amount_Difference"] <= tolerance).sum()
            accuracy_rate = accurate_calculations / len(df) if len(df) > 0 else 0

            if accuracy_rate >= 0.95:
                passed_checks += 1
                validation_result["checks"]["amount_calculation"] = {
                    "status": "PASS",
                    "message": f"ê¸ˆì•¡ ê³„ì‚° ì •í™•ë„ {accuracy_rate:.1%}",
                }
            else:
                validation_result["checks"]["amount_calculation"] = {
                    "status": "FAIL",
                    "message": f"ê¸ˆì•¡ ê³„ì‚° ì˜¤ì°¨ {1-accuracy_rate:.1%}",
                }
                validation_result["errors"].append(
                    f"ê¸ˆì•¡ ê³„ì‚° ì˜¤ì°¨ {1-accuracy_rate:.1%}"
                )

        # ì ìˆ˜ ê³„ì‚°
        validation_result["score"] = (
            passed_checks / total_checks if total_checks > 0 else 0
        )
        validation_result["status"] = (
            "PASS" if validation_result["score"] >= 0.9 else "FAIL"
        )

        logger.info(f"âœ… ì²­êµ¬ì„œ ê²€ì¦ ì™„ë£Œ - ì ìˆ˜: {validation_result['score']:.3f}")
        return validation_result

    def _validate_warehouse_data(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ì°½ê³  ë°ì´í„° ê²€ì¦"""
        logger.info("ğŸ” ì°½ê³  ë°ì´í„° ê²€ì¦ ì¤‘...")

        validation_result = {
            "status": "PASS",
            "score": 0.0,
            "checks": {},
            "errors": [],
            "warnings": [],
        }

        total_checks = 0
        passed_checks = 0

        # 1. ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
        total_checks += 1
        if len(df) > 0:
            passed_checks += 1
            validation_result["checks"]["data_structure"] = {
                "status": "PASS",
                "message": "ë°ì´í„° êµ¬ì¡° ì •ìƒ",
            }
        else:
            validation_result["checks"]["data_structure"] = {
                "status": "FAIL",
                "message": "ë¹ˆ ë°ì´í„°",
            }
            validation_result["errors"].append("ë¹ˆ ë°ì´í„°")

        # 2. í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        required_columns = ["Item"]
        for col in required_columns:
            total_checks += 1
            if col in df.columns:
                passed_checks += 1
                validation_result["checks"][f"column_{col}"] = {
                    "status": "PASS",
                    "message": f"{col} ì»¬ëŸ¼ ì¡´ì¬",
                }
            else:
                validation_result["checks"][f"column_{col}"] = {
                    "status": "FAIL",
                    "message": f"{col} ì»¬ëŸ¼ ëˆ„ë½",
                }
                validation_result["errors"].append(f"{col} ì»¬ëŸ¼ ëˆ„ë½")

        # 3. ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        total_checks += 1
        null_count = df["Item"].isnull().sum()
        if null_count == 0:
            passed_checks += 1
            validation_result["checks"]["data_quality"] = {
                "status": "PASS",
                "message": "ë°ì´í„° í’ˆì§ˆ ì–‘í˜¸",
            }
        else:
            validation_result["checks"]["data_quality"] = {
                "status": "WARNING",
                "message": f"{null_count}ê°œ ë¹ˆ ê°’ ë°œê²¬",
            }
            validation_result["warnings"].append(f"{null_count}ê°œ ë¹ˆ ê°’")

        # 4. ì°½ê³  ì»¬ëŸ¼ ê²€ì¦
        warehouse_columns = [
            col
            for col in df.columns
            if any(
                warehouse in col
                for warehouse in [
                    "DSV",
                    "DHL",
                    "AAA",
                    "Hauler",
                    "MOSB",
                    "MIR",
                    "SHU",
                    "DAS",
                    "AGI",
                ]
            )
        ]

        total_checks += 1
        if len(warehouse_columns) >= 3:
            passed_checks += 1
            validation_result["checks"]["warehouse_columns"] = {
                "status": "PASS",
                "message": f"{len(warehouse_columns)}ê°œ ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ ë°œê²¬",
            }
        else:
            validation_result["checks"]["warehouse_columns"] = {
                "status": "WARNING",
                "message": f"ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ ë¶€ì¡± ({len(warehouse_columns)}ê°œ)",
            }
            validation_result["warnings"].append(f"ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ ë¶€ì¡±")

        # ì ìˆ˜ ê³„ì‚°
        validation_result["score"] = (
            passed_checks / total_checks if total_checks > 0 else 0
        )
        validation_result["status"] = (
            "PASS" if validation_result["score"] >= 0.9 else "FAIL"
        )

        logger.info(
            f"âœ… ì°½ê³  ë°ì´í„° ê²€ì¦ ì™„ë£Œ - ì ìˆ˜: {validation_result['score']:.3f}"
        )
        return validation_result

    def _perform_cross_validation(
        self, invoice_df: pd.DataFrame, warehouse_df: pd.DataFrame
    ) -> Dict[str, Any]:
        """ì²­êµ¬ì„œì™€ ì°½ê³  ë°ì´í„° êµì°¨ ê²€ì¦ - êµ¬ì¡° ì°¨ì´ ë°˜ì˜ ë° ë¡œì§ ê°œì„ """
        logger.info("ğŸ” ì²­êµ¬ì„œì™€ ì°½ê³  ë°ì´í„° êµì°¨ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")

        validation_result = {
            "status": "PASS",
            "score": 0.0,
            "checks": {},
            "errors": [],
            "warnings": [],
            "details": {},
        }

        total_checks = 0
        passed_checks = 0

        # 1. ì•„ì´í…œ ID ë§¤ì¹­ ê²€ì¦
        total_checks += 1
        invoice_items = set(invoice_df["Item"].astype(str))
        warehouse_items = set(warehouse_df["Item"].astype(str))

        matched_items = invoice_items.intersection(warehouse_items)
        invoice_only = invoice_items - warehouse_items
        warehouse_only = warehouse_items - invoice_items

        match_rate = (
            len(matched_items) / len(invoice_items) if len(invoice_items) > 0 else 0
        )

        if match_rate >= 0.95:
            validation_result["checks"]["item_matching"] = {
                "status": "PASS",
                "message": f"ì•„ì´í…œ ë§¤ì¹­ë¥  {match_rate:.1%} ({len(matched_items)}/{len(invoice_items)})",
            }
            passed_checks += 1
        else:
            validation_result["checks"]["item_matching"] = {
                "status": "FAIL",
                "message": f"ì•„ì´í…œ ë§¤ì¹­ë¥  ë‚®ìŒ {match_rate:.1%} ({len(matched_items)}/{len(invoice_items)})",
            }

        # ì•„ì´í…œ ë§¤ì¹­ ìƒì„¸ ì •ë³´ ì €ì¥
        validation_result["details"]["item_matching"] = {
            "total_invoice_items": len(invoice_items),
            "total_warehouse_items": len(warehouse_items),
            "matched_items": len(matched_items),
            "invoice_only": len(invoice_only),
            "warehouse_only": len(warehouse_only),
            "match_rate": match_rate,
        }

        # 2. HVDC CODE ì¼ì¹˜ì„± ê²€ì¦ (ê°œì„ ëœ ë¡œì§)
        total_checks += 1
        if len(matched_items) > 0:
            # ë§¤ì¹­ëœ ì•„ì´í…œë“¤ì˜ HVDC CODE ë¹„êµ
            matched_invoice = invoice_df[
                invoice_df["Item"].astype(str).isin(matched_items)
            ]
            matched_warehouse = warehouse_df[
                warehouse_df["Item"].astype(str).isin(matched_items)
            ]

            # HVDC CODE ì»¬ëŸ¼ ì°¾ê¸°
            invoice_hvdccode_col = (
                "HVDC CODE" if "HVDC CODE" in matched_invoice.columns else "Description"
            )
            warehouse_hvdccode_col = (
                "HVDC CODE"
                if "HVDC CODE" in matched_warehouse.columns
                else "Description"
            )

            # HVDC CODE ë§¤ì¹­ ê²€ì¦ (ê°œì„ ëœ ë¡œì§)
            hvdccode_matches = 0
            hvdccode_mismatches = 0
            mismatch_details = []

            for _, invoice_row in matched_invoice.iterrows():
                item_id = str(invoice_row["Item"])

                # HVDC CODE ì •ê·œí™” í•¨ìˆ˜
                def normalize_hvdccode(code):
                    if pd.isna(code):
                        return ""
                    # ë¬¸ìì—´ë¡œ ë³€í™˜
                    code_str = str(code).strip()
                    # ëŒ€ì†Œë¬¸ì í†µì¼ (ëŒ€ë¬¸ìë¡œ)
                    code_str = code_str.upper()
                    # ê³µë°± ì œê±°
                    code_str = (
                        code_str.replace(" ", "").replace("\t", "").replace("\n", "")
                    )
                    # íŠ¹ìˆ˜ë¬¸ì ì •ê·œí™”
                    code_str = code_str.replace("-", "-").replace("_", "-")
                    return code_str

                invoice_hvdccode = normalize_hvdccode(invoice_row[invoice_hvdccode_col])

                # ì°½ê³ ì—ì„œ í•´ë‹¹ ì•„ì´í…œì˜ HVDC CODE í™•ì¸
                warehouse_items_for_id = matched_warehouse[
                    matched_warehouse["Item"].astype(str) == item_id
                ]

                if len(warehouse_items_for_id) > 0:
                    warehouse_hvdccode = normalize_hvdccode(
                        warehouse_items_for_id.iloc[0][warehouse_hvdccode_col]
                    )

                    # ì •ê·œí™”ëœ HVDC CODE ë¹„êµ
                    if invoice_hvdccode == warehouse_hvdccode:
                        hvdccode_matches += 1
                    else:
                        hvdccode_mismatches += 1
                        mismatch_details.append(
                            {
                                "item": item_id,
                                "invoice_hvdccode_original": str(
                                    invoice_row[invoice_hvdccode_col]
                                ),
                                "warehouse_hvdccode_original": str(
                                    warehouse_items_for_id.iloc[0][
                                        warehouse_hvdccode_col
                                    ]
                                ),
                                "invoice_hvdccode_normalized": invoice_hvdccode,
                                "warehouse_hvdccode_normalized": warehouse_hvdccode,
                            }
                        )

            hvdccode_match_rate = (
                hvdccode_matches / len(matched_invoice)
                if len(matched_invoice) > 0
                else 0
            )

            if hvdccode_match_rate >= 0.95:
                validation_result["checks"]["hvdccode_matching"] = {
                    "status": "PASS",
                    "message": f"HVDC CODE ì¼ì¹˜ë¥  {hvdccode_match_rate:.1%} (ì •ê·œí™” ì ìš©)",
                }
                passed_checks += 1
            else:
                validation_result["checks"]["hvdccode_matching"] = {
                    "status": "FAIL",
                    "message": f"HVDC CODE ì¼ì¹˜ë¥  ë‚®ìŒ {hvdccode_match_rate:.1%} (ì •ê·œí™” ì ìš©)",
                }

            # HVDC CODE ë§¤ì¹­ ìƒì„¸ ì •ë³´ ì €ì¥
            validation_result["details"]["hvdccode_matching"] = {
                "total_compared": len(matched_invoice),
                "matches": hvdccode_matches,
                "mismatches": hvdccode_mismatches,
                "match_rate": hvdccode_match_rate,
                "mismatch_details": mismatch_details[:10],  # ì²˜ìŒ 10ê°œë§Œ ì €ì¥
            }
        else:
            validation_result["checks"]["hvdccode_matching"] = {
                "status": "SKIP",
                "message": "ë§¤ì¹­ëœ ì•„ì´í…œì´ ì—†ì–´ HVDC CODE ê²€ì¦ ìƒëµ",
            }

        # 3. ìˆ˜ëŸ‰ ì¼ì¹˜ì„± ê²€ì¦ (ê°œì„ ëœ ë¡œì§ - ì˜¤ì°¨ í—ˆìš© ë²”ìœ„ ì¡°ì •)
        total_checks += 1
        if len(matched_items) > 0:
            # ë§¤ì¹­ëœ ì•„ì´í…œë“¤ì˜ ìˆ˜ëŸ‰ ë¹„êµ
            matched_invoice = invoice_df[
                invoice_df["Item"].astype(str).isin(matched_items)
            ]
            matched_warehouse = warehouse_df[
                warehouse_df["Item"].astype(str).isin(matched_items)
            ]

            # ìˆ˜ëŸ‰ ì»¬ëŸ¼ ì°¾ê¸°
            invoice_qty_col = (
                "Quantity" if "Quantity" in matched_invoice.columns else "pkg"
            )
            warehouse_qty_col = "Pkg" if "Pkg" in matched_warehouse.columns else "pkg"

            # ìˆ˜ëŸ‰ ë§¤ì¹­ ê²€ì¦ (ê°œì„ ëœ ì§‘ê³„ ë°©ì‹)
            qty_matches = 0
            qty_mismatches = 0
            qty_mismatch_details = []

            for _, invoice_row in matched_invoice.iterrows():
                item_id = str(invoice_row["Item"])
                invoice_qty = int(invoice_row[invoice_qty_col])

                # ì°½ê³ ì—ì„œ í•´ë‹¹ ì•„ì´í…œì˜ ì´ ìˆ˜ëŸ‰ ì§‘ê³„
                warehouse_items_for_id = matched_warehouse[
                    matched_warehouse["Item"].astype(str) == item_id
                ]
                warehouse_total_qty = len(warehouse_items_for_id)  # ê°œë³„ ë ˆì½”ë“œ ìˆ˜

                # ê°œì„ ëœ ì˜¤ì°¨ í—ˆìš© ë²”ìœ„ (ìˆ˜ëŸ‰ì— ë”°ë¥¸ ë™ì  ì¡°ì •)
                if invoice_qty <= 5:
                    qty_tolerance = 1  # 5ê°œ ì´í•˜: 1ê°œ ì˜¤ì°¨ í—ˆìš©
                elif invoice_qty <= 20:
                    qty_tolerance = max(
                        2, int(invoice_qty * 0.1)
                    )  # 6-20ê°œ: 10% ë˜ëŠ” 2ê°œ
                elif invoice_qty <= 100:
                    qty_tolerance = max(
                        3, int(invoice_qty * 0.08)
                    )  # 21-100ê°œ: 8% ë˜ëŠ” 3ê°œ
                else:
                    qty_tolerance = max(
                        5, int(invoice_qty * 0.05)
                    )  # 100ê°œ ì´ˆê³¼: 5% ë˜ëŠ” 5ê°œ

                qty_difference = abs(invoice_qty - warehouse_total_qty)

                if qty_difference <= qty_tolerance:
                    qty_matches += 1
                else:
                    qty_mismatches += 1
                    qty_mismatch_details.append(
                        {
                            "item": item_id,
                            "invoice_qty": invoice_qty,
                            "warehouse_qty": warehouse_total_qty,
                            "difference": qty_difference,
                            "tolerance": qty_tolerance,
                            "tolerance_rate": (
                                f"{qty_tolerance/invoice_qty*100:.1f}%"
                                if invoice_qty > 0
                                else "N/A"
                            ),
                        }
                    )

            qty_match_rate = (
                qty_matches / len(matched_invoice) if len(matched_invoice) > 0 else 0
            )

            if qty_match_rate >= 0.95:  # 95% ì´ìƒì´ë©´ í†µê³¼
                validation_result["checks"]["quantity_matching"] = {
                    "status": "PASS",
                    "message": f"ìˆ˜ëŸ‰ ì¼ì¹˜ë¥  {qty_match_rate:.1%} (ê°œì„ ëœ ì§‘ê³„ ë°©ì‹)",
                }
                passed_checks += 1
            elif qty_match_rate >= 0.90:  # 90-95%ëŠ” ê²½ê³ 
                validation_result["checks"]["quantity_matching"] = {
                    "status": "WARNING",
                    "message": f"ìˆ˜ëŸ‰ ì¼ì¹˜ë¥  {qty_match_rate:.1%} (ê°œì„ ëœ ì§‘ê³„ ë°©ì‹)",
                }
            else:
                validation_result["checks"]["quantity_matching"] = {
                    "status": "FAIL",
                    "message": f"ìˆ˜ëŸ‰ ì¼ì¹˜ë¥  ë‚®ìŒ {qty_match_rate:.1%} (ê°œì„ ëœ ì§‘ê³„ ë°©ì‹)",
                }

            # ìˆ˜ëŸ‰ ë§¤ì¹­ ìƒì„¸ ì •ë³´ ì €ì¥
            validation_result["details"]["quantity_matching"] = {
                "total_compared": len(matched_invoice),
                "matches": qty_matches,
                "mismatches": qty_mismatches,
                "match_rate": qty_match_rate,
                "mismatch_details": qty_mismatch_details[:10],  # ì²˜ìŒ 10ê°œë§Œ ì €ì¥
                "method": "improved_aggregation",  # ê°œì„ ëœ ì§‘ê³„ ë°©ì‹ ì‚¬ìš©
                "tolerance_policy": "dynamic",  # ë™ì  ì˜¤ì°¨ í—ˆìš© ë²”ìœ„
            }
        else:
            validation_result["checks"]["quantity_matching"] = {
                "status": "SKIP",
                "message": "ë§¤ì¹­ëœ ì•„ì´í…œì´ ì—†ì–´ ìˆ˜ëŸ‰ ê²€ì¦ ìƒëµ",
            }

        # 4. ë°ì´í„° ì™„ì „ì„± ê²€ì¦
        total_checks += 1
        invoice_completeness = (
            (
                matched_invoice.notna().sum().sum()
                / (len(matched_invoice) * len(matched_invoice.columns))
            )
            * 100
            if len(matched_invoice) > 0
            else 0
        )
        warehouse_completeness = (
            (
                matched_warehouse.notna().sum().sum()
                / (len(matched_warehouse) * len(matched_warehouse.columns))
            )
            * 100
            if len(matched_warehouse) > 0
            else 0
        )
        average_completeness = (invoice_completeness + warehouse_completeness) / 2

        if average_completeness >= 80:
            validation_result["checks"]["data_completeness"] = {
                "status": "PASS",
                "message": f"ë°ì´í„° ì™„ì „ì„± {average_completeness:.1%}",
            }
            passed_checks += 1
        else:
            validation_result["checks"]["data_completeness"] = {
                "status": "WARNING",
                "message": f"ë°ì´í„° ì™„ì „ì„± ë‚®ìŒ {average_completeness:.1%}",
            }

        # ë°ì´í„° ì™„ì „ì„± ìƒì„¸ ì •ë³´ ì €ì¥
        validation_result["details"]["data_completeness"] = {
            "invoice_completeness": invoice_completeness,
            "warehouse_completeness": warehouse_completeness,
            "average_completeness": average_completeness,
        }

        # 5. ë‚ ì§œ ì¼ê´€ì„± ê²€ì¦
        total_checks += 1
        # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸°
        invoice_date_cols = [
            col
            for col in matched_invoice.columns
            if "date" in col.lower() or "month" in col.lower()
        ]
        warehouse_date_cols = [
            col
            for col in matched_warehouse.columns
            if "date" in col.lower() or "month" in col.lower()
        ]

        if invoice_date_cols and warehouse_date_cols:
            # ì²­êµ¬ì„œ ë‚ ì§œ ë²”ìœ„
            invoice_dates = pd.to_datetime(
                matched_invoice[invoice_date_cols[0]], errors="coerce"
            ).dropna()
            invoice_date_range = (
                (invoice_dates.min(), invoice_dates.max())
                if len(invoice_dates) > 0
                else (None, None)
            )

            # ì°½ê³  ë‚ ì§œ ë²”ìœ„
            warehouse_dates = pd.to_datetime(
                matched_warehouse[warehouse_date_cols[0]], errors="coerce"
            ).dropna()
            warehouse_date_range = (
                (warehouse_dates.min(), warehouse_dates.max())
                if len(warehouse_dates) > 0
                else (None, None)
            )

            # ë‚ ì§œ ë²”ìœ„ ê²¹ì¹¨ í™•ì¸
            overlap = False
            overlap_range = (None, None)

            if invoice_date_range[0] and warehouse_date_range[0]:
                overlap_start = max(invoice_date_range[0], warehouse_date_range[0])
                overlap_end = min(invoice_date_range[1], warehouse_date_range[1])
                overlap = overlap_start <= overlap_end
                overlap_range = (
                    (overlap_start, overlap_end) if overlap else (None, None)
                )

            if overlap:
                validation_result["checks"]["date_consistency"] = {
                    "status": "PASS",
                    "message": "ë‚ ì§œ ë²”ìœ„ ì¼ê´€ì„± í™•ì¸",
                }
                passed_checks += 1
            else:
                validation_result["checks"]["date_consistency"] = {
                    "status": "WARNING",
                    "message": "ë‚ ì§œ ë²”ìœ„ ë¶ˆì¼ì¹˜",
                }

            # ë‚ ì§œ ì¼ê´€ì„± ìƒì„¸ ì •ë³´ ì €ì¥
            validation_result["details"]["date_consistency"] = {
                "invoice_date_range": invoice_date_range,
                "warehouse_date_range": warehouse_date_range,
                "overlap": overlap,
                "overlap_range": overlap_range,
            }
        else:
            validation_result["checks"]["date_consistency"] = {
                "status": "SKIP",
                "message": "ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê²€ì¦ ìƒëµ",
            }

        # ì „ì²´ ì ìˆ˜ ê³„ì‚°
        validation_result["score"] = (
            passed_checks / total_checks if total_checks > 0 else 0
        )

        # ìƒíƒœ ê²°ì •
        if validation_result["score"] >= 0.8:
            validation_result["status"] = "PASS"
        elif validation_result["score"] >= 0.6:
            validation_result["status"] = "WARNING"
        else:
            validation_result["status"] = "FAIL"

        logger.info(f"âœ… êµì°¨ ê²€ì¦ ì™„ë£Œ - ì ìˆ˜: {validation_result['score']:.3f}")
        logger.info(
            f"  ğŸ“Š ë§¤ì¹­ëœ ì•„ì´í…œ: {len(matched_items)}/{len(invoice_items)} ({match_rate:.1%})"
        )
        logger.info(
            f"  ğŸ“‹ ì²­êµ¬ì„œ ì „ìš©: {len(invoice_only)}ê±´, ì°½ê³  ì „ìš©: {len(warehouse_only)}ê±´"
        )

        return validation_result

    def _validate_compliance(
        self, invoice_df: pd.DataFrame, warehouse_df: pd.DataFrame
    ) -> Dict[str, Any]:
        """ê·œì • ì¤€ìˆ˜ ê²€ì¦ - ë¹„í™œì„±í™”ë¨"""
        logger.info("ğŸ” ê·œì • ì¤€ìˆ˜ ê²€ì¦ ë¹„í™œì„±í™”ë¨")

        validation_result = {
            "status": "PASS",
            "score": 1.0,  # í•­ìƒ í†µê³¼
            "checks": {},
            "errors": [],
            "warnings": ["ê·œì • ì¤€ìˆ˜ ê²€ì¦ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤."],
        }

        validation_result["checks"]["compliance_disabled"] = {
            "status": "PASS",
            "message": "ê·œì • ì¤€ìˆ˜ ê²€ì¦ ë¹„í™œì„±í™”ë¨",
        }

        logger.info(
            f"âœ… ê·œì • ì¤€ìˆ˜ ê²€ì¦ ë¹„í™œì„±í™” - ì ìˆ˜: {validation_result['score']:.3f}"
        )
        return validation_result

    def _calculate_overall_validation(
        self,
        invoice_validation: Dict,
        warehouse_validation: Dict,
        cross_validation: Dict,
        compliance_validation: Dict,
    ) -> Dict[str, Any]:
        """ì „ì²´ ê²€ì¦ ê²°ê³¼ ê³„ì‚°"""
        logger.info("ğŸ” ì „ì²´ ê²€ì¦ ê²°ê³¼ ê³„ì‚° ì¤‘...")

        # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°
        weights = {"invoice": 0.3, "warehouse": 0.3, "cross": 0.25, "compliance": 0.15}

        total_score = (
            invoice_validation["score"] * weights["invoice"]
            + warehouse_validation["score"] * weights["warehouse"]
            + cross_validation["score"] * weights["cross"]
            + compliance_validation["score"] * weights["compliance"]
        )

        # ë“±ê¸‰ ê²°ì •
        if total_score >= 0.95:
            grade = "A+"
        elif total_score >= 0.90:
            grade = "A"
        elif total_score >= 0.85:
            grade = "B+"
        elif total_score >= 0.80:
            grade = "B"
        else:
            grade = "C"

        overall_validation = {
            "total_score": total_score,
            "grade": grade,
            "status": "PASS" if total_score >= 0.85 else "FAIL",
            "target_achieved": total_score >= self.config.confidence_threshold,
            "component_scores": {
                "invoice": invoice_validation["score"],
                "warehouse": warehouse_validation["score"],
                "cross": cross_validation["score"],
                "compliance": compliance_validation["score"],
            },
            "summary": {
                "total_checks": 0,
                "passed_checks": 0,
                "failed_checks": 0,
                "warning_checks": 0,
            },
        }

        # ìš”ì•½ í†µê³„ ê³„ì‚°
        all_validations = [
            invoice_validation,
            warehouse_validation,
            cross_validation,
            compliance_validation,
        ]
        for validation in all_validations:
            for check_name, check_result in validation["checks"].items():
                overall_validation["summary"]["total_checks"] += 1
                if check_result["status"] == "PASS":
                    overall_validation["summary"]["passed_checks"] += 1
                elif check_result["status"] == "FAIL":
                    overall_validation["summary"]["failed_checks"] += 1
                elif check_result["status"] == "WARNING":
                    overall_validation["summary"]["warning_checks"] += 1

        logger.info(
            f"âœ… ì „ì²´ ê²€ì¦ ê²°ê³¼ ê³„ì‚° ì™„ë£Œ - ì ìˆ˜: {total_score:.3f}, ë“±ê¸‰: {grade}"
        )
        return overall_validation

    def _generate_report_files(
        self,
        timestamp: str,
        invoice_validation: Dict,
        warehouse_validation: Dict,
        cross_validation: Dict,
        compliance_validation: Dict,
        overall_validation: Dict,
    ) -> Dict[str, str]:
        """ë¦¬í¬íŠ¸ íŒŒì¼ ìƒì„±"""
        logger.info("ğŸ“„ ë¦¬í¬íŠ¸ íŒŒì¼ ìƒì„± ì¤‘...")

        generated_files = {}

        # 1. PDF ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        if self.config.generate_pdf and REPORTLAB_AVAILABLE:
            pdf_file = self._generate_pdf_report(
                timestamp,
                invoice_validation,
                warehouse_validation,
                cross_validation,
                compliance_validation,
                overall_validation,
            )
            generated_files["pdf_summary"] = str(pdf_file)
        elif self.config.generate_pdf and not REPORTLAB_AVAILABLE:
            logger.warning(
                "PDF ë³´ê³ ì„œ ìƒì„±ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (reportlab íŒ¨í‚¤ì§€ ì—†ìŒ)"
            )

        # 2. Excel ìƒì„¸ ê²°ê³¼ ìƒì„±
        if self.config.generate_excel:
            excel_file = self._generate_excel_report(
                timestamp,
                invoice_validation,
                warehouse_validation,
                cross_validation,
                compliance_validation,
                overall_validation,
            )
            generated_files["excel_detailed"] = str(excel_file)

        # 3. RDF TTL íŒŒì¼ ìƒì„±
        if self.config.generate_rdf and RDF_AVAILABLE:
            rdf_file = self._generate_rdf_report(
                timestamp,
                invoice_validation,
                warehouse_validation,
                cross_validation,
                compliance_validation,
                overall_validation,
            )
            generated_files["rdf_ontology"] = str(rdf_file)
        elif self.config.generate_rdf and not RDF_AVAILABLE:
            logger.warning(
                "RDF TTL íŒŒì¼ ìƒì„±ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤ (rdflib íŒ¨í‚¤ì§€ ì—†ìŒ)"
            )

        logger.info(f"âœ… ë¦¬í¬íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ: {len(generated_files)}ê°œ íŒŒì¼")
        return generated_files

    def _generate_pdf_report(
        self,
        timestamp: str,
        invoice_validation: Dict,
        warehouse_validation: Dict,
        cross_validation: Dict,
        compliance_validation: Dict,
        overall_validation: Dict,
    ) -> Path:
        """PDF ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        pdf_file = self.output_dir / f"validation_summary_report_{timestamp}.pdf"

        doc = SimpleDocTemplate(str(pdf_file), pagesize=A4)
        story = []

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        styles = getSampleStyleSheet()
        title_style = ParagraphStyle(
            "CustomTitle",
            parent=styles["Heading1"],
            fontSize=16,
            spaceAfter=30,
            alignment=1,  # ì¤‘ì•™ ì •ë ¬
        )

        # ì œëª©
        story.append(Paragraph("MACHO-GPT v3.4-mini ê²€ì¦ ë¦¬í¬íŠ¸", title_style))
        story.append(Spacer(1, 20))

        # ìš”ì•½ ì •ë³´
        summary_data = [
            ["ê²€ì¦ í•­ëª©", "ìƒíƒœ", "ì ìˆ˜", "ë“±ê¸‰"],
            [
                "ì „ì²´ ê²€ì¦",
                overall_validation["status"],
                f"{overall_validation['total_score']:.3f}",
                overall_validation["grade"],
            ],
            [
                "ì²­êµ¬ì„œ ê²€ì¦",
                invoice_validation["status"],
                f"{invoice_validation['score']:.3f}",
                "",
            ],
            [
                "ì°½ê³  ê²€ì¦",
                warehouse_validation["status"],
                f"{warehouse_validation['score']:.3f}",
                "",
            ],
            [
                "êµì°¨ ê²€ì¦",
                cross_validation["status"],
                f"{cross_validation['score']:.3f}",
                "",
            ],
            [
                "ê·œì • ì¤€ìˆ˜",
                compliance_validation["status"],
                f"{compliance_validation['score']:.3f}",
                "",
            ],
        ]

        summary_table = Table(summary_data)
        summary_table.setStyle(
            TableStyle(
                [
                    ("BACKGROUND", (0, 0), (-1, 0), colors.grey),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.whitesmoke),
                    ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                    ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                    ("FONTSIZE", (0, 0), (-1, 0), 12),
                    ("BOTTOMPADDING", (0, 0), (-1, 0), 12),
                    ("BACKGROUND", (0, 1), (-1, -1), colors.beige),
                    ("GRID", (0, 0), (-1, -1), 1, colors.black),
                ]
            )
        )

        story.append(summary_table)
        story.append(Spacer(1, 20))

        # ìƒì„¸ ê²€ì¦ ê²°ê³¼
        story.append(Paragraph("ìƒì„¸ ê²€ì¦ ê²°ê³¼", styles["Heading2"]))
        story.append(Spacer(1, 12))

        for validation_name, validation_data in [
            ("ì²­êµ¬ì„œ ê²€ì¦", invoice_validation),
            ("ì°½ê³  ê²€ì¦", warehouse_validation),
            ("êµì°¨ ê²€ì¦", cross_validation),
            ("ê·œì • ì¤€ìˆ˜", compliance_validation),
        ]:
            story.append(
                Paragraph(
                    f"{validation_name}: {validation_data['status']}",
                    styles["Heading3"],
                )
            )

            for check_name, check_result in validation_data["checks"].items():
                status_color = (
                    "green"
                    if check_result["status"] == "PASS"
                    else "red" if check_result["status"] == "FAIL" else "orange"
                )
                story.append(
                    Paragraph(
                        f"â€¢ {check_name}: {check_result['status']} - {check_result['message']}",
                        ParagraphStyle(
                            "CheckResult",
                            parent=styles["Normal"],
                            textColor=colors.HexColor(status_color),
                        ),
                    )
                )

            story.append(Spacer(1, 12))

        # ë¹Œë“œ ë° ì €ì¥
        doc.build(story)
        logger.info(f"âœ… PDF ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {pdf_file}")
        return pdf_file

    def _generate_excel_report(
        self,
        timestamp: str,
        invoice_validation: Dict,
        warehouse_validation: Dict,
        cross_validation: Dict,
        compliance_validation: Dict,
        overall_validation: Dict,
    ) -> Path:
        """Excel ìƒì„¸ ê²°ê³¼ ìƒì„±"""
        excel_file = self.output_dir / f"validation_detailed_report_{timestamp}.xlsx"

        with pd.ExcelWriter(excel_file, engine="openpyxl") as writer:

            # 1. ìš”ì•½ ì‹œíŠ¸
            summary_data = {
                "ê²€ì¦ í•­ëª©": [
                    "ì „ì²´ ì ìˆ˜",
                    "ë“±ê¸‰",
                    "ìƒíƒœ",
                    "ëª©í‘œ ë‹¬ì„±",
                    "ì²­êµ¬ì„œ ê²€ì¦",
                    "ì°½ê³  ê²€ì¦",
                    "êµì°¨ ê²€ì¦",
                    "ê·œì • ì¤€ìˆ˜",
                    "ì´ ê²€ì¦ ìˆ˜",
                    "í†µê³¼",
                    "ì‹¤íŒ¨",
                    "ê²½ê³ ",
                ],
                "ê²°ê³¼": [
                    f"{overall_validation['total_score']:.3f}",
                    overall_validation["grade"],
                    overall_validation["status"],
                    "âœ…" if overall_validation["target_achieved"] else "âŒ",
                    f"{invoice_validation['score']:.3f}",
                    f"{warehouse_validation['score']:.3f}",
                    f"{cross_validation['score']:.3f}",
                    f"{compliance_validation['score']:.3f}",
                    overall_validation["summary"]["total_checks"],
                    overall_validation["summary"]["passed_checks"],
                    overall_validation["summary"]["failed_checks"],
                    overall_validation["summary"]["warning_checks"],
                ],
            }
            pd.DataFrame(summary_data).to_excel(writer, sheet_name="ìš”ì•½", index=False)

            # 2. ì²­êµ¬ì„œ ê²€ì¦ ìƒì„¸
            invoice_details = []
            for check_name, check_result in invoice_validation["checks"].items():
                invoice_details.append(
                    {
                        "ê²€ì¦ í•­ëª©": check_name,
                        "ìƒíƒœ": check_result["status"],
                        "ë©”ì‹œì§€": check_result["message"],
                    }
                )
            pd.DataFrame(invoice_details).to_excel(
                writer, sheet_name="ì²­êµ¬ì„œ_ê²€ì¦", index=False
            )

            # 3. ì°½ê³  ê²€ì¦ ìƒì„¸
            warehouse_details = []
            for check_name, check_result in warehouse_validation["checks"].items():
                warehouse_details.append(
                    {
                        "ê²€ì¦ í•­ëª©": check_name,
                        "ìƒíƒœ": check_result["status"],
                        "ë©”ì‹œì§€": check_result["message"],
                    }
                )
            pd.DataFrame(warehouse_details).to_excel(
                writer, sheet_name="ì°½ê³ _ê²€ì¦", index=False
            )

            # 4. êµì°¨ ê²€ì¦ ìƒì„¸
            cross_details = []
            for check_name, check_result in cross_validation["checks"].items():
                cross_details.append(
                    {
                        "ê²€ì¦ í•­ëª©": check_name,
                        "ìƒíƒœ": check_result["status"],
                        "ë©”ì‹œì§€": check_result["message"],
                    }
                )
            pd.DataFrame(cross_details).to_excel(
                writer, sheet_name="êµì°¨_ê²€ì¦", index=False
            )

            # 5. êµì°¨ ê²€ì¦ ìƒì„¸ í†µê³„
            if "details" in cross_validation:
                cross_stats = []

                # ì•„ì´í…œ ë§¤ì¹­ í†µê³„
                if "item_matching" in cross_validation["details"]:
                    item_stats = cross_validation["details"]["item_matching"]
                    cross_stats.extend(
                        [
                            {
                                "í†µê³„ í•­ëª©": "ì•„ì´í…œ ë§¤ì¹­ - ì´ ì²­êµ¬ì„œ ì•„ì´í…œ",
                                "ê°’": item_stats["total_invoice_items"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ì•„ì´í…œ ë§¤ì¹­ - ì´ ì°½ê³  ì•„ì´í…œ",
                                "ê°’": item_stats["total_warehouse_items"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ì•„ì´í…œ ë§¤ì¹­ - ë§¤ì¹­ëœ ì•„ì´í…œ",
                                "ê°’": item_stats["matched_items"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ì•„ì´í…œ ë§¤ì¹­ - ì²­êµ¬ì„œ ì „ìš©",
                                "ê°’": item_stats["invoice_only"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ì•„ì´í…œ ë§¤ì¹­ - ì°½ê³  ì „ìš©",
                                "ê°’": item_stats["warehouse_only"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ì•„ì´í…œ ë§¤ì¹­ - ë§¤ì¹­ë¥ ",
                                "ê°’": f"{item_stats['match_rate']:.1%}",
                            },
                        ]
                    )

                # HVDC CODE ë§¤ì¹­ í†µê³„
                if "hvdccode_matching" in cross_validation["details"]:
                    hvdccode_stats = cross_validation["details"]["hvdccode_matching"]
                    cross_stats.extend(
                        [
                            {
                                "í†µê³„ í•­ëª©": "HVDC CODE - ì´ ë¹„êµ í•­ëª©",
                                "ê°’": hvdccode_stats["total_compared"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "HVDC CODE - ì¼ì¹˜ í•­ëª©",
                                "ê°’": hvdccode_stats["matches"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "HVDC CODE - ë¶ˆì¼ì¹˜ í•­ëª©",
                                "ê°’": hvdccode_stats["mismatches"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "HVDC CODE - ì¼ì¹˜ë¥ ",
                                "ê°’": f"{hvdccode_stats['match_rate']:.1%}",
                            },
                        ]
                    )

                # ìˆ˜ëŸ‰ ë§¤ì¹­ í†µê³„
                if "quantity_matching" in cross_validation["details"]:
                    qty_stats = cross_validation["details"]["quantity_matching"]
                    cross_stats.extend(
                        [
                            {
                                "í†µê³„ í•­ëª©": "ìˆ˜ëŸ‰ ë§¤ì¹­ - ì´ ë¹„êµ í•­ëª©",
                                "ê°’": qty_stats["total_compared"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ìˆ˜ëŸ‰ ë§¤ì¹­ - ì¼ì¹˜ í•­ëª©",
                                "ê°’": qty_stats["matches"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ìˆ˜ëŸ‰ ë§¤ì¹­ - ë¶ˆì¼ì¹˜ í•­ëª©",
                                "ê°’": qty_stats["mismatches"],
                            },
                            {
                                "í†µê³„ í•­ëª©": "ìˆ˜ëŸ‰ ë§¤ì¹­ - ì¼ì¹˜ë¥ ",
                                "ê°’": f"{qty_stats['match_rate']:.1%}",
                            },
                        ]
                    )

                # ë°ì´í„° ì™„ì „ì„± í†µê³„
                if "data_completeness" in cross_validation["details"]:
                    completeness_stats = cross_validation["details"][
                        "data_completeness"
                    ]
                    cross_stats.extend(
                        [
                            {
                                "í†µê³„ í•­ëª©": "ë°ì´í„° ì™„ì „ì„± - ì²­êµ¬ì„œ",
                                "ê°’": f"{completeness_stats['invoice_completeness']:.1%}",
                            },
                            {
                                "í†µê³„ í•­ëª©": "ë°ì´í„° ì™„ì „ì„± - ì°½ê³ ",
                                "ê°’": f"{completeness_stats['warehouse_completeness']:.1%}",
                            },
                            {
                                "í†µê³„ í•­ëª©": "ë°ì´í„° ì™„ì „ì„± - í‰ê· ",
                                "ê°’": f"{completeness_stats['average_completeness']:.1%}",
                            },
                        ]
                    )

                # ë‚ ì§œ ì¼ê´€ì„± í†µê³„
                if "date_consistency" in cross_validation["details"]:
                    date_stats = cross_validation["details"]["date_consistency"]
                    cross_stats.extend(
                        [
                            {
                                "í†µê³„ í•­ëª©": "ë‚ ì§œ ì¼ê´€ì„± - ì²­êµ¬ì„œ ë²”ìœ„",
                                "ê°’": f"{date_stats['invoice_date_range'][0]} ~ {date_stats['invoice_date_range'][1]}",
                            },
                            {
                                "í†µê³„ í•­ëª©": "ë‚ ì§œ ì¼ê´€ì„± - ì°½ê³  ë²”ìœ„",
                                "ê°’": f"{date_stats['warehouse_date_range'][0]} ~ {date_stats['warehouse_date_range'][1]}",
                            },
                            {
                                "í†µê³„ í•­ëª©": "ë‚ ì§œ ì¼ê´€ì„± - ê²¹ì¹¨ ì—¬ë¶€",
                                "ê°’": "ì˜ˆ" if date_stats["overlap"] else "ì•„ë‹ˆì˜¤",
                            },
                            {
                                "í†µê³„ í•­ëª©": "ë‚ ì§œ ì¼ê´€ì„± - ê²¹ì¹¨ ë²”ìœ„",
                                "ê°’": (
                                    f"{date_stats['overlap_range'][0]} ~ {date_stats['overlap_range'][1]}"
                                    if date_stats["overlap"]
                                    else "í•´ë‹¹ì—†ìŒ"
                                ),
                            },
                        ]
                    )

                pd.DataFrame(cross_stats).to_excel(
                    writer, sheet_name="êµì°¨_ê²€ì¦_í†µê³„", index=False
                )

            # 6. HVDC CODE ë¶ˆì¼ì¹˜ ìƒì„¸
            if (
                "details" in cross_validation
                and "hvdccode_matching" in cross_validation["details"]
            ):
                hvdccode_mismatches = cross_validation["details"][
                    "hvdccode_matching"
                ].get("mismatch_details", [])
                if hvdccode_mismatches:
                    mismatch_df = pd.DataFrame(hvdccode_mismatches)
                    mismatch_df.to_excel(
                        writer, sheet_name="HVDC_CODE_ë¶ˆì¼ì¹˜", index=False
                    )
                else:
                    # ë¶ˆì¼ì¹˜ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ì‹œíŠ¸ ìƒì„±
                    pd.DataFrame(
                        {"ë©”ì‹œì§€": ["HVDC CODE ë¶ˆì¼ì¹˜ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."]}
                    ).to_excel(writer, sheet_name="HVDC_CODE_ë¶ˆì¼ì¹˜", index=False)

            # 7. ìˆ˜ëŸ‰ ë¶ˆì¼ì¹˜ ìƒì„¸
            if (
                "details" in cross_validation
                and "quantity_matching" in cross_validation["details"]
            ):
                qty_mismatches = cross_validation["details"]["quantity_matching"].get(
                    "mismatch_details", []
                )
                if qty_mismatches:
                    qty_mismatch_df = pd.DataFrame(qty_mismatches)
                    qty_mismatch_df.to_excel(
                        writer, sheet_name="ìˆ˜ëŸ‰_ë¶ˆì¼ì¹˜", index=False
                    )
                else:
                    # ë¶ˆì¼ì¹˜ê°€ ì—†ëŠ” ê²½ìš° ë¹ˆ ì‹œíŠ¸ ìƒì„±
                    pd.DataFrame({"ë©”ì‹œì§€": ["ìˆ˜ëŸ‰ ë¶ˆì¼ì¹˜ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤."]}).to_excel(
                        writer, sheet_name="ìˆ˜ëŸ‰_ë¶ˆì¼ì¹˜", index=False
                    )

            # 8. ì²­êµ¬ì„œ ì „ìš© ì•„ì´í…œ
            if (
                "details" in cross_validation
                and "item_matching" in cross_validation["details"]
            ):
                invoice_only_count = cross_validation["details"]["item_matching"].get(
                    "invoice_only", 0
                )
                if invoice_only_count > 0:
                    pd.DataFrame(
                        {
                            "ë©”ì‹œì§€": [
                                f"ì²­êµ¬ì„œì—ë§Œ ì¡´ì¬í•˜ëŠ” ì•„ì´í…œ: {invoice_only_count}ê±´"
                            ]
                        }
                    ).to_excel(writer, sheet_name="ì²­êµ¬ì„œ_ì „ìš©_ì•„ì´í…œ", index=False)
                else:
                    pd.DataFrame(
                        {"ë©”ì‹œì§€": ["ì²­êµ¬ì„œ ì „ìš© ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤."]}
                    ).to_excel(writer, sheet_name="ì²­êµ¬ì„œ_ì „ìš©_ì•„ì´í…œ", index=False)

            # 9. ì°½ê³  ì „ìš© ì•„ì´í…œ
            if (
                "details" in cross_validation
                and "item_matching" in cross_validation["details"]
            ):
                warehouse_only_count = cross_validation["details"]["item_matching"].get(
                    "warehouse_only", 0
                )
                if warehouse_only_count > 0:
                    pd.DataFrame(
                        {
                            "ë©”ì‹œì§€": [
                                f"ì°½ê³ ì—ë§Œ ì¡´ì¬í•˜ëŠ” ì•„ì´í…œ: {warehouse_only_count}ê±´"
                            ]
                        }
                    ).to_excel(writer, sheet_name="ì°½ê³ _ì „ìš©_ì•„ì´í…œ", index=False)
                else:
                    pd.DataFrame({"ë©”ì‹œì§€": ["ì°½ê³  ì „ìš© ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤."]}).to_excel(
                        writer, sheet_name="ì°½ê³ _ì „ìš©_ì•„ì´í…œ", index=False
                    )

            # 10. ê·œì • ì¤€ìˆ˜ ê²€ì¦ ìƒì„¸
            compliance_details = []
            for check_name, check_result in compliance_validation["checks"].items():
                compliance_details.append(
                    {
                        "ê²€ì¦ í•­ëª©": check_name,
                        "ìƒíƒœ": check_result["status"],
                        "ë©”ì‹œì§€": check_result["message"],
                    }
                )
            pd.DataFrame(compliance_details).to_excel(
                writer, sheet_name="ê·œì •_ì¤€ìˆ˜_ê²€ì¦", index=False
            )

            # 11. ì˜¤ë¥˜ ë° ê²½ê³  ëª©ë¡
            all_errors = []
            all_warnings = []

            # ëª¨ë“  ê²€ì¦ì—ì„œ ì˜¤ë¥˜ì™€ ê²½ê³  ìˆ˜ì§‘
            for validation_name, validation_data in [
                ("ì²­êµ¬ì„œ", invoice_validation),
                ("ì°½ê³ ", warehouse_validation),
                ("êµì°¨", cross_validation),
                ("ê·œì •ì¤€ìˆ˜", compliance_validation),
            ]:
                for error in validation_data.get("errors", []):
                    all_errors.append(
                        {"ê²€ì¦ ìœ í˜•": validation_name, "ì˜¤ë¥˜ ë‚´ìš©": error}
                    )
                for warning in validation_data.get("warnings", []):
                    all_warnings.append(
                        {"ê²€ì¦ ìœ í˜•": validation_name, "ê²½ê³  ë‚´ìš©": warning}
                    )

            if all_errors:
                pd.DataFrame(all_errors).to_excel(
                    writer, sheet_name="ì˜¤ë¥˜_ëª©ë¡", index=False
                )
            else:
                pd.DataFrame({"ë©”ì‹œì§€": ["ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤."]}).to_excel(
                    writer, sheet_name="ì˜¤ë¥˜_ëª©ë¡", index=False
                )

            if all_warnings:
                pd.DataFrame(all_warnings).to_excel(
                    writer, sheet_name="ê²½ê³ _ëª©ë¡", index=False
                )
            else:
                pd.DataFrame({"ë©”ì‹œì§€": ["ê²½ê³ ê°€ ì—†ìŠµë‹ˆë‹¤."]}).to_excel(
                    writer, sheet_name="ê²½ê³ _ëª©ë¡", index=False
                )

        logger.info(f"âœ… Excel ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {excel_file}")
        return excel_file

    def _generate_rdf_report(
        self,
        timestamp: str,
        invoice_validation: Dict,
        warehouse_validation: Dict,
        cross_validation: Dict,
        compliance_validation: Dict,
        overall_validation: Dict,
    ) -> Path:
        """RDF TTL íŒŒì¼ ìƒì„±"""
        rdf_file = self.output_dir / f"validation_ontology_{timestamp}.ttl"

        # RDF ê·¸ë˜í”„ ìƒì„±
        g = Graph()
        g.bind("logi", self.LOGI)
        g.bind("hvdc", self.HVDC)
        g.bind("fanr", self.FANR)

        # ê²€ì¦ ê²°ê³¼ë¥¼ RDF íŠ¸ë¦¬í”Œë¡œ ë³€í™˜
        validation_uri = URIRef(f"http://macho-gpt.com/validation/{timestamp}")

        # ê²€ì¦ ë©”íƒ€ë°ì´í„°
        g.add((validation_uri, RDF.type, self.LOGI.ValidationReport))
        g.add(
            (validation_uri, self.LOGI.timestamp, Literal(datetime.now().isoformat()))
        )
        g.add(
            (
                validation_uri,
                self.LOGI.totalScore,
                Literal(overall_validation["total_score"], datatype=XSD.float),
            )
        )
        g.add((validation_uri, self.LOGI.grade, Literal(overall_validation["grade"])))
        g.add((validation_uri, self.LOGI.status, Literal(overall_validation["status"])))

        # ì»´í¬ë„ŒíŠ¸ ì ìˆ˜
        for component, score in overall_validation["component_scores"].items():
            component_uri = URIRef(
                f"http://macho-gpt.com/validation/{timestamp}#{component}"
            )
            g.add((component_uri, RDF.type, self.LOGI.ValidationComponent))
            g.add((component_uri, self.LOGI.componentType, Literal(component)))
            g.add((component_uri, self.LOGI.score, Literal(score, datatype=XSD.float)))
            g.add((validation_uri, self.LOGI.hasComponent, component_uri))

        # ê²€ì¦ ì²´í¬ ê²°ê³¼
        all_validations = [
            ("invoice", invoice_validation),
            ("warehouse", warehouse_validation),
            ("cross", cross_validation),
            ("compliance", compliance_validation),
        ]

        for validation_type, validation_data in all_validations:
            for check_name, check_result in validation_data["checks"].items():
                check_uri = URIRef(
                    f"http://macho-gpt.com/validation/{timestamp}#{validation_type}_{check_name}"
                )
                g.add((check_uri, RDF.type, self.LOGI.ValidationCheck))
                g.add((check_uri, self.LOGI.checkName, Literal(check_name)))
                g.add((check_uri, self.LOGI.status, Literal(check_result["status"])))
                g.add((check_uri, self.LOGI.message, Literal(check_result["message"])))
                g.add((validation_uri, self.LOGI.hasCheck, check_uri))

        # TTL íŒŒì¼ ì €ì¥
        g.serialize(destination=str(rdf_file), format="turtle")
        logger.info(f"âœ… RDF TTL íŒŒì¼ ìƒì„± ì™„ë£Œ: {rdf_file}")
        return rdf_file

    def _generate_recommendations(
        self, overall_validation: Dict[str, Any]
    ) -> List[str]:
        """ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if overall_validation["total_score"] < 0.9:
            recommendations.append("ì „ì²´ ê²€ì¦ ì ìˆ˜ ê°œì„  í•„ìš” - ë°ì´í„° í’ˆì§ˆ í–¥ìƒ ê¶Œê³ ")

        if overall_validation["component_scores"]["invoice"] < 0.9:
            recommendations.append(
                "ì²­êµ¬ì„œ ë°ì´í„° ê²€ì¦ ê°•í™” í•„ìš” - í•„ìˆ˜ ì»¬ëŸ¼ ë° ê³„ì‚° ì •í™•ë„ í™•ì¸"
            )

        if overall_validation["component_scores"]["warehouse"] < 0.9:
            recommendations.append(
                "ì°½ê³  ë°ì´í„° ê²€ì¦ ê°•í™” í•„ìš” - ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ êµ¬ì¡° í™•ì¸"
            )

        if overall_validation["component_scores"]["cross"] < 0.8:
            recommendations.append(
                "êµì°¨ ê²€ì¦ ê°œì„  í•„ìš” - ì•„ì´í…œ ë§¤ì¹­ ë° ìˆ˜ëŸ‰ ì¼ì¹˜ì„± í™•ì¸"
            )

        if overall_validation["component_scores"]["compliance"] < 0.8:
            recommendations.append(
                "ê·œì • ì¤€ìˆ˜ ê²€ì¦ ê°•í™” í•„ìš” - FANR/MOIAT ìš”êµ¬ì‚¬í•­ í™•ì¸"
            )

        if overall_validation["total_score"] >= 0.95:
            recommendations.append("ê²€ì¦ ê²°ê³¼ ìš°ìˆ˜ - ì •ê¸°ì  ëª¨ë‹ˆí„°ë§ ìœ ì§€ ê¶Œê³ ")

        return recommendations

    def _suggest_next_actions(self, overall_validation: Dict[str, Any]) -> List[str]:
        """ë‹¤ìŒ ì•¡ì…˜ ì œì•ˆ"""
        if overall_validation["target_achieved"]:
            return [
                "/test-scenario validation-compliance",
                "/monitor-kpi validation-performance",
                "/automate validation-pipeline",
            ]
        else:
            return [
                "/tune-reliability validation-improvement",
                "/optimize-performance validation-process",
                "/enhance-compliance validation-requirements",
            ]

    def _create_error_response(self, error_message: str) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return {
            "command": "generate_validation_report",
            "execution_time": datetime.now().isoformat(),
            "status": "ERROR",
            "error_message": error_message,
            "recommendations": ["íŒŒì¼ ê²½ë¡œ í™•ì¸", "íŒŒì¼ í˜•ì‹ ê²€ì¦", "ê¶Œí•œ í™•ì¸"],
            "next_actions": ["/validate-data file-format", "/check-file-permissions"],
        }


# ëª…ë ¹ì–´ ì²˜ë¦¬ í•¨ìˆ˜
def generate_validation_report(
    invoice_file: str, warehouse_file: str, config: ValidationConfig = None
) -> Dict[str, Any]:
    """
    /generate-validation-report ëª…ë ¹ì–´ ì²˜ë¦¬

    Args:
        invoice_file: ì²­êµ¬ì„œ ì›ë³¸ íŒŒì¼ ê²½ë¡œ
        warehouse_file: í™”ë¬¼ ì…ì¶œê³  ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ
        config: ê²€ì¦ ì„¤ì •

    Returns:
        ê²€ì¦ ê²°ê³¼ ë° ìƒì„±ëœ íŒŒì¼ ê²½ë¡œë“¤
    """
    logger.info("ğŸ“‹ /generate-validation-report ëª…ë ¹ì–´ ì‹¤í–‰")

    generator = ValidationReportGenerator(config)
    return generator.generate_validation_report(invoice_file, warehouse_file)


if __name__ == "__main__":
    # ì§ì ‘ ì‹¤í–‰ì‹œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    print("ğŸš€ MACHO-GPT v3.4-mini ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ")
    print("=" * 70)

    # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ì‹¤ì œ íŒŒì¼ë¡œ êµì²´ í•„ìš”)
    test_invoice_file = "../data/HVDC_WAREHOUSE_INVOICE_CLEANED_20250709_201121.xlsx"
    test_warehouse_file = "../data/HVDC WAREHOUSE_HITACHI(HE).xlsx"

    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(test_invoice_file):
        print(f"âŒ ì²­êµ¬ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_invoice_file}")
        print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼:")
        for file in Path("../data").glob("*.xlsx"):
            print(f"  - {file}")
    elif not os.path.exists(test_warehouse_file):
        print(f"âŒ ì°½ê³  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_warehouse_file}")
        print("ğŸ“ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼:")
        for file in Path("../data").glob("*.xlsx"):
            print(f"  - {file}")
    else:
        # ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        result = generate_validation_report(test_invoice_file, test_warehouse_file)

        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "=" * 80)
        print("ğŸ“‹ MACHO-GPT ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ê²°ê³¼")
        print("=" * 80)
        print(
            f"ì „ì²´ ì ìˆ˜: {result['validation_results']['overall_validation']['total_score']:.3f}"
        )
        print(f"ë“±ê¸‰: {result['validation_results']['overall_validation']['grade']}")
        print(f"ìƒíƒœ: {result['validation_results']['overall_validation']['status']}")

        print("\nğŸ“„ ìƒì„±ëœ íŒŒì¼:")
        for file_type, file_path in result["generated_files"].items():
            print(f"  - {file_type}: {file_path}")

        print("\nğŸ”§ ì¶”ì²œ ëª…ë ¹ì–´:")
        for cmd in result["next_actions"]:
            print(f"  {cmd}")

        print("=" * 80)
