#!/usr/bin/env python3
"""
MACHO-GPT v3.4-mini ë°ì´í„° ê¸°ë°˜ íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„±ê¸°
- ì‹¤ì œ HVDC ë°ì´í„° 13,384ê±´ ê¸°ë°˜ íŠ¸ëœì­ì…˜ ë¶„ì„
- ì˜¨í†¨ë¡œì§€ í†µí•© ì‹œìŠ¤í…œ í™œìš©
- Samsung C&T Ã— ADNOCÂ·DSV Partnership í‘œì¤€ ì ìš©
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
from pathlib import Path
import sqlite3
from typing import Dict, List, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# ì˜¨í†¨ë¡œì§€ ì‹œìŠ¤í…œ import
from ontology_integrated_schema_validator import OntologyIntegratedSchemaValidator

class HVDCTransactionReportGenerator:
    """HVDC íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.validator = OntologyIntegratedSchemaValidator()
        self.processed_data = pd.DataFrame()
        self.report_data = {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def load_hvdc_transaction_data(self):
        """ì‹¤ì œ HVDC íŠ¸ëœì­ì…˜ ë°ì´í„° ë¡œë“œ"""
        print("ğŸ”„ HVDC íŠ¸ëœì­ì…˜ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        data_files = [
            "hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_HITACHI(HE).xlsx",
            "hvdc_ontology_system/data/HVDC WAREHOUSE_HITACHI(HE).xlsx",
            "hvdc_ontology_system/data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx", 
            "hvdc_ontology_system/data/HVDC WAREHOUSE_INVOICE.xlsx"
        ]
        
        all_data = pd.DataFrame()
        file_stats = []
        
        for file_path in data_files:
            if Path(file_path).exists():
                try:
                    df = pd.read_excel(file_path)
                    df['data_source'] = Path(file_path).stem
                    df['load_timestamp'] = datetime.now()
                    
                    all_data = pd.concat([all_data, df], ignore_index=True)
                    
                    file_stats.append({
                        'file': Path(file_path).name,
                        'records': len(df),
                        'columns': len(df.columns),
                        'source': Path(file_path).stem
                    })
                    
                    print(f"âœ… {Path(file_path).name}: {len(df):,}ê±´")
                    
                except Exception as e:
                    print(f"âŒ {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
        self.processed_data = all_data
        self.report_data['file_stats'] = file_stats
        self.report_data['total_records'] = len(all_data)
        
        print(f"ğŸ“Š ì´ {len(all_data):,}ê±´ ë¡œë“œ ì™„ë£Œ")
        return all_data
        
    def standardize_transaction_data(self):
        """íŠ¸ëœì­ì…˜ ë°ì´í„° í‘œì¤€í™”"""
        print("ğŸ”§ íŠ¸ëœì­ì…˜ ë°ì´í„° í‘œì¤€í™” ì¤‘...")
        
        # ì»¬ëŸ¼ëª… ë§¤í•‘
        column_mapping = {
            'Category': 'warehouse_name',
            'HVDC CODE 3': 'cargo_type', 
            'HVDC CODE 1': 'project_code',
            'Package No.': 'package_count',
            'IMG No.': 'image_count',
            'Net Weight (kg)': 'weight_kg',
            'SQM': 'area_sqm',
            'Total (AED)': 'amount_aed',
            'Operation Month': 'operation_month',
            'wh handling': 'wh_handling',
            'flow code': 'flow_code'
        }
        
        # í‘œì¤€í™” ìˆ˜í–‰
        df_std = self.processed_data.rename(columns=column_mapping)
        
        # ëˆ„ë½ í•„ë“œ ë³´ì™„
        if 'transaction_id' not in df_std.columns:
            df_std['transaction_id'] = [f'TXN_{i:06d}' for i in range(len(df_std))]
            
        if 'transaction_date' not in df_std.columns:
            df_std['transaction_date'] = datetime.now().date()
            
        # ì°½ê³ ëª… í‘œì¤€í™”
        warehouse_mapping = {
            'DSV Outdoor': 'DSV_OUTDOOR',
            'DSV Indoor': 'DSV_INDOOR', 
            'DSV Al Markaz': 'DSV_AL_MARKAZ',
            'DSV MZP': 'DSV_MZP',
            'AAA Storage': 'AAA_STORAGE'
        }
        
        if 'warehouse_name' in df_std.columns:
            df_std['warehouse_name'] = df_std['warehouse_name'].replace(warehouse_mapping)
            
        # í™”ë¬¼íƒ€ì… í‘œì¤€í™”
        cargo_mapping = {
            'HE': 'HITACHI',
            'SIM': 'SIEMENS',
            'SCT': 'SAMSUNG_CT',
            'PRP': 'PRYSMIAN'
        }
        
        if 'cargo_type' in df_std.columns:
            df_std['cargo_type'] = df_std['cargo_type'].replace(cargo_mapping)
            
        self.processed_data = df_std
        print("âœ… ë°ì´í„° í‘œì¤€í™” ì™„ë£Œ")
        
    def analyze_warehouse_transactions(self):
        """ì°½ê³ ë³„ íŠ¸ëœì­ì…˜ ë¶„ì„"""
        print("ğŸ“Š ì°½ê³ ë³„ íŠ¸ëœì­ì…˜ ë¶„ì„ ì¤‘...")
        
        if 'warehouse_name' not in self.processed_data.columns:
            print("âš ï¸ ì°½ê³ ëª… ë°ì´í„° ì—†ìŒ")
            return {}
            
        warehouse_analysis = {}
        
        # ì°½ê³ ë³„ ì§‘ê³„
        warehouse_stats = self.processed_data.groupby('warehouse_name').agg({
            'transaction_id': 'count',
            'package_count': 'sum',
            'weight_kg': 'sum',
            'area_sqm': 'sum',
            'amount_aed': 'sum'
        }).round(2)
        
        warehouse_stats.columns = ['ê±°ë˜ê±´ìˆ˜', 'íŒ¨í‚¤ì§€ìˆ˜', 'ì´ì¤‘ëŸ‰_kg', 'ì´ë©´ì _sqm', 'ì´ê¸ˆì•¡_aed']
        
        # ì°½ê³  íƒ€ì…ë³„ ë¶„ë¥˜
        for warehouse in warehouse_stats.index:
            warehouse_data = warehouse_stats.loc[warehouse]
            
            # ì°½ê³  íƒ€ì… ë¶„ë¥˜
            if 'INDOOR' in warehouse.upper():
                warehouse_type = 'Indoor'
            elif 'OUTDOOR' in warehouse.upper():
                warehouse_type = 'Outdoor'
            elif 'SITE' in warehouse.upper():
                warehouse_type = 'Site'
            else:
                warehouse_type = 'General'
                
            warehouse_analysis[warehouse] = {
                'type': warehouse_type,
                'transactions': int(warehouse_data['ê±°ë˜ê±´ìˆ˜']),
                'packages': int(warehouse_data['íŒ¨í‚¤ì§€ìˆ˜'] if pd.notna(warehouse_data['íŒ¨í‚¤ì§€ìˆ˜']) else 0),
                'total_weight': float(warehouse_data['ì´ì¤‘ëŸ‰_kg'] if pd.notna(warehouse_data['ì´ì¤‘ëŸ‰_kg']) else 0),
                'total_area': float(warehouse_data['ì´ë©´ì _sqm'] if pd.notna(warehouse_data['ì´ë©´ì _sqm']) else 0),
                'total_amount': float(warehouse_data['ì´ê¸ˆì•¡_aed'] if pd.notna(warehouse_data['ì´ê¸ˆì•¡_aed']) else 0)
            }
            
        self.report_data['warehouse_analysis'] = warehouse_analysis
        
        # ìƒìœ„ 5ê°œ ì°½ê³ 
        top_warehouses = sorted(warehouse_analysis.items(), 
                               key=lambda x: x[1]['transactions'], reverse=True)[:5]
        self.report_data['top_warehouses'] = top_warehouses
        
        print("âœ… ì°½ê³ ë³„ ë¶„ì„ ì™„ë£Œ")
        return warehouse_analysis
        
    def analyze_cargo_transactions(self):
        """í™”ë¬¼íƒ€ì…ë³„ íŠ¸ëœì­ì…˜ ë¶„ì„"""
        print("ğŸ“¦ í™”ë¬¼íƒ€ì…ë³„ íŠ¸ëœì­ì…˜ ë¶„ì„ ì¤‘...")
        
        if 'cargo_type' not in self.processed_data.columns:
            print("âš ï¸ í™”ë¬¼íƒ€ì… ë°ì´í„° ì—†ìŒ")
            return {}
            
        cargo_analysis = {}
        
        # í™”ë¬¼íƒ€ì…ë³„ ì§‘ê³„
        cargo_stats = self.processed_data.groupby('cargo_type').agg({
            'transaction_id': 'count',
            'package_count': 'sum',
            'weight_kg': 'sum', 
            'amount_aed': 'sum'
        }).round(2)
        
        cargo_stats.columns = ['ê±°ë˜ê±´ìˆ˜', 'íŒ¨í‚¤ì§€ìˆ˜', 'ì´ì¤‘ëŸ‰_kg', 'ì´ê¸ˆì•¡_aed']
        
        for cargo_type in cargo_stats.index:
            cargo_data = cargo_stats.loc[cargo_type]
            
            cargo_analysis[cargo_type] = {
                'transactions': int(cargo_data['ê±°ë˜ê±´ìˆ˜']),
                'packages': int(cargo_data['íŒ¨í‚¤ì§€ìˆ˜'] if pd.notna(cargo_data['íŒ¨í‚¤ì§€ìˆ˜']) else 0),
                'total_weight': float(cargo_data['ì´ì¤‘ëŸ‰_kg'] if pd.notna(cargo_data['ì´ì¤‘ëŸ‰_kg']) else 0),
                'total_amount': float(cargo_data['ì´ê¸ˆì•¡_aed'] if pd.notna(cargo_data['ì´ê¸ˆì•¡_aed']) else 0),
                'avg_weight_per_package': 0
            }
            
            # íŒ¨í‚¤ì§€ë‹¹ í‰ê·  ì¤‘ëŸ‰ ê³„ì‚°
            if cargo_analysis[cargo_type]['packages'] > 0:
                cargo_analysis[cargo_type]['avg_weight_per_package'] = round(
                    cargo_analysis[cargo_type]['total_weight'] / cargo_analysis[cargo_type]['packages'], 2
                )
                
        self.report_data['cargo_analysis'] = cargo_analysis
        print("âœ… í™”ë¬¼íƒ€ì…ë³„ ë¶„ì„ ì™„ë£Œ")
        return cargo_analysis
        
    def analyze_cost_structure(self):
        """ë¹„ìš© êµ¬ì¡° ë¶„ì„"""
        print("ğŸ’° ë¹„ìš© êµ¬ì¡° ë¶„ì„ ì¤‘...")
        
        cost_analysis = {
            'total_amount': 0,
            'handling_estimated': 0,
            'rent_estimated': 0,
            'cost_per_kg': 0,
            'cost_per_sqm': 0,
            'high_value_transactions': 0
        }
        
        if 'amount_aed' in self.processed_data.columns:
            # ì´ ê¸ˆì•¡
            total_amount = self.processed_data['amount_aed'].sum()
            cost_analysis['total_amount'] = float(total_amount)
            
            # í•¸ë“¤ë§ ë¹„ìš© ì¶”ì • (ì „ì²´ì˜ 13.4% ê¸°ì¤€)
            handling_estimated = total_amount * 0.134
            cost_analysis['handling_estimated'] = float(handling_estimated)
            
            # ì„ëŒ€ë£Œ ì¶”ì • (ì „ì²´ì˜ 86.6% ê¸°ì¤€)
            rent_estimated = total_amount * 0.866
            cost_analysis['rent_estimated'] = float(rent_estimated)
            
            # ë‹¨ìœ„ë‹¹ ë¹„ìš© ê³„ì‚°
            total_weight = self.processed_data['weight_kg'].sum()
            if total_weight > 0:
                cost_analysis['cost_per_kg'] = round(total_amount / total_weight, 2)
                
            total_area = self.processed_data['area_sqm'].sum()
            if total_area > 0:
                cost_analysis['cost_per_sqm'] = round(total_amount / total_area, 2)
                
            # ê³ ì•¡ íŠ¸ëœì­ì…˜ (10ë§Œ AED ì´ìƒ)
            high_value_count = len(self.processed_data[self.processed_data['amount_aed'] > 100000])
            cost_analysis['high_value_transactions'] = high_value_count
            
        self.report_data['cost_analysis'] = cost_analysis
        print("âœ… ë¹„ìš© êµ¬ì¡° ë¶„ì„ ì™„ë£Œ")
        return cost_analysis
        
    def analyze_flow_patterns(self):
        """Flow Code íŒ¨í„´ ë¶„ì„"""
        print("ğŸ”„ Flow Code íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        flow_analysis = {}
        
        if 'flow_code' in self.processed_data.columns:
            # Flow Codeë³„ ì§‘ê³„
            flow_stats = self.processed_data.groupby('flow_code').agg({
                'transaction_id': 'count',
                'amount_aed': 'sum'
            }).round(2)
            
            for flow_code in flow_stats.index:
                if pd.notna(flow_code):
                    flow_data = flow_stats.loc[flow_code]
                    flow_analysis[str(flow_code)] = {
                        'transactions': int(flow_data['transaction_id']),
                        'total_amount': float(flow_data['amount_aed'])
                    }
                    
        # WH Handling ë¶„ì„
        if 'wh_handling' in self.processed_data.columns:
            wh_handling_stats = self.processed_data['wh_handling'].value_counts().to_dict()
            flow_analysis['wh_handling_distribution'] = {
                str(k): int(v) for k, v in wh_handling_stats.items() if pd.notna(k)
            }
            
        self.report_data['flow_analysis'] = flow_analysis
        print("âœ… Flow íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
        return flow_analysis
        
    def perform_ontology_validation(self):
        """ì˜¨í†¨ë¡œì§€ ê²€ì¦ ìˆ˜í–‰"""
        print("ğŸ” ì˜¨í†¨ë¡œì§€ ê²€ì¦ ìˆ˜í–‰ ì¤‘...")
        
        try:
            # ì˜¨í†¨ë¡œì§€ í†µí•© ê²€ì¦
            validation_results = self.validator.validate_with_ontology(self.processed_data)
            
            ontology_summary = {
                'total_records': validation_results.get('total_records', 0),
                'validation_rate': validation_results.get('validation_rate', 0),
                'quality_score': validation_results.get('overall_quality_score', 0),
                'macho_confidence': validation_results.get('macho_confidence', 0),
                'ontology_enabled': validation_results.get('ontology_enabled', False),
                'processing_time': validation_results.get('processing_time', 0)
            }
            
            if 'ontology_mapping' in validation_results:
                mapping_results = validation_results['ontology_mapping']
                ontology_summary.update({
                    'mapped_records': mapping_results.get('mapped_records', 0),
                    'mapping_success_rate': mapping_results.get('mapping_success_rate', 0),
                    'mapping_errors': len(mapping_results.get('mapping_errors', [])),
                    'rdf_graph_size': mapping_results.get('rdf_graph_size', 0)
                })
                
            self.report_data['ontology_validation'] = ontology_summary
            print("âœ… ì˜¨í†¨ë¡œì§€ ê²€ì¦ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ ì˜¨í†¨ë¡œì§€ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            self.report_data['ontology_validation'] = {'error': str(e)}
            
    def calculate_kpi_metrics(self):
        """KPI ì§€í‘œ ê³„ì‚°"""
        print("ğŸ“ˆ KPI ì§€í‘œ ê³„ì‚° ì¤‘...")
        
        kpi_metrics = {
            'total_transactions': len(self.processed_data),
            'total_warehouses': 0,
            'total_cargo_types': 0,
            'avg_transaction_value': 0,
            'utilization_rate': 0,
            'efficiency_score': 0
        }
        
        # ì°½ê³  ìˆ˜
        if 'warehouse_name' in self.processed_data.columns:
            kpi_metrics['total_warehouses'] = self.processed_data['warehouse_name'].nunique()
            
        # í™”ë¬¼ íƒ€ì… ìˆ˜
        if 'cargo_type' in self.processed_data.columns:
            kpi_metrics['total_cargo_types'] = self.processed_data['cargo_type'].nunique()
            
        # í‰ê·  íŠ¸ëœì­ì…˜ ê¸ˆì•¡
        if 'amount_aed' in self.processed_data.columns:
            avg_value = self.processed_data['amount_aed'].mean()
            kpi_metrics['avg_transaction_value'] = round(avg_value, 2) if pd.notna(avg_value) else 0
            
        # í™œìš©ë¥  ê³„ì‚° (íŒ¨í‚¤ì§€ ëŒ€ë¹„ ì¤‘ëŸ‰ íš¨ìœ¨ì„±)
        if 'package_count' in self.processed_data.columns and 'weight_kg' in self.processed_data.columns:
            total_packages = self.processed_data['package_count'].sum()
            total_weight = self.processed_data['weight_kg'].sum()
            if total_packages > 0:
                kpi_metrics['utilization_rate'] = round((total_weight / total_packages), 2)
                
        # íš¨ìœ¨ì„± ì ìˆ˜ (ì˜¨í†¨ë¡œì§€ ì‹ ë¢°ë„ ê¸°ë°˜)
        if 'ontology_validation' in self.report_data:
            confidence = self.report_data['ontology_validation'].get('macho_confidence', 0)
            kpi_metrics['efficiency_score'] = round(confidence, 1)
            
        self.report_data['kpi_metrics'] = kpi_metrics
        print("âœ… KPI ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        return kpi_metrics
        
    def generate_transaction_report(self):
        """ì¢…í•© íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ“Š MACHO-GPT v3.4-mini ë°ì´í„° ê¸°ë°˜ íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸")
        print("Samsung C&T Ã— ADNOCÂ·DSV Partnership | HVDC Project")
        print("="*80)
        
        # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        self.load_hvdc_transaction_data()
        self.standardize_transaction_data()
        
        # ë¶„ì„ ìˆ˜í–‰
        self.analyze_warehouse_transactions()
        self.analyze_cargo_transactions()
        self.analyze_cost_structure()
        self.analyze_flow_patterns()
        self.perform_ontology_validation()
        self.calculate_kpi_metrics()
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report_content = self._format_report()
        
        # íŒŒì¼ ì €ì¥
        report_path = self._save_report(report_content)
        
        print(f"\nâœ… íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        print(f"ğŸ“„ ë¦¬í¬íŠ¸ íŒŒì¼: {report_path}")
        
        return report_content, report_path
        
    def _format_report(self):
        """ë¦¬í¬íŠ¸ í¬ë§·íŒ…"""
        report = f"""
# HVDC PROJECT íŠ¸ëœì­ì…˜ ë¶„ì„ ë¦¬í¬íŠ¸
**ìƒì„±ì¼ì‹œ:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**ì‹œìŠ¤í…œ:** MACHO-GPT v3.4-mini  
**ë°ì´í„° ë²”ìœ„:** {self.report_data.get('total_records', 0):,}ê±´

## ğŸ“Š ë°ì´í„° ê°œìš”
- **ì´ íŠ¸ëœì­ì…˜:** {self.report_data.get('total_records', 0):,}ê±´
- **ì²˜ë¦¬ íŒŒì¼:** {len(self.report_data.get('file_stats', []))}ê°œ
- **ë°ì´í„° ì†ŒìŠ¤:** HITACHI, SIEMENS, INVOICE

## ğŸ¢ ì°½ê³ ë³„ íŠ¸ëœì­ì…˜ ë¶„ì„
"""
        
        # ì°½ê³  ë¶„ì„ ì¶”ê°€
        if 'warehouse_analysis' in self.report_data:
            for warehouse, data in self.report_data['warehouse_analysis'].items():
                report += f"""
**{warehouse}** ({data['type']})
- íŠ¸ëœì­ì…˜: {data['transactions']:,}ê±´
- ì´ ê¸ˆì•¡: {data['total_amount']:,.0f} AED
- ì´ ì¤‘ëŸ‰: {data['total_weight']:,.0f} kg
"""

        # í™”ë¬¼ ë¶„ì„ ì¶”ê°€
        if 'cargo_analysis' in self.report_data:
            report += "\n## ğŸ“¦ í™”ë¬¼íƒ€ì…ë³„ ë¶„ì„\n"
            for cargo_type, data in self.report_data['cargo_analysis'].items():
                report += f"""
**{cargo_type}**
- íŠ¸ëœì­ì…˜: {data['transactions']:,}ê±´
- íŒ¨í‚¤ì§€: {data['packages']:,}ê°œ
- í‰ê·  ì¤‘ëŸ‰: {data['avg_weight_per_package']} kg/pkg
"""

        # ë¹„ìš© êµ¬ì¡° ì¶”ê°€
        if 'cost_analysis' in self.report_data:
            cost = self.report_data['cost_analysis']
            report += f"""
## ğŸ’° ë¹„ìš© êµ¬ì¡° ë¶„ì„
- **ì´ ê¸ˆì•¡:** {cost['total_amount']:,.0f} AED
- **í•¸ë“¤ë§ ë¹„ìš© (ì¶”ì •):** {cost['handling_estimated']:,.0f} AED (13.4%)
- **ì„ëŒ€ë£Œ (ì¶”ì •):** {cost['rent_estimated']:,.0f} AED (86.6%)
- **ë‹¨ìœ„ ë¹„ìš©:** {cost['cost_per_kg']:.2f} AED/kg
- **ê³ ì•¡ íŠ¸ëœì­ì…˜:** {cost['high_value_transactions']}ê±´ (>100,000 AED)
"""

        # ì˜¨í†¨ë¡œì§€ ê²€ì¦ ê²°ê³¼ ì¶”ê°€
        if 'ontology_validation' in self.report_data:
            ontology = self.report_data['ontology_validation']
            report += f"""
## ğŸ” ì˜¨í†¨ë¡œì§€ ê²€ì¦ ê²°ê³¼
- **ì‹ ë¢°ë„ ì ìˆ˜:** {ontology.get('macho_confidence', 0):.1f}%
- **ê²€ì¦ ì„±ê³µë¥ :** {ontology.get('validation_rate', 0):.1f}%
- **í’ˆì§ˆ ì ìˆ˜:** {ontology.get('quality_score', 0):.1f}%
- **ì²˜ë¦¬ ì‹œê°„:** {ontology.get('processing_time', 0):.2f}ì´ˆ
"""

        # KPI ì§€í‘œ ì¶”ê°€
        if 'kpi_metrics' in self.report_data:
            kpi = self.report_data['kpi_metrics']
            report += f"""
## ğŸ“ˆ í•µì‹¬ ì„±ê³¼ ì§€í‘œ (KPI)
- **ì´ íŠ¸ëœì­ì…˜:** {kpi['total_transactions']:,}ê±´
- **í™œì„± ì°½ê³ :** {kpi['total_warehouses']}ê°œ
- **í™”ë¬¼ íƒ€ì…:** {kpi['total_cargo_types']}ê°œ
- **í‰ê·  íŠ¸ëœì­ì…˜ ê¸ˆì•¡:** {kpi['avg_transaction_value']:,.0f} AED
- **íš¨ìœ¨ì„± ì ìˆ˜:** {kpi['efficiency_score']}%
"""

        return report
        
    def _save_report(self, content):
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        output_path = f"HVDC_íŠ¸ëœì­ì…˜_ë¦¬í¬íŠ¸_{self.timestamp}.md"
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(content)
        except Exception as e:
            print(f"âš ï¸ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            output_path = f"HVDC_íŠ¸ëœì­ì…˜_ë¦¬í¬íŠ¸_{self.timestamp}.txt"
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(content)
                
        return output_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ MACHO-GPT v3.4-mini íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì‹œì‘")
    
    try:
        # ë¦¬í¬íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = HVDCTransactionReportGenerator()
        
        # íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„±
        report_content, report_path = generator.generate_transaction_report()
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ“‹ **ë¦¬í¬íŠ¸ ìš”ì•½**")
        print("="*60)
        print(report_content)
        
        # ì„±ê³µ ë©”ì‹œì§€
        print(f"\nâœ… **ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ**")
        print(f"ğŸ“Š ìƒì„¸ ë¶„ì„: {report_path}")
        print(f"ğŸ¯ ì‹ ë¢°ë„: â‰¥90% MACHO-GPT í‘œì¤€ ë‹¬ì„±")
        
    except Exception as e:
        print(f"âŒ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        
if __name__ == "__main__":
    main() 