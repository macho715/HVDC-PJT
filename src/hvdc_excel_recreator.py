"""
ğŸ”Œ HVDC Excel Recreator v2.8.4
Samsung C&T Ã— ADNOCÂ·DSV Partnership | ì‹¤ì œ RAW DATA 100% í™œìš©

Based on HVDC_Real_Data_Excel_System_REV.MD specifications:
- 5ê°œ ì‹œíŠ¸ êµ¬ì¡°: ì „ì²´ íŠ¸ëœì­ì…˜, ë¶„ì„ìš”ì•½, Pre-Arrival, ì°½ê³ ë³„, í˜„ì¥ë³„
- 7,405 total records (HITACHI 5,552 + SIMENSE 1,853)
- Multi-Level Headers
- Flow Code 0-4 classification

Author: MACHO-GPT v3.5
Date: 2025-01-06
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class HVDCExcelRecreator:
    """HVDC Excel ë³´ê³ ì„œ ì¬ìƒì„±ê¸° - REV.MD êµ¬ì¡° ê¸°ë°˜"""

    def __init__(self):
        self.data_dir = Path("data")
        self.output_dir = Path("src")

        # MACHO-GPT v3.5 compliance attributes
        self.confidence_threshold = 0.95
        self.containment_mode = "LATTICE"  # Default mode for logistics

        # ì‹¤ì œ ì°½ê³  ì»¬ëŸ¼ ë§¤í•‘ (REV.MD ê¸°ë°˜)
        self.warehouse_columns = {
            "DSV Indoor": "DSV Indoor",
            "DSV Outdoor": "DSV Outdoor",
            "DSV Al Markaz": "DSV Al Markaz",
            "DSV MZP": "DSV MZP",
            "AAA Storage": "AAA Storage",
            "Hauler Indoor": "Hauler Indoor",
            "MOSB": "MOSB",
        }

        # ì‹¤ì œ í˜„ì¥ ì»¬ëŸ¼ ë§¤í•‘ (REV.MD ê¸°ë°˜)
        self.site_columns = {"AGI": "AGI", "DAS": "DAS", "MIR": "MIR", "SHU": "SHU"}

        self.df_combined = None
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    def standardize_case_list(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        í—¤ë” ì •ê·œí™” ë° í‘œì¤€í™” (REV.MD ê·œê²©)
        - í—¤ë” ê³µë°±Â·ëŒ€/ì†Œë¬¸ì ì •ë¹„
        - total handling â†’ FLOW_0â€¦4 ë§¤í•‘
        """
        # í—¤ë” ì •ê·œí™”
        df.columns = df.columns.str.strip().str.lower()

        # total handling ì»¬ëŸ¼ì„ wh handlingìœ¼ë¡œ ë§¤í•‘
        if "total handling" in df.columns:
            df["wh handling"] = df["total handling"]

        return df

    def load_raw_data(self) -> pd.DataFrame:
        """ì‹¤ì œ RAW DATA ë¡œë“œ ë° í†µí•© (REV.MD ê·œê²©: 7,405ê±´)"""
        logger.info("ğŸ” ì‹¤ì œ RAW DATA ë¡œë”© ì‹œì‘...")

        # HITACHI íŒŒì¼ ë¡œë“œ
        hitachi_path = self.data_dir / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        df_hitachi = pd.read_excel(hitachi_path, sheet_name="Case List")
        df_hitachi = self.standardize_case_list(df_hitachi)
        df_hitachi["VENDOR"] = "HITACHI"
        logger.info(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_hitachi)}ê±´")

        # SIMENSE íŒŒì¼ ë¡œë“œ
        simense_path = self.data_dir / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        df_simense = pd.read_excel(simense_path, sheet_name="Case List")
        df_simense = self.standardize_case_list(df_simense)
        df_simense["VENDOR"] = "SIMENSE"
        logger.info(f"âœ… SIMENSE ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_simense)}ê±´")

        # ë°ì´í„° í†µí•©
        self.df_combined = pd.concat([df_hitachi, df_simense], ignore_index=True)

        # Status_Locationì´ 'ALL'ì¸ ì§‘ê³„í–‰ ì œê±° (REV.MD íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì°¸ì¡°)
        if "status_location" in self.df_combined.columns:
            self.df_combined = self.df_combined[
                self.df_combined["status_location"] != "ALL"
            ]

        logger.info(f"âœ… í†µí•© ë°ì´í„° ì™„ë£Œ: {len(self.df_combined)}ê±´")

        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        self._convert_date_columns()

        # Flow Code ê³„ì‚°
        self._calculate_flow_codes()

        return self.df_combined

    def _convert_date_columns(self):
        """ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜"""
        date_columns = []

        # ì°½ê³  ê´€ë ¨ ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        for col in self.warehouse_columns.values():
            if col.lower() in self.df_combined.columns:
                self.df_combined[col] = pd.to_datetime(
                    self.df_combined[col.lower()], errors="coerce"
                )
                date_columns.append(col)

        # í˜„ì¥ ê´€ë ¨ ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        for col in self.site_columns.values():
            if col.lower() in self.df_combined.columns:
                self.df_combined[col] = pd.to_datetime(
                    self.df_combined[col.lower()], errors="coerce"
                )
                date_columns.append(col)

        logger.info(f"ğŸ“… ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜ ì™„ë£Œ: {len(date_columns)}ê°œ")

    def _calculate_flow_codes(self):
        """Flow Code 0-4 ê³„ì‚° (REV.MD ê·œê²©)"""
        logger.info("ğŸ“Š Flow Code ê³„ì‚° ì‹œì‘...")

        if "wh handling" in self.df_combined.columns:
            # wh handling ì»¬ëŸ¼ ê¸°ë°˜ Flow Code ê³„ì‚°
            self.df_combined["FLOW_CODE"] = (
                self.df_combined["wh handling"].fillna(0).astype(int)
            )

            # Flow Code ë²”ìœ„ ì œí•œ (0-4)
            self.df_combined["FLOW_CODE"] = self.df_combined["FLOW_CODE"].clip(0, 4)
        else:
            # ëŒ€ì•ˆ: ì°½ê³  ê²½ìœ  íšŸìˆ˜ ê¸°ë°˜ ê³„ì‚°
            self.df_combined["FLOW_CODE"] = 0
            for idx, row in self.df_combined.iterrows():
                warehouse_count = 0
                for col in self.warehouse_columns.values():
                    if col.lower() in self.df_combined.columns and pd.notna(
                        row[col.lower()]
                    ):
                        warehouse_count += 1
                self.df_combined.loc[idx, "FLOW_CODE"] = min(warehouse_count, 4)

        # Flow Code ë¶„í¬ ë¡œê¹…
        flow_distribution = self.df_combined["FLOW_CODE"].value_counts().sort_index()
        for code, count in flow_distribution.items():
            logger.info(f"  Flow Code {code}: {count}ê±´")

        logger.info("ğŸ“Š Flow Code ê³„ì‚° ì™„ë£Œ")

    def create_sheet1_transaction_data(self) -> pd.DataFrame:
        """Sheet 1: ì „ì²´_íŠ¸ëœì­ì…˜_FLOWCODE0-4"""
        logger.info("ğŸ“‹ Sheet 1: ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° ìƒì„± ì¤‘...")

        # í•µì‹¬ ì»¬ëŸ¼ ì„ íƒ
        core_columns = ["VENDOR", "FLOW_CODE"]

        # ì°½ê³  ì»¬ëŸ¼ ì¶”ê°€
        for col in self.warehouse_columns.values():
            if col.lower() in self.df_combined.columns:
                core_columns.append(col)

        # í˜„ì¥ ì»¬ëŸ¼ ì¶”ê°€
        for col in self.site_columns.values():
            if col.lower() in self.df_combined.columns:
                core_columns.append(col)

        # ê¸°íƒ€ ì¤‘ìš” ì»¬ëŸ¼ ì¶”ê°€
        other_columns = ["status_location", "wh handling"]
        for col in other_columns:
            if col in self.df_combined.columns:
                core_columns.append(col)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [
            col for col in core_columns if col in self.df_combined.columns
        ]

        sheet1_data = self.df_combined[available_columns].copy()

        logger.info(
            f"âœ… Sheet 1 ìƒì„± ì™„ë£Œ: {len(sheet1_data)}ê±´, {len(available_columns)}ê°œ ì»¬ëŸ¼"
        )
        return sheet1_data

    def create_sheet2_flowcode_analysis(self) -> pd.DataFrame:
        """Sheet 2: FLOWCODE0-4_ë¶„ì„ìš”ì•½"""
        logger.info("ğŸ“Š Sheet 2: Flow Code ë¶„ì„ ìƒì„± ì¤‘...")

        # Flow Codeë³„ ë¶„í¬ ê³„ì‚°
        flowcode_stats = (
            self.df_combined.groupby("FLOW_CODE")
            .agg({"VENDOR": "count"})
            .rename(columns={"VENDOR": "Count"})
        )

        # ë°±ë¶„ìœ¨ ê³„ì‚°
        total_count = len(self.df_combined)
        flowcode_stats["Percentage"] = (
            flowcode_stats["Count"] / total_count * 100
        ).round(2)

        # ì„¤ëª… ì¶”ê°€
        flowcode_descriptions = {
            0: "Pre-Arrival (í•­êµ¬ ë„ì°© ì „)",
            1: "Port â†’ Site (ì§ì ‘ ì´ë™)",
            2: "Port â†’ WH â†’ Site (ì°½ê³  1ê°œ ê²½ìœ )",
            3: "Port â†’ WH â†’ MOSB â†’ Site (ì°½ê³  2ê°œ ê²½ìœ )",
            4: "Port â†’ WH â†’ WH â†’ MOSB â†’ Site (ì°½ê³  3ê°œ+ ê²½ìœ )",
        }

        flowcode_stats["Description"] = flowcode_stats.index.map(flowcode_descriptions)

        # ì „ì²´ 5ê°œ Flow Codeê°€ ëª¨ë‘ ìˆë„ë¡ ë³´ì¥
        for code in range(5):
            if code not in flowcode_stats.index:
                flowcode_stats.loc[code] = [0, 0.0, flowcode_descriptions[code]]

        flowcode_stats = flowcode_stats.sort_index()

        logger.info(f"âœ… Sheet 2 ìƒì„± ì™„ë£Œ: {len(flowcode_stats)}ê°œ Flow Code ë¶„ì„")
        return flowcode_stats

    def create_sheet3_pre_arrival_analysis(self) -> pd.DataFrame:
        """Sheet 3: Pre_Arrival_ìƒì„¸ë¶„ì„"""
        logger.info("ğŸš¢ Sheet 3: Pre-Arrival ìƒì„¸ ë¶„ì„ ìƒì„± ì¤‘...")

        # FLOW_CODE = 0ì¸ ë°ì´í„° í•„í„°ë§
        pre_arrival_data = self.df_combined[self.df_combined["FLOW_CODE"] == 0].copy()

        if len(pre_arrival_data) == 0:
            logger.warning("âš ï¸ Pre-Arrival ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame({"Message": ["Pre-Arrival ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]})

        logger.info(f"âœ… Sheet 3 ìƒì„± ì™„ë£Œ: {len(pre_arrival_data)}ê±´ Pre-Arrival ë¶„ì„")
        return pre_arrival_data

    def create_sheet4_warehouse_multilevel(self) -> pd.DataFrame:
        """Sheet 4: ì°½ê³ ë³„_ì›”ë³„_ì…ì¶œê³ _ì™„ì „ì²´ê³„ (Multi-Level Header)"""
        logger.info("ğŸ­ Sheet 4: ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  Multi-Level Header ìƒì„± ì¤‘...")

        # ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
        all_dates = []
        for col in self.warehouse_columns.values():
            if col in self.df_combined.columns:
                dates = self.df_combined[col].dropna()
                all_dates.extend(dates.tolist())
            elif col.lower() in self.df_combined.columns:
                dates = self.df_combined[col.lower()].dropna()
                all_dates.extend(dates.tolist())

        if not all_dates:
            logger.warning("âš ï¸ ì°½ê³  ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame({"Message": ["ì°½ê³  ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]})

        min_date = min(all_dates)
        max_date = max(all_dates)

        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        periods = pd.date_range(
            start=min_date.replace(day=1), end=max_date.replace(day=1), freq="MS"
        )

        # Multi-Level Header êµ¬ì„±
        level_0 = ["Month"]
        level_1 = [""]

        for warehouse_name in self.warehouse_columns.keys():
            level_0.extend(["ì…ê³ ", "ì¶œê³ "])
            level_1.extend([warehouse_name, warehouse_name])

        multi_columns = pd.MultiIndex.from_arrays(
            [level_0, level_1], names=["êµ¬ë¶„", "Warehouse"]
        )

        # ë°ì´í„° ê³„ì‚°
        warehouse_data = []
        for period in periods:
            row_data = [period.strftime("%Y-%m")]

            for warehouse_name, warehouse_col in self.warehouse_columns.items():
                # ì…ê³  ê³„ì‚°
                inbound = self._calculate_warehouse_inbound(warehouse_col, period)
                # ì¶œê³  ê³„ì‚°
                outbound = self._calculate_warehouse_outbound(warehouse_col, period)

                row_data.extend([inbound, outbound])

            warehouse_data.append(row_data)

        # DataFrame ìƒì„±
        result = pd.DataFrame(warehouse_data, columns=multi_columns)

        logger.info(
            f"âœ… Sheet 4 ìƒì„± ì™„ë£Œ: {len(result)}ê°œì›” Ã— {len(self.warehouse_columns)}ê°œ ì°½ê³ "
        )
        return result

    def create_sheet5_site_multilevel(self) -> pd.DataFrame:
        """Sheet 5: í˜„ì¥ë³„_ì›”ë³„_ì…ê³ ì¬ê³ _ì™„ì „ì²´ê³„ (Multi-Level Header)"""
        logger.info("ğŸ—ï¸ Sheet 5: í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  Multi-Level Header ìƒì„± ì¤‘...")

        # ë‚ ì§œ ë²”ìœ„ ì¶”ì¶œ
        all_dates = []
        for col in self.site_columns.values():
            if col in self.df_combined.columns:
                dates = self.df_combined[col].dropna()
                all_dates.extend(dates.tolist())
            elif col.lower() in self.df_combined.columns:
                dates = self.df_combined[col.lower()].dropna()
                all_dates.extend(dates.tolist())

        if not all_dates:
            logger.warning("âš ï¸ í˜„ì¥ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame({"Message": ["í˜„ì¥ ë‚ ì§œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."]})

        min_date = min(all_dates)
        max_date = max(all_dates)

        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        periods = pd.date_range(
            start=min_date.replace(day=1), end=max_date.replace(day=1), freq="MS"
        )

        # Multi-Level Header êµ¬ì„±
        level_0 = ["Month"]
        level_1 = [""]

        for site_name in self.site_columns.keys():
            level_0.extend(["ì…ê³ ", "ì¬ê³ "])
            level_1.extend([site_name, site_name])

        multi_columns = pd.MultiIndex.from_arrays(
            [level_0, level_1], names=["êµ¬ë¶„", "Site"]
        )

        # ë°ì´í„° ê³„ì‚°
        site_data = []
        for period in periods:
            row_data = [period.strftime("%Y-%m")]

            for site_name, site_col in self.site_columns.items():
                # ì…ê³  ê³„ì‚°
                inbound = self._calculate_site_inbound(site_col, period)
                # ì¬ê³  ê³„ì‚°
                inventory = self._calculate_site_inventory(site_col, period)

                row_data.extend([inbound, inventory])

            site_data.append(row_data)

        # DataFrame ìƒì„±
        result = pd.DataFrame(site_data, columns=multi_columns)

        logger.info(
            f"âœ… Sheet 5 ìƒì„± ì™„ë£Œ: {len(result)}ê°œì›” Ã— {len(self.site_columns)}ê°œ í˜„ì¥"
        )
        return result

    def _calculate_warehouse_inbound(
        self, warehouse_col: str, period: pd.Timestamp
    ) -> int:
        """ì°½ê³ ë³„ ì›”ë³„ ì…ê³  ê³„ì‚° (REV.MD calculate_warehouse_inbound_correct ê¸°ë°˜)"""
        col_name = (
            warehouse_col
            if warehouse_col in self.df_combined.columns
            else warehouse_col.lower()
        )

        if col_name not in self.df_combined.columns:
            return 0

        warehouse_dates = self.df_combined[col_name].dropna()
        month_mask = warehouse_dates.dt.to_period("M") == period.to_period("M")
        return month_mask.sum()

    def _calculate_warehouse_outbound(
        self, warehouse_col: str, period: pd.Timestamp
    ) -> int:
        """ì°½ê³ ë³„ ì›”ë³„ ì¶œê³  ê³„ì‚° (REV.MD calculate_warehouse_outbound_real ê¸°ë°˜)"""
        col_name = (
            warehouse_col
            if warehouse_col in self.df_combined.columns
            else warehouse_col.lower()
        )

        if col_name not in self.df_combined.columns:
            return 0

        warehouse_visited = self.df_combined[self.df_combined[col_name].notna()].copy()
        outbound_count = 0

        for _, row in warehouse_visited.iterrows():
            warehouse_date = row[col_name]
            if pd.isna(warehouse_date):
                continue

            # ë‹¤ìŒ ë‹¨ê³„ ì´ë™ ë‚ ì§œ íƒìƒ‰
            next_dates = []

            # ë‹¤ë¥¸ ì°½ê³ ë¡œ ì´ë™ í™•ì¸
            for other_col in self.warehouse_columns.values():
                other_col_name = (
                    other_col
                    if other_col in self.df_combined.columns
                    else other_col.lower()
                )
                if (
                    other_col_name != col_name
                    and other_col_name in self.df_combined.columns
                ):
                    other_date = row[other_col_name]
                    if pd.notna(other_date) and other_date > warehouse_date:
                        next_dates.append(other_date)

            # í˜„ì¥ìœ¼ë¡œ ì´ë™ í™•ì¸
            for site_col in self.site_columns.values():
                site_col_name = (
                    site_col
                    if site_col in self.df_combined.columns
                    else site_col.lower()
                )
                if site_col_name in self.df_combined.columns:
                    site_date = row[site_col_name]
                    if pd.notna(site_date) and site_date > warehouse_date:
                        next_dates.append(site_date)

            # ê°€ì¥ ë¹ ë¥¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì¶œê³  ì‹œì  ê²°ì •
            if next_dates:
                earliest_next_date = min(next_dates)
                if earliest_next_date.to_period("M") == period.to_period("M"):
                    outbound_count += 1

        return outbound_count

    def _calculate_site_inbound(self, site_col: str, period: pd.Timestamp) -> int:
        """í˜„ì¥ë³„ ì›”ë³„ ì…ê³  ê³„ì‚°"""
        col_name = (
            site_col if site_col in self.df_combined.columns else site_col.lower()
        )

        if col_name not in self.df_combined.columns:
            return 0

        site_dates = self.df_combined[col_name].dropna()
        month_mask = site_dates.dt.to_period("M") == period.to_period("M")
        return month_mask.sum()

    def _calculate_site_inventory(self, site_col: str, period: pd.Timestamp) -> int:
        """í˜„ì¥ë³„ ì›”ë³„ ì¬ê³  ê³„ì‚° (ëˆ„ì  ê°œë…)"""
        col_name = (
            site_col if site_col in self.df_combined.columns else site_col.lower()
        )

        if col_name not in self.df_combined.columns:
            return 0

        site_dates = self.df_combined[col_name].dropna()

        # í•´ë‹¹ ì›” ë§ê¹Œì§€ ëˆ„ì  ë„ì°© ê±´ìˆ˜
        month_end = period + pd.DateOffset(months=1) - pd.DateOffset(days=1)
        arrived_by_month_end = (site_dates <= month_end).sum()

        # í˜„ì¬ ìœ„ì¹˜ ìƒíƒœ í™•ì¸ (ë³´ìˆ˜ì  ì ‘ê·¼)
        if "status_location" in self.df_combined.columns:
            site_name = [k for k, v in self.site_columns.items() if v == site_col][0]
            current_at_site = (self.df_combined["status_location"] == site_name).sum()
            return (
                min(arrived_by_month_end, current_at_site)
                if current_at_site > 0
                else arrived_by_month_end
            )

        return arrived_by_month_end

    def create_excel_report(self) -> str:
        """5ê°œ ì‹œíŠ¸ Excel ë³´ê³ ì„œ ìƒì„± (REV.MD ê·œê²©)"""
        logger.info("ğŸ“Š 5ê°œ ì‹œíŠ¸ Excel ë³´ê³ ì„œ ìƒì„± ì‹œì‘...")

        # ë°ì´í„° ë¡œë“œ
        self.load_raw_data()

        # ì¶œë ¥ íŒŒì¼ëª… (REV.MD í˜•ì‹ ë”°ë¼)
        output_filename = f"HVDC_Real_Data_Excel_System_{self.timestamp}.xlsx"
        output_path = self.output_dir / output_filename

        # Excel Writer ìƒì„±
        with pd.ExcelWriter(output_path, engine="openpyxl") as writer:

            # Sheet 1: ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„°
            sheet1_data = self.create_sheet1_transaction_data()
            sheet1_data.to_excel(
                writer, sheet_name="ì „ì²´_íŠ¸ëœì­ì…˜_FLOWCODE0-4", index=False
            )

            # Sheet 2: Flow Code ë¶„ì„
            sheet2_data = self.create_sheet2_flowcode_analysis()
            sheet2_data.to_excel(writer, sheet_name="FLOWCODE0-4_ë¶„ì„ìš”ì•½")

            # Sheet 3: Pre-Arrival ìƒì„¸ ë¶„ì„
            sheet3_data = self.create_sheet3_pre_arrival_analysis()
            sheet3_data.to_excel(writer, sheet_name="Pre_Arrival_ìƒì„¸ë¶„ì„", index=False)

            # Sheet 4: ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  (Multi-Level Header)
            sheet4_data = self.create_sheet4_warehouse_multilevel()
            if not sheet4_data.empty and "Message" not in sheet4_data.columns:
                sheet4_data.to_excel(writer, sheet_name="ì°½ê³ ë³„_ì›”ë³„_ì…ì¶œê³ _ì™„ì „ì²´ê³„")
            else:
                sheet4_data.to_excel(
                    writer, sheet_name="ì°½ê³ ë³„_ì›”ë³„_ì…ì¶œê³ _ì™„ì „ì²´ê³„", index=False
                )

            # Sheet 5: í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  (Multi-Level Header)
            sheet5_data = self.create_sheet5_site_multilevel()
            if not sheet5_data.empty and "Message" not in sheet5_data.columns:
                sheet5_data.to_excel(writer, sheet_name="í˜„ì¥ë³„_ì›”ë³„_ì…ê³ ì¬ê³ _ì™„ì „ì²´ê³„")
            else:
                sheet5_data.to_excel(
                    writer, sheet_name="í˜„ì¥ë³„_ì›”ë³„_ì…ê³ ì¬ê³ _ì™„ì „ì²´ê³„", index=False
                )

        logger.info(f"âœ… Excel ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {output_path}")

        # í†µê³„ ì •ë³´ ì¶œë ¥
        self._print_summary_statistics()

        return str(output_path)

    def get_recommended_commands(self) -> List[str]:
        """MACHO-GPT í†µí•©ì„ ìœ„í•œ ì¶”ì²œ ëª…ë ¹ì–´ ë°˜í™˜"""
        return [
            "/logi_master analyze-warehouse-performance",
            "/validate-data flow-code-accuracy",
            "/visualize-data multi-level-dashboard",
        ]

    def _print_summary_statistics(self):
        """ìš”ì•½ í†µê³„ ì¶œë ¥ (REV.MD ê·œê²©)"""
        logger.info("ğŸ“Š === HVDC 5ê°œ ì‹œíŠ¸ Excel ë³´ê³ ì„œ ìš”ì•½ ===")
        logger.info(f"ğŸ“‹ ì´ íŠ¸ëœì­ì…˜ ê±´ìˆ˜: {len(self.df_combined):,}ê±´")

        # ë²¤ë”ë³„ ë¶„í¬
        vendor_counts = self.df_combined["VENDOR"].value_counts()
        for vendor, count in vendor_counts.items():
            percentage = (count / len(self.df_combined)) * 100
            logger.info(f"ğŸ­ {vendor}: {count:,}ê±´ ({percentage:.1f}%)")

        # Flow Code ë¶„í¬
        flowcode_counts = self.df_combined["FLOW_CODE"].value_counts().sort_index()
        logger.info("ğŸ“Š Flow Code ë¶„í¬:")
        for code, count in flowcode_counts.items():
            percentage = (count / len(self.df_combined)) * 100
            logger.info(f"   Code {code}: {count:,}ê±´ ({percentage:.1f}%)")

        logger.info("ğŸ‰ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”Œ HVDC Excel Recreator v2.8.4")
    print("=" * 50)

    try:
        # ë³´ê³ ì„œ ìƒì„±ê¸° ì´ˆê¸°í™”
        recreator = HVDCExcelRecreator()

        # Excel ë³´ê³ ì„œ ìƒì„±
        output_path = recreator.create_excel_report()

        print(f"\nâœ… ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_path}")
        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path) / 1024:.1f} KB")

        return output_path

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        logger.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        return None


if __name__ == "__main__":
    main()
