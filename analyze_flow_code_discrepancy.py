#!/usr/bin/env python3
"""
FLOW CODE ë¶„í¬ ì°¨ì´ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
MACHO-GPT v3.4-mini | TDD ëª©í‘œê°’ vs ì‹¤ì œ ë°ì´í„° ë¶„ì„

ëª©ì :
1. TDD ëª©í‘œê°’ê³¼ ì‹¤ì œ ë°ì´í„°ì˜ ì°¨ì´ ì›ì¸ ë¶„ì„
2. ë°ì´í„° íŠ¹ì„±ì— ë”°ë¥¸ ì •í™•í•œ ë¶„í¬ ì˜ˆì¸¡
3. í˜„ì‹¤ì ì¸ ëª©í‘œê°’ ì¬ì„¤ì •
"""

import pandas as pd
import numpy as np
from datetime import datetime
import logging
import os
from pathlib import Path

# ì •í™•í•œ ë°ì´í„° êµ¬ì¡° ì •ì˜
WAREHOUSE_COLUMNS = [
    'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'AAA Storage', 
    'Hauler Indoor', 'DSV MZP', 'MOSB', 'DHL Warehouse'
]

SITE_COLUMNS = ['AGI', 'DAS', 'MIR', 'SHU']

BASIC_COLUMNS = [
    'no.', 'Case No.', 'Pkg', 'L(CM)', 'W(CM)', 'H(CM)', 'CBM'
]

MATERIAL_COLUMNS = [
    'N.W(kgs)', 'G.W(kgs)', 'Stack', 'HS Code', 'Currency'
]

ADDITIONAL_COLUMNS = [
    'SQM', 'Stack_Status', 'Description', 'Site', 'EQ No'
]

ANALYSIS_COLUMNS = [
    'WH_HANDLING', 'FLOW_CODE', 'FLOW_DESCRIPTION', 'FLOW_PATTERN'
]

META_COLUMNS = [
    'VENDOR', 'SOURCE_FILE', 'PROCESSED_AT', 'TRANSACTION_ID',
    'Status_Location_Date', 'Status_Location_Location', 
    'Status_Location_Date_Year', 'Status_Location_Date_Month'
]

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('flow_code_analysis.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def load_data():
    """ë°ì´í„° ë¡œë“œ - HITACHI Sheet1 ì‚¬ìš©"""
    try:
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë° ì‹œíŠ¸ ì„¤ì •
        data_configs = [
            {
                "path": "hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_HITACHI(HE).xlsx",
                "sheet": "Sheet1",  # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ì‹œíŠ¸
                "source": "HITACHI(HE)"
            },
            {
                "path": "hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx", 
                "sheet": 0,  # ì²« ë²ˆì§¸ ì‹œíŠ¸
                "source": "SIMENSE(SIM)"
            }
        ]
        
        dfs = []
        for config in data_configs:
            if os.path.exists(config["path"]):
                # íŠ¹ì • ì‹œíŠ¸ ë¡œë“œ
                df = pd.read_excel(config["path"], sheet_name=config["sheet"])
                df['DATA_SOURCE'] = config["source"]
                dfs.append(df)
                logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {config['path']} (ì‹œíŠ¸: {config['sheet']}) ({len(df):,}ê±´)")
            else:
                logger.warning(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {config['path']}")
        
        if not dfs:
            raise FileNotFoundError("ë¡œë“œí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ê²°í•©
        combined_df = pd.concat(dfs, ignore_index=True)
        logger.info(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(combined_df):,}ê±´")
        
        return combined_df
    
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

def analyze_data_characteristics(df):
    """ë°ì´í„° íŠ¹ì„± ë¶„ì„"""
    logger.info("ğŸ” ë°ì´í„° íŠ¹ì„± ë¶„ì„")
    
    # 1. ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„ì„
    print("\n" + "="*80)
    print("ğŸ“Š ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„ì„")
    print("="*80)
    
    source_analysis = df.groupby('DATA_SOURCE').size()
    for source, count in source_analysis.items():
        percentage = (count / len(df)) * 100
        print(f"  {source}: {count:,}ê±´ ({percentage:.1f}%)")
    
    # 2. ì°½ê³  ê´€ë ¨ ì»¬ëŸ¼ë“¤ - ì •í™•í•œ ì»¬ëŸ¼ëª… ì‚¬ìš©
    print("\n" + "="*80)
    print("ğŸ“Š ì°½ê³ ë³„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€")
    print("="*80)
    
    warehouse_cols = [col for col in df.columns if col in WAREHOUSE_COLUMNS]
    
    for col in warehouse_cols:
        non_null_count = df[col].notna().sum()
        percentage = (non_null_count / len(df)) * 100
        print(f"  {col}: {non_null_count:,}ê±´ ({percentage:.1f}%)")
    
    # 3. í˜„ì¥ ê´€ë ¨ ì»¬ëŸ¼ë“¤ - ì •í™•í•œ ì»¬ëŸ¼ëª… ì‚¬ìš©
    print(f"\nğŸ“Š í˜„ì¥ë³„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€:")
    site_cols = [col for col in df.columns if col in SITE_COLUMNS]
    
    for col in site_cols:
        non_null_count = df[col].notna().sum()
        percentage = (non_null_count / len(df)) * 100
        print(f"  {col}: {non_null_count:,}ê±´ ({percentage:.1f}%)")
    
    # 4. Site ì»¬ëŸ¼ ë¶„ì„
    if 'Site' in df.columns:
        site_data_count = df['Site'].notna().sum()
        site_percentage = (site_data_count / len(df)) * 100
        print(f"\nğŸ“Š Site ì»¬ëŸ¼:")
        print(f"  Site: {site_data_count:,}ê±´ ({site_percentage:.1f}%)")
    
    return warehouse_cols, site_cols

def calculate_flow_code_distribution(df):
    """Flow Code ë¶„í¬ ê³„ì‚° - ì •í™•í•œ ì»¬ëŸ¼ ë¶„ë¥˜ ì‚¬ìš©"""
    logger.info("ğŸ“Š Flow Code ë¶„í¬ ê³„ì‚°")
    
    flow_codes = []
    
    for _, row in df.iterrows():
        # í˜„ì¥ ë°ì´í„° í™•ì¸ (Site ì»¬ëŸ¼ + ì‹¤ì œ í˜„ì¥ ì»¬ëŸ¼ë“¤)
        has_site_column = 'Site' in row.index and pd.notna(row.get('Site', '')) and row['Site'] != ''
        has_site_data = any(col in row.index and pd.notna(row.get(col, '')) and row[col] != '' 
                           for col in SITE_COLUMNS)
        has_site = has_site_column or has_site_data
        
        # ì°½ê³  ë°ì´í„° í™•ì¸ - ì •í™•í•œ ì°½ê³  ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        warehouse_count = 0
        for col in WAREHOUSE_COLUMNS:
            if col in row.index and pd.notna(row.get(col, '')) and row[col] != '':
                warehouse_count += 1
        
        # MOSB í™•ì¸
        has_mosb = 'MOSB' in row.index and pd.notna(row.get('MOSB', '')) and row['MOSB'] != ''
        
        # Flow Code ê²°ì •
        if not has_site:
            flow_code = 0  # Pre Arrival
        elif warehouse_count == 0:
            flow_code = 1  # Port â†’ Site ì§ì†¡
        elif has_mosb:
            flow_code = 3  # MOSB ê²½ìœ 
        else:
            flow_code = 2  # ì¼ë°˜ ì°½ê³  ê²½ìœ 
        
        flow_codes.append(flow_code)
    
    df['FLOW_CODE_CALC'] = flow_codes
    
    # ë¶„í¬ ê³„ì‚°
    distribution = df['FLOW_CODE_CALC'].value_counts().sort_index()
    
    print("\n" + "="*80)
    print("ğŸ“Š ì‹¤ì œ ë°ì´í„° Flow Code ë¶„í¬")
    print("="*80)
    
    for code, count in distribution.items():
        percentage = (count / len(df)) * 100
        print(f"  Code {code}: {count:,}ê±´ ({percentage:.1f}%)")
    
    return df, distribution

def compare_with_tdd_targets(actual_dist):
    """TDD ëª©í‘œê°’ê³¼ ë¹„êµ"""
    logger.info("ğŸ¯ TDD ëª©í‘œê°’ê³¼ ë¹„êµ")
    
    # TDD ëª©í‘œê°’ (apply_flow_code_2_fix.py ê¸°ì¤€)
    tdd_targets = {
        0: 2845,  # Pre Arrival
        1: 3517,  # Port â†’ Site
        2: 1131,  # Port â†’ WH â†’ Site
        3: 80     # Port â†’ WH â†’ MOSB â†’ Site
    }
    
    total_target = sum(tdd_targets.values())
    total_actual = sum(actual_dist.values)
    
    print("\n" + "="*80)
    print("ğŸ¯ TDD ëª©í‘œê°’ vs ì‹¤ì œ ë°ì´í„° ë¹„êµ")
    print("="*80)
    
    print(f"ğŸ“Š ì „ì²´ ë°ì´í„°:")
    print(f"  TDD ëª©í‘œ: {total_target:,}ê±´")
    print(f"  ì‹¤ì œ ë°ì´í„°: {total_actual:,}ê±´")
    print(f"  ì°¨ì´: {total_actual - total_target:+,}ê±´")
    
    print(f"\nğŸ“‹ ìƒì„¸ ë¹„êµ:")
    for code in [0, 1, 2, 3]:
        target = tdd_targets.get(code, 0)
        actual = actual_dist.get(code, 0)
        difference = actual - target
        accuracy = (min(actual, target) / max(actual, target)) * 100 if max(actual, target) > 0 else 0
        
        print(f"  Code {code}:")
        print(f"    ëª©í‘œ: {target:,}ê±´")
        print(f"    ì‹¤ì œ: {actual:,}ê±´")
        print(f"    ì°¨ì´: {difference:+,}ê±´")
        print(f"    ì •í™•ë„: {accuracy:.1f}%")
    
    return tdd_targets

def analyze_root_causes(df, actual_dist, tdd_targets):
    """ê·¼ë³¸ ì›ì¸ ë¶„ì„ - ì •í™•í•œ ì»¬ëŸ¼ ë¶„ë¥˜ ì‚¬ìš©"""
    logger.info("ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„")
    
    print("\n" + "="*80)
    print("ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„")
    print("="*80)
    
    # 1. ë°ì´í„° ì†ŒìŠ¤ë³„ Flow Code ë¶„í¬
    print(f"\nğŸ“Š ë°ì´í„° ì†ŒìŠ¤ë³„ Flow Code ë¶„í¬:")
    source_flow = df.groupby(['DATA_SOURCE', 'FLOW_CODE_CALC']).size().unstack(fill_value=0)
    print(source_flow)
    
    # 2. Pre Arrival ì¼€ì´ìŠ¤ ë¶„ì„
    pre_arrival_cases = df[df['FLOW_CODE_CALC'] == 0]
    print(f"\nğŸ“Š Pre Arrival ì¼€ì´ìŠ¤ ë¶„ì„ ({len(pre_arrival_cases):,}ê±´):")
    
    # Site ì»¬ëŸ¼ í™•ì¸
    if 'Site' in df.columns:
        no_site_column = pre_arrival_cases['Site'].isna().sum()
        print(f"  Site ì»¬ëŸ¼ ì—†ìŒ: {no_site_column:,}ê±´")
    
    # í˜„ì¥ ë°ì´í„°ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤
    no_site_data = 0
    for _, row in pre_arrival_cases.iterrows():
        if not any(col in row.index and pd.notna(row.get(col, '')) and row[col] != '' 
                  for col in SITE_COLUMNS):
            no_site_data += 1
    print(f"  í˜„ì¥ ë°ì´í„° ì—†ìŒ: {no_site_data:,}ê±´")
    
    # 3. ì°½ê³  ê²½ìœ  íŒ¨í„´ ë¶„ì„ - ì •í™•í•œ ì°½ê³  ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    print(f"\nğŸ“Š ì°½ê³  ê²½ìœ  íŒ¨í„´ ë¶„ì„:")
    for code in [1, 2, 3]:
        code_cases = df[df['FLOW_CODE_CALC'] == code]
        if len(code_cases) > 0:
            warehouse_counts = []
            for _, row in code_cases.iterrows():
                count = sum(1 for col in WAREHOUSE_COLUMNS 
                           if col in row.index and pd.notna(row.get(col, '')) and row[col] != '')
                warehouse_counts.append(count)
            
            avg_warehouses = np.mean(warehouse_counts)
            print(f"  Code {code}: í‰ê·  ì°½ê³  {avg_warehouses:.1f}ê°œ")
    
    # 4. MOSB ê²½ìœ  ë¶„ì„
    mosb_cases = df[df['FLOW_CODE_CALC'] == 3]
    print(f"\nğŸ“Š MOSB ê²½ìœ  ì¼€ì´ìŠ¤: {len(mosb_cases):,}ê±´")
    
    # 5. ì»¬ëŸ¼ ë¶„ë¥˜ ì •í™•ì„± ê²€ì¦
    print(f"\nğŸ“Š ì»¬ëŸ¼ ë¶„ë¥˜ ì •í™•ì„±:")
    print(f"  ì°½ê³  ì»¬ëŸ¼: {len(WAREHOUSE_COLUMNS)}ê°œ")
    print(f"  í˜„ì¥ ì»¬ëŸ¼: {len(SITE_COLUMNS)}ê°œ")
    print(f"  ì°½ê³  ì»¬ëŸ¼: {', '.join(WAREHOUSE_COLUMNS)}")
    print(f"  í˜„ì¥ ì»¬ëŸ¼: {', '.join(SITE_COLUMNS)}")
    
    return source_flow

def suggest_realistic_targets(actual_dist, tdd_targets):
    """í˜„ì‹¤ì ì¸ ëª©í‘œê°’ ì œì•ˆ"""
    logger.info("ğŸ’¡ í˜„ì‹¤ì ì¸ ëª©í‘œê°’ ì œì•ˆ")
    
    print("\n" + "="*80)
    print("ğŸ’¡ í˜„ì‹¤ì ì¸ ëª©í‘œê°’ ì œì•ˆ")
    print("="*80)
    
    total_actual = sum(actual_dist.values)
    
    # í˜„ì¬ ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í˜„ì‹¤ì ì¸ ëª©í‘œê°’
    realistic_targets = {}
    for code, actual in actual_dist.items():
        percentage = (actual / total_actual) * 100
        realistic_targets[code] = {
            'actual': actual,
            'percentage': percentage,
            'suggested_target': actual,  # í˜„ì¬ ë¶„í¬ ìœ ì§€
            'tdd_target': tdd_targets.get(code, 0)
        }
    
    print(f"ğŸ“Š í˜„ì‹¤ì ì¸ ëª©í‘œê°’ (í˜„ì¬ ë¶„í¬ ê¸°ë°˜):")
    for code, data in realistic_targets.items():
        print(f"  Code {code}: {data['actual']:,}ê±´ ({data['percentage']:.1f}%)")
    
    print(f"\nğŸ“Š TDD ëª©í‘œê°’ vs í˜„ì‹¤ì  ëª©í‘œê°’:")
    for code, data in realistic_targets.items():
        tdd_diff = abs(data['actual'] - data['tdd_target'])
        print(f"  Code {code}: TDD ì°¨ì´ {tdd_diff:,}ê±´")
    
    return realistic_targets

def generate_analysis_report(df, actual_dist, tdd_targets, realistic_targets, source_flow):
    """ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    logger.info("ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Excel ë¦¬í¬íŠ¸
    excel_path = f"FLOW_CODE_ANALYSIS_REPORT_{timestamp}.xlsx"
    
    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        # ì „ì²´ ë°ì´í„°
        df.to_excel(writer, sheet_name='ì „ì²´ë°ì´í„°', index=False)
        
        # Flow Code ë¶„í¬
        distribution_df = pd.DataFrame([
            {
                'Flow_Code': code,
                'Actual_Count': count,
                'Actual_Percentage': (count / len(df)) * 100,
                'TDD_Target': tdd_targets.get(code, 0),
                'TDD_Difference': count - tdd_targets.get(code, 0),
                'Realistic_Target': count
            }
            for code, count in actual_dist.items()
        ])
        distribution_df.to_excel(writer, sheet_name='FlowCodeë¶„í¬', index=False)
        
        # ë°ì´í„° ì†ŒìŠ¤ë³„ ë¶„í¬
        source_flow.to_excel(writer, sheet_name='ì†ŒìŠ¤ë³„ë¶„í¬')
        
        # Pre Arrival ë¶„ì„
        pre_arrival_cases = df[df['FLOW_CODE_CALC'] == 0]
        pre_arrival_cases.to_excel(writer, sheet_name='PreArrivalì¼€ì´ìŠ¤', index=False)
        
        # ì»¬ëŸ¼ ë¶„ë¥˜ ì •ë³´
        column_info = pd.DataFrame({
            'Column_Type': ['ì°½ê³ '] * len(WAREHOUSE_COLUMNS) + ['í˜„ì¥'] * len(SITE_COLUMNS),
            'Column_Name': WAREHOUSE_COLUMNS + SITE_COLUMNS,
            'In_Data': [col in df.columns for col in WAREHOUSE_COLUMNS + SITE_COLUMNS]
        })
        column_info.to_excel(writer, sheet_name='ì»¬ëŸ¼ë¶„ë¥˜ì •ë³´', index=False)
    
    # ë§ˆí¬ë‹¤ìš´ ìš”ì•½
    md_path = f"FLOW_CODE_ANALYSIS_SUMMARY_{timestamp}.md"
    
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(f"# FLOW CODE ë¶„í¬ ì°¨ì´ ë¶„ì„ ë¦¬í¬íŠ¸\n\n")
        f.write(f"**ìƒì„±ì¼ì‹œ:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write(f"## ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½\n")
        f.write(f"- ì „ì²´ ë°ì´í„°: {len(df):,}ê±´\n")
        f.write(f"- ë°ì´í„° ì†ŒìŠ¤: {', '.join(df['DATA_SOURCE'].unique())}\n")
        f.write(f"- ì •í™•í•œ ì»¬ëŸ¼ ë¶„ë¥˜ ì ìš©: ì°½ê³  {len(WAREHOUSE_COLUMNS)}ê°œ, í˜„ì¥ {len(SITE_COLUMNS)}ê°œ\n\n")
        
        f.write(f"## ğŸ“ˆ Flow Code ë¶„í¬\n")
        f.write(f"| Code | ì‹¤ì œ | ë¹„ìœ¨ | TDDëª©í‘œ | ì°¨ì´ |\n")
        f.write(f"|------|------|------|---------|------|\n")
        
        for code, count in actual_dist.items():
            percentage = (count / len(df)) * 100
            tdd_target = tdd_targets.get(code, 0)
            difference = count - tdd_target
            f.write(f"| {code} | {count:,} | {percentage:.1f}% | {tdd_target:,} | {difference:+,} |\n")
        
        f.write(f"\n## ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­\n")
        f.write(f"1. **ì»¬ëŸ¼ ë¶„ë¥˜ ê°œì„ **: ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ì„ ì •í™•íˆ ë¶„ë¥˜í•˜ì—¬ ë¶„ì„\n")
        f.write(f"2. **ë°ì´í„° íŠ¹ì„± ì°¨ì´**: ì‹¤ì œ ë°ì´í„°ëŠ” TDD ëª©í‘œê°’ê³¼ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§\n")
        f.write(f"3. **Pre Arrival ê³¼ë‹¤**: í˜„ì¥ ë°ì´í„°ê°€ ì—†ëŠ” ì¼€ì´ìŠ¤ê°€ ì˜ˆìƒë³´ë‹¤ ë§ìŒ\n")
        f.write(f"4. **ì°½ê³  ê²½ìœ  íŒ¨í„´**: ì‹¤ì œ ì°½ê³  ì‚¬ìš© íŒ¨í„´ì´ TDD ê°€ì •ê³¼ ë‹¤ë¦„\n")
        f.write(f"5. **MOSB ì‚¬ìš©**: MOSB ê²½ìœ  ì¼€ì´ìŠ¤ê°€ ì˜ˆìƒë³´ë‹¤ ë§ìŒ\n\n")
        
        f.write(f"## ğŸ’¡ ê¶Œì¥ì‚¬í•­\n")
        f.write(f"1. **í˜„ì‹¤ì  ëª©í‘œ ì„¤ì •**: í˜„ì¬ ë°ì´í„° ë¶„í¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª©í‘œê°’ ì¬ì„¤ì •\n")
        f.write(f"2. **ë°ì´í„° í’ˆì§ˆ ê°œì„ **: í˜„ì¥ ë°ì´í„° ëˆ„ë½ ì¼€ì´ìŠ¤ ë³´ì™„\n")
        f.write(f"3. **ë¡œì§ ê²€ì¦**: ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ í”„ë¡œì„¸ìŠ¤ì™€ ë¡œì§ ì¼ì¹˜ì„± í™•ì¸\n")
        f.write(f"4. **ì»¬ëŸ¼ ë¶„ë¥˜ ìœ ì§€**: ì •í™•í•œ ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ ë¶„ë¥˜ ì§€ì† ì‚¬ìš©\n")
        
        f.write(f"\n## ğŸ“‹ ì •í™•í•œ ì»¬ëŸ¼ ë¶„ë¥˜\n")
        f.write(f"### ì°½ê³  ì»¬ëŸ¼\n")
        f.write(f"- {', '.join(WAREHOUSE_COLUMNS)}\n\n")
        f.write(f"### í˜„ì¥ ì»¬ëŸ¼\n")
        f.write(f"- {', '.join(SITE_COLUMNS)}\n")
    
    logger.info(f"ğŸ“‹ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ:")
    logger.info(f"  - Excel: {excel_path}")
    logger.info(f"  - Markdown: {md_path}")
    
    return excel_path, md_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ FLOW CODE ë¶„í¬ ì°¨ì´ ë¶„ì„ ì‹œì‘")
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        df = load_data()
        
        # 2. ë°ì´í„° íŠ¹ì„± ë¶„ì„
        warehouse_cols, site_cols = analyze_data_characteristics(df)
        
        # 3. Flow Code ë¶„í¬ ê³„ì‚°
        df, actual_dist = calculate_flow_code_distribution(df)
        
        # 4. TDD ëª©í‘œê°’ê³¼ ë¹„êµ
        tdd_targets = compare_with_tdd_targets(actual_dist)
        
        # 5. ê·¼ë³¸ ì›ì¸ ë¶„ì„
        source_flow = analyze_root_causes(df, actual_dist, tdd_targets)
        
        # 6. í˜„ì‹¤ì ì¸ ëª©í‘œê°’ ì œì•ˆ
        realistic_targets = suggest_realistic_targets(actual_dist, tdd_targets)
        
        # 7. ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        excel_path, md_path = generate_analysis_report(
            df, actual_dist, tdd_targets, realistic_targets, source_flow
        )
        
        # 8. ìµœì¢… ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ‰ FLOW CODE ë¶„í¬ ì°¨ì´ ë¶„ì„ ì™„ë£Œ!")
        print("="*80)
        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")
        print(f"ğŸ“ Excel ë¦¬í¬íŠ¸: {excel_path}")
        print(f"ğŸ“ ìš”ì•½ ë¦¬í¬íŠ¸: {md_path}")
        
        print(f"\nğŸ’¡ í•µì‹¬ ë°œê²¬ì‚¬í•­:")
        print(f"  1. ì •í™•í•œ ì°½ê³ /í˜„ì¥ ì»¬ëŸ¼ ë¶„ë¥˜ ì ìš©")
        print(f"  2. ì‹¤ì œ ë°ì´í„°ëŠ” TDD ëª©í‘œê°’ê³¼ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§")
        print(f"  3. Pre Arrival ì¼€ì´ìŠ¤ê°€ ì˜ˆìƒë³´ë‹¤ ë§ìŒ")
        print(f"  4. ì°½ê³  ê²½ìœ  íŒ¨í„´ì´ TDD ê°€ì •ê³¼ ë‹¤ë¦„")
        print(f"  5. í˜„ì‹¤ì ì¸ ëª©í‘œê°’ ì¬ì„¤ì •ì´ í•„ìš”í•¨")
        
        print("="*80)
        
        logger.info("âœ… FLOW CODE ë¶„í¬ ì°¨ì´ ë¶„ì„ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

if __name__ == "__main__":
    main() 