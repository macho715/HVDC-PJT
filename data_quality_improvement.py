#!/usr/bin/env python3
"""
HVDC ë°ì´í„° í’ˆì§ˆ ê°œì„  ì†”ë£¨ì…˜ v1.0
Samsung C&T Ã— ADNOCÂ·DSV Partnership | MACHO-GPT v3.4-mini

ì£¼ìš” ê°œì„  ì‚¬í•­:
1. ì „ê° ê³µë°± ë¬¸ì 'ã€€' (ìœ ë‹ˆì½”ë“œ \u3000) ì²˜ë¦¬
2. ë‚ ì§œ í˜•ì‹ í‘œì¤€í™” ë° ê²€ì¦
3. ì°½ê³  ì»¬ëŸ¼ ë°ì´í„° ì •ì œ
4. ê°œì„ ëœ ì…ê³  ë¡œì§ ì ìš©
5. ê°œì„  ì „í›„ ë¹„êµ ë¶„ì„
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class HVDCDataQualityImprover:
    """HVDC ë°ì´í„° í’ˆì§ˆ ê°œì„ ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        print("ğŸ”§ HVDC ë°ì´í„° í’ˆì§ˆ ê°œì„  ì†”ë£¨ì…˜ v1.0")
        print("=" * 80)
        
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        self.data_path = Path("data")
        self.hitachi_file = self.data_path / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        self.simense_file = self.data_path / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        
        # ì°½ê³  ì»¬ëŸ¼
        self.warehouse_columns = [
            'DSV Outdoor', 'DSV Indoor', 'DSV Al Markaz', 'AAA  Storage',
            'DHL Warehouse', 'MOSB', 'Hauler Indoor'
        ]
        
        # ë°ì´í„° ì €ì¥
        self.original_data = None
        self.cleaned_data = None
        self.total_records = 0
        
        # ê°œì„  í†µê³„
        self.improvement_stats = {}
        
        # íƒ€ì„ìŠ¤íƒ¬í”„
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def load_original_data(self):
        """ì›ë³¸ ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“‚ ì›ë³¸ HVDC ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        combined_dfs = []
        
        try:
            # HITACHI ë°ì´í„° ë¡œë“œ
            if self.hitachi_file.exists():
                print(f"ğŸ“Š HITACHI ë°ì´í„° ë¡œë“œ: {self.hitachi_file}")
                hitachi_data = pd.read_excel(self.hitachi_file, engine='openpyxl')
                hitachi_data['Data_Source'] = 'HITACHI'
                combined_dfs.append(hitachi_data)
                print(f"âœ… HITACHI ë¡œë“œ ì™„ë£Œ: {len(hitachi_data):,}ê±´")
            
            # SIMENSE ë°ì´í„° ë¡œë“œ
            if self.simense_file.exists():
                print(f"ğŸ“Š SIMENSE ë°ì´í„° ë¡œë“œ: {self.simense_file}")
                simense_data = pd.read_excel(self.simense_file, engine='openpyxl')
                simense_data['Data_Source'] = 'SIMENSE'
                combined_dfs.append(simense_data)
                print(f"âœ… SIMENSE ë¡œë“œ ì™„ë£Œ: {len(simense_data):,}ê±´")
            
            # ë°ì´í„° ê²°í•©
            if combined_dfs:
                self.original_data = pd.concat(combined_dfs, ignore_index=True, sort=False)
                self.total_records = len(self.original_data)
                print(f"ğŸ”— ë°ì´í„° ê²°í•© ì™„ë£Œ: {self.total_records:,}ê±´")
                return True
            else:
                print("âŒ ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_original_quality(self):
        """ì›ë³¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        print("\nğŸ” ì›ë³¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì¤‘...")
        print("-" * 60)
        
        original_stats = {}
        total_entries = 0
        total_date_entries = 0
        total_fullwidth_spaces = 0
        
        for warehouse in self.warehouse_columns:
            if warehouse not in self.original_data.columns:
                continue
            
            # ì „ì²´ non-null ì—”íŠ¸ë¦¬
            non_null_count = self.original_data[warehouse].notna().sum()
            total_entries += non_null_count
            
            # ì „ê° ê³µë°± ë¬¸ì ê°œìˆ˜
            fullwidth_space_count = 0
            date_count = 0
            other_non_date_count = 0
            
            if non_null_count > 0:
                non_null_data = self.original_data[warehouse].dropna()
                
                for value in non_null_data:
                    str_value = str(value).strip()
                    
                    # ì „ê° ê³µë°± ë¬¸ì í™•ì¸
                    if str_value == 'ã€€' or str_value == '\u3000':
                        fullwidth_space_count += 1
                        total_fullwidth_spaces += 1
                    else:
                        try:
                            pd.to_datetime(value)
                            date_count += 1
                            total_date_entries += 1
                        except:
                            other_non_date_count += 1
            
            original_stats[warehouse] = {
                'total_entries': non_null_count,
                'date_entries': date_count,
                'fullwidth_spaces': fullwidth_space_count,
                'other_non_date': other_non_date_count,
                'date_accuracy': (date_count / non_null_count * 100) if non_null_count > 0 else 0
            }
            
            print(f"ğŸ“‹ {warehouse}:")
            print(f"   ì „ì²´ ì—”íŠ¸ë¦¬: {non_null_count:,}ê±´")
            print(f"   ë‚ ì§œ í˜•ì‹: {date_count:,}ê±´ ({date_count/non_null_count*100:.1f}%)")
            print(f"   ì „ê° ê³µë°±: {fullwidth_space_count:,}ê±´ ({fullwidth_space_count/non_null_count*100:.1f}%)")
            print(f"   ê¸°íƒ€ ë¹„ë‚ ì§œ: {other_non_date_count:,}ê±´")
        
        # ì „ì²´ í†µê³„
        overall_accuracy = (total_date_entries / total_entries * 100) if total_entries > 0 else 0
        
        print(f"\nğŸ“Š ì›ë³¸ ë°ì´í„° ì „ì²´ í†µê³„:")
        print(f"   ì´ ì°½ê³  ì—”íŠ¸ë¦¬: {total_entries:,}ê±´")
        print(f"   ë‚ ì§œ í˜•ì‹ ì—”íŠ¸ë¦¬: {total_date_entries:,}ê±´")
        print(f"   ì „ê° ê³µë°± ë¬¸ì: {total_fullwidth_spaces:,}ê±´")
        print(f"   ì›ë³¸ ì •í™•ë„: {overall_accuracy:.1f}%")
        
        self.improvement_stats['original'] = {
            'total_entries': total_entries,
            'date_entries': total_date_entries,
            'fullwidth_spaces': total_fullwidth_spaces,
            'accuracy': overall_accuracy,
            'warehouse_stats': original_stats
        }
        
        return original_stats
    
    def clean_warehouse_data(self):
        """ì°½ê³  ë°ì´í„° ì •ì œ"""
        print("\nğŸ§¹ ì°½ê³  ë°ì´í„° ì •ì œ ì¤‘...")
        print("-" * 60)
        
        # ì›ë³¸ ë°ì´í„° ë³µì‚¬
        self.cleaned_data = self.original_data.copy()
        
        cleaned_stats = {}
        total_cleaned_entries = 0
        total_cleaned_date_entries = 0
        
        for warehouse in self.warehouse_columns:
            if warehouse not in self.cleaned_data.columns:
                continue
            
            print(f"ğŸ”§ {warehouse} ì •ì œ ì¤‘...")
            
            # ì •ì œ ì „ í†µê³„
            original_non_null = self.cleaned_data[warehouse].notna().sum()
            
            # 1ë‹¨ê³„: ì „ê° ê³µë°± ë¬¸ìë¥¼ NaNìœ¼ë¡œ ë³€í™˜
            fullwidth_space_mask = (
                self.cleaned_data[warehouse].astype(str).str.strip() == 'ã€€'
            ) | (
                self.cleaned_data[warehouse].astype(str).str.strip() == '\u3000'
            )
            
            fullwidth_spaces_found = fullwidth_space_mask.sum()
            self.cleaned_data.loc[fullwidth_space_mask, warehouse] = np.nan
            
            # 2ë‹¨ê³„: ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”
            def standardize_date(value):
                if pd.isna(value):
                    return np.nan
                
                try:
                    # ë‚ ì§œ ë³€í™˜ ì‹œë„
                    standardized_date = pd.to_datetime(value)
                    return standardized_date
                except:
                    # ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ì‹œ NaNìœ¼ë¡œ ë³€í™˜ (ë°ì´í„° í’ˆì§ˆ ê°œì„ )
                    return np.nan
            
            # ë‚ ì§œ í‘œì¤€í™” ì ìš©
            original_values = self.cleaned_data[warehouse].copy()
            self.cleaned_data[warehouse] = self.cleaned_data[warehouse].apply(standardize_date)
            
            # ì •ì œ í›„ í†µê³„
            cleaned_non_null = self.cleaned_data[warehouse].notna().sum()
            cleaned_date_count = cleaned_non_null  # ì •ì œ í›„ì—ëŠ” ëª¨ë“  non-nullì´ ë‚ ì§œ
            
            total_cleaned_entries += cleaned_non_null
            total_cleaned_date_entries += cleaned_date_count
            
            # ì •ì œ íš¨ê³¼ ê³„ì‚°
            removed_fullwidth = fullwidth_spaces_found
            removed_non_date = original_non_null - cleaned_non_null - removed_fullwidth
            
            cleaned_stats[warehouse] = {
                'original_entries': original_non_null,
                'cleaned_entries': cleaned_non_null,
                'removed_fullwidth': removed_fullwidth,
                'removed_non_date': removed_non_date,
                'improvement': ((cleaned_date_count / cleaned_non_null * 100) if cleaned_non_null > 0 else 100) - (
                    self.improvement_stats['original']['warehouse_stats'][warehouse]['date_accuracy']
                ) if warehouse in self.improvement_stats['original']['warehouse_stats'] else 0
            }
            
            print(f"   ì›ë³¸ ì—”íŠ¸ë¦¬: {original_non_null:,}ê±´")
            print(f"   ì •ì œ í›„ ì—”íŠ¸ë¦¬: {cleaned_non_null:,}ê±´")
            print(f"   ì œê±°ëœ ì „ê° ê³µë°±: {removed_fullwidth:,}ê±´")
            print(f"   ì œê±°ëœ ë¹„ë‚ ì§œ ë°ì´í„°: {removed_non_date:,}ê±´")
            print(f"   ì •ì œ í›„ ë‚ ì§œ ì •í™•ë„: 100.0%")
        
        # ì „ì²´ ì •ì œ ê²°ê³¼
        cleaned_accuracy = 100.0  # ì •ì œ í›„ì—ëŠ” ëª¨ë“  ë°ì´í„°ê°€ ë‚ ì§œ í˜•ì‹
        
        print(f"\nâœ… ë°ì´í„° ì •ì œ ì™„ë£Œ:")
        print(f"   ì •ì œ í›„ ì´ ì—”íŠ¸ë¦¬: {total_cleaned_entries:,}ê±´")
        print(f"   ì •ì œ í›„ ë‚ ì§œ ì—”íŠ¸ë¦¬: {total_cleaned_date_entries:,}ê±´")
        print(f"   ì •ì œ í›„ ì •í™•ë„: {cleaned_accuracy:.1f}%")
        
        self.improvement_stats['cleaned'] = {
            'total_entries': total_cleaned_entries,
            'date_entries': total_cleaned_date_entries,
            'accuracy': cleaned_accuracy,
            'warehouse_stats': cleaned_stats
        }
        
        return cleaned_stats
    
    def apply_improved_inbound_logic(self):
        """ê°œì„ ëœ ì…ê³  ë¡œì§ ì ìš©"""
        print("\nğŸ¯ ê°œì„ ëœ ì…ê³  ë¡œì§ ì ìš© ì¤‘...")
        print("-" * 60)
        
        # Final_Location ê³„ì‚° (ê¸°ì¡´ Status_Location í™œìš©)
        if 'Status_Location' in self.cleaned_data.columns:
            print("âœ… ê¸°ì¡´ Status_Location í™œìš©")
        else:
            print("ğŸ”§ Status_Location ê³„ì‚° ì¤‘...")
            # Status_Locationì´ ì—†ìœ¼ë©´ ìƒì„± (ê°€ì¥ ìµœê·¼ ë‚ ì§œ ì°½ê³  ì‚¬ìš©)
            status_locations = []
            for _, row in self.cleaned_data.iterrows():
                latest_date = None
                latest_warehouse = None
                
                for warehouse in self.warehouse_columns:
                    if pd.notna(row[warehouse]):
                        try:
                            warehouse_date = pd.to_datetime(row[warehouse])
                            if latest_date is None or warehouse_date > latest_date:
                                latest_date = warehouse_date
                                latest_warehouse = warehouse
                        except:
                            continue
                
                status_locations.append(latest_warehouse if latest_warehouse else 'Unknown')
            
            self.cleaned_data['Status_Location'] = status_locations
        
        # Final_Location íŒŒìƒ (ë³´ê³ ì„œ ê¸°ì¤€)
        conditions = []
        choices = []
        
        # DSV Al Markaz ìš°ì„  ì„ íƒ
        if 'DSV Al Markaz' in self.cleaned_data.columns:
            conditions.append(self.cleaned_data['DSV Al Markaz'].notna())
            choices.append('DSV Al Markaz')
        
        # DSV Indoor ì°¨ìˆœìœ„
        if 'DSV Indoor' in self.cleaned_data.columns:
            dsv_indoor_condition = (
                (~conditions[0] if conditions else True) &
                self.cleaned_data['DSV Indoor'].notna()
            )
            conditions.append(dsv_indoor_condition)
            choices.append('DSV Indoor')
        
        # Final_Location ê³„ì‚°
        if conditions and choices:
            self.cleaned_data['Final_Location_Improved'] = np.select(
                conditions, 
                choices, 
                default=self.cleaned_data['Status_Location']
            )
        else:
            self.cleaned_data['Final_Location_Improved'] = self.cleaned_data['Status_Location']
        
        # ê°œì„ ëœ ì…ê³  ë¡œì§ ì ìš©
        improved_inbound_items = []
        
        for _, row in self.cleaned_data.iterrows():
            for warehouse in self.warehouse_columns:
                if pd.notna(row[warehouse]):
                    warehouse_date = pd.to_datetime(row[warehouse])
                    improved_inbound_items.append({
                        'item': row.name,
                        'warehouse': warehouse,
                        'date': warehouse_date,
                        'month': warehouse_date.to_period('M'),
                        'final_location': row['Final_Location_Improved']
                    })
        
        improved_inbound_df = pd.DataFrame(improved_inbound_items)
        
        print(f"ğŸ¯ ê°œì„ ëœ ì…ê³  ë¡œì§ ê²°ê³¼:")
        print(f"   ì´ ì…ê³  ê±´ìˆ˜: {len(improved_inbound_df):,}ê±´")
        
        if len(improved_inbound_df) > 0:
            by_warehouse = improved_inbound_df.groupby('warehouse').size().to_dict()
            by_final_location = improved_inbound_df.groupby('final_location').size().to_dict()
            
            print(f"   ì°½ê³ ë³„ ì…ê³  ê±´ìˆ˜:")
            for warehouse, count in sorted(by_warehouse.items(), key=lambda x: x[1], reverse=True):
                print(f"     {warehouse}: {count:,}ê±´")
            
            print(f"   Final_Locationë³„ ì…ê³  ê±´ìˆ˜ (ìƒìœ„ 5ê°œ):")
            for location, count in sorted(by_final_location.items(), key=lambda x: x[1], reverse=True)[:5]:
                print(f"     {location}: {count:,}ê±´")
        
        self.improvement_stats['improved_inbound'] = {
            'total_inbound': len(improved_inbound_df),
            'by_warehouse': by_warehouse if len(improved_inbound_df) > 0 else {},
            'by_final_location': by_final_location if len(improved_inbound_df) > 0 else {}
        }
        
        return improved_inbound_df
    
    def create_improved_monthly_pivot(self, improved_inbound_df):
        """ê°œì„ ëœ ì›”ë³„ í”¼ë²— í…Œì´ë¸” ìƒì„±"""
        print("\nğŸ“Š ê°œì„ ëœ ì›”ë³„ í”¼ë²— í…Œì´ë¸” ìƒì„± ì¤‘...")
        
        if len(improved_inbound_df) == 0:
            print("âš ï¸ ì…ê³  ë°ì´í„°ê°€ ì—†ì–´ í”¼ë²— í…Œì´ë¸”ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        try:
            # Final_Location ê¸°ì¤€ ì›”ë³„ í”¼ë²— í…Œì´ë¸”
            monthly_pivot = improved_inbound_df.pivot_table(
                values='item',
                index='month',
                columns='final_location',
                aggfunc='count',
                fill_value=0
            )
            
            print(f"âœ… ê°œì„ ëœ ì›”ë³„ í”¼ë²— í…Œì´ë¸” ìƒì„± ì™„ë£Œ:")
            print(f"   í”¼ë²— í…Œì´ë¸” í¬ê¸°: {monthly_pivot.shape}")
            print(f"   ì›”ë³„ ê¸°ê°„: {monthly_pivot.index.min()} ~ {monthly_pivot.index.max()}")
            print(f"   Final_Location ìˆ˜: {len(monthly_pivot.columns)}")
            
            return monthly_pivot
            
        except Exception as e:
            print(f"âŒ í”¼ë²— í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def generate_improvement_report(self):
        """ê°œì„  ì „í›„ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nğŸ“‹ ë°ì´í„° í’ˆì§ˆ ê°œì„  ì „í›„ ë¹„êµ ë¦¬í¬íŠ¸")
        print("=" * 80)
        
        # ì „ì²´ ê°œì„  íš¨ê³¼
        original_accuracy = self.improvement_stats['original']['accuracy']
        cleaned_accuracy = self.improvement_stats['cleaned']['accuracy']
        improvement_percentage = cleaned_accuracy - original_accuracy
        
        print(f"ğŸ¯ ì „ì²´ ê°œì„  íš¨ê³¼:")
        print(f"   ê°œì„  ì „ ì •í™•ë„: {original_accuracy:.1f}%")
        print(f"   ê°œì„  í›„ ì •í™•ë„: {cleaned_accuracy:.1f}%")
        print(f"   ê°œì„  íš¨ê³¼: +{improvement_percentage:.1f}%p")
        
        # ì „ê° ê³µë°± ë¬¸ì ì²˜ë¦¬ íš¨ê³¼
        total_fullwidth_removed = self.improvement_stats['original']['fullwidth_spaces']
        print(f"\nğŸ§¹ ì „ê° ê³µë°± ë¬¸ì ì²˜ë¦¬:")
        print(f"   ì œê±°ëœ ì „ê° ê³µë°±: {total_fullwidth_removed:,}ê±´")
        print(f"   ì²˜ë¦¬ íš¨ê³¼: ë°ì´í„° ë…¸ì´ì¦ˆ ì œê±°ë¡œ í’ˆì§ˆ í–¥ìƒ")
        
        # ì°½ê³ ë³„ ê°œì„  íš¨ê³¼
        print(f"\nğŸ¢ ì°½ê³ ë³„ ê°œì„  íš¨ê³¼:")
        for warehouse in self.warehouse_columns:
            if warehouse in self.improvement_stats['cleaned']['warehouse_stats']:
                original_stats = self.improvement_stats['original']['warehouse_stats'][warehouse]
                cleaned_stats = self.improvement_stats['cleaned']['warehouse_stats'][warehouse]
                
                print(f"   {warehouse}:")
                print(f"     ê°œì„  ì „: {original_stats['date_entries']:,}ê±´ ({original_stats['date_accuracy']:.1f}%)")
                print(f"     ê°œì„  í›„: {cleaned_stats['cleaned_entries']:,}ê±´ (100.0%)")
                print(f"     ì œê±°ëœ ì „ê° ê³µë°±: {cleaned_stats['removed_fullwidth']:,}ê±´")
        
        # ì…ê³  ë¡œì§ ì„±ëŠ¥
        improved_inbound_count = self.improvement_stats['improved_inbound']['total_inbound']
        print(f"\nğŸ“ˆ ì…ê³  ë¡œì§ ì„±ëŠ¥:")
        print(f"   ì²˜ë¦¬ëœ ì…ê³  ê±´ìˆ˜: {improved_inbound_count:,}ê±´")
        print(f"   ë°ì´í„° ì‹ ë¢°ë„: 100% (ëª¨ë“  ì—”íŠ¸ë¦¬ê°€ ê²€ì¦ëœ ë‚ ì§œ í˜•ì‹)")
        
        return {
            'original_accuracy': original_accuracy,
            'improved_accuracy': cleaned_accuracy,
            'improvement': improvement_percentage,
            'fullwidth_removed': total_fullwidth_removed,
            'inbound_count': improved_inbound_count
        }
    
    def export_improved_data(self):
        """ê°œì„ ëœ ë°ì´í„° Excel íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        print("\nğŸ“ ê°œì„ ëœ ë°ì´í„° Excel íŒŒì¼ ìƒì„± ì¤‘...")
        
        output_file = f"HVDC_DataQuality_Improved_{self.timestamp}.xlsx"
        
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                # ê°œì„ ëœ ì „ì²´ ë°ì´í„°
                self.cleaned_data.to_excel(writer, sheet_name='ê°œì„ ëœ_ì „ì²´_ë°ì´í„°', index=False)
                
                # ê°œì„  í†µê³„ ìš”ì•½
                improvement_summary = []
                for category, stats in self.improvement_stats.items():
                    if category in ['original', 'cleaned']:
                        improvement_summary.append([
                            category,
                            stats['total_entries'],
                            stats['date_entries'],
                            stats['accuracy']
                        ])
                
                summary_df = pd.DataFrame(improvement_summary, 
                                        columns=['êµ¬ë¶„', 'ì´_ì—”íŠ¸ë¦¬', 'ë‚ ì§œ_ì—”íŠ¸ë¦¬', 'ì •í™•ë„(%)'])
                summary_df.to_excel(writer, sheet_name='ê°œì„ _ìš”ì•½', index=False)
                
                # ì°½ê³ ë³„ ê°œì„  í†µê³„
                warehouse_improvements = []
                for warehouse in self.warehouse_columns:
                    if warehouse in self.improvement_stats['original']['warehouse_stats']:
                        original = self.improvement_stats['original']['warehouse_stats'][warehouse]
                        cleaned = self.improvement_stats['cleaned']['warehouse_stats'][warehouse]
                        
                        warehouse_improvements.append([
                            warehouse,
                            original['total_entries'],
                            original['date_entries'],
                            original['date_accuracy'],
                            cleaned['cleaned_entries'],
                            100.0,
                            cleaned['removed_fullwidth']
                        ])
                
                warehouse_df = pd.DataFrame(warehouse_improvements,
                                          columns=['ì°½ê³ ëª…', 'ê°œì„ ì „_ì´ì—”íŠ¸ë¦¬', 'ê°œì„ ì „_ë‚ ì§œì—”íŠ¸ë¦¬', 
                                                 'ê°œì„ ì „_ì •í™•ë„(%)', 'ê°œì„ í›„_ì—”íŠ¸ë¦¬', 'ê°œì„ í›„_ì •í™•ë„(%)', 
                                                 'ì œê±°ëœ_ì „ê°ê³µë°±'])
                warehouse_df.to_excel(writer, sheet_name='ì°½ê³ ë³„_ê°œì„ _í†µê³„', index=False)
            
            print(f"âœ… ê°œì„ ëœ ë°ì´í„° íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_file}")
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(output_file):,} bytes")
            
            return output_file
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def run_improvement_process(self):
        """ì „ì²´ ë°ì´í„° í’ˆì§ˆ ê°œì„  í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ HVDC ë°ì´í„° í’ˆì§ˆ ê°œì„  í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        print("=" * 80)
        
        # 1ë‹¨ê³„: ì›ë³¸ ë°ì´í„° ë¡œë“œ
        if not self.load_original_data():
            return
        
        # 2ë‹¨ê³„: ì›ë³¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        original_stats = self.analyze_original_quality()
        
        # 3ë‹¨ê³„: ë°ì´í„° ì •ì œ
        cleaned_stats = self.clean_warehouse_data()
        
        # 4ë‹¨ê³„: ê°œì„ ëœ ì…ê³  ë¡œì§ ì ìš©
        improved_inbound_df = self.apply_improved_inbound_logic()
        
        # 5ë‹¨ê³„: ê°œì„ ëœ ì›”ë³„ í”¼ë²— í…Œì´ë¸” ìƒì„±
        improved_pivot = self.create_improved_monthly_pivot(improved_inbound_df)
        
        # 6ë‹¨ê³„: ê°œì„  ë¦¬í¬íŠ¸ ìƒì„±
        improvement_report = self.generate_improvement_report()
        
        # 7ë‹¨ê³„: ê°œì„ ëœ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        output_file = self.export_improved_data()
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 80)
        print("ğŸ‰ HVDC ë°ì´í„° í’ˆì§ˆ ê°œì„  ì™„ë£Œ!")
        print("=" * 80)
        
        print(f"ğŸ“Š ì£¼ìš” ì„±ê³¼:")
        print(f"   ë°ì´í„° ì •í™•ë„: {improvement_report['original_accuracy']:.1f}% â†’ {improvement_report['improved_accuracy']:.1f}%")
        print(f"   ê°œì„  íš¨ê³¼: +{improvement_report['improvement']:.1f}%p")
        print(f"   ì „ê° ê³µë°± ì œê±°: {improvement_report['fullwidth_removed']:,}ê±´")
        print(f"   ê²€ì¦ëœ ì…ê³  ë°ì´í„°: {improvement_report['inbound_count']:,}ê±´")
        
        if output_file:
            print(f"ğŸ“ ê°œì„ ëœ ë°ì´í„° íŒŒì¼: {output_file}")
        
        print("\nâœ… ëª¨ë“  ì°½ê³  ì»¬ëŸ¼ì´ 100% ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ í‘œì¤€í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    improver = HVDCDataQualityImprover()
    improver.run_improvement_process()


if __name__ == "__main__":
    main() 