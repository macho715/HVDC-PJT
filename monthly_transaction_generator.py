#!/usr/bin/env python3
"""
MACHO-GPT v3.4-mini: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì›”ë³„/ìœ„ì¹˜ë³„ ìž…ê³  ë° ìž¬ê³  ì§‘ê³„ê¸°
warehouse_site_monthly_report.py ë¡œì§ì„ ê¸°ë°˜ìœ¼ë¡œ ìž¬ìž‘ì„±ë¨.
"""

import pandas as pd
from datetime import datetime
import os

class SiteMonthlyAggregator:
    def __init__(self, base_path='HVDC_PJT/hvdc_macho_gpt/WAREHOUSE/data'):
        """ì´ˆê¸°í™”"""
        self.base_path = base_path
        self.file_paths = {
            'HITACHI': os.path.join(self.base_path, 'HVDC WAREHOUSE_HITACHI(HE).xlsx'),
            'SIMENSE': os.path.join(self.base_path, 'HVDC WAREHOUSE_SIMENSE(SIM).xlsx')
        }
        self.output_dir = 'HVDC_PJT/MACHO_í†µí•©ê´€ë¦¬_20250702_205301/01_ì›ë³¸íŒŒì¼'
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def load_data(self):
        """HITACHI ë° SIMENSE ë°ì´í„° ë¡œë“œ ë° í†µí•©"""
        try:
            df_hitachi = pd.read_excel(self.file_paths['HITACHI'])
            df_simense = pd.read_excel(self.file_paths['SIMENSE'])
            df_hitachi['Vendor'] = 'HITACHI'
            df_simense['Vendor'] = 'SIMENSE'
            return pd.concat([df_hitachi, df_simense], ignore_index=True)
        except FileNotFoundError as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return None

    @staticmethod
    def classify_location(row):
        """í–‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„ì¹˜(Site/Warehouse) ë¶„ë¥˜"""
        # í˜„ìž¥ ì»¬ëŸ¼ ìš°ì„  í™•ì¸
        site_cols = ['AGI', 'DAS', 'MIR', 'SHU']
        for col in site_cols:
            if col in row.index and pd.notna(row[col]):
                return 'Site', col

        # ì°½ê³  ì»¬ëŸ¼ í™•ì¸
        warehouse_cols = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'Hauler Indoor', 'DSV MZP', 'MOSB', 'AAA  Storage']
        for col in warehouse_cols:
             if col in row.index and pd.notna(row[col]):
                return 'Warehouse', col

        # Status_Locationì—ì„œ 2ì°¨ í™•ì¸
        if 'Status_Location' in row.index and pd.notna(row['Status_Location']):
            loc = str(row['Status_Location']).upper()
            if any(site in loc for site in site_cols):
                return 'Site', row['Status_Location']
            else:
                return 'Warehouse', row['Status_Location']
        
        return 'ê¸°íƒ€', 'ì•Œ ìˆ˜ ì—†ìŒ'

    @staticmethod
    def get_first_valid_date(row, date_columns):
        """ì—¬ëŸ¬ ë‚ ì§œ ì»¬ëŸ¼ì—ì„œ ì²« ë²ˆì§¸ ìœ íš¨í•œ ë‚ ì§œë¥¼ ì°¾ì•„ ë°˜í™˜"""
        for col in date_columns:
            if pd.notna(row[col]):
                return pd.to_datetime(row[col], errors='coerce')
        return pd.NaT

    def process_data(self, df):
        """ë°ì´í„° ì²˜ë¦¬: ìœ„ì¹˜ ë¶„ë¥˜, ë‚ ì§œ ì¶”ì¶œ, ì›”ë³„ ì§‘ê³„"""
        # ë‚ ì§œ ì»¬ëŸ¼ ì‹ë³„
        date_columns = [col for col in df.columns if any(x in col.upper() for x in ['DSV', 'AGI', 'DAS', 'MIR', 'SHU', 'HAULER', 'AAA', 'JDN'])]

        # ìœ„ì¹˜ ë° ë‚ ì§œ ì •ë³´ ì¶”ê°€
        df[['êµ¬ë¶„', 'Location']] = df.apply(self.classify_location, axis=1, result_type='expand')
        df['ìž…ê³ ì¼'] = df.apply(self.get_first_valid_date, axis=1, date_columns=date_columns)
        
        # ìœ íš¨í•œ ìž…ê³ ì¼ì´ ìžˆëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
        df = df.dropna(subset=['ìž…ê³ ì¼'])
        df['ìž…ê³ ì›”'] = df['ìž…ê³ ì¼'].dt.to_period('M').astype(str)
        
        # Pkg ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš° 1ë¡œ ê°„ì£¼
        if 'Pkg' not in df.columns:
            df['Pkg'] = 1
            
        # ìž…ê³ ì™€ ì‹¤ì œì¶œê³  ë¶„ë¦¬
        df['ìž…ê³ '] = df['Pkg'].apply(lambda x: x if x > 0 else 0)
        df['ì‹¤ì œì¶œê³ '] = df['Pkg'].apply(lambda x: -x if x < 0 else 0) # ì¶œê³ ëŠ” ì–‘ìˆ˜ë¡œ í‘œí˜„

        # ì›”ë³„ ìž…ê³ ëŸ‰/ì¶œê³ ëŸ‰ ì§‘ê³„
        monthly_inbound = df.pivot_table(
            index=['êµ¬ë¶„', 'Location'], columns='ìž…ê³ ì›”', values='ìž…ê³ ', aggfunc='sum', fill_value=0
        )
        monthly_outbound = df.pivot_table(
            index=['êµ¬ë¶„', 'Location'], columns='ìž…ê³ ì›”', values='ì‹¤ì œì¶œê³ ', aggfunc='sum', fill_value=0
        )

        # ëˆ„ì  ìž¬ê³  ê³„ì‚° (ìž¬ê³ ë³€ë™ì˜ ëˆ„ì í•©)
        df_sorted = df.sort_values(by=['êµ¬ë¶„', 'Location', 'ìž…ê³ ì¼'])
        df_sorted['ìž¬ê³ ë³€ë™'] = df_sorted['ìž…ê³ '] - df_sorted['ì‹¤ì œì¶œê³ ']
        df_sorted['ëˆ„ì ìž¬ê³ '] = df_sorted.groupby(['êµ¬ë¶„', 'Location'])['ìž¬ê³ ë³€ë™'].cumsum()
        
        cumulative_stock = df_sorted.pivot_table(
            index=['êµ¬ë¶„', 'Location'],
            columns='ìž…ê³ ì›”',
            values='ëˆ„ì ìž¬ê³ ',
            aggfunc='last',
            fill_value=0
        )
        # ì´ì „ ì›”ì˜ ë§ˆì§€ë§‰ ëˆ„ì ê°’ì„ ì±„ìš°ê¸°
        cumulative_stock = cumulative_stock.ffill(axis=1)

        return monthly_inbound, monthly_outbound, cumulative_stock
        
    def generate_report(self):
        """ìš”ì²­ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ êµ¬ì¡°ì˜ ë¶„ë¦¬ëœ ë¦¬í¬íŠ¸ ìƒì„±"""
        df = self.load_data()
        if df is None:
            return

        monthly_inbound_pivot, monthly_outbound_pivot, cumulative_stock_pivot = self.process_data(df)

        # --- 1. ì°½ê³ (Warehouse) ë¦¬í¬íŠ¸ ìƒì„± ---
        wh_inbound = monthly_inbound_pivot[monthly_inbound_pivot.index.get_level_values('êµ¬ë¶„') == 'Warehouse']
        wh_outbound = monthly_outbound_pivot[monthly_outbound_pivot.index.get_level_values('êµ¬ë¶„') == 'Warehouse']

        # Multi-level column ìƒì„± (ìˆ˜ì •ëœ ë°©ì‹)
        wh_inbound.columns = pd.MultiIndex.from_tuples([('ìž…ê³ ', col) for col in wh_inbound.columns])
        wh_outbound.columns = pd.MultiIndex.from_tuples([('ì¶œê³ ', col) for col in wh_outbound.columns])
        
        # í–‰ ì¸ë±ìŠ¤ì—ì„œ 'êµ¬ë¶„' ë ˆë²¨ ì œê±° ë° ìž¬êµ¬ì„±
        df_report_wh = pd.concat([wh_inbound.droplevel('êµ¬ë¶„'), wh_outbound.droplevel('êµ¬ë¶„')], axis=1).fillna(0).astype(int)
        df_report_wh = df_report_wh.T.reindex(['ìž…ê³ ', 'ì¶œê³ '], level=0).T # ìˆœì„œ ê³ ì •

        
        # --- 2. í˜„ìž¥(Site) ë¦¬í¬íŠ¸ ìƒì„± ---
        site_inbound = monthly_inbound_pivot[monthly_inbound_pivot.index.get_level_values('êµ¬ë¶„') == 'Site']
        site_stock = cumulative_stock_pivot[cumulative_stock_pivot.index.get_level_values('êµ¬ë¶„') == 'Site']

        # Multi-level column ìƒì„± (ìˆ˜ì •ëœ ë°©ì‹)
        site_inbound.columns = pd.MultiIndex.from_tuples([('ìž…ê³ ', col) for col in site_inbound.columns])
        site_stock.columns = pd.MultiIndex.from_tuples([('ìž¬ê³ ', col) for col in site_stock.columns])
        
        # í–‰ ì¸ë±ìŠ¤ì—ì„œ 'êµ¬ë¶„' ë ˆë²¨ ì œê±° ë° ìž¬êµ¬ì„±
        df_report_site = pd.concat([site_inbound.droplevel('êµ¬ë¶„'), site_stock.droplevel('êµ¬ë¶„')], axis=1).fillna(0).astype(int)
        df_report_site = df_report_site.T.reindex(['ìž…ê³ ', 'ìž¬ê³ '], level=0).T # ìˆœì„œ ê³ ì •

        # ë³´ê³ ì„œ íŒŒì¼ëª…
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = os.path.join(self.output_dir, f'MACHO_ìµœì¢…_ì›”ë³„ë¦¬í¬íŠ¸_{timestamp}.xlsx')

        # í•©ê³„ í–‰ ì¶”ê°€
        df_report_wh.loc['Total'] = df_report_wh.sum().astype(int)
        df_report_site.loc['í•©ê³„'] = df_report_site.sum().astype(int)

        with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:
            df_report_wh.T.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ìž…ì¶œê³ ')
            df_report_site.T.to_excel(writer, sheet_name='í˜„ìž¥_ì›”ë³„_ìž…ê³ ìž¬ê³ ')
            
            # ìš”ì•½ ì‹œíŠ¸ ì¶”ê°€
            summary_df = pd.DataFrame({
                'í•­ëª©': ['ë¦¬í¬íŠ¸ ìœ í˜•', 'ìƒì„± ì‹œê°„', 'ë°ì´í„° ì†ŒìŠ¤'],
                'ê°’': ['ìµœì¢… ì›”ë³„ ë¦¬í¬íŠ¸ (ë¶„ë¦¬í˜•)', timestamp, self.base_path]
            })
            summary_df.to_excel(writer, sheet_name='ë¦¬í¬íŠ¸_ì •ë³´', index=False)

        print(f"âœ… ìµœì¢… ì›”ë³„ ë¦¬í¬íŠ¸ (ë¶„ë¦¬í˜•) ìƒì„± ì™„ë£Œ: {output_filename}")
        return output_filename

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ðŸš€ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì›”ë³„ ìž…ê³ /ìž¬ê³  ì§‘ê³„ ì‹œìž‘")
    aggregator = SiteMonthlyAggregator()
    aggregator.generate_report()
    print("âœ… ìž‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    main() 