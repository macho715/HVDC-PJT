#!/usr/bin/env python3
"""
SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA) ë°ì´í„° ë¶„ì„ ë° ë§¤í•‘ ë„êµ¬ (ê°œì„  ë²„ì „)
/cmd_scnt_invoice_mapping_fixed ëª…ë ¹ì–´ êµ¬í˜„
"""

import pandas as pd
import json
from datetime import datetime
from pathlib import Path
import logging
from tqdm import tqdm
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_scnt_invoice_fixed():
    """SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA).xlsx íŒŒì¼ êµ¬ì¡° ë¶„ì„ (ê°œì„  ë²„ì „)"""
    print("ğŸš€ /cmd_scnt_invoice_mapping_fixed ì‹¤í–‰")
    print("=" * 70)
    print("ğŸ“ˆ SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA) ë°ì´í„° ë¶„ì„ ë° ë§¤í•‘ (ê°œì„  ë²„ì „)")
    print("=" * 70)
    
    try:
        # íŒŒì¼ ë¡œë“œ (í—¤ë”ë¥¼ 5ë²ˆì§¸ í–‰ìœ¼ë¡œ ì„¤ì •)
        print("ğŸ“‹ SCNT INVOICE íŒŒì¼ ë¡œë“œ ì¤‘ (í—¤ë”: 5í–‰)...")
        df = pd.read_excel('data/SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA).xlsx', header=5)
        
        # ë¹ˆ í–‰ ì œê±°
        df = df.dropna(how='all')
        
        print(f"âœ… SCNT INVOICE: {len(df):,}í–‰ ë¡œë“œ ì™„ë£Œ")
        print(f"   ğŸ“Š ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
        print(f"   ğŸ“Š ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f}MB")
        
        # ì»¬ëŸ¼ ì •ë¦¬ (Unnamed ì»¬ëŸ¼ ì œê±°)
        original_cols = len(df.columns)
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        print(f"   ğŸ“Š ì •ë¦¬ í›„ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)} (ì œê±°: {original_cols - len(df.columns)}ê°œ)")
        
        # ì»¬ëŸ¼ ëª©ë¡ ì¶œë ¥
        print(f"\nğŸ“‹ SCNT INVOICE ì»¬ëŸ¼ ëª©ë¡ ({len(df.columns)}ê°œ):")
        for i, col in enumerate(df.columns, 1):
            print(f"   {i:2d}. {col}")
        
        # ë°ì´í„° íƒ€ì… ë¶„ì„
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        datetime_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
        text_cols = df.select_dtypes(include=['object']).columns.tolist()
        
        print(f"\nğŸ“Š ë°ì´í„° íƒ€ì… ë¶„ì„:")
        print(f"   ğŸ“Š ìˆ«ìí˜• ì»¬ëŸ¼: {len(numeric_cols)}ê°œ")
        print(f"   ğŸ“Š ë‚ ì§œí˜• ì»¬ëŸ¼: {len(datetime_cols)}ê°œ")
        print(f"   ğŸ“Š í…ìŠ¤íŠ¸í˜• ì»¬ëŸ¼: {len(text_cols)}ê°œ")
        print(f"   ğŸ“Š ê²°ì¸¡ê°’ ìˆëŠ” ì»¬ëŸ¼: {df.isnull().any().sum()}ê°œ")
        
        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥ (ì»¬ëŸ¼ëª…ë§Œ)
        print(f"\nğŸ“ ì£¼ìš” ì»¬ëŸ¼ ìƒ˜í”Œ:")
        key_columns = ['S/No', 'Shpt Ref', 'Job #', 'Type', 'BL #', 'POL', 'POD', 'Mode', 'Volume', 'Quantity']
        available_key_cols = [col for col in key_columns if col in df.columns]
        if available_key_cols:
            print(df[available_key_cols].head(3).to_string())
        
        # ë§¤í•‘ ê·œì¹™ ë¡œë“œ
        try:
            with open('mapping_rules_v2.6.json', 'r', encoding='utf-8') as f:
                mapping_rules = json.load(f)
            print("âœ… ë§¤í•‘ ê·œì¹™ ë¡œë“œ ì„±ê³µ")
        except FileNotFoundError:
            print("âš ï¸ ë§¤í•‘ ê·œì¹™ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # SCNT íŠ¹í™” ë§¤í•‘ ê·œì¹™ ìƒì„±
        scnt_mapping = create_scnt_specific_mapping(df.columns)
        
        # ì»¬ëŸ¼ ë§¤í•‘ ë¶„ì„
        print(f"\nğŸ”— SCNT INVOICE ì»¬ëŸ¼ ì˜¨í†¨ë¡œì§€ ë§¤í•‘")
        print("-" * 50)
        
        field_mappings = mapping_rules.get('field_mappings', {})
        field_mappings.update(scnt_mapping)  # SCNT íŠ¹í™” ë§¤í•‘ ì¶”ê°€
        
        mapped_columns = []
        unmapped_columns = []
        
        for col in df.columns:
            if col in field_mappings:
                mapped_columns.append((col, field_mappings[col]))
            else:
                unmapped_columns.append(col)
        
        print(f"ğŸ“‹ SCNT INVOICE ì»¬ëŸ¼ ë§¤í•‘ ê²°ê³¼:")
        print(f"   âœ… ë§¤í•‘ ì„±ê³µ: {len(mapped_columns)}ê°œ")
        print(f"   âŒ ë§¤í•‘ ì‹¤íŒ¨: {len(unmapped_columns)}ê°œ")
        print(f"   ğŸ“Š ë§¤í•‘ ì„±ê³µë¥ : {len(mapped_columns)/len(df.columns)*100:.1f}%")
        
        if mapped_columns:
            print(f"\nâœ… ì„±ê³µì ìœ¼ë¡œ ë§¤í•‘ëœ ì»¬ëŸ¼:")
            for original, mapped in mapped_columns:
                print(f"   {original} â†’ {mapped}")
        
        if unmapped_columns:
            print(f"\nâŒ ë§¤í•‘ë˜ì§€ ì•Šì€ ì»¬ëŸ¼:")
            for col in unmapped_columns[:15]:  # ì²˜ìŒ 15ê°œë§Œ í‘œì‹œ
                print(f"   â€¢ {col}")
            if len(unmapped_columns) > 15:
                print(f"   ... ë° {len(unmapped_columns) - 15}ê°œ ì¶”ê°€")
        
        # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        print(f"\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¶„ì„:")
        total_cells = len(df) * len(df.columns)
        missing_cells = df.isnull().sum().sum()
        data_completeness = ((total_cells - missing_cells) / total_cells) * 100
        print(f"   ğŸ“Š ë°ì´í„° ì™„ì „ì„±: {data_completeness:.1f}%")
        print(f"   ğŸ“Š ì¤‘ë³µ í–‰: {df.duplicated().sum()}ê°œ")
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
        print(f"\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸:")
        if 'Type' in df.columns:
            type_counts = df['Type'].value_counts()
            print(f"   ğŸ“¦ ì„ ì  íƒ€ì… ë¶„í¬: {dict(type_counts)}")
        
        if 'POL' in df.columns and 'POD' in df.columns:
            routes = df.groupby(['POL', 'POD']).size().head(3)
            print(f"   ğŸš¢ ì£¼ìš” ìš´ì†¡ ê²½ë¡œ (ìƒìœ„ 3ê°œ):")
            for (pol, pod), count in routes.items():
                print(f"      {pol} â†’ {pod}: {count}ê±´")
        
        # RDF ë³€í™˜
        print(f"\nğŸ”— SCNT INVOICE ë°ì´í„°ë¥¼ RDFë¡œ ë³€í™˜ ì¤‘...")
        rdf_triples = generate_rdf_triples(df, mapped_columns, mapping_rules)
        print(f"âœ… SCNT INVOICE RDF ë³€í™˜ ì™„ë£Œ: {len(df)}ê°œ ì´ë²¤íŠ¸")
        
        # SPARQL ì¿¼ë¦¬ ìƒì„±
        print(f"ğŸ” SCNT INVOICE ì „ìš© SPARQL ì¿¼ë¦¬ ìƒì„± ì¤‘...")
        sparql_queries = generate_enhanced_sparql_queries(df, mapped_columns)
        
        # ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = Path("rdf_output")
        output_dir.mkdir(exist_ok=True)
        
        # TTL íŒŒì¼ ì €ì¥
        ttl_file = output_dir / f"scnt_invoice_fixed_{len(df)}records_{timestamp}.ttl"
        with open(ttl_file, 'w', encoding='utf-8') as f:
            f.write(rdf_triples)
        print(f"âœ… SCNT INVOICE RDF/TTL ì €ì¥: {ttl_file}")
        print(f"   ğŸ“Š íŒŒì¼ í¬ê¸°: {ttl_file.stat().st_size / 1024**2:.2f}MB")
        
        # SPARQL ì¿¼ë¦¬ ì €ì¥
        sparql_file = output_dir / f"scnt_invoice_fixed_queries_{len(df)}records_{timestamp}.sparql"
        with open(sparql_file, 'w', encoding='utf-8') as f:
            f.write(sparql_queries)
        print(f"âœ… SCNT INVOICE SPARQL ì¿¼ë¦¬ ì €ì¥: {sparql_file}")
        
        # í†µê³„ ì €ì¥
        stats_content = generate_enhanced_stats_report(df, mapped_columns, unmapped_columns, data_completeness)
        stats_file = output_dir / f"scnt_invoice_fixed_stats_{timestamp}.md"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(stats_content)
        print(f"âœ… SCNT INVOICE í†µê³„ ì €ì¥: {stats_file}")
        
        print(f"\nğŸ‰ SCNT INVOICE ë§¤í•‘ ì™„ë£Œ!")
        print("=" * 70)
        print(f"ğŸ“Š ìµœì¢… í†µê³„:")
        print(f"   â€¢ ì´ ë ˆì½”ë“œ ìˆ˜: {len(df):,}ê°œ")
        print(f"   â€¢ ìœ íš¨ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
        print(f"   â€¢ ë§¤í•‘ ì„±ê³µ: {len(mapped_columns)}ê°œ ì»¬ëŸ¼ ({len(mapped_columns)/len(df.columns)*100:.1f}%)")
        print(f"   â€¢ ë§¤í•‘ ì‹¤íŒ¨: {len(unmapped_columns)}ê°œ ì»¬ëŸ¼")
        print(f"   â€¢ ë°ì´í„° ì™„ì „ì„±: {data_completeness:.1f}%")
        
        print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        print(f"   â€¢ RDF/TTL: {ttl_file.name}")
        print(f"   â€¢ SPARQL: {sparql_file.name}")
        print(f"   â€¢ í†µê³„: {stats_file.name}")
        
        print(f"\nğŸ”§ ì¶”ì²œ ëª…ë ¹ì–´:")
        print(f"/cmd_scnt_query_fixed [ê°œì„ ëœ SCNT INVOICE ì¿¼ë¦¬ ì‹¤í–‰]")
        print(f"/cmd_scnt_route_analysis [ìš´ì†¡ ê²½ë¡œ ë¶„ì„]")
        print(f"/cmd_scnt_cost_analysis [ë¹„ìš© êµ¬ì¡° ë¶„ì„]")
        print(f"/cmd_export_scnt_dashboard [ëŒ€ì‹œë³´ë“œ ìƒì„±]")
        
    except Exception as e:
        logger.error(f"SCNT INVOICE ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print(f"âŒ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()

def create_scnt_specific_mapping(columns):
    """SCNT íŠ¹í™” ë§¤í•‘ ê·œì¹™ ìƒì„±"""
    scnt_mapping = {
        'S/No': 'hasSerialNumber',
        'Shpt Ref': 'hasShipmentReference',
        'Job #': 'hasJobNumber',
        'Type': 'hasShipmentType',
        'BL #': 'hasBillOfLading',
        'POL': 'hasPortOfLoading',
        'POD': 'hasPortOfDischarge',
        'Mode': 'hasTransportMode',
        'No. Of CNTR': 'hasContainerCount',
        'Volume': 'hasVolume',
        'Quantity': 'hasQuantity',
        'BOE': 'hasBOE',
        'BOE Issued Date': 'hasBOEIssuedDate',
        '# Trips': 'hasTripCount',
        'MASTER DO\\nCHARGE': 'hasMasterDOCharge',
        'CUSTOMS\\nCLEARANCE\\nCHARGE': 'hasCustomsClearanceCharge',
        'HOUSE\\nDO\\nCHARGE': 'hasHouseDOCharge',
        'PORT HANDLING CHARGE': 'hasPortHandlingCharge',
        'TRANSPORTATION\\nCHARGE': 'hasTransportationCharge',
        'ADDITIONAL AMOUNT\\n(Please refer to the detail sheet)': 'hasAdditionalAmount',
        'AT COST AMOUNT': 'hasAtCostAmount',
        'GRAND TOTAL (USD)': 'hasGrandTotal',
        'Remarks': 'hasRemarks',
        'Reviewed by SCT': 'hasReviewedBySCT',
        'Difference': 'hasDifference'
    }
    
    # ì‹¤ì œ ì»¬ëŸ¼ëª…ê³¼ ë§¤ì¹­ë˜ëŠ” ê²ƒë§Œ ë°˜í™˜
    return {col: mapping for col, mapping in scnt_mapping.items() if col in columns}

def generate_rdf_triples(df, mapped_columns, mapping_rules):
    """RDF íŠ¸ë¦¬í”Œ ìƒì„± (ê°œì„  ë²„ì „)"""
    namespace = mapping_rules.get('namespace', 'http://samsung.com/project-logistics#')
    
    rdf_content = f"""@prefix : <{namespace}> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

# SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA) ì˜¨í†¨ë¡œì§€ ë°ì´í„° (ê°œì„  ë²„ì „)
# ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# ì´ ë ˆì½”ë“œ: {len(df):,}ê°œ
# ë§¤í•‘ëœ ì†ì„±: {len(mapped_columns)}ê°œ

"""
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="SCNT INVOICE ì²˜ë¦¬"):
        event_uri = f":SCNTInvoiceEvent_{idx+1:06d}"
        rdf_content += f"\n{event_uri} rdf:type :SCNTInvoiceEvent ;\n"
        rdf_content += f"    :hasRecordIndex {idx+1} ;\n"
        
        for original_col, rdf_property in mapped_columns:
            value = row[original_col]
            if pd.notna(value):
                if isinstance(value, (int, float)):
                    if not np.isnan(value):
                        rdf_content += f"    :{rdf_property} {value} ;\n"
                elif isinstance(value, str):
                    escaped_value = value.replace('"', '\\"').replace('\n', '\\n').replace('\r', '')
                    rdf_content += f"    :{rdf_property} \"{escaped_value}\" ;\n"
                elif hasattr(value, 'strftime'):  # datetime
                    rdf_content += f"    :{rdf_property} \"{value.strftime('%Y-%m-%d')}\"^^xsd:date ;\n"
                else:
                    rdf_content += f"    :{rdf_property} \"{str(value)}\" ;\n"
        
        rdf_content = rdf_content.rstrip(' ;\n') + " .\n"
    
    return rdf_content

def generate_enhanced_sparql_queries(df, mapped_columns):
    """í–¥ìƒëœ SPARQL ì¿¼ë¦¬ ìƒì„±"""
    queries = f"""# SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA) SPARQL ì¿¼ë¦¬ (ê°œì„  ë²„ì „)
# ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# ì´ ë ˆì½”ë“œ: {len(df):,}ê°œ
# ë§¤í•‘ëœ ì†ì„±: {len(mapped_columns)}ê°œ

PREFIX : <http://samsung.com/project-logistics#>
PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

# 1. ì „ì²´ SCNT ì¸ë³´ì´ìŠ¤ ì´ë²¤íŠ¸ ì¡°íšŒ
SELECT ?event ?property ?value WHERE {{
    ?event rdf:type :SCNTInvoiceEvent .
    ?event ?property ?value .
}} LIMIT 100

# 2. SCNT ì¸ë³´ì´ìŠ¤ ì´ë²¤íŠ¸ ìˆ˜ ì¡°íšŒ
SELECT (COUNT(?event) AS ?totalEvents) WHERE {{
    ?event rdf:type :SCNTInvoiceEvent .
}}

# 3. ìš´ì†¡ ê²½ë¡œë³„ ì§‘ê³„
SELECT ?pol ?pod (COUNT(?event) AS ?shipmentCount) WHERE {{
    ?event rdf:type :SCNTInvoiceEvent .
    ?event :hasPortOfLoading ?pol .
    ?event :hasPortOfDischarge ?pod .
}} GROUP BY ?pol ?pod
ORDER BY DESC(?shipmentCount)

# 4. ì´ ë¹„ìš© ë¶„ì„
SELECT ?event ?grandTotal WHERE {{
    ?event rdf:type :SCNTInvoiceEvent .
    ?event :hasGrandTotal ?grandTotal .
    FILTER(?grandTotal > 0)
}} ORDER BY DESC(?grandTotal)

# 5. ì»¨í…Œì´ë„ˆ íƒ€ì…ë³„ ë¶„ì„
SELECT ?transportMode (COUNT(?event) AS ?count) WHERE {{
    ?event rdf:type :SCNTInvoiceEvent .
    ?event :hasTransportMode ?transportMode .
}} GROUP BY ?transportMode

"""
    
    # ë§¤í•‘ëœ ì»¬ëŸ¼ë³„ íŠ¹í™” ì¿¼ë¦¬ ìƒì„±
    for i, (original_col, rdf_property) in enumerate(mapped_columns[:3], 6):
        queries += f"""
# {i}. {original_col} ê¸°ì¤€ ë¶„ì„
SELECT ?event ?{rdf_property.lower()} WHERE {{
    ?event rdf:type :SCNTInvoiceEvent .
    ?event :{rdf_property} ?{rdf_property.lower()} .
    FILTER(?{rdf_property.lower()} != "")
}} LIMIT 50
"""
    
    return queries

def generate_enhanced_stats_report(df, mapped_columns, unmapped_columns, data_completeness):
    """í–¥ìƒëœ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±"""
    return f"""# SCNT SHIPMENT DRAFT INVOICE (APRIL 2025_CHA) ë¶„ì„ ë¦¬í¬íŠ¸ (ê°œì„  ë²„ì „)

## ğŸ“Š ê¸°ë³¸ í†µê³„
- **ì´ ë ˆì½”ë“œ ìˆ˜**: {len(df):,}ê°œ
- **ì´ ì»¬ëŸ¼ ìˆ˜**: {len(df.columns)}ê°œ
- **ë§¤í•‘ ì„±ê³µ**: {len(mapped_columns)}ê°œ ì»¬ëŸ¼ ({len(mapped_columns)/len(df.columns)*100:.1f}%)
- **ë§¤í•‘ ì‹¤íŒ¨**: {len(unmapped_columns)}ê°œ ì»¬ëŸ¼ ({len(unmapped_columns)/len(df.columns)*100:.1f}%)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: {df.memory_usage(deep=True).sum() / 1024**2:.2f}MB
- **ë°ì´í„° ì™„ì „ì„±**: {data_completeness:.1f}%

## âœ… ë§¤í•‘ëœ ì»¬ëŸ¼
{chr(10).join([f"- {orig} â†’ {mapped}" for orig, mapped in mapped_columns])}

## âŒ ë§¤í•‘ë˜ì§€ ì•Šì€ ì»¬ëŸ¼
{chr(10).join([f"- {col}" for col in unmapped_columns[:20]])}
{f"... ë° {len(unmapped_columns) - 20}ê°œ ì¶”ê°€" if len(unmapped_columns) > 20 else ""}

## ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ
- **ê²°ì¸¡ê°’ ìˆëŠ” ì»¬ëŸ¼**: {df.isnull().any().sum()}ê°œ
- **ì™„ì „í•œ ì»¬ëŸ¼**: {(~df.isnull().any()).sum()}ê°œ
- **ì¤‘ë³µ í–‰**: {df.duplicated().sum()}ê°œ
- **ì „ì²´ ì…€ ìˆ˜**: {len(df) * len(df.columns):,}ê°œ
- **ê²°ì¸¡ ì…€ ìˆ˜**: {df.isnull().sum().sum():,}ê°œ

## ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
{f"- **ì„ ì  íƒ€ì… ë¶„í¬**: {dict(df['Type'].value_counts()) if 'Type' in df.columns else 'N/A'}"} 
{f"- **ì£¼ìš” ìš´ì†¡ ê²½ë¡œ**: {dict(df.groupby(['POL', 'POD']).size().head(3)) if 'POL' in df.columns and 'POD' in df.columns else 'N/A'}"}
{f"- **í‰ê·  ì»¨í…Œì´ë„ˆ ìˆ˜**: {df['No. Of CNTR'].mean():.1f}ê°œ" if 'No. Of CNTR' in df.columns else ''}
{f"- **ì´ ë³¼ë¥¨**: {df['Volume'].sum():.2f}" if 'Volume' in df.columns else ''}

ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

if __name__ == "__main__":
    analyze_scnt_invoice_fixed() 