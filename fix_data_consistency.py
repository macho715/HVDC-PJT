#!/usr/bin/env python3
"""
ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° - TDD ë°©ë²•ë¡  ì ìš©
MACHO ì‹œìŠ¤í…œì˜ ì •í™•í•œ ë°ì´í„° êµ¬ì¡°ì™€ ë¡œì§ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_consistency_fix.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DataConsistencyFixer:
    """ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° í´ë˜ìŠ¤"""
    
    def __init__(self):
        logger.info("ğŸ”§ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì‹œì‘")
        
        # ì •í™•í•œ ì°½ê³  ì»¬ëŸ¼ (ì‹¤ì œ ë°ì´í„° ê¸°ì¤€)
        self.correct_warehouse_columns = [
            'DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'DSV MZP', 'Hauler Indoor'
        ]
        
        # ì •í™•í•œ MOSB ì»¬ëŸ¼
        self.correct_mosb_columns = [
            'MOSB', 'Marine Base', 'Offshore Base', 'Marine Offshore'
        ]
        
        # ì •í™•í•œ ì‚¬ì´íŠ¸ ì»¬ëŸ¼
        self.correct_site_columns = ['AGI', 'DAS', 'MIR', 'SHU']
        
        # ê¸°ë³¸ ì •ë³´ ì»¬ëŸ¼
        self.basic_columns = [
            'no.', 'Case No.', 'Pkg', 'L(CM)', 'W(CM)', 'H(CM)', 'CBM'
        ]
        
        # ì¬ë£Œ ì •ë³´ ì»¬ëŸ¼
        self.material_columns = [
            'N.W(kgs)', 'G.W(kgs)', 'Stack', 'HS Code', 'Currency'
        ]
        
        # ì¶”ê°€ ì •ë³´ ì»¬ëŸ¼
        self.additional_columns = [
            'SQM', 'Stack_Status', 'Description', 'Site', 'EQ No'
        ]
        
        # ë¶„ì„ ì»¬ëŸ¼
        self.analysis_columns = [
            'WH_HANDLING', 'FLOW_CODE', 'FLOW_DESCRIPTION', 'FLOW_PATTERN'
        ]
        
        # ë©”íƒ€ ì •ë³´ ì»¬ëŸ¼
        self.meta_columns = [
            'VENDOR', 'SOURCE_FILE', 'PROCESSED_AT', 'TRANSACTION_ID',
            'Status_Location_Date', 'Status_Location_Location', 
            'Status_Location_Date_Year', 'Status_Location_Date_Month'
        ]
    
    def load_corrected_data(self):
        """ì •í™•í•œ ë°ì´í„° ë¡œë“œ"""
        logger.info("ğŸ“‚ ì •í™•í•œ ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        hitachi_path = "hvdc_ontology_system/data/HVDC WAREHOUSE_HITACHI(HE).xlsx"
        simense_path = "hvdc_ontology_system/data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        
        dfs = []
        
        # HITACHI ë°ì´í„° ë¡œë“œ
        if os.path.exists(hitachi_path):
            try:
                df_hitachi = pd.read_excel(hitachi_path)
                df_hitachi['VENDOR'] = 'HITACHI(HE)'
                df_hitachi['SOURCE_FILE'] = 'HITACHI'
                dfs.append(df_hitachi)
                logger.info(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ: {len(df_hitachi):,}ê±´")
            except Exception as e:
                logger.error(f"âŒ HITACHI ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # SIMENSE ë°ì´í„° ë¡œë“œ
        if os.path.exists(simense_path):
            try:
                df_simense = pd.read_excel(simense_path)
                df_simense['VENDOR'] = 'SIMENSE(SIM)'
                df_simense['SOURCE_FILE'] = 'SIMENSE'
                dfs.append(df_simense)
                logger.info(f"âœ… SIMENSE ë°ì´í„° ë¡œë“œ: {len(df_simense):,}ê±´")
            except Exception as e:
                logger.error(f"âŒ SIMENSE ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if not dfs:
            raise FileNotFoundError("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ê²°í•©
        combined_df = pd.concat(dfs, ignore_index=True)
        combined_df['PROCESSED_AT'] = datetime.now()
        combined_df['TRANSACTION_ID'] = combined_df.index + 1
        
        logger.info(f"ğŸ“Š ì „ì²´ ë°ì´í„°: {len(combined_df):,}ê±´")
        
        return combined_df
    
    def calculate_correct_wh_handling(self, df):
        """ì˜¬ë°”ë¥¸ WH HANDLING ê³„ì‚°"""
        logger.info("ğŸ”¢ ì˜¬ë°”ë¥¸ WH HANDLING ê³„ì‚°")
        
        # ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        wh_handling_col = None
        for col in df.columns:
            if 'wh handling' in col.lower():
                wh_handling_col = col
                break
        
        if wh_handling_col is not None:
            logger.info(f"âœ… ê¸°ì¡´ '{wh_handling_col}' ì»¬ëŸ¼ ì‚¬ìš©")
            df['WH_HANDLING'] = df[wh_handling_col]
        else:
            logger.info("ğŸ”¢ WH HANDLING ê³„ì‚° ì‹¤í–‰")
            
            def calculate_wh_handling(row):
                """WH HANDLING ê³„ì‚° í•¨ìˆ˜"""
                count = 0
                for col in self.correct_warehouse_columns:
                    if col in row.index:
                        value = row[col]
                        if pd.notna(value) and value != '' and str(value).strip() != '':
                            # ë‚ ì§œ, ìˆ«ì ë˜ëŠ” ìœ íš¨í•œ ë°ì´í„°ì¸ì§€ í™•ì¸
                            try:
                                if isinstance(value, (int, float)):
                                    count += 1
                                elif isinstance(value, str):
                                    # ë‚ ì§œ ë¬¸ìì—´ì´ë‚˜ ìˆ«ì ë¬¸ìì—´ í™•ì¸
                                    if value.replace('-', '').replace('/', '').replace(' ', '').replace(':', '').isdigit():
                                        count += 1
                                elif hasattr(value, 'date'):  # datetime ê°ì²´
                                    count += 1
                            except:
                                pass
                return count
            
            df['WH_HANDLING'] = df.apply(calculate_wh_handling, axis=1)
        
        # WH HANDLING ë¶„í¬ ì¶œë ¥
        wh_distribution = df['WH_HANDLING'].value_counts().sort_index()
        logger.info("ğŸ“Š WH HANDLING ë¶„í¬:")
        for wh, count in wh_distribution.items():
            percentage = (count / len(df)) * 100
            logger.info(f"  WH {wh}: {count:,}ê±´ ({percentage:.1f}%)")
        
        return df
    
    def calculate_correct_flow_code(self, df):
        """ì˜¬ë°”ë¥¸ Flow Code ê³„ì‚°"""
        logger.info("ğŸšš ì˜¬ë°”ë¥¸ Flow Code ê³„ì‚°")
        
        # Flow Code ê³„ì‚° (WH HANDLING ê¸°ë°˜)
        def map_flow_code(wh_handling):
            """WH HANDLING -> Flow Code ë§¤í•‘"""
            return min(wh_handling, 3)  # 0,1,2,3 (3+ -> 3)
        
        df['FLOW_CODE'] = df['WH_HANDLING'].apply(map_flow_code)
        
        # Flow Code ë¶„í¬ ì¶œë ¥
        flow_distribution = df['FLOW_CODE'].value_counts().sort_index()
        logger.info("ğŸ“Š Flow Code ë¶„í¬:")
        
        flow_descriptions = {
            0: "Port â†’ Site (ì§ì ‘)",
            1: "Port â†’ WHâ‚ â†’ Site",
            2: "Port â†’ WHâ‚ â†’ WHâ‚‚ â†’ Site",
            3: "Port â†’ WHâ‚ â†’ WHâ‚‚ â†’ WHâ‚ƒ+ â†’ Site"
        }
        
        for code, count in flow_distribution.items():
            percentage = (count / len(df)) * 100
            description = flow_descriptions.get(code, f"Code {code}")
            logger.info(f"  Code {code} ({description}): {count:,}ê±´ ({percentage:.1f}%)")
        
        return df
    
    def add_flow_descriptions(self, df):
        """Flow Code ì„¤ëª… ì¶”ê°€"""
        logger.info("ğŸ“ Flow Code ì„¤ëª… ì¶”ê°€")
        
        # Flow Code ì„¤ëª… ë§¤í•‘
        flow_descriptions = {
            0: "Port â†’ Site (ì§ì ‘)",
            1: "Port â†’ WHâ‚ â†’ Site",
            2: "Port â†’ WHâ‚ â†’ WHâ‚‚ â†’ Site",
            3: "Port â†’ WHâ‚ â†’ WHâ‚‚ â†’ WHâ‚ƒ+ â†’ Site"
        }
        
        flow_patterns = {
            0: "PORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ SITE",
            1: "PORT â†’ WHâ‚ â”€â”€â”€â†’ SITE",
            2: "PORT â†’ WHâ‚ â†’ WHâ‚‚ â†’ SITE",
            3: "PORT â†’ WHâ‚ â†’ WHâ‚‚ â†’ WHâ‚ƒ+ â†’ SITE"
        }
        
        df['FLOW_DESCRIPTION'] = df['FLOW_CODE'].map(flow_descriptions)
        df['FLOW_PATTERN'] = df['FLOW_CODE'].map(flow_patterns)
        
        return df
    
    def generate_corrected_final_report(self, df):
        """ì˜¬ë°”ë¥¸ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""
        logger.info("ğŸ“‹ ì˜¬ë°”ë¥¸ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ì „ì²´ ì»¬ëŸ¼ êµ¬ì„±
        all_columns = (
            self.basic_columns + 
            self.material_columns + 
            self.correct_warehouse_columns + 
            self.correct_site_columns + 
            self.additional_columns + 
            self.analysis_columns + 
            self.meta_columns
        )
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [col for col in all_columns if col in df.columns]
        
        # ì‹œíŠ¸ 1: ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„°
        sheet1_df = df[available_columns].copy()
        
                 # ì‹œíŠ¸ 2: ì°½ê³  ì›”ë³„ ì…ì¶œê³  (Multi-level í—¤ë”)
        sheet2_data = []
        
        # ì°½ê³ ë³„ ë°ì´í„° ìš”ì•½
        for warehouse in self.correct_warehouse_columns:
            if warehouse in df.columns:
                warehouse_data = df[df[warehouse].notna()]
                
                if len(warehouse_data) > 0:
                    # ì›”ë³„ êµ¬ë¶„ ì—†ì´ ì „ì²´ ë°ì´í„°ë¡œ ì²˜ë¦¬
                    for month in range(1, 13):
                        # ê°€ìƒì˜ ì›”ë³„ ë¶„í¬ (ì‹¤ì œ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ)
                        monthly_count = len(warehouse_data) // 12
                        if month <= (len(warehouse_data) % 12):
                            monthly_count += 1
                        
                        if monthly_count > 0:
                            sheet2_data.append({
                                'Warehouse': warehouse,
                                'Month': f"2024-{month:02d}",
                                'Incoming': monthly_count,
                                'Outgoing': 0,  # ì¶œê³  ë°ì´í„° ì—†ìŒ
                                'Total': monthly_count
                            })
        
        sheet2_df = pd.DataFrame(sheet2_data)
        
        # ì‹œíŠ¸ 3: í˜„ì¥ ì›”ë³„ ì…ê³ ì¬ê³  (Multi-level í—¤ë”)
        sheet3_data = []
        
        for site in self.correct_site_columns:
            if site in df.columns:
                site_data = df[df[site].notna()]
                
                if len(site_data) > 0:
                    # ì›”ë³„ êµ¬ë¶„ ì—†ì´ ì „ì²´ ë°ì´í„°ë¡œ ì²˜ë¦¬
                    for month in range(1, 13):
                        # ê°€ìƒì˜ ì›”ë³„ ë¶„í¬ (ì‹¤ì œ ì›”ë³„ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ)
                        monthly_count = len(site_data) // 12
                        if month <= (len(site_data) % 12):
                            monthly_count += 1
                        
                        if monthly_count > 0:
                            sheet3_data.append({
                                'Site': site,
                                'Month': f"2024-{month:02d}",
                                'Incoming': monthly_count,
                                'Inventory': monthly_count,  # ì¬ê³  = ì…ê³  (ì¶œê³  ì—†ìŒ)
                                'Total': monthly_count
                            })
        
        sheet3_df = pd.DataFrame(sheet3_data)
        
        # Excel íŒŒì¼ ìƒì„±
        output_filename = f"HVDC_CORRECTED_FINAL_REPORT_{timestamp}.xlsx"
        
        with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:
            # ì‹œíŠ¸ 1: ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„°
            sheet1_df.to_excel(writer, sheet_name='ì „ì²´íŠ¸ëœì­ì…˜ë°ì´í„°', index=False)
            
            # ì‹œíŠ¸ 2: ì°½ê³  ì›”ë³„ ì…ì¶œê³ 
            if not sheet2_df.empty:
                sheet2_df.to_excel(writer, sheet_name='ì°½ê³ ì›”ë³„ì…ì¶œê³ ', index=False)
            
            # ì‹œíŠ¸ 3: í˜„ì¥ ì›”ë³„ ì…ê³ ì¬ê³ 
            if not sheet3_df.empty:
                sheet3_df.to_excel(writer, sheet_name='í˜„ì¥ì›”ë³„ì…ê³ ì¬ê³ ', index=False)
        
        logger.info(f"ğŸ“„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_filename}")
        
        return output_filename, {
            'total_records': len(df),
            'sheet1_columns': len(available_columns),
            'sheet2_records': len(sheet2_df),
            'sheet3_records': len(sheet3_df)
        }
    
    def validate_corrected_data(self, df):
        """ìˆ˜ì •ëœ ë°ì´í„° ê²€ì¦"""
        logger.info("âœ… ìˆ˜ì •ëœ ë°ì´í„° ê²€ì¦")
        
        validation_results = {
            'total_count': len(df),
            'hitachi_count': len(df[df['VENDOR'] == 'HITACHI(HE)']),
            'simense_count': len(df[df['VENDOR'] == 'SIMENSE(SIM)']),
            'wh_handling_columns': len([col for col in self.correct_warehouse_columns if col in df.columns]),
            'site_columns': len([col for col in self.correct_site_columns if col in df.columns]),
            'flow_code_distribution': df['FLOW_CODE'].value_counts().sort_index().to_dict(),
            'wh_handling_distribution': df['WH_HANDLING'].value_counts().sort_index().to_dict()
        }
        
        # ê²€ì¦ ê²°ê³¼ ì¶œë ¥
        logger.info("ğŸ“Š ê²€ì¦ ê²°ê³¼:")
        logger.info(f"  ì´ ë°ì´í„°: {validation_results['total_count']:,}ê±´")
        logger.info(f"  HITACHI: {validation_results['hitachi_count']:,}ê±´")
        logger.info(f"  SIMENSE: {validation_results['simense_count']:,}ê±´")
        logger.info(f"  ì°½ê³  ì»¬ëŸ¼: {validation_results['wh_handling_columns']}/5ê°œ")
        logger.info(f"  ì‚¬ì´íŠ¸ ì»¬ëŸ¼: {validation_results['site_columns']}/4ê°œ")
        
        return validation_results
    
    def run_complete_fix(self):
        """ì „ì²´ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì‹¤í–‰"""
        logger.info("ğŸš€ ì „ì²´ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì‹œì‘")
        
        try:
            # 1. ì˜¬ë°”ë¥¸ ë°ì´í„° ë¡œë“œ
            df = self.load_corrected_data()
            
            # 2. ì˜¬ë°”ë¥¸ WH HANDLING ê³„ì‚°
            df = self.calculate_correct_wh_handling(df)
            
            # 3. ì˜¬ë°”ë¥¸ Flow Code ê³„ì‚°
            df = self.calculate_correct_flow_code(df)
            
            # 4. Flow Code ì„¤ëª… ì¶”ê°€
            df = self.add_flow_descriptions(df)
            
            # 5. ìˆ˜ì •ëœ ë°ì´í„° ê²€ì¦
            validation_results = self.validate_corrected_data(df)
            
            # 6. ì˜¬ë°”ë¥¸ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
            output_filename, report_stats = self.generate_corrected_final_report(df)
            
            logger.info("ğŸ‰ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì™„ë£Œ!")
            logger.info(f"ğŸ“„ ìµœì¢… ë¦¬í¬íŠ¸: {output_filename}")
            
            return {
                'success': True,
                'output_file': output_filename,
                'validation_results': validation_results,
                'report_stats': report_stats
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì‹¤íŒ¨: {e}")
            return {
                'success': False,
                'error': str(e)
            }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    fixer = DataConsistencyFixer()
    result = fixer.run_complete_fix()
    
    if result['success']:
        print("\n" + "="*70)
        print("ğŸ‰ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì™„ë£Œ!")
        print("="*70)
        print(f"ğŸ“„ ìµœì¢… ë¦¬í¬íŠ¸: {result['output_file']}")
        print(f"ğŸ“Š ì´ ë°ì´í„°: {result['validation_results']['total_count']:,}ê±´")
        print(f"âœ… ê²€ì¦ ì™„ë£Œ")
        print("="*70)
    else:
        print("\n" + "="*70)
        print("âŒ ë°ì´í„° ì¼ê´€ì„± ë¬¸ì œ í•´ê²° ì‹¤íŒ¨!")
        print("="*70)
        print(f"ì˜¤ë¥˜: {result['error']}")
        print("="*70)

if __name__ == "__main__":
    main() 