"""
MACHO-GPT ìµœì¢… ë¦¬í¬í„° ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (Enhanced)
ì‹¤ì œ ë°ì´í„° íŒŒì¼ê³¼ ì—°ë™í•˜ì—¬ Status_Location ë¶„í¬ ë¶„ì„ ë° ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±

TDD Refactor Phase
ë‚ ì§œ: 2025-01-04
"""

import pandas as pd
import numpy as np
from datetime import datetime
import os
import json
from pathlib import Path
from typing import Dict, List, Any, Optional
import warnings

# ê²½ê³  ë©”ì‹œì§€ ì œê±°
warnings.filterwarnings('ignore')

from final_reporter import FinalReporter


class EnhancedFinalReporter:
    """
    í–¥ìƒëœ ìµœì¢… ë¦¬í¬í„° í´ë˜ìŠ¤
    ì‹¤ì œ ë°ì´í„° íŒŒì¼ê³¼ ì—°ë™í•˜ì—¬ ë¶„ì„ ìˆ˜í–‰
    """
    
    def __init__(self, data_path: str = None):
        """
        ì´ˆê¸°í™”
        
        Args:
            data_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        self.data_path = data_path or "hvdc_macho_gpt/WAREHOUSE/data"
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.reporter = FinalReporter(confidence_threshold=0.95)
        
        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.hitachi_file = os.path.join(self.data_path, "HVDC WAREHOUSE_HITACHI(HE).xlsx")
        self.siemens_file = os.path.join(self.data_path, "HVDC WAREHOUSE_SIMENSE(SIM).xlsx")
        
        print(f"ğŸ“Š MACHO-GPT ìµœì¢… ë¦¬í¬í„° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"â° ì‹¤í–‰ ì‹œê°„: {self.timestamp}")
        print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {self.data_path}")
        
    def load_warehouse_data(self) -> Dict[str, pd.DataFrame]:
        """
        ì°½ê³  ë°ì´í„° ë¡œë“œ
        
        Returns:
            dict: ë¡œë“œëœ ë°ì´í„°í”„ë ˆì„ë“¤
        """
        data = {}
        
        try:
            # HITACHI ë°ì´í„° ë¡œë“œ
            if os.path.exists(self.hitachi_file):
                data['HITACHI'] = pd.read_excel(self.hitachi_file)
                print(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data['HITACHI'])}ê±´")
            else:
                print(f"âŒ HITACHI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.hitachi_file}")
                
            # SIEMENS ë°ì´í„° ë¡œë“œ
            if os.path.exists(self.siemens_file):
                data['SIEMENS'] = pd.read_excel(self.siemens_file)
                print(f"âœ… SIEMENS ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(data['SIEMENS'])}ê±´")
            else:
                print(f"âŒ SIEMENS íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.siemens_file}")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
        return data
    
    def analyze_status_location_distribution(self, data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        Status_Location ë¶„í¬ ë¶„ì„
        
        Args:
            data: ë¡œë“œëœ ë°ì´í„°
            
        Returns:
            dict: ë¶„í¬ ë¶„ì„ ê²°ê³¼
        """
        print("\nğŸ“ˆ Status_Location ë¶„í¬ ë¶„ì„ ì‹œì‘...")
        
        analysis_results = {}
        combined_data = pd.DataFrame()
        
        # ëª¨ë“  ë°ì´í„°ë¥¼ ê²°í•©
        for key, df in data.items():
            if 'Status_Location' in df.columns:
                df['Source'] = key
                combined_data = pd.concat([combined_data, df], ignore_index=True)
        
        if combined_data.empty:
            print("âŒ Status_Location ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return analysis_results
        
        # Status_Location ë¶„í¬ ê³„ì‚°
        status_distribution = combined_data['Status_Location'].value_counts().reset_index()
        status_distribution.columns = ['Status_Location', 'Count']
        status_distribution['Percentage'] = (status_distribution['Count'] / len(combined_data) * 100).round(2)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š Status_Location ë¶„í¬ (ì´ {len(combined_data)}ê±´):")
        print("=" * 60)
        for _, row in status_distribution.head(15).iterrows():
            print(f"{row['Status_Location']:<30} {row['Count']:>8}ê±´ ({row['Percentage']:>6.2f}%)")
        
        # Pre Arrival ë¶„ì„
        pre_arrival_count = combined_data[combined_data['Status_Location'].str.contains('Pre Arrival', case=False, na=False)]['Status_Location'].value_counts()
        print(f"\nğŸ” Pre Arrival ìƒì„¸ ë¶„ì„:")
        for status, count in pre_arrival_count.items():
            print(f"  {status}: {count}ê±´")
        
        # NaN ë¶„ì„
        nan_count = combined_data['Status_Location'].isna().sum()
        print(f"\nğŸ” ë¹„ì–´ìˆëŠ” ê°’(NaN): {nan_count}ê±´")
        
        # Flow Code 0 í•´ë‹¹ ë¶„ì„
        flow_code_0_candidates = combined_data[
            (combined_data['Status_Location'].str.contains('Pre Arrival', case=False, na=False)) |
            (combined_data['Status_Location'].isna())
        ]
        print(f"\nğŸ” Flow Code 0 í›„ë³´ (Pre Arrival + NaN): {len(flow_code_0_candidates)}ê±´")
        
        analysis_results = {
            'total_records': len(combined_data),
            'status_distribution': status_distribution.to_dict('records'),
            'pre_arrival_count': pre_arrival_count.to_dict() if not pre_arrival_count.empty else {},
            'nan_count': nan_count,
            'flow_code_0_candidates': len(flow_code_0_candidates)
        }
        
        return analysis_results
    
    def analyze_flow_code_distribution(self, data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """
        Flow Code ë¶„í¬ ë¶„ì„ (WH Handling ê¸°ë°˜)
        
        Args:
            data: ë¡œë“œëœ ë°ì´í„°
            
        Returns:
            dict: Flow Code ë¶„í¬ ë¶„ì„ ê²°ê³¼
        """
        print("\nğŸ“ˆ Flow Code ë¶„í¬ ë¶„ì„ ì‹œì‘...")
        
        analysis_results = {}
        combined_data = pd.DataFrame()
        
        # ëª¨ë“  ë°ì´í„°ë¥¼ ê²°í•©
        for key, df in data.items():
            if 'wh handling' in df.columns:
                df['Source'] = key
                combined_data = pd.concat([combined_data, df], ignore_index=True)
        
        if combined_data.empty:
            print("âŒ 'wh handling' ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return analysis_results
        
        # Flow Code ë¶„í¬ ê³„ì‚°
        flow_distribution = combined_data['wh handling'].value_counts().sort_index().reset_index()
        flow_distribution.columns = ['Flow_Code', 'Count']
        flow_distribution['Percentage'] = (flow_distribution['Count'] / len(combined_data) * 100).round(2)
        
        # Flow Codeë³„ ì„¤ëª… ì¶”ê°€
        flow_descriptions = {
            0: "Portâ†’Site ì§ì†¡ ë˜ëŠ” Pre Arrival",
            1: "ì°½ê³  1ê°œ ê²½ìœ ",
            2: "ì°½ê³  2ê°œ ê²½ìœ ",
            3: "ì°½ê³  3ê°œ ì´ìƒ ê²½ìœ "
        }
        
        flow_distribution['Description'] = flow_distribution['Flow_Code'].map(flow_descriptions)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š Flow Code ë¶„í¬ (ì´ {len(combined_data)}ê±´):")
        print("=" * 80)
        for _, row in flow_distribution.iterrows():
            print(f"Flow Code {row['Flow_Code']}: {row['Description']:<40} {row['Count']:>8}ê±´ ({row['Percentage']:>6.2f}%)")
        
        # Flow Code 0 ìƒì„¸ ë¶„ì„
        if 'Status_Location' in combined_data.columns:
            flow_0_data = combined_data[combined_data['wh handling'] == 0]
            print(f"\nğŸ” Flow Code 0 ìƒì„¸ ë¶„ì„ ({len(flow_0_data)}ê±´):")
            
            flow_0_status = flow_0_data['Status_Location'].value_counts().head(10)
            for status, count in flow_0_status.items():
                print(f"  {status}: {count}ê±´")
        
        analysis_results = {
            'total_records': len(combined_data),
            'flow_distribution': flow_distribution.to_dict('records'),
            'flow_0_detail': flow_0_status.to_dict() if 'flow_0_status' in locals() else {}
        }
        
        return analysis_results
    
    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """
        ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        
        Returns:
            dict: ì¢…í•© ë¦¬í¬íŠ¸ ê²°ê³¼
        """
        print(f"\nğŸš€ MACHO-GPT ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")
        
        # 1. ë°ì´í„° ë¡œë“œ
        warehouse_data = self.load_warehouse_data()
        
        if not warehouse_data:
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return {'status': 'ERROR', 'message': 'ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨'}
        
        # 2. Status_Location ë¶„í¬ ë¶„ì„
        status_analysis = self.analyze_status_location_distribution(warehouse_data)
        
        # 3. Flow Code ë¶„í¬ ë¶„ì„
        flow_analysis = self.analyze_flow_code_distribution(warehouse_data)
        
        # 4. í†µí•© ë°ì´í„° ì¤€ë¹„
        integrated_data = {
            'STATUS_LOCATION': status_analysis,
            'FLOW_CODE': flow_analysis,
            'WAREHOUSE_DATA': {key: len(df) for key, df in warehouse_data.items()}
        }
        
        # 5. ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        final_report = self.reporter.generate_integrated_monthly_report(integrated_data)
        
        # 6. ì¶”ê°€ ë¶„ì„ ê²°ê³¼ í†µí•©
        final_report.update({
            'status_location_analysis': status_analysis,
            'flow_code_analysis': flow_analysis,
            'data_sources': list(warehouse_data.keys()),
            'analysis_timestamp': self.timestamp
        })
        
        # 7. ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ ì¶œë ¥ íŒŒì¼: {final_report.get('output_file', 'N/A')}")
        print(f"ğŸ¯ ì‹ ë¢°ë„: {final_report.get('confidence', 0):.2%}")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ë ˆì½”ë“œ: {final_report.get('records_processed', 0)}ê±´")
        
        return final_report
    
    def print_next_commands(self, report_result: Dict[str, Any]):
        """
        ë‹¤ìŒ ëª…ë ¹ì–´ ì¶œë ¥
        
        Args:
            report_result: ë¦¬í¬íŠ¸ ê²°ê³¼
        """
        next_cmds = self.reporter.recommend_next_commands(report_result)
        
        print(f"\nğŸ”§ **ì¶”ì²œ ëª…ë ¹ì–´:**")
        for i, cmd in enumerate(next_cmds.get('next_cmds', [])[:3], 1):
            if cmd == '/validate-data code-quality':
                print(f"{cmd} [Status_Location ê°’ ë¶„í¬ ìë™ ì¶œë ¥]")
            elif cmd == '/test-scenario unit-tests':
                print(f"{cmd} [Flow Code 0 ì§‘ê³„ ìë™í™” í…ŒìŠ¤íŠ¸]")
            elif cmd == '/automate test-pipeline':
                print(f"{cmd} [ëª©í‘œ ë¶„í¬ ìë™í™”]")
            else:
                print(f"{cmd} [ë¬¼ë¥˜ ë„ë©”ì¸ íŠ¹í™” ë¶„ì„]")


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("ğŸ”Œ MACHO-GPT v3.4-mini ìµœì¢… ë¦¬í¬í„° ì‹¤í–‰")
    print("ğŸ—ï¸ HVDC PROJECT - Samsung C&TÂ·ADNOCÂ·DSV Partnership")
    print("ğŸ“…", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    print("=" * 70)
    
    # ìµœì¢… ë¦¬í¬í„° ì‹¤í–‰
    enhanced_reporter = EnhancedFinalReporter()
    
    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    report_result = enhanced_reporter.generate_comprehensive_report()
    
    # ë‹¤ìŒ ëª…ë ¹ì–´ ì¶œë ¥
    enhanced_reporter.print_next_commands(report_result)
    
    print("\n" + "=" * 70)
    print("ğŸ¯ ìµœì¢… ë¦¬í¬í„° ì‹¤í–‰ ì™„ë£Œ!")


if __name__ == "__main__":
    main() 