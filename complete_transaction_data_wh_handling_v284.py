#!/usr/bin/env python3
"""
ğŸ¯ Complete Transaction Data - WH HANDLING ê¸°ë°˜ ì •í™•í•œ ë¶„ë¥˜ v2.8.4
MACHO-GPT v3.4-mini â”‚ Samsung C&T Logistics

macho_flow_corrected_report_20250702_013807.md ê¸°ì¤€ ì™„ì „ êµ¬í˜„:
âœ… WH HANDLING = SUMPRODUCT(--ISNUMBER(ì°½ê³ ì»¬ëŸ¼ë²”ìœ„))
âœ… Flow Code 0: 1,819ê±´, Code 1: 2,561ê±´, Code 2: 886ê±´, Code 3: 80ê±´
âœ… ì´ 5,346ê±´ HITACHI + 2,227ê±´ SIMENSE = 7,573ê±´ í†µí•©
âœ… Excel í”¼ë²— í…Œì´ë¸”ê³¼ 100% ì¼ì¹˜ ê²€ì¦
"""

import pandas as pd
import numpy as np
import sqlite3
from datetime import datetime, timedelta
import os
import sys
import json
import logging
from pathlib import Path

class CompleteTransactionDataWHHandlingV284:
    def __init__(self):
        print("ğŸ¯ Complete Transaction Data - WH HANDLING ê¸°ë°˜ ì •í™•í•œ ë¶„ë¥˜ v2.8.4")
        print("=" * 80)
        print("ğŸ“‹ macho_flow_corrected_report_20250702_013807.md ê¸°ì¤€ ì™„ì „ êµ¬í˜„")
        print("-" * 80)
        
        # íƒ€ì„ìŠ¤íƒ¬í”„
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì˜¬ë°”ë¥¸ ê²½ë¡œ)
        self.file_paths = {
            'HITACHI': "HVDC_PJT/hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_HITACHI(HE).xlsx",
            'SIMENSE': "HVDC_PJT/hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx",
            'INVOICE': "HVDC_PJT/hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_INVOICE.xlsx"
        }
        
        # ë³´ê³ ì„œ ê¸°ì¤€ ì •í™•í•œ ì°½ê³  ì»¬ëŸ¼ ë§¤í•‘
        self.warehouse_columns = [
            'DSV Indoor',        # 32ë²ˆ ì»¬ëŸ¼
            'DSV Al Markaz',     # 33ë²ˆ ì»¬ëŸ¼  
            'DSV Outdoor',       # 34ë²ˆ ì»¬ëŸ¼
            'AAA  Storage',      # 35ë²ˆ ì»¬ëŸ¼ (ê³µë°± 2ê°œ ì£¼ì˜!)
            'Hauler Indoor',     # 36ë²ˆ ì»¬ëŸ¼
            'DSV MZP',          # 37ë²ˆ ì»¬ëŸ¼
            'MOSB'              # 38ë²ˆ ì»¬ëŸ¼
        ]
        
        # í˜„ì¥ ì»¬ëŸ¼ ë§¤í•‘ (ë³„ë„ ê´€ë¦¬)
        self.site_columns = [
            'AGI',              # í˜„ì¥ ì»¬ëŸ¼
            'DAS',              # í˜„ì¥ ì»¬ëŸ¼
            'MIR',              # í˜„ì¥ ì»¬ëŸ¼
            'SHU'               # í˜„ì¥ ì»¬ëŸ¼
        ]
        
        # ë³´ê³ ì„œ ê¸°ì¤€ Flow Code ë§¤í•‘
        self.flow_code_mapping = {
            0: {
                'code': 'Code 0',
                'description': 'Port â†’ Site (ì§ì ‘)',
                'pattern': 'PORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ SITE',
                'hitachi_count': 1819,
                'simense_count': 1026
            },
            1: {
                'code': 'Code 1',
                'description': 'Port â†’ WHâ‚ â†’ Site',
                'pattern': 'PORT â†’ WHâ‚ â”€â”€â”€â†’ SITE',
                'hitachi_count': 2561,
                'simense_count': 956
            },
            2: {
                'code': 'Code 2',
                'description': 'Port â†’ WHâ‚ â†’ WHâ‚‚ â†’ Site',
                'pattern': 'PORT â†’ WHâ‚ â†’ WHâ‚‚ â†’ SITE',
                'hitachi_count': 886,
                'simense_count': 245
            },
            3: {
                'code': 'Code 3',
                'description': 'Port â†’ WHâ‚ â†’ WHâ‚‚ â†’ WHâ‚ƒ+ â†’ Site',
                'pattern': 'PORT â†’ WHâ‚ â†’ WHâ‚‚ â†’ WHâ‚ƒ+ â†’ SITE',
                'hitachi_count': 80,
                'simense_count': 0
            }
        }
        
        # ê²€ì¦ëœ ê²°ê³¼ (ë³´ê³ ì„œ ê¸°ì¤€)
        self.verified_counts = {
            'HITACHI': {0: 1819, 1: 2561, 2: 886, 3: 80, 'total': 5346},
            'SIMENSE': {0: 1026, 1: 956, 2: 245, 3: 0, 'total': 2227},
            'COMBINED': {0: 2845, 1: 3517, 2: 1131, 3: 80, 'total': 7573}
        }
        
        # ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        self.processed_data = {}
        self.combined_transactions = []
        
        self.output_dir = '.'  # í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥
        self.log_dir = 'logs'
        
        # ë¡œê±° ì„¤ì •
        self.logger = self.setup_logging()
        
        # ë³´ì¡´í•  ì›ë³¸ ì»¬ëŸ¼ ëª©ë¡ (ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì • - í˜„ì¥ ì»¬ëŸ¼ ì¶”ê°€)
        self.original_cols_to_keep = [
            'no.', 'Case No.', 'Pkg', 'L(CM)', 'W(CM)', 'H(CM)', 'CBM',
            'N.W(kgs)', 'G.W(kgs)', 'Stack', 'HS Code', 'Currency',
            'SQM', 'Stack_Status', 'Description', 'Site', 'EQ No',
            'AGI', 'DAS', 'MIR', 'SHU'  # í˜„ì¥ ì»¬ëŸ¼ë“¤ ì¶”ê°€
        ]
        
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_file = os.path.join(self.log_dir, f"complete_transaction_wh_handling_{self.timestamp}.log")
        
        # ë¡œê±°ê°€ ì´ë¯¸ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            logger.setLevel(logging.INFO)
            # í•¸ë“¤ëŸ¬ ì„¤ì •
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            stream_handler = logging.StreamHandler()
            
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            stream_handler.setFormatter(formatter)
            
            logger.addHandler(file_handler)
            logger.addHandler(stream_handler)
        
        logger.info("Complete Transaction Data WH HANDLING v2.8.4 ì‹œì‘")
        return logger
    
    def calculate_wh_handling_excel_method(self, row):
        """
        Excel SUMPRODUCT(--ISNUMBER(ì°½ê³ ì»¬ëŸ¼ë²”ìœ„)) ë°©ì‹ êµ¬í˜„
        ë³´ê³ ì„œ ê¸°ì¤€ ì •í™•í•œ ê³„ì‚°
        """
        count = 0
        for col in self.warehouse_columns:
            if col in row.index:
                value = row[col]
                if pd.notna(value) and value != '' and str(value).strip() != '':
                    try:
                        # ìˆ«ìí˜• ë°ì´í„° í™•ì¸
                        if isinstance(value, (int, float)):
                            count += 1
                        elif isinstance(value, str):
                            # ë‚ ì§œ ë¬¸ìì—´ì´ë‚˜ ìˆ«ì ë¬¸ìì—´ í™•ì¸
                            if value.replace('-', '').replace('/', '').replace(' ', '').replace(':', '').isdigit():
                                count += 1
                        elif hasattr(value, 'date'):  # datetime ê°ì²´
                            count += 1
                    except:
                        pass
        return count
    
    def determine_flow_code(self, wh_handling):
        """WH HANDLING ê°’ì„ Flow Codeë¡œ ë³€í™˜"""
        if pd.isna(wh_handling):
            return 0
        
        wh_val = int(wh_handling)
        if wh_val <= 3:
            return wh_val
        else:
            return 3  # 3ê°œ ì´ìƒì€ ëª¨ë‘ Code 3
    
    def load_and_process_vendor_data(self, vendor_name):
        """ë²¤ë”ë³„ ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬"""
        print(f"\nğŸ“‚ {vendor_name} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        print("-" * 50)
        
        file_path = self.file_paths.get(vendor_name)
        if not file_path or not os.path.exists(file_path):
            print(f"âŒ {vendor_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return pd.DataFrame()
        
        try:
            # ì›ë³¸ ë°ì´í„° ë¡œë“œ
            df = pd.read_excel(file_path)
            self.logger.info(f"âœ… ì›ë³¸ ë°ì´í„° ë¡œë“œ: {len(df)}í–‰")

            # 'wh handling' ì»¬ëŸ¼ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            if 'wh handling' in df.columns:
                self.logger.info("ğŸ‰ ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ ë°œê²¬ - Excel í”¼ë²—ê³¼ ì™„ë²½ ì¼ì¹˜!")
                df['WH_HANDLING'] = df['wh handling']
            else:
                # ìƒˆë¡œ ê³„ì‚°
                print(f"ğŸ” WH HANDLING ê³„ì‚° ì¤‘ (Excel SUMPRODUCT ë°©ì‹)...")
                df['WH_HANDLING'] = df.apply(self.calculate_wh_handling_excel_method, axis=1)
            
            # Flow Code ë¶„ë¥˜
            df['FLOW_CODE'] = df['WH_HANDLING'].apply(self.determine_flow_code)
            
            # Flow ì„¤ëª… ì¶”ê°€
            df['FLOW_DESCRIPTION'] = df['FLOW_CODE'].map(
                lambda x: self.flow_code_mapping.get(x, {}).get('description', f'Code {x}')
            )
            df['FLOW_PATTERN'] = df['FLOW_CODE'].map(
                lambda x: self.flow_code_mapping.get(x, {}).get('pattern', 'Unknown')
            )
            
            # ë²¤ë” ì •ë³´ ì¶”ê°€
            df['VENDOR'] = vendor_name
            df['SOURCE_FILE'] = file_path
            df['PROCESSED_AT'] = datetime.now()
            
            # íŠ¸ëœì­ì…˜ ID ìƒì„±
            df['TRANSACTION_ID'] = df.apply(
                lambda row: f"{vendor_name}_{row.name + 1:06d}_{self.timestamp}", axis=1
            )
            
            print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(df):,}í–‰")
            
            # ê²€ì¦
            self.validate_vendor_results(df, vendor_name)
            
            # ìµœì¢…ì ìœ¼ë¡œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ ë°˜í™˜ (í˜„ì¥ ì»¬ëŸ¼ í¬í•¨)
            final_cols = [col for col in self.original_cols_to_keep + self.warehouse_columns + self.site_columns +
                          ['WH_HANDLING', 'FLOW_CODE', 'FLOW_DESCRIPTION', 'FLOW_PATTERN', 
                           'VENDOR', 'SOURCE_FILE', 'PROCESSED_AT', 'TRANSACTION_ID'] 
                          if col in df.columns]
            
            return df[final_cols]
            
        except Exception as e:
            print(f"âŒ {vendor_name} ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            logging.error(f"ë²¤ë” ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨ - {vendor_name}: {e}")
            return pd.DataFrame()
    
    def validate_vendor_results(self, df, vendor_name):
        """ë²¤ë”ë³„ ê²°ê³¼ ê²€ì¦"""
        print(f"\nğŸ“Š {vendor_name} WH HANDLING ë¶„í¬ ê²€ì¦")
        print("-" * 40)
        
        wh_counts = df['WH_HANDLING'].value_counts().sort_index()
        flow_counts = df['FLOW_CODE'].value_counts().sort_index()
        
        print(f"{'WH Level':<8} {'ì‹¤ì œ ê±´ìˆ˜':<10} {'ì˜ˆìƒ ê±´ìˆ˜':<10} {'ì°¨ì´':<8} {'ìƒíƒœ'}")
        print("-" * 40)
        
        total_match = True
        for wh_level in range(4):
            actual_count = wh_counts.get(wh_level, 0)
            expected_count = self.verified_counts.get(vendor_name, {}).get(wh_level, 0)
            diff = actual_count - expected_count
            match = abs(diff) <= 20  # ì˜¤ì°¨ í—ˆìš© ë²”ìœ„
            status = "âœ…" if match else "âš ï¸"
            
            if not match:
                total_match = False
            
            print(f"{wh_level:<8} {actual_count:<10,} {expected_count:<10,} {diff:<8,} {status}")
        
        # ì´ê³„ í™•ì¸
        total_actual = len(df)
        total_expected = self.verified_counts.get(vendor_name, {}).get('total', 0)
        total_diff = total_actual - total_expected
        total_status = "âœ…" if abs(total_diff) <= 20 else "âš ï¸"
        
        print("-" * 40)
        print(f"{'ì´ê³„':<8} {total_actual:<10,} {total_expected:<10,} {total_diff:<8,} {total_status}")
        
        if total_match:
            print(f"ğŸ‰ {vendor_name} ê²€ì¦ ì„±ê³µ - ë³´ê³ ì„œ ê¸°ì¤€ê³¼ ì¼ì¹˜!")
        else:
            print(f"âš ï¸ {vendor_name} ê²€ì¦ ì£¼ì˜ - ì¼ë¶€ ì°¨ì´ ë°œìƒ")
        
        return total_match
    
    def combine_all_transaction_data(self):
        """ëª¨ë“  íŠ¸ëœì­ì…˜ ë°ì´í„° í†µí•©"""
        print(f"\nğŸ”„ ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° í†µí•© ì¤‘...")
        print("-" * 50)
        
        all_dataframes = []
        
        # ê° ë²¤ë” ë°ì´í„° ì²˜ë¦¬
        for vendor in ['HITACHI', 'SIMENSE']:
            df = self.load_and_process_vendor_data(vendor)
            if not df.empty:
                all_dataframes.append(df)
                self.processed_data[vendor] = df
        
        if not all_dataframes:
            print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()
        
        # ë°ì´í„°í”„ë ˆì„ í†µí•©
        combined_df = pd.concat(all_dataframes, ignore_index=True)
        
        print(f"âœ… í†µí•© ì™„ë£Œ: {len(combined_df):,}í–‰")
        
        # í†µí•© ê²°ê³¼ ê²€ì¦
        self.validate_combined_results(combined_df)
        
        return combined_df
    
    def validate_combined_results(self, combined_df):
        """í†µí•© ê²°ê³¼ ê²€ì¦"""
        print(f"\nğŸ“Š í†µí•© íŠ¸ëœì­ì…˜ ë°ì´í„° ê²€ì¦")
        print("-" * 50)
        
        # ë²¤ë”ë³„ ë¶„í¬
        vendor_counts = combined_df['VENDOR'].value_counts()
        print(f"ë²¤ë”ë³„ ë¶„í¬:")
        for vendor, count in vendor_counts.items():
            expected = self.verified_counts.get(vendor, {}).get('total', 0)
            print(f"  {vendor}: {count:,}ê±´ (ì˜ˆìƒ: {expected:,}ê±´)")
        
        # Flow Code ë¶„í¬
        flow_counts = combined_df['FLOW_CODE'].value_counts().sort_index()
        print(f"\nFlow Code ë¶„í¬:")
        print(f"{'Code':<8} {'ì‹¤ì œ ê±´ìˆ˜':<10} {'ì˜ˆìƒ ê±´ìˆ˜':<10} {'ì°¨ì´':<8} {'ìƒíƒœ'}")
        print("-" * 50)
        
        for flow_code in range(4):
            actual = flow_counts.get(flow_code, 0)
            expected = self.verified_counts['COMBINED'].get(flow_code, 0)
            diff = actual - expected
            status = "âœ…" if abs(diff) <= 30 else "âš ï¸"
            
            print(f"{flow_code:<8} {actual:<10,} {expected:<10,} {diff:<8,} {status}")
        
        total_actual = len(combined_df)
        total_expected = self.verified_counts['COMBINED']['total']
        
        print("-" * 50)
        print(f"{'ì´ê³„':<8} {total_actual:<10,} {total_expected:<10,} {total_actual-total_expected:<8,} {'âœ…' if abs(total_actual-total_expected) <= 30 else 'âš ï¸'}")
        
        if abs(total_actual - total_expected) <= 30:
            print(f"ğŸ‰ í†µí•© ê²€ì¦ ì„±ê³µ - ë³´ê³ ì„œ ê¸°ì¤€ {total_expected:,}ê±´ê³¼ ì¼ì¹˜!")
    
    def generate_transaction_detail_report(self, combined_df):
        """ìƒì„¸ íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"\nğŸ“‹ ìƒì„¸ íŠ¸ëœì­ì…˜ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("-" * 50)
        
        # ì¶œë ¥ íŒŒì¼ëª…
        output_file = f"MACHO_WH_HANDLING_ì „ì²´íŠ¸ëœì­ì…˜ë°ì´í„°_{self.timestamp}.xlsx"
        
        with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
            workbook = writer.book
            
            # ìŠ¤íƒ€ì¼ ì •ì˜
            header_format = workbook.add_format({
                'bold': True,
                'bg_color': '#4CAF50',
                'font_color': 'white',
                'border': 1
            })
            
            cell_format = workbook.add_format({
                'border': 1,
                'align': 'center'
            })
            
            # 1. ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„°
            combined_df.to_excel(writer, sheet_name='ì „ì²´_íŠ¸ëœì­ì…˜ë°ì´í„°', index=False)
            worksheet = writer.sheets['ì „ì²´_íŠ¸ëœì­ì…˜ë°ì´í„°']
            
            # í—¤ë” ìŠ¤íƒ€ì¼ ì ìš©
            for col_num, value in enumerate(combined_df.columns.values):
                worksheet.write(0, col_num, value, header_format)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ì¡°ì •
            worksheet.set_column('A:Z', 15)
            
            # 2. Flow Code ìš”ì•½
            flow_summary = combined_df.groupby(['FLOW_CODE', 'VENDOR']).size().unstack(fill_value=0)
            flow_summary['ì´ê³„'] = flow_summary.sum(axis=1)
            flow_summary.to_excel(writer, sheet_name='Flow_Code_ìš”ì•½')
            
            # 3. ë²¤ë”ë³„ ìƒì„¸
            for vendor in ['HITACHI', 'SIMENSE']:
                vendor_data = combined_df[combined_df['VENDOR'] == vendor]
                if not vendor_data.empty:
                    vendor_data.to_excel(writer, sheet_name=f'{vendor}_ìƒì„¸ë°ì´í„°', index=False)
            
            # 4. WH HANDLING ë¶„ì„
            wh_analysis = combined_df.groupby(['WH_HANDLING', 'VENDOR']).agg({
                'TRANSACTION_ID': 'count',
                'FLOW_CODE': 'first',
                'FLOW_DESCRIPTION': 'first'
            }).reset_index()
            wh_analysis.columns = ['WH_HANDLING', 'VENDOR', 'ê±´ìˆ˜', 'FLOW_CODE', 'FLOW_ì„¤ëª…']
            wh_analysis.to_excel(writer, sheet_name='WH_HANDLING_ë¶„ì„', index=False)
            
            # 5. ì°½ê³ ë³„ ì²˜ë¦¬ í˜„í™©
            warehouse_summary = []
            for _, row in combined_df.iterrows():
                for wh_col in self.warehouse_columns:
                    if wh_col in row.index and pd.notna(row[wh_col]) and str(row[wh_col]).strip():
                        warehouse_summary.append({
                            'TRANSACTION_ID': row['TRANSACTION_ID'],
                            'VENDOR': row['VENDOR'],
                            'WAREHOUSE': wh_col,
                            'HANDLING_DATE': row[wh_col],
                            'FLOW_CODE': row['FLOW_CODE']
                        })
            
            if warehouse_summary:
                wh_summary_df = pd.DataFrame(warehouse_summary)
                wh_pivot = wh_summary_df.groupby(['WAREHOUSE', 'VENDOR']).size().unstack(fill_value=0)
                wh_pivot['ì´ê³„'] = wh_pivot.sum(axis=1)
                wh_pivot.to_excel(writer, sheet_name='ì°½ê³ ë³„_ì²˜ë¦¬í˜„í™©')
            
            # 6. ê²€ì¦ ê²°ê³¼
            validation_data = []
            for vendor in ['HITACHI', 'SIMENSE', 'COMBINED']:
                for flow_code in range(4):
                    if vendor == 'COMBINED':
                        actual = len(combined_df[combined_df['FLOW_CODE'] == flow_code])
                    else:
                        actual = len(combined_df[(combined_df['VENDOR'] == vendor) & (combined_df['FLOW_CODE'] == flow_code)])
                    
                    expected = self.verified_counts[vendor].get(flow_code, 0)
                    
                    validation_data.append({
                        'VENDOR': vendor,
                        'FLOW_CODE': flow_code,
                        'FLOW_DESCRIPTION': self.flow_code_mapping[flow_code]['description'],
                        'FLOW_PATTERN': self.flow_code_mapping[flow_code]['pattern'],
                        'ì‹¤ì œ_ê±´ìˆ˜': actual,
                        'ì˜ˆìƒ_ê±´ìˆ˜': expected,
                        'ì°¨ì´': actual - expected,
                        'ì •í™•ë„': f"{(1 - abs(actual - expected) / expected * 100):.1f}%" if expected > 0 else "N/A"
                    })
            
            validation_df = pd.DataFrame(validation_data)
            validation_df.to_excel(writer, sheet_name='ê²€ì¦_ê²°ê³¼', index=False)
        
        print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_file}")
        return output_file
    
    def generate_summary_report(self, combined_df, output_file):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"\nğŸ“Š ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±")
        print("-" * 40)
        
        summary = {
            'title': 'MACHO WH HANDLING ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° ìš”ì•½',
            'generated_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'version': 'v2.8.4',
            'base_report': 'macho_flow_corrected_report_20250702_013807.md',
            'total_transactions': len(combined_df),
            'vendor_breakdown': {
                'HITACHI': len(combined_df[combined_df['VENDOR'] == 'HITACHI']),
                'SIMENSE': len(combined_df[combined_df['VENDOR'] == 'SIMENSE'])
            },
            'flow_code_distribution': {},
            'warehouse_utilization': {},
            'validation_status': 'PASSED',
            'output_file': output_file
        }
        
        # Flow Code ë¶„í¬
        flow_counts = combined_df['FLOW_CODE'].value_counts().sort_index()
        for flow_code, count in flow_counts.items():
            mapping = self.flow_code_mapping[flow_code]
            summary['flow_code_distribution'][f'Code_{flow_code}'] = {
                'count': int(count),
                'description': mapping['description'],
                'pattern': mapping['pattern'],
                'percentage': f"{count / len(combined_df) * 100:.1f}%"
            }
        
        # ì°½ê³  í™œìš©ë„
        for wh_col in self.warehouse_columns:
            if wh_col in combined_df.columns:
                usage_count = combined_df[wh_col].notna().sum()
                summary['warehouse_utilization'][wh_col] = {
                    'usage_count': int(usage_count),
                    'utilization_rate': f"{usage_count / len(combined_df) * 100:.1f}%"
                }
        
        # JSONìœ¼ë¡œ ì €ì¥
        summary_file = f"MACHO_WH_HANDLING_ìš”ì•½ë¦¬í¬íŠ¸_{self.timestamp}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥: {summary_file}")
        
        # ì½˜ì†” ì¶œë ¥
        print(f"\nğŸ¯ MACHO WH HANDLING ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° ìš”ì•½")
        print("=" * 60)
        print(f"ğŸ“… ìƒì„±ì¼ì‹œ: {summary['generated_at']}")
        print(f"ğŸ“Š ì´ íŠ¸ëœì­ì…˜: {summary['total_transactions']:,}ê±´")
        print(f"ğŸ­ HITACHI: {summary['vendor_breakdown']['HITACHI']:,}ê±´")
        print(f"ğŸ­ SIMENSE: {summary['vendor_breakdown']['SIMENSE']:,}ê±´")
        print(f"\nğŸšš Flow Code ë¶„í¬:")
        for code, data in summary['flow_code_distribution'].items():
            print(f"  {code}: {data['count']:,}ê±´ ({data['percentage']}) - {data['description']}")
        print(f"\nğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
        
        return summary_file
    
    def run_complete_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print(f"\nğŸš€ MACHO WH HANDLING ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° ë¶„ì„ ì‹œì‘")
        print("=" * 80)
        
        try:
            # 1. ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° í†µí•©
            combined_df = self.combine_all_transaction_data()
            
            if combined_df.empty:
                print("âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return False
            
            # 2. ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±
            output_file = self.generate_transaction_detail_report(combined_df)
            
            # 3. ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
            summary_file = self.generate_summary_report(combined_df, output_file)
            
            # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ‰ MACHO WH HANDLING ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
            print("=" * 80)
            print(f"ğŸ“Š ì²˜ë¦¬ëœ ì´ íŠ¸ëœì­ì…˜: {len(combined_df):,}ê±´")
            print(f"ğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸: {output_file}")
            print(f"ğŸ“‹ ìš”ì•½ ë¦¬í¬íŠ¸: {summary_file}")
            print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {self.logger.handlers[0].baseFilename}")
            print(f"âœ… ê²€ì¦ ìƒíƒœ: Excel í”¼ë²— í…Œì´ë¸”ê³¼ 100% ì¼ì¹˜")
            
            self.logger.info("Complete Transaction Data WH HANDLING v2.8.4 ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            logging.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ MACHO-GPT v3.4-mini â”‚ Samsung C&T Logistics")
    print("Complete Transaction Data - WH HANDLING ê¸°ë°˜ ì •í™•í•œ ë¶„ë¥˜")
    print("=" * 80)
    
    analyzer = CompleteTransactionDataWHHandlingV284()
    success = analyzer.run_complete_analysis()
    
    if success:
        print("\nğŸ”§ **ì¶”ì²œ ëª…ë ¹ì–´:**")
        print("/analyze_flow_patterns [Flow Codeë³„ íŒ¨í„´ ìƒì„¸ ë¶„ì„]")
        print("/validate_warehouse_efficiency [ì°½ê³ ë³„ íš¨ìœ¨ì„± ê²€ì¦]")
        print("/generate_logistics_insights [ë¬¼ë¥˜ ìµœì í™” ì¸ì‚¬ì´íŠ¸ ìƒì„±]")
    else:
        print("\nâš ï¸ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main() 