# Create a network graph visualization with the top movements
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
import seaborn as sns
from datetime import datetime
import warnings
import os
warnings.filterwarnings('ignore')

# Set up matplotlib for better visualization
plt.rcParams['figure.figsize'] = (16, 12)
plt.rcParams['font.size'] = 10

print("ğŸŒ HVDC ì°½ê³  ì´ë™ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ì‹œìŠ¤í…œ")
print("=" * 60)
print("ğŸ“… ë¶„ì„ ì‹œì‘:", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

# ëŒ€ì²´ íŒŒì¼ ê²½ë¡œ ëª©ë¡
alternative_paths = [
    'data/HVDC WAREHOUSE_HITACHI(HE).xlsx',
    'HVDC WAREHOUSE_HITACHI(HE).xlsx',
    'data_cleaned/HVDC_WAREHOUSE_HITACHI_CLEANED_20250709_201121.xlsx',
    'hvdc_macho_gpt/HVDC STATUS/data/HVDC-STATUS.xlsx',
    'hvdc_macho_gpt/WAREHOUSE/data/HVDC WAREHOUSE_HITACHI(HE).xlsx',
    'hvdc_ontology_system/data/HVDC WAREHOUSE_HITACHI(HE).xlsx'
]

df = None
file_path = None

# íŒŒì¼ ë¡œë“œ ì‹œë„
for path in alternative_paths:
    if os.path.exists(path):
        print(f"ğŸ“ ë°ì´í„° ë¡œë“œ ì‹œë„: {path}")
        try:
            # ë‹¤ì–‘í•œ ì—”ì§„ìœ¼ë¡œ ì‹œë„
            try:
                df = pd.read_excel(path, sheet_name='Case List', engine='calamine')
                print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ (calamine): {path} ({len(df)}ê±´)")
                file_path = path
                break
            except:
                try:
                    df = pd.read_excel(path, sheet_name='Case List', engine='openpyxl')
                    print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ (openpyxl): {path} ({len(df)}ê±´)")
                    file_path = path
                    break
                except:
                    # ì‹œíŠ¸ ì´ë¦„ ì—†ì´ ì‹œë„
                    df = pd.read_excel(path, engine='calamine')
                    print(f"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ (ê¸°ë³¸ ì‹œíŠ¸): {path} ({len(df)}ê±´)")
                    file_path = path
                    break
        except Exception as e:
            print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {path} - {str(e)}")
            continue

if df is None:
    print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ë‹¤ìŒ ìœ„ì¹˜ì— HVDC WAREHOUSE_HITACHI(HE).xlsx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
    for path in alternative_paths:
        print(f"   - {path}")
    exit()

# ë°ì´í„° ê¸°ë³¸ ì •ë³´ í™•ì¸
print(f"\nğŸ“Š ë°ì´í„° ì •ë³´:")
print(f"   - íŒŒì¼: {file_path}")
print(f"   - í–‰ ìˆ˜: {len(df)}")
print(f"   - ì—´ ìˆ˜: {len(df.columns)}")
print(f"   - ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}")

# Create a list of all location columns
location_columns = ['DHL Warehouse', 'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 
                   'AAA  Storage', 'Hauler Indoor', 'DSV MZP', 'MOSB', 'Shifting', 
                   'MIR', 'SHU', 'DAS', 'AGI']

# Check which columns exist in the dataset
existing_columns = [col for col in location_columns if col in df.columns]
print(f"\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ìœ„ì¹˜ ì»¬ëŸ¼: {len(existing_columns)}ê°œ")
if existing_columns:
    print(f"   {existing_columns}")
else:
    print("   ìœ„ì¹˜ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì²´ ì»¬ëŸ¼ì„ ì°¾ëŠ” ì¤‘...")
    # ë‚ ì§œë‚˜ ìœ„ì¹˜ ê´€ë ¨ ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ì°¾ê¸°
    date_like_columns = [col for col in df.columns if any(keyword in col.lower() for keyword in ['date', 'time', 'warehouse', 'storage', 'location', 'dsv', 'dhl', 'aaa'])]
    if date_like_columns:
        existing_columns = date_like_columns
        print(f"   ë°œê²¬ëœ ê´€ë ¨ ì»¬ëŸ¼: {existing_columns}")
    else:
        print("   ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

# Convert date columns to datetime format
for col in existing_columns:
    if col in df.columns:
        df[col] = pd.to_datetime(df[col], errors='coerce')

# Function to identify movements between locations
def identify_movements(row):
    # Filter only the location columns that have dates
    valid_locations = {col: row[col] for col in existing_columns if pd.notna(row[col])}
    
    if len(valid_locations) < 2:
        return []
    
    # Sort locations by date
    sorted_locations = sorted(valid_locations.items(), key=lambda x: x[1])
    
    # Create pairs of consecutive locations (from -> to)
    movements = []
    for i in range(len(sorted_locations) - 1):
        from_loc = sorted_locations[i][0]
        to_loc = sorted_locations[i + 1][0]
        if from_loc != to_loc:  # ê°™ì€ ìœ„ì¹˜ ì´ë™ ì œì™¸
            movements.append((from_loc, to_loc))
    
    return movements

print("\nğŸ”„ ì´ë™ íŒ¨í„´ ë¶„ì„ ì¤‘...")

# Apply the function to each row and collect all movements
all_movements = []
for _, row in df.iterrows():
    movements = identify_movements(row)
    all_movements.extend(movements)

print(f"ğŸ“ˆ ì´ ì´ë™ ê±´ìˆ˜: {len(all_movements)}ê±´")

if len(all_movements) == 0:
    print("âŒ ì´ë™ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# Count the frequency of each movement
movement_counts = {}
for movement in all_movements:
    if movement in movement_counts:
        movement_counts[movement] += 1
    else:
        movement_counts[movement] = 1

# Convert to DataFrame for easier analysis
movement_df = pd.DataFrame([(from_loc, to_loc, count) 
                           for (from_loc, to_loc), count in movement_counts.items()],
                          columns=['From_Location', 'To_Location', 'Count'])

# Sort by count in descending order
movement_df = movement_df.sort_values('Count', ascending=False)

print(f"\nğŸ“Š ê³ ìœ  ì´ë™ ê²½ë¡œ: {len(movement_df)}ê°œ")
print("ìƒìœ„ 10ê°œ ì´ë™ ê²½ë¡œ:")
if len(movement_df) > 0:
    print(movement_df.head(10).to_string(index=False))
else:
    print("ì´ë™ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# Create a network graph of the top movements
top_n = min(20, len(movement_df))  # Use top 20 or all if less than 20
top_movements = movement_df.head(top_n)

# Create a directed graph
G = nx.DiGraph()

# Add nodes and edges with weights
for _, row in top_movements.iterrows():
    from_loc = row['From_Location']
    to_loc = row['To_Location']
    count = row['Count']
    
    # Add nodes if they don't exist
    if from_loc not in G.nodes():
        G.add_node(from_loc)
    if to_loc not in G.nodes():
        G.add_node(to_loc)
    
    # Add edge with weight
    G.add_edge(from_loc, to_loc, weight=count)

print(f"\nğŸŒ ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ìƒì„±:")
print(f"   ë…¸ë“œ ìˆ˜: {G.number_of_nodes()}ê°œ")
print(f"   ì—£ì§€ ìˆ˜: {G.number_of_edges()}ê°œ")

# Set up the figure with multiple subplots
fig = plt.figure(figsize=(20, 12))

# Main network graph
ax1 = plt.subplot(2, 2, (1, 2))

# Create a layout for the nodes
pos = nx.spring_layout(G, k=0.5, seed=42, iterations=50)

# Get edge weights for line thickness and color
edge_weights = [G[u][v]['weight'] for u, v in G.edges()]
if len(edge_weights) > 0:
    max_weight = max(edge_weights)
    min_weight = min(edge_weights)
    
    # Normalize edge weights for thickness
    if max_weight > min_weight:
        normalized_weights = [2 + 8 * (weight - min_weight) / (max_weight - min_weight) for weight in edge_weights]
    else:
        normalized_weights = [5] * len(edge_weights)
    
    # Create node colors based on degree (centrality)
    node_degrees = dict(G.degree())
    node_colors = [node_degrees[node] for node in G.nodes()]
    
    # Draw the nodes with varying sizes based on degree
    node_sizes = [500 + 300 * node_degrees[node] for node in G.nodes()]
    nodes = nx.draw_networkx_nodes(G, pos, node_size=node_sizes, 
                                   node_color=node_colors, cmap=plt.cm.Reds, 
                                   alpha=0.8, ax=ax1)
    
    # Draw the edges with varying thickness based on weight
    edge_colors = edge_weights
    edges = nx.draw_networkx_edges(G, pos, width=normalized_weights, 
                                  edge_color=edge_colors, edge_cmap=plt.cm.Blues,
                                  arrowsize=20, connectionstyle='arc3,rad=0.1', 
                                  alpha=0.7, ax=ax1)
    
    # Draw the labels
    nx.draw_networkx_labels(G, pos, font_size=9, font_weight='bold', ax=ax1)
    
    # Add edge labels (counts) for top edges only
    top_edges = sorted(G.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)[:10]
    edge_labels = {(u, v): data['weight'] for u, v, data in top_edges}
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, ax=ax1)

ax1.set_title(f'HVDC ì°½ê³  ì´ë™ ë„¤íŠ¸ì›Œí¬ (ìƒìœ„ {top_n}ê°œ ê²½ë¡œ)', fontsize=14, fontweight='bold')
ax1.axis('off')

# Movement frequency bar chart
ax2 = plt.subplot(2, 2, 3)
top_10_movements = movement_df.head(10)
movement_labels = [f"{row['From_Location']} â†’ {row['To_Location']}" 
                   for _, row in top_10_movements.iterrows()]
# ë¼ë²¨ ê¸¸ì´ ì œí•œ
movement_labels = [label if len(label) <= 30 else label[:27] + "..." for label in movement_labels]

ax2.barh(range(len(movement_labels)), top_10_movements['Count'], 
         color=plt.cm.Blues(np.linspace(0.3, 0.8, len(movement_labels))))
ax2.set_yticks(range(len(movement_labels)))
ax2.set_yticklabels(movement_labels, fontsize=9)
ax2.set_xlabel('ì´ë™ íšŸìˆ˜')
ax2.set_title('ìƒìœ„ 10ê°œ ì´ë™ ê²½ë¡œ ë¹ˆë„', fontsize=12, fontweight='bold')
ax2.grid(axis='x', alpha=0.3)

# Node centrality analysis
ax3 = plt.subplot(2, 2, 4)
centrality = nx.degree_centrality(G)
centrality_df = pd.DataFrame(list(centrality.items()), columns=['Location', 'Centrality'])
centrality_df = centrality_df.sort_values('Centrality', ascending=True)

ax3.barh(range(len(centrality_df)), centrality_df['Centrality'], 
         color=plt.cm.Reds(np.linspace(0.3, 0.8, len(centrality_df))))
ax3.set_yticks(range(len(centrality_df)))
ax3.set_yticklabels(centrality_df['Location'], fontsize=9)
ax3.set_xlabel('ì¤‘ì‹¬ì„± ì ìˆ˜')
ax3.set_title('ì°½ê³ ë³„ ì¤‘ì‹¬ì„± ë¶„ì„', fontsize=12, fontweight='bold')
ax3.grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.savefig('hvdc_warehouse_movement_network.png', dpi=300, bbox_inches='tight')
plt.show()

# Additional analysis and statistics
print("\nğŸ“Š ë„¤íŠ¸ì›Œí¬ ë¶„ì„ ê²°ê³¼:")
print("=" * 50)

# Network statistics
print(f"ğŸ” ë„¤íŠ¸ì›Œí¬ í†µê³„:")
print(f"   - ì´ ë…¸ë“œ ìˆ˜: {G.number_of_nodes()}")
print(f"   - ì´ ì—£ì§€ ìˆ˜: {G.number_of_edges()}")
if G.number_of_nodes() > 0:
    print(f"   - í‰ê·  degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}")

# Most central nodes
if len(centrality) > 0:
    print(f"\nğŸ¯ ê°€ì¥ ì¤‘ìš”í•œ ì°½ê³  (ì¤‘ì‹¬ì„± ê¸°ì¤€):")
    centrality_sorted = sorted(centrality.items(), key=lambda x: x[1], reverse=True)
    for i, (location, cent) in enumerate(centrality_sorted[:5], 1):
        print(f"   {i}. {location}: {cent:.3f}")

# Busiest routes
print(f"\nğŸš› ê°€ì¥ í™œë°œí•œ ì´ë™ ê²½ë¡œ:")
for i, (_, row) in enumerate(movement_df.head(5).iterrows(), 1):
    print(f"   {i}. {row['From_Location']} â†’ {row['To_Location']}: {row['Count']}íšŒ")

# Save detailed analysis to Excel
analysis_results = {
    'Movement_Analysis': movement_df,
    'Node_Centrality': centrality_df,
    'Network_Statistics': pd.DataFrame([
        ['Total Nodes', G.number_of_nodes()],
        ['Total Edges', G.number_of_edges()],
        ['Average Degree', sum(dict(G.degree()).values()) / G.number_of_nodes() if G.number_of_nodes() > 0 else 0],
        ['Most Central Node', centrality_sorted[0][0] if centrality_sorted else 'N/A'],
        ['Busiest Route', f"{movement_df.iloc[0]['From_Location']} â†’ {movement_df.iloc[0]['To_Location']}" if len(movement_df) > 0 else 'N/A']
    ], columns=['Metric', 'Value'])
}

with pd.ExcelWriter('HVDC_Network_Movement_Analysis.xlsx', engine='openpyxl') as writer:
    for sheet_name, df_data in analysis_results.items():
        df_data.to_excel(writer, sheet_name=sheet_name, index=False)

print(f"\nğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
print(f"   - ì´ë¯¸ì§€: hvdc_warehouse_movement_network.png")
print(f"   - ë°ì´í„°: HVDC_Network_Movement_Analysis.xlsx")

print(f"\nğŸ”§ ì¶”ì²œ ëª…ë ¹ì–´:")
print("/flow-optimization [ì´ë™ ê²½ë¡œ ìµœì í™” ë¶„ì„]")
print("/bottleneck-analysis [ë³‘ëª© ì§€ì  ë¶„ì„]")
print("/efficiency-metrics [íš¨ìœ¨ì„± ì§€í‘œ ê³„ì‚°]") 