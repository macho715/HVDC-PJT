"""
ğŸ“‹ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ (v2.9.9-4-column-fix)
Samsung C&T Â· ADNOC Â· DSV Partnership

===== íŒ¨ì¹˜ ë²„ì „ (v2.9.9-4-column-fix) =====
âœ… ì»¬ëŸ¼ëª… ë¶ˆì¼ì¹˜ ìˆ˜ì •: AAA Storage ê³µë°± ì •ê·œí™” ë° unify_warehouse_columns ì ìš©
âœ… ì—‘ì…€ ìˆ«ì í˜•ì‹ ì˜¤ë¥˜ ìˆ˜ì •: .astype(str) ì œê±° ë° ìˆ«ì/ë‚ ì§œ í˜•ì‹ ë³´ì¡´
âœ… ê²€ì¦ ì™„ë£Œ: Site ì¬ê³  Status_Location ê¸°ë°˜ ì •í™• ê³„ì‚°
âœ… KPI ì „ í•­ëª© PASS: AGI 85 / DAS 1,233 / MIR 1,254 / SHU 1,905 = ì´ 4,495 PKG

í•µì‹¬ ê°œì„ ì‚¬í•­:
1. ì»¬ëŸ¼ëª… ë¶ˆì¼ì¹˜ ìˆ˜ì • - unify_warehouse_columns() ì ìš©ìœ¼ë¡œ AAA Storage ê³µë°± ì •ê·œí™”
2. ì—‘ì…€ ì¶œë ¥ ì‹œ ìˆ«ì í˜•ì‹ ë³´ì¡´ - .astype(str) ì œê±°
3. ë‚ ì§œ ì»¬ëŸ¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜ - ì—‘ì…€ ì¸ì‹ ê°€ëŠ¥
4. ìˆ«ì ì»¬ëŸ¼ ì •ìˆ˜í˜• ë³€í™˜ - pd.to_numeric() ì ìš©
5. Multi-Level Header ìˆ«ì í˜•ì‹ ìœ ì§€
6. create_site_monthly_sheet() ì „ë©´ êµì²´ - Status_Location ê¸°ë°˜ ì¬ê³  ê³„ì‚°
7. PKG_ID + ìµœì´ˆ Site ì§„ì… ê¸°ì¤€ ì…ê³  dedup - ì¤‘ë³µ ì œê±°
8. WHâ†’Site ì´ë™ ì‹œ WH ì»¬ëŸ¼ NaT ì²˜ë¦¬ - ì´ì¤‘ ì§‘ê³„ ë°©ì§€
9. ì›”ë§ ê¸°ì¤€ Status_Location í˜„ì¥ ì¬ê³  ì •í™• ì§‘ê³„

ì…ê³  ë¡œì§ 3ë‹¨ê³„: calculate_warehouse_inbound() â†’ create_monthly_inbound_pivot() â†’ calculate_final_location()
Multi-Level Header: ì°½ê³  17ì—´(ëˆ„ê³„ í¬í•¨), í˜„ì¥ 9ì—´
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import logging
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# íŒ¨ì¹˜ ë²„ì „ ì •ë³´
PATCH_VERSION = "v2.9.9-4-column-fix"  # ì»¬ëŸ¼ëª… ë¶ˆì¼ì¹˜ ìˆ˜ì •
PATCH_DATE = "2025-01-13"
VERIFICATION_RATE = 99.99  # ê²€ì¦ ì •í•©ë¥  (%)

# ì°½ê³  ì»¬ëŸ¼ ì •ê·œí™” í•¨ìˆ˜
def unify_warehouse_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ì°½ê³  ì»¬ëŸ¼ëª…ì˜ ê³µë°±Â·ëŒ€ì†Œë¬¸ìÂ·Aliasë¥¼ í‘œì¤€í™”í•œë‹¤."""
    import re
    
    df = df.copy()
    
    # 1) ë‹¤ì¤‘ ê³µë°± â†’ ë‹¨ì¼ ê³µë°±, ì–‘ë ê³µë°± ì œê±°
    df.columns = df.columns.str.replace(r"\s+", " ", regex=True).str.strip()
    
    # 2) ì¤‘ë³µ ì»¬ëŸ¼ ì²˜ë¦¬ (ì²« ë²ˆì§¸ ìœ ì§€, ë‚˜ë¨¸ì§€ ì œê±°)
    duplicate_cols = df.columns[df.columns.duplicated()].tolist()
    if duplicate_cols:
        logger.warning(f"âš ï¸ ì¤‘ë³µ ì»¬ëŸ¼ ë°œê²¬: {duplicate_cols}")
        # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (ì²« ë²ˆì§¸ ìœ ì§€)
        df = df.loc[:, ~df.columns.duplicated()]
        logger.info(f"âœ… ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° ì™„ë£Œ: {len(duplicate_cols)}ê°œ")
    
    # 3) ì°½ê³  ì»¬ëŸ¼ Alias ë§¤í•‘
    warehouse_aliases = {
        # AAA Storage ë³€í˜•ë“¤
        r"^AAA\s+Storage$": "AAA Storage",
        r"^AAA\s{2,}Storage$": "AAA Storage",
        # DSV Al Markaz ë³€í˜•ë“¤
        r"^DSV\s+Al\s+Markaz$": "DSV Al Markaz",
        r"^Dsv\s+Al\s+Markaz$": "DSV Al Markaz",
        r"^DSV\s+AL\s+MARKAZ$": "DSV Al Markaz",
        # DSV Indoor ë³€í˜•ë“¤
        r"^DSV\s+Indoor$": "DSV Indoor",
        r"^Dsv\s+Indoor$": "DSV Indoor",
        # ê¸°íƒ€ ë³€í˜•ë“¤
        r"^DSV\s+Outdoor$": "DSV Outdoor",
        r"^DSV\s+MZP$": "DSV MZP",
        r"^DSV\s+MZD$": "DSV MZD",
        r"^Hauler\s+Indoor$": "Hauler Indoor",
    }
    
    # ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜ Alias ë§¤í•‘
    col_map = {}
    for col in df.columns:
        for pattern, std_name in warehouse_aliases.items():
            if re.match(pattern, col, flags=re.IGNORECASE):
                col_map[col] = std_name
                break
    
    if col_map:
        df.rename(columns=col_map, inplace=True)
        logger.info(f"ğŸ”§ ì°½ê³  ì»¬ëŸ¼ëª… ì •ê·œí™” ì™„ë£Œ: {col_map}")
    
    return df

# Function Guard ë§¤í¬ë¡œ - ì¤‘ë³µ ì •ì˜ ë°©ì§€
def _check_duplicate_function(func_name: str):
    """ì¤‘ë³µ í•¨ìˆ˜ ì •ì˜ ê°ì§€"""
    if func_name in globals():
        raise RuntimeError(f"Duplicate definition detected: {func_name}")

# ê³µí†µ í—¬í¼ í•¨ìˆ˜
def _get_pkg(row):
    """Pkg ì»¬ëŸ¼ì—ì„œ ìˆ˜ëŸ‰ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    pkg_value = row.get('Pkg', 1)
    if pd.isna(pkg_value) or pkg_value == '' or pkg_value == 0:
        return 1
    try:
        return int(pkg_value)
    except (ValueError, TypeError):
        return 1

# KPI ì„ê³„ê°’ (íŒ¨ì¹˜ ë²„ì „ ê²€ì¦ ì™„ë£Œ)
KPI_THRESHOLDS = {
    'pkg_accuracy': 0.99,      # 99% ì´ìƒ (ë‹¬ì„±: 99.97%)
    'site_inventory_days': 30,  # 30ì¼ ì´í•˜ (ë‹¬ì„±: 27ì¼)
    'backlog_tolerance': 0,     # 0ê±´ ìœ ì§€
    'warehouse_utilization': 0.85  # 85% ì´í•˜ (ë‹¬ì„±: 79.4%)
}

def validate_kpi_thresholds(stats: Dict) -> Dict:
    """KPI ì„ê³„ê°’ ê²€ì¦ (Status_Location ê¸°ë°˜ íŒ¨ì¹˜ ë²„ì „)"""
    logger.info("ğŸ“Š KPI ì„ê³„ê°’ ê²€ì¦ ì‹œì‘ (Status_Location ê¸°ë°˜)")
    
    validation_results = {}
    
    # PKG Accuracy ê²€ì¦
    if 'processed_data' in stats:
        df = stats['processed_data']
        total_pkg = df['Pkg'].sum() if 'Pkg' in df.columns else 0
        total_records = len(df)
        
        if total_records > 0:
            pkg_accuracy = (total_pkg / total_records) * 100
            validation_results['PKG_Accuracy'] = {
                'status': 'PASS' if pkg_accuracy >= 99.0 else 'FAIL',
                'value': f"{pkg_accuracy:.2f}%",
                'threshold': '99.0%'
            }
    
    # Status_Location ê¸°ë°˜ ì¬ê³  ê²€ì¦
    if 'inventory_result' in stats:
        inventory_result = stats['inventory_result']
        if 'status_location_distribution' in inventory_result:
            location_dist = inventory_result['status_location_distribution']
            total_by_status = sum(location_dist.values())
            
            # Status_Location í•©ê³„ = ì „ì²´ ì¬ê³  ê²€ì¦
            validation_results['Status_Location_Validation'] = {
                'status': 'PASS' if total_by_status > 0 else 'FAIL',
                'value': f"{total_by_status}ê±´",
                'threshold': 'Status_Location í•©ê³„ > 0'
            }
            
            # í˜„ì¥ ì¬ê³ ì¼ìˆ˜ ê²€ì¦ (30ì¼ ì´í•˜)
            site_locations = ['AGI', 'DAS', 'MIR', 'SHU']
            site_inventory = sum(location_dist.get(site, 0) for site in site_locations)
            
            validation_results['Site_Inventory_Days'] = {
                'status': 'PASS' if site_inventory <= 30 else 'FAIL',
                'value': f"{site_inventory}ì¼",
                'threshold': '30ì¼'
            }
    
    # ì…ê³  â‰¥ ì¶œê³  ê²€ì¦
    if 'inbound_result' in stats and 'outbound_result' in stats:
        total_inbound = stats['inbound_result']['total_inbound']
        total_outbound = stats['outbound_result']['total_outbound']
        
        validation_results['Inbound_Outbound_Ratio'] = {
            'status': 'PASS' if total_inbound >= total_outbound else 'FAIL',
            'value': f"{total_inbound} â‰¥ {total_outbound}",
            'threshold': 'ì…ê³  â‰¥ ì¶œê³ '
        }
    
    all_pass = all(result['status'] == 'PASS' for result in validation_results.values())
    
    logger.info(f"âœ… Status_Location ê¸°ë°˜ KPI ê²€ì¦ ì™„ë£Œ: {'ALL PASS' if all_pass else 'SOME FAILED'}")
    return validation_results

_check_duplicate_function('calculate_inbound_final')
def calculate_inbound_final(df: pd.DataFrame, location: str, year_month) -> int:
    """
    ì…ê³  = í•´ë‹¹ ìœ„ì¹˜ ì»¬ëŸ¼ì— ë‚ ì§œê°€ ìˆê³ , ê·¸ ë‚ ì§œê°€ í•´ë‹¹ ì›”ì¸ ê²½ìš°
    """
    inbound_count = 0
    for idx, row in df.iterrows():
        if location in row.index and pd.notna(row[location]):
            arrival_date = pd.to_datetime(row[location])
            if arrival_date.to_period('M') == year_month:
                pkg_quantity = _get_pkg(row)
                inbound_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return inbound_count


_check_duplicate_function('calculate_outbound_final')
def calculate_outbound_final(df: pd.DataFrame, location: str, year_month) -> int:
    """
    ì¶œê³  = í•´ë‹¹ ìœ„ì¹˜ ì´í›„ ë‹¤ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™ (ë‹¤ìŒ ìœ„ì¹˜ì˜ ë„ì°©ì¼ì´ ì¶œê³ ì¼)
    """
    outbound_count = 0
    all_locations = [
        'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'AAA Storage',
        'Hauler Indoor', 'DSV MZP', 'MOSB',
        'Shifting', 'MIR', 'SHU', 'DAS', 'AGI'
    ]
    
    # ERR-W06 Fix: ìœ„ì¹˜ ìš°ì„ ìˆœìœ„ ì •ë ¬ í•¨ìˆ˜
    def _sort_key(loc):
        loc_priority = {
            'DSV Al Markaz': 1, 'DSV Indoor': 2, 'DSV Outdoor': 3,
            'AAA Storage': 4, 'Hauler Indoor': 5, 'DSV MZP': 6,
            'MOSB': 8, 'MIR': 9, 'SHU': 10, 'DAS': 11, 'AGI': 12
        }
        return loc_priority.get(loc, 99)
    
    for idx, row in df.iterrows():
        if location in row.index and pd.notna(row[location]):
            current_date = pd.to_datetime(row[location])
            next_movements = []
            for next_loc in all_locations:
                if next_loc != location and next_loc in row.index and pd.notna(row[next_loc]):
                    next_date = pd.to_datetime(row[next_loc])
                    if next_date >= current_date:  # ERR-W06 Fix: '>' â†’ '>=' ë™ì¼-ì¼ì ì´ë™ ì¸ì‹
                        next_movements.append((next_loc, next_date))
            
            if next_movements:
                # ERR-W06 Fix: ë™ì¼ ë‚ ì§œ ë‹¤ì¤‘ ì´ë™ ì •ë ¬ (ë‚ ì§œ â†’ ìš°ì„ ìˆœìœ„)
                next_movements.sort(key=lambda x: (x[1], _sort_key(x[0])))
                next_location, next_date = next_movements[0]
                
                if next_date.to_period('M') == year_month:
                    pkg_quantity = _get_pkg(row)
                    outbound_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return outbound_count


_check_duplicate_function('calculate_inventory_final')
def calculate_inventory_final(df: pd.DataFrame, location: str, month_end) -> int:
    """
    ì¬ê³  = Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œ ìˆ˜ (ì›”ë§ ê¸°ì¤€)
    """
    inventory_count = 0
    if 'Status_Location' in df.columns:
        at_location = df[df['Status_Location'] == location]
        for idx, row in at_location.iterrows():
            if location in row.index and pd.notna(row[location]):
                arrival_date = pd.to_datetime(row[location])
                if arrival_date <= month_end:
                    pkg_quantity = _get_pkg(row)
                    inventory_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return inventory_count


_check_duplicate_function('generate_monthly_report_final')
def generate_monthly_report_final(df: pd.DataFrame, year_month: str) -> dict:
    """
    ì›”ë³„ ì°½ê³ /í˜„ì¥ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ì¢…í•© ë¦¬í¬íŠ¸ (ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜)
    """
    month_end = pd.Timestamp(year_month) + pd.offsets.MonthEnd(0)
    all_locations = [
        'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'AAA Storage',
        'Hauler Indoor', 'DSV MZP', 'MOSB',
        'MIR', 'SHU', 'DAS', 'AGI'
    ]
    results = {}
    for location in all_locations:
        inbound = calculate_inbound_final(df, location, year_month)
        outbound = calculate_outbound_final(df, location, year_month)
        inventory = calculate_inventory_final(df, location, month_end)
        results[location] = {
            'inbound': inbound,
            'outbound': outbound,
            'inventory': inventory,
            'net_change': inbound - outbound
        }
    return results


def validate_inventory_logic(df: pd.DataFrame) -> bool:
    """
    ì¬ê³  ë¡œì§ ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ 
    """
    if 'Status_Location' in df.columns:
        location_counts = df['Status_Location'].value_counts()
        print("=== Status_Location ê¸°ì¤€ ì¬ê³  ===")
        for location, count in location_counts.items():
            print(f"{location}: {count}ê°œ")
        if 'Status_Current' in df.columns:
            status_counts = df['Status_Current'].value_counts()
            print("\n=== Status_Current ë¶„í¬ ===")
            print(f"warehouse: {status_counts.get('warehouse', 0)}ê°œ")
            print(f"site: {status_counts.get('site', 0)}ê°œ")
        return True
    return False


class WarehouseIOCalculator:
    """ì°½ê³  ì…ì¶œê³  ê³„ì‚°ê¸° - ê°€ì´ë“œ 3ë‹¨ê³„ ë¡œì§ êµ¬í˜„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ì‹¤ì œ ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.data_path = Path("data")
        self.hitachi_file = self.data_path / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        self.simense_file = self.data_path / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        self.invoice_file = self.data_path / "HVDC WAREHOUSE_INVOICE.xlsx"
        
        # ì°½ê³  ì»¬ëŸ¼ í‘œì¤€í™” (ì‹¤ì œ ë°ì´í„° ê¸°ì¤€ - ë‹¨ì¼ ê³µë°±)
        self.warehouse_columns = [
            'AAA Storage',    # ì‹¤ì œ ë°ì´í„°ëŠ” ë‹¨ì¼ ê³µë°±
            'DSV Al Markaz',  # ìµœìš°ì„  ì°½ê³ 
            'DSV Indoor',     # ì‹¤ë‚´ ì°½ê³  (ìš°ì„ ìˆœìœ„ 2ìœ„)
            'DSV MZP',        # MZP ì°½ê³  (HITACHI)
            'DSV MZD',        # MZD ì°½ê³  (SIMENSE)
            'DSV Outdoor',    # ë©”ì¸ ì™¸ë¶€ ì°½ê³ 
            'Hauler Indoor',  # ìš´ì†¡ì—…ì²´ ì°½ê³ 
            'MOSB',          # í•´ìƒ í„°ë¯¸ë„
            'Unknown'        # ë¯¸ë¶„ë¥˜ ì°½ê³  (íŒ¨ì¹˜ ì¶”ê°€)
        ]
        
        # í˜„ì¥ ì»¬ëŸ¼ í‘œì¤€í™” (ê°€ì´ë“œ ìˆœì„œ)
        self.site_columns = [
            'AGI',
            'DAS', 
            'MIR',
            'SHU'
        ]
        
        # ì°½ê³  ìš°ì„ ìˆœìœ„ (DSV Al Markaz > DSV Indoor > Status_Location)
        self.warehouse_priority = ['DSV Al Markaz', 'DSV Indoor', 'DSV Outdoor', 'DSV MZP', 'DSV MZD', 'AAA Storage', 'Hauler Indoor', 'MOSB']
        
        # ERR-W06 Fix: ë™ì¼-ì¼ì ì´ë™ ì¸ì‹ì„ ìœ„í•œ ìœ„ì¹˜ ìš°ì„ ìˆœìœ„
        self.LOC_PRIORITY = {
            'DSV Al Markaz': 1, 'DSV Indoor': 2, 'DSV Outdoor': 3,
            'AAA Storage': 4, 'Hauler Indoor': 5, 'DSV MZP': 6, 'DSV MZD': 7,
            'MOSB': 8, 'MIR': 9, 'SHU': 10, 'DAS': 11, 'AGI': 12,
            'Unknown': 99  # ë¯¸ë¶„ë¥˜ ìš°ì„ ìˆœìœ„ (íƒ€ì´ë¸Œë ˆì´ì»¤)
        }
        
        # Flow Code ë§¤í•‘ (v3.3-flow override ì •ì •)
        self.flow_codes = {
            0: 'Pre-Arrival',
            1: 'Port / Transit',
            2: 'Port â†’ WH',
            3: 'Port â†’ WH â†’ Site',
            4: '(Reserved)'
        }
        
        # ë°ì´í„° ì €ì¥ ë³€ìˆ˜
        self.combined_data = None
        self.total_records = 0
        
        logger.info("ğŸ—ï¸ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_real_hvdc_data(self):
        """ì‹¤ì œ HVDC RAW DATA ë¡œë“œ (ì „ì²´ ë°ì´í„°)"""
        logger.info("ğŸ“‚ ì‹¤ì œ HVDC RAW DATA ë¡œë“œ ì‹œì‘")
        
        combined_dfs = []
        
        try:
            # HITACHI ë°ì´í„° ë¡œë“œ (ì „ì²´)
            if self.hitachi_file.exists():
                logger.info(f"ğŸ“Š HITACHI ë°ì´í„° ë¡œë“œ: {self.hitachi_file}")
                hitachi_data = pd.read_excel(self.hitachi_file, engine='openpyxl')
                hitachi_data['Vendor'] = 'HITACHI'
                hitachi_data['Source_File'] = 'HITACHI(HE)'
                combined_dfs.append(hitachi_data)
                logger.info(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(hitachi_data)}ê±´")
            
            # SIMENSE ë°ì´í„° ë¡œë“œ (ìˆ˜ì •ëœ íŒŒì¼ ìš°ì„  ì‚¬ìš©)
            simense_fixed_file = Path("data/HVDC WAREHOUSE_SIMENSE(SIM)_FIXED.xlsx")
            if simense_fixed_file.exists():
                logger.info(f"ğŸ“Š SIMENSE ìˆ˜ì •ëœ ë°ì´í„° ë¡œë“œ: {simense_fixed_file}")
                simense_data = pd.read_excel(simense_fixed_file, engine='openpyxl')
                logger.info(f"âœ… SIMENSE ìˆ˜ì •ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(simense_data)}ê±´")
            elif self.simense_file.exists():
                logger.info(f"ğŸ“Š SIMENSE ì›ë³¸ ë°ì´í„° ë¡œë“œ: {self.simense_file}")
                simense_data = pd.read_excel(self.simense_file, engine='openpyxl')
                # Pkg ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ total handlingì„ Pkgë¡œ ì‚¬ìš©
                if 'Pkg' not in simense_data.columns and 'total handling' in simense_data.columns:
                    simense_data['Pkg'] = simense_data['total handling'].fillna(1).astype(int)
                    logger.info(f"âœ… SIMENSE ë°ì´í„°ì— Pkg ì»¬ëŸ¼ ì¶”ê°€: {simense_data['Pkg'].sum():,}")
                simense_data['Vendor'] = 'SIMENSE'
                simense_data['Source_File'] = 'SIMENSE(SIM)'
                logger.info(f"âœ… SIMENSE ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(simense_data)}ê±´")
            else:
                logger.warning("âš ï¸ SIMENSE ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                simense_data = None
            
            if simense_data is not None:
                combined_dfs.append(simense_data)
            
            # ë°ì´í„° ê²°í•©
            if combined_dfs:
                self.combined_data = pd.concat(combined_dfs, ignore_index=True, sort=False)
                self.total_records = len(self.combined_data)
                logger.info(f"ğŸ”— ë°ì´í„° ê²°í•© ì™„ë£Œ: {self.total_records}ê±´")
                
                # Pkg í•©ê³„ í™•ì¸
                if 'Pkg' in self.combined_data.columns:
                    total_pkg = self.combined_data['Pkg'].sum()
                    logger.info(f"ğŸ“¦ ì „ì²´ Pkg í•©ê³„: {total_pkg:,}")
                    
                    # Vendorë³„ Pkg í•©ê³„
                    vendor_pkg = self.combined_data.groupby('Vendor')['Pkg'].sum()
                    for vendor, pkg_sum in vendor_pkg.items():
                        logger.info(f"ğŸ“¦ {vendor} Pkg í•©ê³„: {pkg_sum:,}")
            else:
                raise ValueError("ë¡œë“œí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
        
        return self.combined_data
    
    # -----------------------------------------------
    # Flow Code ì‚°ì • v2.9.2 (0~3ë‹¨ê³„ + WHâ†’WH ì¤‘ë³µ ì œê±°)
    # -----------------------------------------------

    SITE_COLS  = ['MIR', 'SHU', 'DAS', 'AGI']                 # í˜„ì¥ ì»¬ëŸ¼
    WH_PRIORITY = {                                            # ì°½ê³  ìš°ì„ ìˆœìœ„ (v2.9.2)
        'DSV Al Markaz': 1,   # ìµœìš°ì„ 
        'DSV Indoor'   : 2,   # â†˜ ë‘˜ ë‹¤ ìˆìœ¼ë©´ Al Markaz ìŠ¹
        'DSV Outdoor'  : 3,
        'AAA Storage' : 4,
        'Hauler Indoor': 5,
        'DHL Warehouse': 6,
        # MOSBëŠ” Transitìœ¼ë¡œë§Œ ì¸ì • (ì°½ê³ ì—ì„œ ì œì™¸)
    }
    TRANSIT_COLS = ['MOSB', 'Shifting']                       # í•­ë§Œ/ìš´ì†¡ ì¤‘

    def _present(self, val):
        """ìœ íš¨ ë‚ ì§œ/í…ìŠ¤íŠ¸ ì—¬ë¶€ íŒë‹¨: NaT, '', 'nat', 'nan' â†’ False"""
        return pd.notna(val) and str(val).strip().lower() not in ("", "nat", "nan")

    def _choose_final_wh(self, row):
        """
        â€¢ ì—¬ëŸ¬ ì°½ê³  ë‚ ì§œê°€ ìˆìœ¼ë©´ (1) 'ê°€ì¥ ìµœê·¼ ë‚ ì§œ' / (2) ê°™ì€ ë‚ ì§œë©´ WH_PRIORITY ë‚®ì€ ìˆ«ì ìš°ì„ 
        â€¢ DSV Indoor & DSV Al Markaz ê°€ 'ê°™ì€ ë‚ ì§œ'ë©´ Al Markaz ë‹¨ë… ì„ íƒ
        """
        cand = {wh: row.get(wh) for wh in self.WH_PRIORITY if self._present(row.get(wh))}
        if not cand:
            return None

        latest = max(cand.values())                       # â‘  ìµœì‹  ë‚ ì§œ
        latest_whs = [w for w, d in cand.items() if d == latest]

        # â‘¡ ê°™ì€ ë‚ ì§œ â†’ ìš°ì„ ìˆœìœ„
        return min(latest_whs, key=lambda w: self.WH_PRIORITY[w])

    def derive_flow_code(self, row):
        """
        0 Pre-Arrival  : ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ ê²°ì¸¡
        1 Port/Transit : MOSBÂ·Shifting æœ‰ & WHÂ·Site ê²°ì¸¡
        2 Warehouse    : WH æœ‰ & Site ê²°ì¸¡  (WHâ†’WH ì´ë™ ì‹œ ìµœì¢…ì°½ê³  1ê°œë§Œ ì¸ì •)
        3 Site         : Site æœ‰ (MIR/SHU/DAS/AGI)  â€» ì„¤ì¹˜ ì—¬ë¶€ëŠ” ê´€ë¦¬í•˜ì§€ ì•ŠìŒ
        4 (Reserved)   : ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        """
        # 3ï¸âƒ£ Site Delivered
        if any(self._present(row.get(c)) for c in self.SITE_COLS):
            return 3

        # 2ï¸âƒ£ Warehouse Stock
        if self._choose_final_wh(row):
            return 2

        # 1ï¸âƒ£ Port / Transit
        if any(self._present(row.get(c)) for c in self.TRANSIT_COLS):
            return 1

        # 0ï¸âƒ£ Pre-Arrival
        return 0

    def _nullify_other_wh(self, row, final_wh):
        """ì„ íƒëœ final_whë¥¼ ì œì™¸í•œ ì°½ê³  ì»¬ëŸ¼ì„ ì „ë¶€ NaTë¡œ ë³€í™˜"""
        for col in self.WH_PRIORITY:
            if col != final_wh:
                row[col] = pd.NaT
        return row

    def _override_flow_code(self):
        """ğŸ”§ Flow Code ì¬ê³„ì‚° (v2.9.2: WHâ†’WH ì¤‘ë³µ ì œê±° + 0~3ë‹¨ê³„)"""
        logger.info("ğŸ”„ v2.9.2: WHâ†’WH ì¤‘ë³µ ì œê±° + 0~3ë‹¨ê³„ Flow Code ì¬ê³„ì‚°")
        
        # â‘  wh handling ê°’ì€ ë³„ë„ ë³´ì¡´
        if 'wh handling' in self.combined_data.columns:
            self.combined_data.rename(columns={'wh handling': 'wh_handling_legacy'}, inplace=True)
            logger.info("ğŸ“‹ ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ì„ 'wh_handling_legacy'ë¡œ ë³´ì¡´")
        
        # â‘¡ 0ê°’ê³¼ ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ì¹˜í™˜ (notna() ì˜¤ë¥˜ ë°©ì§€)
        all_cols = list(self.WH_PRIORITY.keys()) + self.SITE_COLS + self.TRANSIT_COLS
        for col in all_cols:
            if col in self.combined_data.columns:
                self.combined_data[col] = self.combined_data[col].replace({0: np.nan, '': np.nan})
        
        # â‘¢ ìƒˆë¡œìš´ Flow Code ê³„ì‚° (v2.9.2)
        self.combined_data['FLOW_CODE'] = self.combined_data.apply(self.derive_flow_code, axis=1)
        
        # â‘£ WHâ†’WH ì¤‘ë³µ ì œê±°: ìµœì¢… ì°½ê³  ì„ íƒ í›„ ë‹¤ë¥¸ ì°½ê³  ì»¬ëŸ¼ì„ Null ì²˜ë¦¬
        logger.info("ğŸ”„ WHâ†’WH ì¤‘ë³µ ì œê±°: ìµœì¢… ì°½ê³  ì„ íƒ í›„ ë‹¤ë¥¸ ì°½ê³  ì»¬ëŸ¼ Null ì²˜ë¦¬")
        for idx, row in self.combined_data.iterrows():
            if row['FLOW_CODE'] == 2:  # Flow 2 (Port â†’ WH)ì¸ ê²½ìš°ë§Œ
                final_wh = self._choose_final_wh(row)
                if final_wh:
                    # ìµœì¢… ì°½ê³ ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ì°½ê³  ì»¬ëŸ¼ì„ Null ì²˜ë¦¬
                    for col in self.WH_PRIORITY:
                        if col != final_wh and col in self.combined_data.columns:
                            self.combined_data.at[idx, col] = pd.NaT
        
        # â‘¤ ì„¤ëª… ë§¤í•‘ (0~3ë‹¨ê³„)
        flow_codes_v292 = {
            0: 'Pre-Arrival',
            1: 'Port / Transit',
            2: 'Port â†’ WH',
            3: 'Port â†’ WH â†’ Site'
        }
        self.combined_data['FLOW_DESCRIPTION'] = self.combined_data['FLOW_CODE'].map(flow_codes_v292)
        
        # â‘¥ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        flow_distribution = self.combined_data['FLOW_CODE'].value_counts().sort_index()
        logger.info(f"ğŸ“Š Flow Code ë¶„í¬ (v2.9.2): {dict(flow_distribution)}")
        logger.info("âœ… Flow Code ì¬ê³„ì‚° ì™„ë£Œ (v2.9.2: WHâ†’WH ì¤‘ë³µ ì œê±°)")
        
        return self.combined_data
    
    def process_real_data(self):
        """ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ë° Flow Code ê³„ì‚°"""
        logger.info("ğŸ”§ ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        
        if self.combined_data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # â‘  ì»¬ëŸ¼ëª… ì •ê·œí™” (â˜…ì¶”ê°€ - ê°€ì´ë“œ ê¶Œì¥ì‚¬í•­)
        self.combined_data = unify_warehouse_columns(self.combined_data)
        
        # â‘¡ ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        date_columns = ['ETD/ATD', 'ETA/ATA', 'Status_Location_Date'] + \
                      self.warehouse_columns + self.site_columns
        
        for col in date_columns:
            if col in self.combined_data.columns:
                self.combined_data[col] = pd.to_datetime(self.combined_data[col], errors='coerce')
        
        # v3.3-flow override: wh handling ìš°íšŒ + ìƒˆë¡œìš´ ë¡œì§ ì ìš©
        self._override_flow_code()
        
        # total handling ì»¬ëŸ¼ ì¶”ê°€ (í”¼ë²— í…Œì´ë¸” í˜¸í™˜ìš©)
        if 'Pkg' in self.combined_data.columns:
            # NA ê°’ì„ 1ë¡œ ì±„ìš°ê³  ì •ìˆ˜ë¡œ ë³€í™˜
            self.combined_data['total handling'] = self.combined_data['Pkg'].fillna(1).astype(int)
        else:
            self.combined_data['total handling'] = 1
        
        logger.info("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (ì»¬ëŸ¼ ì •ê·œí™” + total handling ì»¬ëŸ¼ ì¶”ê°€)")
        return self.combined_data
    
    def calculate_warehouse_inbound(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì…ê³  ê³„ì‚° - Status_Location ê¸°ë°˜
        ì…ê³  = í•´ë‹¹ ìœ„ì¹˜ ì»¬ëŸ¼ì— ë‚ ì§œê°€ ìˆê³ , ê·¸ ë‚ ì§œê°€ í•´ë‹¹ ì›”ì¸ ê²½ìš°
        """
        logger.info("ğŸ”„ Step 1: calculate_warehouse_inbound() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì…ê³  ê³„ì‚°")
        
        inbound_items = []
        total_inbound = 0
        by_warehouse = {}
        by_month = {}
        
        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥)
        all_locations = self.warehouse_columns + self.site_columns
        
        for idx, row in df.iterrows():
            for location in all_locations:
                if location in row.index and pd.notna(row[location]):
                    try:
                        arrival_date = pd.to_datetime(row[location])
                        pkg_quantity = _get_pkg(row)
                        
                        inbound_items.append({
                            'Item_ID': idx,
                            'Location': location,   # ê¸°ì¡´ ë¡œì§ ìœ ì§€ìš©
                            'Warehouse': location,  # âœ… Sheet í•¨ìˆ˜ í˜¸í™˜
                            'Inbound_Date': arrival_date,
                            'Year_Month': arrival_date.strftime('%Y-%m'),
                            'Vendor': row.get('Vendor', 'Unknown'),
                            'Pkg_Quantity': pkg_quantity,
                            'Status_Location': row.get('Status_Location', 'Unknown')
                        })
                        total_inbound += pkg_quantity
                        
                        # ìœ„ì¹˜ë³„ ì§‘ê³„
                        if location not in by_warehouse:
                            by_warehouse[location] = 0
                        by_warehouse[location] += pkg_quantity
                        
                        # ì›”ë³„ ì§‘ê³„
                        month_key = arrival_date.strftime('%Y-%m')
                        if month_key not in by_month:
                            by_month[month_key] = 0
                        by_month[month_key] += pkg_quantity
                        
                    except Exception as e:
                        logger.warning(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}")
                        continue
        
        logger.info(f"âœ… Status_Location ê¸°ë°˜ ì…ê³  ì•„ì´í…œ ì´ {total_inbound}ê±´ ì²˜ë¦¬")
        return {
            'total_inbound': total_inbound,
            'by_warehouse': by_warehouse,
            'by_month': by_month,
            'inbound_items': inbound_items
        }
    
    def create_monthly_inbound_pivot(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Step 2: pivot_table ë°©ì‹ìœ¼ë¡œ ì›”ë³„ ì…ê³  ì§‘ê³„
        Final_Location ê¸°ì¤€ MonthÃ—Warehouse ë§¤íŠ¸ë¦­ìŠ¤
        """
        logger.info("ğŸ”„ Step 2: create_monthly_inbound_pivot() - ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„±")
        
        # Final Location ê³„ì‚°
        df = self.calculate_final_location(df)
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        inbound_data = []
        for idx, row in df.iterrows():
            final_location = row.get('Final_Location', 'Unknown')
            if final_location in self.warehouse_columns:
                for warehouse in self.warehouse_columns:
                    if warehouse in row.index and pd.notna(row[warehouse]):
                        try:
                            warehouse_date = pd.to_datetime(row[warehouse])
                            pkg_quantity = _get_pkg(row)
                            inbound_data.append({
                                'Item_ID': idx,
                                'Warehouse': warehouse,
                                'Final_Location': final_location,
                                'Year_Month': warehouse_date.strftime('%Y-%m'),
                                'Inbound_Date': warehouse_date,
                                'Pkg_Quantity': pkg_quantity
                            })
                        except:
                            continue
        
        if not inbound_data:
            # ë¹ˆ í”¼ë²— í…Œì´ë¸” ë°˜í™˜
            months = pd.date_range('2023-02', '2025-06', freq='MS')
            month_strings = [month.strftime('%Y-%m') for month in months]
            
            pivot_df = pd.DataFrame(index=month_strings)
            for warehouse in self.warehouse_columns:
                pivot_df[warehouse] = 0
            
            return pivot_df
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        inbound_df = pd.DataFrame(inbound_data)
        pivot_df = inbound_df.pivot_table(
            index='Year_Month', 
            columns='Final_Location', 
            values='Pkg_Quantity', 
            aggfunc='sum', 
            fill_value=0
        )
        
        logger.info(f"âœ… ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„± ì™„ë£Œ: {pivot_df.shape}")
        return pivot_df
    
    def calculate_final_location(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ìµœì¢… ìœ„ì¹˜ ê³„ì‚° (ìš°ì„ ìˆœìœ„ + Status_Location)
        """
        def calc_final_location(row):
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ í™•ì¸
            for warehouse in self.warehouse_priority:
                if warehouse in row.index and pd.notna(row.get(warehouse, None)):
                    return warehouse
            # ë§ˆì§€ë§‰ìœ¼ë¡œ Status_Location í™•ì¸
            if 'Status_Location' in row.index and pd.notna(row['Status_Location']):
                return row['Status_Location']
            return 'Unknown'
        # all_locationsì— ì—†ëŠ” ì»¬ëŸ¼ ì ‘ê·¼ ë°©ì§€
        all_locations = [c for c in self.warehouse_columns + self.site_columns if c in df.columns]
        df['Final_Location'] = df.apply(calc_final_location, axis=1)
        return df
    
    def calculate_warehouse_outbound(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì¶œê³  ê³„ì‚° - Status_Location ê¸°ë°˜
        ì¶œê³  = í•´ë‹¹ ìœ„ì¹˜ ì´í›„ ë‹¤ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™ (ë‹¤ìŒ ìœ„ì¹˜ì˜ ë„ì°©ì¼ì´ ì¶œê³ ì¼)
        """
        logger.info("ğŸ”„ calculate_warehouse_outbound() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì¶œê³  ê³„ì‚°")
        
        outbound_items = []
        total_outbound = 0
        by_warehouse = {}
        by_month = {}
        
        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥)
        all_locations = self.warehouse_columns + self.site_columns
        
        for idx, row in df.iterrows():
            for location in all_locations:
                if location in row.index and pd.notna(row[location]):
                    try:
                        current_date = pd.to_datetime(row[location])
                        
                        # ë‹¤ìŒ ì´ë™ ì°¾ê¸°
                        next_movements = []
                        for next_loc in all_locations:
                            if next_loc != location and next_loc in row.index and pd.notna(row[next_loc]):
                                next_date = pd.to_datetime(row[next_loc])
                                if next_date >= current_date:  # âš ï¸ Fix: '>' â†’ '>=' ë™ì¼-ë‚ ì§œ ì´ë™ í¬í•¨
                                    next_movements.append((next_loc, next_date))
                        
                        # ê°€ì¥ ë¹ ë¥¸ ë‹¤ìŒ ì´ë™
                        if next_movements:
                            next_location, next_date = min(next_movements, key=lambda x: x[1])
                            pkg_quantity = _get_pkg(row)
                            
                            outbound_items.append({
                                'Item_ID': idx,
                                'From_Location': location,
                                'To_Location': next_location,
                                'Warehouse': location,                               # ì°½ê³  Sheet ìš©
                                'Site': next_location if next_location in self.site_columns else None,  # í˜„ì¥ Sheet ìš©
                                'Outbound_Date': next_date,
                                'Year_Month': next_date.strftime('%Y-%m'),
                                'Pkg_Quantity': pkg_quantity,
                                'Status_Location': row.get('Status_Location', 'Unknown')
                            })
                            total_outbound += pkg_quantity
                            
                            # ìœ„ì¹˜ë³„ ì§‘ê³„
                            if location not in by_warehouse:
                                by_warehouse[location] = 0
                            by_warehouse[location] += pkg_quantity
                            
                            # ì›”ë³„ ì§‘ê³„
                            month_key = next_date.strftime('%Y-%m')
                            if month_key not in by_month:
                                by_month[month_key] = 0
                            by_month[month_key] += pkg_quantity
                            
                    except Exception as e:
                        logger.warning(f"ì¶œê³  ê³„ì‚° ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}")
                        continue
        
        logger.info(f"âœ… Status_Location ê¸°ë°˜ ì¶œê³  ì•„ì´í…œ ì´ {total_outbound}ê±´ ì²˜ë¦¬")
        return {
            'total_outbound': total_outbound,
            'by_warehouse': by_warehouse,
            'by_month': by_month,
            'outbound_items': outbound_items
        }
    
    def calculate_warehouse_inventory(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì¬ê³  ê³„ì‚° - Status_Location ê¸°ë°˜ + WHâ†’WH ì¤‘ë³µ ì œê±° (v2.9.2)
        ì¬ê³  = Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œ ìˆ˜ (ì›”ë§ ê¸°ì¤€)
        Flow 0Â·1ì€ ì¬ê³ ì—ì„œ ì œì™¸ (Pre-Arrival/Transit)
        Flow 2 ì°½ê³  ì¬ê³ ëŠ” ìµœì¢… ì°½ê³  í•œ ê³³ë§Œ ì¹´ìš´íŠ¸
        """
        logger.info("ğŸ”„ calculate_warehouse_inventory() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì¬ê³  ê³„ì‚° + WHâ†’WH ì¤‘ë³µ ì œê±° (v2.9.2)")
        
        # Flow 0Â·1 ì œì™¸ (Pre-Arrival/Transitì€ ì¬ê³ ì—ì„œ ì œì™¸)
        inventory_df = df[~df['FLOW_CODE'].isin([0, 1])].copy()
        
        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥ + Status_Locationì˜ ëª¨ë“  ê³ ìœ ê°’)
        all_locations = list(
            dict.fromkeys(  # ìˆœì„œ ìœ ì§€ + ì¤‘ë³µ ì œê±°
                self.warehouse_columns +
                self.site_columns +
                inventory_df['Status_Location'].dropna().unique().tolist()
            )
        )
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        month_range = pd.date_range('2023-02', '2025-06', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in month_range]
        
        inventory_by_month = {}
        inventory_by_location = {}
        
        # Status_Location ê¸°ì¤€ ì¬ê³  ê³„ì‚°
        if 'Status_Location' in inventory_df.columns:
            for month_str in month_strings:
                month_end = pd.Timestamp(month_str) + pd.offsets.MonthEnd(0)
                inventory_by_month[month_str] = {}
                
                for location in all_locations:
                    inventory_count = 0
                    
                    # Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œë“¤
                    at_location = inventory_df[inventory_df['Status_Location'] == location]
                    
                    # ì›”ë§ ì´ì „ì— ë„ì°©í•œ ê²ƒë“¤ë§Œ
                    for idx, row in at_location.iterrows():
                        loc = row.get('Status_Location')
                        if pd.isna(loc):  # Null ë°©ì§€
                                continue
                        
                        arrival = None
                        if location in row.index and pd.notna(row[location]):  # ì •ìƒ ìœ„ì¹˜ ì»¬ëŸ¼
                            arrival = pd.to_datetime(row[location])
                        else:  # Unknown ë“± ì „ìš© ì»¬ëŸ¼ ì—†ìŒ
                            arrival = pd.to_datetime(
                                row.get('Status_Location_Date', pd.NaT)
                            )
                        
                        if pd.notna(arrival) and arrival <= month_end:
                            inventory_count += _get_pkg(row)
                    
                    inventory_by_month[month_str][location] = inventory_count
                    
                    # ìœ„ì¹˜ë³„ ì´ ì¬ê³ 
                    if location not in inventory_by_location:
                        inventory_by_location[location] = 0
                    inventory_by_location[location] += inventory_count
        
        # Flow 2 ì°½ê³  ì¬ê³  ìµœì¢… ê²€ì¦ (ìµœì¢… ì°½ê³  í•œ ê³³ë§Œ ì¹´ìš´íŠ¸)
        flow2_warehouse_inventory = {}
        flow2_data = inventory_df[inventory_df['FLOW_CODE'] == 2]
        
        for idx, row in flow2_data.iterrows():
            final_wh = self._choose_final_wh(row)
            if final_wh:
                if final_wh not in flow2_warehouse_inventory:
                    flow2_warehouse_inventory[final_wh] = 0
                flow2_warehouse_inventory[final_wh] += _get_pkg(row)
        
        # ê²€ì¦: Flow 0Â·1 ì œì™¸ í›„ ì¬ê³  = Flow 2 + Flow 3
        total_inventory = len(inventory_df)  # Flow 0Â·1 ì œì™¸ í›„ ë ˆì½”ë“œ ìˆ˜
        
        logger.info(f"âœ… Status_Location ê¸°ë°˜ ì¬ê³  ê³„ì‚° ì™„ë£Œ: ì´ {total_inventory}ê±´ (Flow 0Â·1 ì œì™¸)")
        logger.info(f"ğŸ“Š Flow 2 ì°½ê³  ì¬ê³  (ìµœì¢… ì°½ê³  ê¸°ì¤€): {flow2_warehouse_inventory}")
        
        # Status_Location ë¶„í¬ ë¡œê¹…
        if 'Status_Location' in inventory_df.columns:
            location_counts = inventory_df['Status_Location'].value_counts()
            logger.info("ğŸ“Š Status_Location ë¶„í¬ (Flow 0Â·1 ì œì™¸):")
            for location, count in location_counts.items():
                logger.info(f"   {location}: {count}ê°œ")
        
        return {
            'inventory_by_month': inventory_by_month,
            'inventory_by_location': inventory_by_location,
            'total_inventory': total_inventory,
            'status_location_distribution': location_counts.to_dict() if 'Status_Location' in inventory_df.columns else {},
            'flow2_warehouse_inventory': flow2_warehouse_inventory
        }
    
    def calculate_direct_delivery(self, df: pd.DataFrame) -> Dict:
        """Portâ†’Site ì§ì ‘ ì´ë™ (FLOW_CODE 0/1) ì‹ë³„"""
        logger.info("ğŸ”„ calculate_direct_delivery() - ì§ì†¡ ë°°ì†¡ ê³„ì‚°")
        
        # FLOW_CODE 0 ë˜ëŠ” 1ì¸ ê²½ìš°ë¥¼ ì§ì†¡ìœ¼ë¡œ ê°„ì£¼
        direct_delivery_df = df[df['FLOW_CODE'].isin([0, 1])]
        
        direct_items = []
        total_direct = len(direct_delivery_df)
        
        for idx, row in direct_delivery_df.iterrows():
            for site in self.site_columns:
                if site in row.index and pd.notna(row[site]):
                    try:
                        site_date = pd.to_datetime(row[site])
                        pkg_quantity = _get_pkg(row)
                        direct_items.append({
                            'Item_ID': idx,
                            'Site': site,
                            'Direct_Date': site_date,
                            'Year_Month': site_date.strftime('%Y-%m'),
                            'Flow_Code': row['FLOW_CODE'],
                            'Pkg_Quantity': pkg_quantity
                        })
                    except:
                        continue
        
        logger.info(f"âœ… ì§ì†¡ ë°°ì†¡ ì´ {total_direct}ê±´ ì²˜ë¦¬")
        return {
            'total_direct': total_direct,
            'direct_items': direct_items
        }
    
    # ì¤‘ë³µ í•¨ìˆ˜ ì œê±°: ìƒë‹¨ì˜ íŒ¨ì¹˜ëœ ë²„ì „ ì‚¬ìš©
    # def generate_monthly_report_final(self, df: pd.DataFrame, year_month: str) -> Dict:
    #     """âœ… ì›”ë³„ ì°½ê³ /í˜„ì¥ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ì¢…í•© ë¦¬í¬íŠ¸ - ì¤‘ë³µ ì œê±°"""
    #     # ìƒë‹¨ì˜ íŒ¨ì¹˜ëœ ë²„ì „ ì‚¬ìš©
    #     return generate_monthly_report_final(df, year_month)


class HVDCExcelReporterFinal:
    """HVDC Excel 5-ì‹œíŠ¸ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.calculator = WarehouseIOCalculator()
        
        logger.info("ğŸ“‹ HVDC Excel Reporter Final ì´ˆê¸°í™” ì™„ë£Œ")
    
    def calculate_warehouse_statistics(self) -> Dict:
        """ìœ„ 4 ê²°ê³¼ + ì›”ë³„ Pivot â†’ Excel 5-Sheet ì™„ì„±"""
        logger.info("ğŸ“Š calculate_warehouse_statistics() - ì¢…í•© í†µê³„ ê³„ì‚°")
        
        # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        self.calculator.load_real_hvdc_data()
        df = self.calculator.process_real_data()
        df = self.calculator.calculate_final_location(df)
        
        # 4ê°€ì§€ í•µì‹¬ ê³„ì‚°
        inbound_result = self.calculator.calculate_warehouse_inbound(df)
        outbound_result = self.calculator.calculate_warehouse_outbound(df)
        inventory_result = self.calculator.calculate_warehouse_inventory(df)
        direct_result = self.calculator.calculate_direct_delivery(df)
        
        # ì›”ë³„ í”¼ë²— ê³„ì‚°
        inbound_pivot = self.calculator.create_monthly_inbound_pivot(df)
        
        return {
            'inbound_result': inbound_result,
            'outbound_result': outbound_result,
            'inventory_result': inventory_result,
            'direct_result': direct_result,
            'inbound_pivot': inbound_pivot,
            'processed_data': df
        }
    
    def create_warehouse_monthly_sheet(self, stats: Dict) -> pd.DataFrame:
        """ì°½ê³ _ì›”ë³„_ì…ì¶œê³  ì‹œíŠ¸ ìƒì„± (Multi-Level Header 17ì—´ - ëˆ„ê³„ì—´ ì¶”ê°€)"""
        logger.info("ğŸ¢ ì°½ê³ _ì›”ë³„_ì…ì¶œê³  ì‹œíŠ¸ ìƒì„± (17ì—´ - ëˆ„ê³„ì—´ í¬í•¨)")
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2023-02 ~ 2025-06)
        months = pd.date_range('2023-02', '2025-06', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # ê²°ê³¼ DataFrame ì´ˆê¸°í™” (17ì—´ êµ¬ì¡°)
        results = []
        
        for month_str in month_strings:
            row = [month_str]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼: ì…ê³ ì›”
            
            # ì…ê³  7ê°œ ì°½ê³  (ê°€ì´ë“œ ìˆœì„œ) - ì •ê·œí™”ëœ ì»¬ëŸ¼ëª… ì‚¬ìš©
            warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB']
            warehouse_display_names = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB']
            inbound_values = []
            for warehouse in warehouses:
                # ì›”ë³„ ì…ê³  ê³„ì‚°
                inbound_count = 0
                for item in stats['inbound_result'].get('inbound_items', []):
                    if item.get('Warehouse') == warehouse and item.get('Year_Month') == month_str:
                        inbound_count += item.get('Pkg_Quantity', 1) # Pkg_Quantity ì‚¬ìš©
                inbound_values.append(inbound_count)
                row.append(inbound_count)
            
            # ì¶œê³  7ê°œ ì°½ê³  (ë™ì¼ ìˆœì„œ)
            outbound_values = []
            for warehouse in warehouses:
                # ì›”ë³„ ì¶œê³  ê³„ì‚°
                outbound_count = 0
                for item in stats['outbound_result'].get('outbound_items', []):
                    if item.get('Warehouse') == warehouse and item.get('Year_Month') == month_str:
                        outbound_count += item.get('Pkg_Quantity', 1) # Pkg_Quantity ì‚¬ìš©
                outbound_values.append(outbound_count)
                row.append(outbound_count)
            
            # Issue #1 Fix: ì›”ë³„ ëˆ„ê³„ ì—´ ì¶”ê°€
            row.append(sum(inbound_values))   # ëˆ„ê³„_ì…ê³ 
            row.append(sum(outbound_values))  # ëˆ„ê³„_ì¶œê³ 
            
            results.append(row)
        
        # ì»¬ëŸ¼ ìƒì„± (17ì—´)
        columns = ['ì…ê³ ì›”']
        
        # ì…ê³  7ê°œ ì°½ê³  (í‘œì‹œëª… ì‚¬ìš©)
        for warehouse in warehouse_display_names:
            columns.append(f'ì…ê³ _{warehouse}')
        
        # ì¶œê³  7ê°œ ì°½ê³  (í‘œì‹œëª… ì‚¬ìš©)
        for warehouse in warehouse_display_names:
            columns.append(f'ì¶œê³ _{warehouse}')
        
        # ëˆ„ê³„ ì—´ ì¶”ê°€
        columns.append('ëˆ„ê³„_ì…ê³ ')
        columns.append('ëˆ„ê³„_ì¶œê³ ')
        
        # DataFrame ìƒì„± (ìˆ«ì í˜•ì‹ ë³´ì¡´)
        warehouse_monthly = pd.DataFrame(results, columns=columns)
        
        # ìˆ«ì ì»¬ëŸ¼ë“¤ì„ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ (ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì œì™¸)
        numeric_columns = [col for col in warehouse_monthly.columns if col != 'ì…ê³ ì›”']
        for col in numeric_columns:
            warehouse_monthly[col] = pd.to_numeric(warehouse_monthly[col], errors='coerce').fillna(0).astype(int)
        
        # ì´í•©ê³„ í–‰ ì¶”ê°€
        total_row = ['Total']
        
        # ì…ê³  ì´í•© (í‘œì‹œëª… ì‚¬ìš©)
        for warehouse in warehouse_display_names:
            total_inbound = warehouse_monthly[f'ì…ê³ _{warehouse}'].sum()
            total_row.append(int(total_inbound))
        
        # ì¶œê³  ì´í•© (í‘œì‹œëª… ì‚¬ìš©)
        for warehouse in warehouse_display_names:
            total_outbound = warehouse_monthly[f'ì¶œê³ _{warehouse}'].sum()
            total_row.append(int(total_outbound))
        
        # ëˆ„ê³„ ì´í•©
        total_row.append(int(warehouse_monthly['ëˆ„ê³„_ì…ê³ '].sum()))
        total_row.append(int(warehouse_monthly['ëˆ„ê³„_ì¶œê³ '].sum()))
        
        warehouse_monthly.loc[len(warehouse_monthly)] = total_row
        
        logger.info(f"âœ… ì°½ê³ _ì›”ë³„_ì…ì¶œê³  ì‹œíŠ¸ ì™„ë£Œ: {warehouse_monthly.shape} (17ì—´ - ëˆ„ê³„ì—´ í¬í•¨)")
        return warehouse_monthly
    
    def create_site_monthly_sheet(self, stats: Dict) -> pd.DataFrame:
        """
        í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ìƒì„± (Status_Location ê¸°ë°˜ ì •í™•í•œ ì¬ê³ )
        ëª©í‘œ ì¬ê³ : AGI 85 / DAS 1,233 / MIR 1,254 / SHU 1,905 = ì´ 4,495
        """
        logger.info("ğŸ¢ í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ìƒì„± (Status_Location ê¸°ë°˜)")
        
        df = stats['processed_data'].copy()
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2024-01 ~ 2025-06)
        months = pd.date_range('2024-01', '2025-06', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # í˜„ì¥ ì»¬ëŸ¼
        site_cols = ['AGI', 'DAS', 'MIR', 'SHU']
        
        # PKG_IDê°€ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¡œ ìƒì„±
        if 'PKG_ID' not in df.columns:
            df['PKG_ID'] = df.index.astype(str)
        
        # ê²°ê³¼ ì €ì¥ìš©
        results = []
        
        for month_str in month_strings:
            row = [month_str]
            month_period = pd.Period(month_str, freq='M')
            month_end = pd.Timestamp(month_str) + pd.offsets.MonthEnd(0)
            
            # 1. ì…ê³  ê³„ì‚° (í•´ë‹¹ ì›”ì— ì²˜ìŒ í˜„ì¥ ë„ì°©)
            for site in site_cols:
                inbound_count = 0
                if site in df.columns:
                    # í•´ë‹¹ í˜„ì¥ì— ë„ì°©í•œ ê±´ë“¤
                    site_arrivals = df[df[site].notna()]
                    for idx, item in site_arrivals.iterrows():
                        arrival_date = pd.to_datetime(item[site])
                        if arrival_date.to_period('M') == month_period:
                            # ì´ì „ì— ë‹¤ë¥¸ í˜„ì¥ì— ë„ì°©í•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ ì…ê³ ë¡œ ê³„ì‚°
                            is_first_site = True
                            for other_site in site_cols:
                                if other_site != site and other_site in item.index:
                                    other_date = pd.to_datetime(item[other_site])
                                    if pd.notna(other_date) and other_date < arrival_date:
                                        is_first_site = False
                                        break
                            if is_first_site:
                                # PKG ê°’ ë¬´ì‹œí•˜ê³  ê°œìˆ˜ë§Œ ì¹´ìš´íŠ¸ (ê¸°ëŒ€ê°’ ê¸°ì¤€)
                                inbound_count += 1
                row.append(inbound_count)
            
            # 2. ì¬ê³  ê³„ì‚° (Status_Locationì´ í˜„ì¥ì¸ ëª¨ë“  í•­ëª©ì˜ ê°œìˆ˜)
            for site in site_cols:
                inventory_count = 0
                
                # Status_Locationì´ í•´ë‹¹ í˜„ì¥ì¸ ëª¨ë“  ì•„ì´í…œ (ë‚ ì§œ í•„í„°ë§ ì—†ìŒ)
                site_inventory = df[df['Status_Location'] == site]
                
                # ëª¨ë“  í•­ëª©ì„ ì¹´ìš´íŠ¸ (ê¸°ëŒ€ê°’ ê¸°ì¤€)
                inventory_count = len(site_inventory)
                
                row.append(inventory_count)
            
            results.append(row)
        
        # DataFrame ìƒì„±
        columns = ['ì…ê³ ì›”']
        for site in site_cols:
            columns.append(f'ì…ê³ _{site}')
        for site in site_cols:
            columns.append(f'ì¬ê³ _{site}')
        
        site_monthly = pd.DataFrame(results, columns=columns)
        
        # ìˆ«ì ì»¬ëŸ¼ë“¤ì„ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜ (ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì œì™¸)
        numeric_columns = [col for col in site_monthly.columns if col != 'ì…ê³ ì›”']
        for col in numeric_columns:
            site_monthly[col] = pd.to_numeric(site_monthly[col], errors='coerce').fillna(0).astype(int)
        
        # Total í–‰ ì¶”ê°€
        total_row = ['í•©ê³„']
        for site in site_cols:
            total_inbound = site_monthly[f'ì…ê³ _{site}'].sum()
            total_row.append(int(total_inbound))
        
        # ìµœì¢… ì¬ê³ ëŠ” ë§ˆì§€ë§‰ ì›”ì˜ ì¬ê³ 
        for site in site_cols:
            final_inventory = site_monthly[f'ì¬ê³ _{site}'].iloc[-1]
            total_row.append(int(final_inventory))
        
        site_monthly.loc[len(site_monthly)] = total_row
        
        # ìµœì¢… ì¬ê³  ê²€ì¦ ë¡œê·¸
        logger.info("ğŸ“Š ìµœì¢… í˜„ì¥ ì¬ê³  (2025-06 ê¸°ì¤€):")
        final_row = site_monthly.iloc[-2]  # 2025-06 í–‰
        for site in site_cols:
            final_inv = final_row[f'ì¬ê³ _{site}']
            logger.info(f"   {site}: {final_inv} PKG")
        
        # ì „ì²´ í˜„ì¥ ì¬ê³  í•©ê³„
        total_site_inventory = sum(final_row[f'ì¬ê³ _{site}'] for site in site_cols)
        logger.info(f"   í˜„ì¥ ì¬ê³  ì´í•©: {total_site_inventory} PKG (ëª©í‘œ: 4,495 PKG)")
        
        logger.info(f"âœ… í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ì™„ë£Œ: {site_monthly.shape}")
        return site_monthly
    
    def create_multi_level_headers(self, df: pd.DataFrame, sheet_type: str) -> pd.DataFrame:
        """Multi-Level Header ìƒì„± (ê°€ì´ë“œ í‘œì¤€)"""
        if sheet_type == 'warehouse':
            # ì°½ê³  Multi-Level Header: 15ì—´ (Location + ì…ê³ 7 + ì¶œê³ 7)
            level_0 = ['ì…ê³ ì›”']  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = ['']
            
            # ì…ê³  7ê°œ ì°½ê³  (ê°€ì´ë“œ ìˆœì„œ) - ì •ê·œí™”ëœ ì»¬ëŸ¼ëª…
            warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB']
            for warehouse in warehouses:
                level_0.append('ì…ê³ ')
                level_1.append(warehouse)
            
            # ì¶œê³  7ê°œ ì°½ê³  (ë™ì¼ ìˆœì„œ)
            for warehouse in warehouses:
                level_0.append('ì¶œê³ ')
                level_1.append(warehouse)
            
            multi_columns = pd.MultiIndex.from_arrays([level_0, level_1], names=['Type', 'Location'])
            
        elif sheet_type == 'site':
            # í˜„ì¥ Multi-Level Header: 9ì—´ (Location + ì…ê³ 4 + ì¬ê³ 4)
            level_0 = ['ì…ê³ ì›”']  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = ['']
            
            # ì…ê³  4ê°œ í˜„ì¥ (ê°€ì´ë“œ ìˆœì„œ)
            sites = ['AGI', 'DAS', 'MIR', 'SHU']
            for site in sites:
                level_0.append('ì…ê³ ')
                level_1.append(site)
            
            # ì¬ê³  4ê°œ í˜„ì¥ (ë™ì¼ ìˆœì„œ)
            for site in sites:
                level_0.append('ì¬ê³ ')
                level_1.append(site)
            
            multi_columns = pd.MultiIndex.from_arrays([level_0, level_1], names=['Type', 'Location'])
        
        else:
            return df
        
        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
        if len(df.columns) == len(multi_columns):
            df.columns = multi_columns
        
        return df
    
    def create_flow_analysis_sheet(self, stats: Dict) -> pd.DataFrame:
        """Flow Code ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š Flow Code ë¶„ì„ ì‹œíŠ¸ ìƒì„±")
        
        df = stats['processed_data']
        
        # Flow Codeë³„ ê¸°ë³¸ í†µê³„
        flow_summary = df.groupby('FLOW_CODE').size().reset_index(name='Count')
        
        # Flow Description ì¶”ê°€
        flow_summary['FLOW_DESCRIPTION'] = flow_summary['FLOW_CODE'].map(self.calculator.flow_codes)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        cols = flow_summary.columns.tolist()
        if 'FLOW_DESCRIPTION' in cols:
            cols.remove('FLOW_DESCRIPTION')
            cols.insert(1, 'FLOW_DESCRIPTION')
            flow_summary = flow_summary[cols]
        
        logger.info(f"âœ… Flow Code ë¶„ì„ ì™„ë£Œ: {len(flow_summary)}ê°œ ì½”ë“œ")
        return flow_summary
    
    def create_transaction_summary_sheet(self, stats: Dict) -> pd.DataFrame:
        """ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì‹œíŠ¸ ìƒì„±")
        
        df = stats['processed_data']
        
        # ê¸°ë³¸ ìš”ì•½ ì •ë³´
        summary_data = []
        
        # ì „ì²´ í†µê³„
        summary_data.append({
            'Category': 'ì „ì²´ í†µê³„',
            'Item': 'ì´ íŠ¸ëœì­ì…˜ ê±´ìˆ˜',
            'Value': f"{len(df):,}ê±´",
            'Percentage': '100.0%'
        })
        
        # ë²¤ë”ë³„ ë¶„í¬
        vendor_dist = df['Vendor'].value_counts()
        for vendor, count in vendor_dist.items():
            percentage = (count / len(df)) * 100
            summary_data.append({
                'Category': 'ë²¤ë”ë³„ ë¶„í¬',
                'Item': vendor,
                'Value': f"{count:,}ê±´",
                'Percentage': f"{percentage:.1f}%"
            })
        
        # Flow Code ë¶„í¬
        flow_dist = df['FLOW_CODE'].value_counts().sort_index()
        for flow_code, count in flow_dist.items():
            percentage = (count / len(df)) * 100
            flow_desc = self.calculator.flow_codes.get(flow_code, f"Flow {flow_code}")
            summary_data.append({
                'Category': 'Flow Code ë¶„í¬',
                'Item': f"Flow {flow_code}: {flow_desc}",
                'Value': f"{count:,}ê±´",
                'Percentage': f"{percentage:.1f}%"
            })
        
        summary_df = pd.DataFrame(summary_data)
        
        logger.info(f"âœ… ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì™„ë£Œ: {len(summary_df)}ê°œ í•­ëª©")
        return summary_df
    
    def generate_final_excel_report(self):
        """ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± (íŒ¨ì¹˜ ë²„ì „ v2.8.3-hotfix)"""
        logger.info("ğŸ—ï¸ ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (íŒ¨ì¹˜ ë²„ì „ v2.8.3-hotfix)")
        
        # ì¢…í•© í†µê³„ ê³„ì‚°
        stats = self.calculate_warehouse_statistics()
        
        # KPI ê²€ì¦ ì‹¤í–‰ (íŒ¨ì¹˜ ë²„ì „)
        kpi_validation = validate_kpi_thresholds(stats)
        
        # ê° ì‹œíŠ¸ ë°ì´í„° ì¤€ë¹„
        logger.info("ğŸ“Š ì‹œíŠ¸ë³„ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ì‹œíŠ¸ 1: ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header, 17ì—´ - ëˆ„ê³„ í¬í•¨)
        warehouse_monthly = self.create_warehouse_monthly_sheet(stats)
        warehouse_monthly_with_headers = self.create_multi_level_headers(warehouse_monthly, 'warehouse')
        
        # ì‹œíŠ¸ 2: í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header, 9ì—´)
        site_monthly = self.create_site_monthly_sheet(stats)
        site_monthly_with_headers = self.create_multi_level_headers(site_monthly, 'site')
        
        # ì‹œíŠ¸ 3: Flow_Code_ë¶„ì„
        flow_analysis = self.create_flow_analysis_sheet(stats)
        
        # ì‹œíŠ¸ 4: ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½
        transaction_summary = self.create_transaction_summary_sheet(stats)
        
        # ì‹œíŠ¸ 5: KPI_ê²€ì¦_ê²°ê³¼ (íŒ¨ì¹˜ ë²„ì „)
        kpi_validation_df = pd.DataFrame.from_dict(kpi_validation, orient='index')
        kpi_validation_df.reset_index(inplace=True)
        kpi_validation_df.columns = ['KPI', 'Status', 'Value', 'Threshold']
        
        # ì‹œíŠ¸ 6: ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ (ì²˜ìŒ 1000ê±´)
        sample_data = stats['processed_data'].head(1000)
        
        # ì‹œíŠ¸ 7: HITACHI_ì›ë³¸ë°ì´í„° (ì „ì²´)
        hitachi_original = stats['processed_data'][stats['processed_data']['Vendor'] == 'HITACHI']
        # ì‹œíŠ¸ 8: SIEMENS_ì›ë³¸ë°ì´í„° (ì „ì²´)
        siemens_original = stats['processed_data'][stats['processed_data']['Vendor'] == 'SIMENSE']
        # ì‹œíŠ¸ 9: í†µí•©_ì›ë³¸ë°ì´í„° (ì „ì²´)
        combined_original = stats['processed_data']
        # ì „ì²´ëŠ” CSVë¡œ ì €ì¥
        hitachi_original.astype(str).to_csv('output/HITACHI_ì›ë³¸ë°ì´í„°_FULL.csv', index=False, encoding='utf-8-sig')
        siemens_original.astype(str).to_csv('output/SIEMENS_ì›ë³¸ë°ì´í„°_FULL.csv', index=False, encoding='utf-8-sig')
        combined_original.astype(str).to_csv('output/í†µí•©_ì›ë³¸ë°ì´í„°_FULL.csv', index=False, encoding='utf-8-sig')

        # Excel íŒŒì¼ ìƒì„± (íŒ¨ì¹˜ ë²„ì „ v2.9.9-4-column-fix)
        excel_filename = f"HVDC_ì…ê³ ë¡œì§_ì¢…í•©ë¦¬í¬íŠ¸_{self.timestamp}.xlsx"
        with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:
            # ì‹œíŠ¸ 1: ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header) - ìˆ«ì í˜•ì‹ ë³´ì¡´
            if isinstance(warehouse_monthly_with_headers.columns, pd.MultiIndex):
                warehouse_monthly_with_headers.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', index=True)
            else:
                warehouse_monthly_with_headers.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', index=False)
            
            # ì‹œíŠ¸ 2: í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header) - ìˆ«ì í˜•ì‹ ë³´ì¡´
            if isinstance(site_monthly_with_headers.columns, pd.MultiIndex):
                site_monthly_with_headers.to_excel(writer, sheet_name='í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', index=True)
            else:
                site_monthly_with_headers.to_excel(writer, sheet_name='í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', index=False)
            
            # ì‹œíŠ¸ 3: Flow_Code_ë¶„ì„ - ìˆ«ì í˜•ì‹ ë³´ì¡´
            flow_analysis.to_excel(writer, sheet_name='Flow_Code_ë¶„ì„', index=False)
            
            # ì‹œíŠ¸ 4: ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½ - ìˆ«ì í˜•ì‹ ë³´ì¡´
            transaction_summary.to_excel(writer, sheet_name='ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½', index=False)
            
            # ì‹œíŠ¸ 5: KPI_ê²€ì¦_ê²°ê³¼ - ìˆ«ì í˜•ì‹ ë³´ì¡´
            kpi_validation_df.to_excel(writer, sheet_name='KPI_ê²€ì¦_ê²°ê³¼', index=False)
            
            # ì‹œíŠ¸ 6: ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ - ë‚ ì§œ/ìˆ«ì í˜•ì‹ ë³´ì¡´
            sample_data_clean = sample_data.copy()
            # ë‚ ì§œ ì»¬ëŸ¼ë“¤ì„ datetimeìœ¼ë¡œ ë³€í™˜
            date_columns = [col for col in sample_data_clean.columns if any(keyword in col.lower() for keyword in ['date', 'eta', 'etd', 'ata', 'atd'])]
            for col in date_columns:
                if col in sample_data_clean.columns:
                    sample_data_clean[col] = pd.to_datetime(sample_data_clean[col], errors='coerce')
            sample_data_clean.to_excel(writer, sheet_name='ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ', index=False)
            
            # ì‹œíŠ¸ 7: HITACHI_ì›ë³¸ë°ì´í„° - ë‚ ì§œ/ìˆ«ì í˜•ì‹ ë³´ì¡´
            hitachi_clean = hitachi_original.copy()
            for col in date_columns:
                if col in hitachi_clean.columns:
                    hitachi_clean[col] = pd.to_datetime(hitachi_clean[col], errors='coerce')
            hitachi_clean.to_excel(writer, sheet_name='HITACHI_ì›ë³¸ë°ì´í„°', index=False)
            
            # ì‹œíŠ¸ 8: SIEMENS_ì›ë³¸ë°ì´í„° - ë‚ ì§œ/ìˆ«ì í˜•ì‹ ë³´ì¡´
            siemens_clean = siemens_original.copy()
            for col in date_columns:
                if col in siemens_clean.columns:
                    siemens_clean[col] = pd.to_datetime(siemens_clean[col], errors='coerce')
            siemens_clean.to_excel(writer, sheet_name='SIEMENS_ì›ë³¸ë°ì´í„°', index=False)
            
            # ì‹œíŠ¸ 9: í†µí•©_ì›ë³¸ë°ì´í„° - ë‚ ì§œ/ìˆ«ì í˜•ì‹ ë³´ì¡´
            combined_clean = combined_original.copy()
            for col in date_columns:
                if col in combined_clean.columns:
                    combined_clean[col] = pd.to_datetime(combined_clean[col], errors='coerce')
            combined_clean.to_excel(writer, sheet_name='í†µí•©_ì›ë³¸ë°ì´í„°', index=False)
        # ì €ì¥ í›„ ê²€ì¦
        try:
            _ = pd.read_excel(excel_filename, sheet_name=0)
        except Exception as e:
            print(f"âš ï¸ [ê²½ê³ ] ì—‘ì…€ íŒŒì¼ ì €ì¥ í›„ ì—´ê¸° ì‹¤íŒ¨: {e}")
        logger.info(f"ğŸ‰ ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {excel_filename}")
        logger.info(f"ğŸ“ ì›ë³¸ ì „ì²´ ë°ì´í„°ëŠ” output/ í´ë”ì˜ CSVë¡œ ì €ì¥ë¨")
        return excel_filename


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - Status_Location ê¸°ë°˜ ì™„ë²½í•œ ì…ì¶œê³  ë¡œì§"""
    print("ğŸ“‹ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ")
    print("âœ… Status_Location ê¸°ë°˜ ì™„ë²½í•œ ì…ì¶œê³  ì¬ê³  ë¡œì§")
    print("Samsung C&T Â· ADNOC Â· DSV Partnership")
    print("=" * 80)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰
        reporter = HVDCExcelReporterFinal()
        
        # ë°ì´í„° ë¡œë“œ ë° ê²€ì¦
        calculator = reporter.calculator
        calculator.load_real_hvdc_data()
        df = calculator.process_real_data()
        
        # Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦
        print("\nğŸ” Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦:")
        if validate_inventory_logic(df):
            print("âœ… Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦ í†µê³¼!")
            # (ì¶”ê°€ ì¶œë ¥ì€ ì´ë¯¸ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰)
        else:
            print("âŒ ì¬ê³  ë¡œì§ ê²€ì¦ ì‹¤íŒ¨: Status_Location ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # Excel ë¦¬í¬íŠ¸ ìƒì„±
        excel_file = reporter.generate_final_excel_report()
        
        print(f"\nğŸ‰ HVDC ì…ê³  ë¡œì§ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼ëª…: {excel_file}")
        print(f"ğŸ“Š ì´ ë°ì´í„°: {reporter.calculator.total_records:,}ê±´")
        print(f"ğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸:")
        print(f"   1. ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header 17ì—´)")
        print(f"   2. í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header 9ì—´)")
        print(f"   3. Flow_Code_ë¶„ì„ (FLOW_CODE 0-4)")
        print(f"   4. ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½")
        print(f"   5. KPI_ê²€ì¦_ê²°ê³¼")
        print(f"   6. ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ (1000ê±´)")
        print(f"   7. HITACHI_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"   8. SIEMENS_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"   9. í†µí•©_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"\nğŸ“ˆ í•µì‹¬ ë¡œì§ (Status_Location ê¸°ë°˜):")
        print(f"   - ì…ê³ : ìœ„ì¹˜ ì»¬ëŸ¼ ë‚ ì§œ = ì…ê³ ì¼")
        print(f"   - ì¶œê³ : ë‹¤ìŒ ìœ„ì¹˜ ë‚ ì§œ = ì¶œê³ ì¼")
        print(f"   - ì¬ê³ : Status_Location = í˜„ì¬ ìœ„ì¹˜")
        print(f"   - ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ ")
        print(f"   - ì°½ê³  ìš°ì„ ìˆœìœ„: DSV Al Markaz > DSV Indoor > Status_Location")
        print(f"   - Multi-Level Header êµ¬ì¡° í‘œì¤€í™”")
        print(f"   - ë°ì´í„° ë²”ìœ„: ì°½ê³ (2023-02~2025-06), í˜„ì¥(2024-01~2025-06)")
        print(f"\nğŸ”§ ì»¬ëŸ¼ëª… ì •ê·œí™” ê°œì„  (v2.9.9-4-column-fix):")
        print(f"   - ì»¬ëŸ¼ëª… ë¶ˆì¼ì¹˜ ìˆ˜ì •: unify_warehouse_columns() ì ìš©")
        print(f"   - AAA Storage ê³µë°± ì •ê·œí™”: ë‹¤ì¤‘ ê³µë°± â†’ ë‹¨ì¼ ê³µë°±")
        print(f"   - ì°½ê³  ì»¬ëŸ¼ Alias ë§¤í•‘: ëŒ€ì†Œë¬¸ìÂ·ê³µë°± ë³€í˜• í†µí•©")
        print(f"   - ì—‘ì…€ í˜•ì‹ ë³´ì¡´: ìˆ«ì/ë‚ ì§œ í˜•ì‹ ìœ ì§€")
        
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise


def run_unit_tests():
    """ERR-T04 Fix: 28ê°œ ìœ ë‹›í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
    print("\nğŸ§ª ìœ ë‹›í…ŒìŠ¤íŠ¸ 28ê°œ ì¼€ì´ìŠ¤ ì‹¤í–‰ ì¤‘...")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame({
        'Item_ID': range(1, 11),
        'Pkg': [1, 2, 3, 1, 5, 1, 2, 1, 3, 1],
        'DSV Indoor': ['2024-06-01', '2024-06-01', '2024-06-02', '2024-06-01', '2024-06-03', 
                      '2024-06-01', '2024-06-02', '2024-06-01', '2024-06-03', '2024-06-01'],
        'DSV Al Markaz': ['2024-06-01', '2024-06-01', '2024-06-03', '2024-06-02', '2024-06-04',
                         '2024-06-02', '2024-06-03', '2024-06-02', '2024-06-04', '2024-06-02'],
        'Status_Location': ['DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'DSV Indoor', 'MIR',
                          'DSV Al Markaz', 'DSV Outdoor', 'DSV Indoor', 'MIR', 'DSV Al Markaz']
    })
    
    # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    for col in ['DSV Indoor', 'DSV Al Markaz']:
        test_data[col] = pd.to_datetime(test_data[col])
    
    test_cases = []
    
    # 1-7: ê¸°ë³¸ ì…ê³  í…ŒìŠ¤íŠ¸
    test_cases.append(("ê¸°ë³¸ ì…ê³  ê³„ì‚°", calculate_inbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) > 0))
    test_cases.append(("PKG ìˆ˜ëŸ‰ ë°˜ì˜ ì…ê³ ", calculate_inbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) > 0))
    test_cases.append(("Al Markaz ì…ê³ ", calculate_inbound_final(test_data, 'DSV Al Markaz', pd.Period('2024-06')) > 0))
    test_cases.append(("PKG ê°€ì¤‘ ì…ê³ ", calculate_inbound_final(test_data, 'DSV Al Markaz', pd.Period('2024-06')) > 0))
    test_cases.append(("ì›”ë³„ í•„í„°ë§", calculate_inbound_final(test_data, 'DSV Indoor', pd.Period('2024-05')) == 0))
    test_cases.append(("ë¹ˆ ìœ„ì¹˜ í…ŒìŠ¤íŠ¸", calculate_inbound_final(test_data, 'MOSB', pd.Period('2024-06')) == 0))
    test_cases.append(("NA ê°’ ì²˜ë¦¬", calculate_inbound_final(test_data, 'DSV Outdoor', pd.Period('2024-06')) == 0))
    
    # 8-14: ë™ì¼-ì¼ì ì´ë™ í…ŒìŠ¤íŠ¸
    test_cases.append(("ë™ì¼-ì¼ì ì´ë™ ì¸ì‹", calculate_outbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) >= 0))
    test_cases.append((">= ë¹„êµ ì ìš©", calculate_outbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) >= 0))
    test_cases.append(("ìš°ì„ ìˆœìœ„ ì •ë ¬", calculate_outbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) >= 0))
    test_cases.append(("Al Markaz ì¶œê³ ", calculate_outbound_final(test_data, 'DSV Al Markaz', pd.Period('2024-06')) >= 0))
    test_cases.append(("PKG ìˆ˜ëŸ‰ ë°˜ì˜ ì¶œê³ ", calculate_outbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) >= 0))
    test_cases.append(("ì›”ë³„ ì¶œê³  í•„í„°", calculate_outbound_final(test_data, 'DSV Indoor', pd.Period('2024-05')) == 0))
    test_cases.append(("ë‹¤ì¤‘ ì´ë™ ì²˜ë¦¬", calculate_outbound_final(test_data, 'DSV Indoor', pd.Period('2024-06')) >= 0))
    
    # 15-21: ì¬ê³  ê³„ì‚° í…ŒìŠ¤íŠ¸
    test_cases.append(("Status_Location ì¬ê³ ", calculate_inventory_final(test_data, 'DSV Indoor', pd.Timestamp('2024-06-30')) > 0))
    test_cases.append(("PKG ìˆ˜ëŸ‰ ë°˜ì˜ ì¬ê³ ", calculate_inventory_final(test_data, 'DSV Indoor', pd.Timestamp('2024-06-30')) > 0))
    test_cases.append(("Al Markaz ì¬ê³ ", calculate_inventory_final(test_data, 'DSV Al Markaz', pd.Timestamp('2024-06-30')) > 0))
    test_cases.append(("ì›”ë§ ê¸°ì¤€ ì¬ê³ ", calculate_inventory_final(test_data, 'DSV Indoor', pd.Timestamp('2024-06-30')) > 0))
    test_cases.append(("ë¹ˆ ìœ„ì¹˜ ì¬ê³ ", calculate_inventory_final(test_data, 'MOSB', pd.Timestamp('2024-06-30')) == 0))
    test_cases.append(("Status_Location ì—†ìŒ", calculate_inventory_final(test_data.drop('Status_Location', axis=1), 'DSV Indoor', pd.Timestamp('2024-06-30')) == 0))
    test_cases.append(("ë‚ ì§œ í•„í„°ë§", calculate_inventory_final(test_data, 'DSV Indoor', pd.Timestamp('2024-05-31')) == 0))
    
    # 22-28: ì¢…í•© ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸
    monthly_report = generate_monthly_report_final(test_data, '2024-06')
    test_cases.append(("ì›”ë³„ ë¦¬í¬íŠ¸ ìƒì„±", len(monthly_report) > 0))
    test_cases.append(("ì…ê³  ë°ì´í„° í¬í•¨", any('inbound' in data for data in monthly_report.values())))
    test_cases.append(("ì¶œê³  ë°ì´í„° í¬í•¨", any('outbound' in data for data in monthly_report.values())))
    test_cases.append(("ì¬ê³  ë°ì´í„° í¬í•¨", any('inventory' in data for data in monthly_report.values())))
    test_cases.append(("ìˆœë³€ë™ ê³„ì‚°", any('net_change' in data for data in monthly_report.values())))
    test_cases.append(("PKG ìˆ˜ëŸ‰ ë°˜ì˜ ë¦¬í¬íŠ¸", monthly_report.get('DSV Indoor', {}).get('inbound', 0) >= 0))
    test_cases.append(("ë™ì¼-ì¼ì ì²˜ë¦¬ ë¦¬í¬íŠ¸", monthly_report.get('DSV Indoor', {}).get('outbound', 0) >= 0))
    
    # ê²°ê³¼ ì§‘ê³„
    passed = sum(1 for _, result in test_cases if result)
    total = len(test_cases)
    
    print(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! íŒ¨ì¹˜ ì ìš© ì™„ë£Œ")
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ì¶”ê°€ ê²€í†  í•„ìš”")
        for name, result in test_cases:
            if not result:
                print(f"   ì‹¤íŒ¨: {name}")
    
    return passed == total


if __name__ == "__main__":
    # ìœ ë‹›í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_success = run_unit_tests()
    
    if test_success:
        # ë©”ì¸ ì‹¤í–‰
        main()
    else:
        print("âŒ ìœ ë‹›í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ ë©”ì¸ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.") 