import pandas as pd
import numpy as np
from typing import List, Dict, Any
from datetime import datetime

REQUIRED_COLUMNS = ['Case No.', 'Vendor', 'Status_Current', 'Status_Location']

def validate_excel_columns(file_path: str) -> List[str]:
    """
    ì—‘ì…€ íŒŒì¼ì˜ ì»¬ëŸ¼ êµ¬ì¡°ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    ëˆ„ë½ëœ í•„ìˆ˜ ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    df = pd.read_excel(file_path, nrows=1)
    missing = [col for col in REQUIRED_COLUMNS if col not in df.columns]
    if missing:
        print(f"[ê²½ê³ ] ëˆ„ë½ëœ í•„ìˆ˜ ì»¬ëŸ¼: {missing}")
        print(f"[ì°¸ê³ ] ì‹¤ì œ ì»¬ëŸ¼ ëª©ë¡: {list(df.columns)}")
    else:
        print("[í™•ì¸] ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    return missing

def validate_vendor_data_quality(hitachi_file: str, simense_file: str) -> Dict[str, Any]:
    """
    ë²¤ë”ë³„ ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì¦
    
    Args:
        hitachi_file: HITACHI ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        simense_file: SIMENSE ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Dict: ê²€ì¦ ê²°ê³¼ ë° í†µê³„
    """
    print("ğŸ” ë²¤ë”ë³„ ë°ì´í„° í’ˆì§ˆ ì¢…í•© ê²€ì¦ ì‹œì‘...")
    
    validation_results = {
        'hitachi_stats': {},
        'simense_stats': {},
        'combined_stats': {},
        'column_analysis': {},
        'status_analysis': {},
        'recommendations': []
    }
    
    # 1. HITACHI íŒŒì¼ ê²€ì¦
    try:
        df_hitachi = pd.read_excel(hitachi_file)
        df_hitachi['Vendor'] = 'HITACHI'
        
        validation_results['hitachi_stats'] = {
            'total_records': len(df_hitachi),
            'columns': list(df_hitachi.columns),
            'missing_values': df_hitachi.isnull().sum().to_dict(),
            'data_types': df_hitachi.dtypes.to_dict()
        }
        print(f"âœ… HITACHI íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {len(df_hitachi)}ê±´")
        
    except Exception as e:
        print(f"âŒ HITACHI íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        validation_results['hitachi_stats'] = {'error': str(e)}
    
    # 2. SIMENSE íŒŒì¼ ê²€ì¦
    try:
        df_simense = pd.read_excel(simense_file)
        df_simense['Vendor'] = 'SIMENSE'
        
        validation_results['simense_stats'] = {
            'total_records': len(df_simense),
            'columns': list(df_simense.columns),
            'missing_values': df_simense.isnull().sum().to_dict(),
            'data_types': df_simense.dtypes.to_dict()
        }
        print(f"âœ… SIMENSE íŒŒì¼ ê²€ì¦ ì™„ë£Œ: {len(df_simense)}ê±´")
        
    except Exception as e:
        print(f"âŒ SIMENSE íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        validation_results['simense_stats'] = {'error': str(e)}
    
    # 3. í†µí•© ë°ì´í„° ê²€ì¦
    if 'error' not in validation_results['hitachi_stats'] and 'error' not in validation_results['simense_stats']:
        df_combined = pd.concat([df_hitachi, df_simense], ignore_index=True)
        
        validation_results['combined_stats'] = {
            'total_records': len(df_combined),
            'vendor_distribution': df_combined['Vendor'].value_counts().to_dict(),
            'columns': list(df_combined.columns)
        }
        
        # 4. ì»¬ëŸ¼ ë¶„ì„
        print("\nğŸ“Š ì»¬ëŸ¼ êµ¬ì¡° ë¶„ì„:")
        for col in df_combined.columns:
            if col in ['Case No.', 'Vendor', 'Status_Current', 'Status_Location']:
                print(f"  âœ… í•„ìˆ˜ ì»¬ëŸ¼: {col}")
            elif 'HVDC' in col or 'CODE' in col:
                print(f"  ğŸ”§ HVDC ì»¬ëŸ¼: {col}")
                unique_values = df_combined[col].dropna().unique()[:5]
                print(f"    ìƒ˜í”Œ ê°’: {unique_values}")
            elif any(loc in col for loc in ['DSV', 'AAA', 'MOSB', 'AGI', 'DAS', 'MIR', 'SHU']):
                print(f"  ğŸ“ ìœ„ì¹˜ ì»¬ëŸ¼: {col}")
                non_null_count = df_combined[col].notna().sum()
                print(f"    ìœ íš¨ ë°ì´í„°: {non_null_count}/{len(df_combined)}")
        
        # 5. ìƒíƒœë³„ ë¶„ì„
        print("\nğŸ“‹ ìƒíƒœë³„ ë°ì´í„° ë¶„ì„:")
        status_columns = [col for col in df_combined.columns if 'Status' in col or 'Current' in col]
        for col in status_columns:
            if col in df_combined.columns:
                status_counts = df_combined[col].value_counts()
                print(f"  {col}: {dict(status_counts)}")
        
        # 6. ìœ„ì¹˜ë³„ ë¶„ì„
        print("\nğŸ“ ìœ„ì¹˜ë³„ ë°ì´í„° ë¶„ì„:")
        location_columns = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'DSV MZP', 
                           'MOSB', 'AAA  Storage', 'Hauler Indoor', 'AGI', 'DAS', 'MIR', 'SHU']
        for col in location_columns:
            if col in df_combined.columns:
                non_null_count = df_combined[col].notna().sum()
                if non_null_count > 0:
                    print(f"  {col}: {non_null_count}ê±´")
        
        # 7. ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []
        
        # ëª©í‘œê°’ê³¼ ë¹„êµ
        target_hitachi = 5126
        target_simense = 1853
        target_total = 6979
        
        actual_hitachi = validation_results['combined_stats']['vendor_distribution'].get('HITACHI', 0)
        actual_simense = validation_results['combined_stats']['vendor_distribution'].get('SIMENSE', 0)
        actual_total = validation_results['combined_stats']['total_records']
        
        if actual_hitachi > target_hitachi:
            recommendations.append(f"HITACHI ë°ì´í„° {actual_hitachi - target_hitachi}ê±´ ì´ˆê³¼ - ìƒíƒœë³„ í•„í„°ë§ í•„ìš”")
        if actual_simense > target_simense:
            recommendations.append(f"SIMENSE ë°ì´í„° {actual_simense - target_simense}ê±´ ì´ˆê³¼ - ìƒíƒœë³„ í•„í„°ë§ í•„ìš”")
        if actual_total > target_total:
            recommendations.append(f"ì´ ë°ì´í„° {actual_total - target_total}ê±´ ì´ˆê³¼ - ì™„ë£Œëœ ì•„ì´í…œ ì œê±° í•„ìš”")
        
        validation_results['recommendations'] = recommendations
        
        print(f"\nğŸ“ˆ ëª©í‘œê°’ ëŒ€ë¹„ í˜„í™©:")
        print(f"  HITACHI: {actual_hitachi} vs {target_hitachi} ({actual_hitachi - target_hitachi:+d})")
        print(f"  SIMENSE: {actual_simense} vs {target_simense} ({actual_simense - target_simense:+d})")
        print(f"  Total: {actual_total} vs {target_total} ({actual_total - target_total:+d})")
        
        if recommendations:
            print(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in recommendations:
                print(f"  - {rec}")
    
    return validation_results

def analyze_status_filtering(df: pd.DataFrame) -> Dict[str, Any]:
    """
    ìƒíƒœë³„ í•„í„°ë§ ë¶„ì„
    
    Args:
        df: í†µí•© ë°ì´í„°í”„ë ˆì„
        
    Returns:
        Dict: ìƒíƒœë³„ ë¶„ì„ ê²°ê³¼
    """
    print("\nğŸ” ìƒíƒœë³„ í•„í„°ë§ ë¶„ì„:")
    
    status_analysis = {}
    
    # ìƒíƒœ ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
    status_columns = [col for col in df.columns if 'Status' in col or 'Current' in col or 'Complete' in col]
    
    for col in status_columns:
        if col in df.columns:
            try:
                unique_values = df[col].dropna().unique()
                print(f"  {col}: {list(unique_values)}")
                
                # ê° ìƒíƒœë³„ ë²¤ë” ë¶„í¬ (ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ ì œì™¸)
                if not pd.api.types.is_datetime64_any_dtype(df[col]):
                    status_vendor_counts = df.groupby([col, 'Vendor']).size().unstack(fill_value=0)
                    print(f"    ë²¤ë”ë³„ ë¶„í¬:\n{status_vendor_counts}")
                    
                    status_analysis[col] = {
                        'unique_values': list(unique_values),
                        'vendor_distribution': status_vendor_counts.to_dict()
                    }
                else:
                    print(f"    â° ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ - ë²¤ë”ë³„ ë¶„í¬ ìƒëµ")
                    status_analysis[col] = {
                        'unique_values': list(unique_values),
                        'vendor_distribution': {}
                    }
            except Exception as e:
                print(f"    âŒ ë¶„ì„ ì˜¤ë¥˜: {e}")
                status_analysis[col] = {'error': str(e)}
    
    return status_analysis

def apply_status_filtering(df: pd.DataFrame) -> pd.DataFrame:
    """
    ìƒíƒœë³„ í•„í„°ë§ ì ìš© (Pre Arrivalë§Œ ì œê±°)
    
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
    """
    print("\nğŸ”§ ìƒíƒœë³„ í•„í„°ë§ ì ìš© (Pre Arrivalë§Œ ì œê±°):")
    
    original_count = len(df)
    df_filtered = df.copy()
    
    # 1. Pre Arrival ìƒíƒœë§Œ ì œê±°
    if 'Status_Current' in df_filtered.columns:
        pre_arrival_mask = df_filtered['Status_Current'] == 'Pre Arrival'
        pre_arrival_count = pre_arrival_mask.sum()
        df_filtered = df_filtered[~pre_arrival_mask]
        print(f"  âœ… Pre Arrival ì œê±°: {pre_arrival_count}ê±´")
    
    # 2. Status_Storageì—ì„œ Pre Arrival ì œê±° (ì¤‘ë³µ í™•ì¸)
    if 'Status_Storage' in df_filtered.columns:
        storage_pre_arrival_mask = df_filtered['Status_Storage'] == 'Pre Arrival'
        storage_pre_arrival_count = storage_pre_arrival_mask.sum()
        if storage_pre_arrival_count > 0:
            df_filtered = df_filtered[~storage_pre_arrival_mask]
            print(f"  âœ… Status_Storage Pre Arrival ì œê±°: {storage_pre_arrival_count}ê±´")
    
    # 3. Status_Locationì—ì„œ Pre Arrival ì œê±°
    if 'Status_Location' in df_filtered.columns:
        location_pre_arrival_mask = df_filtered['Status_Location'] == 'Pre Arrival'
        location_pre_arrival_count = location_pre_arrival_mask.sum()
        if location_pre_arrival_count > 0:
            df_filtered = df_filtered[~location_pre_arrival_mask]
            print(f"  âœ… Status_Location Pre Arrival ì œê±°: {location_pre_arrival_count}ê±´")
    
    filtered_count = len(df_filtered)
    removed_count = original_count - filtered_count
    
    print(f"  ğŸ“Š í•„í„°ë§ ê²°ê³¼: {original_count} â†’ {filtered_count} (ì œê±°: {removed_count}ê±´)")
    
    # ë²¤ë”ë³„ ë¶„í¬ í™•ì¸
    if 'Vendor' in df_filtered.columns:
        vendor_dist = df_filtered['Vendor'].value_counts()
        print(f"  ğŸ“‹ í•„í„°ë§ í›„ ë²¤ë”ë³„ ë¶„í¬:")
        for vendor, count in vendor_dist.items():
            print(f"    {vendor}: {count}ê±´")
    
    # ìƒíƒœë³„ ë¶„í¬ í™•ì¸
    if 'Status_Current' in df_filtered.columns:
        status_dist = df_filtered['Status_Current'].value_counts()
        print(f"  ğŸ“‹ í•„í„°ë§ í›„ ìƒíƒœë³„ ë¶„í¬:")
        for status, count in status_dist.items():
            print(f"    {status}: {count}ê±´")
    
    return df_filtered

def validate_filtered_data_quality(df_filtered: pd.DataFrame) -> Dict[str, Any]:
    """
    í•„í„°ë§ëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
    
    Args:
        df_filtered: í•„í„°ë§ëœ ë°ì´í„°í”„ë ˆì„
        
    Returns:
        Dict: ê²€ì¦ ê²°ê³¼
    """
    print("\nğŸ” í•„í„°ë§ëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦:")
    
    validation_results = {
        'total_records': len(df_filtered),
        'vendor_distribution': {},
        'location_distribution': {},
        'target_comparison': {},
        'recommendations': []
    }
    
    # ë²¤ë”ë³„ ë¶„í¬
    if 'Vendor' in df_filtered.columns:
        vendor_dist = df_filtered['Vendor'].value_counts().to_dict()
        validation_results['vendor_distribution'] = vendor_dist
        print(f"  ğŸ“Š ë²¤ë”ë³„ ë¶„í¬: {vendor_dist}")
    
    # ìœ„ì¹˜ë³„ ë¶„í¬
    if 'Status_Location' in df_filtered.columns:
        location_dist = df_filtered['Status_Location'].value_counts().to_dict()
        validation_results['location_distribution'] = location_dist
        print(f"  ğŸ“ ìœ„ì¹˜ë³„ ë¶„í¬: {location_dist}")
    
    # ëª©í‘œê°’ê³¼ ë¹„êµ
    target_hitachi = 5126
    target_simense = 1853
    target_total = 6979
    
    actual_hitachi = vendor_dist.get('HITACHI', 0)
    actual_simense = vendor_dist.get('SIMENSE', 0)
    actual_total = len(df_filtered)
    
    validation_results['target_comparison'] = {
        'hitachi': {'actual': actual_hitachi, 'target': target_hitachi, 'difference': actual_hitachi - target_hitachi},
        'simense': {'actual': actual_simense, 'target': target_simense, 'difference': actual_simense - target_simense},
        'total': {'actual': actual_total, 'target': target_total, 'difference': actual_total - target_total}
    }
    
    print(f"\nğŸ“ˆ ëª©í‘œê°’ ëŒ€ë¹„ í˜„í™©:")
    print(f"  HITACHI: {actual_hitachi} vs {target_hitachi} ({actual_hitachi - target_hitachi:+d})")
    print(f"  SIMENSE: {actual_simense} vs {target_simense} ({actual_simense - target_simense:+d})")
    print(f"  Total: {actual_total} vs {target_total} ({actual_total - target_total:+d})")
    
    # ê¶Œì¥ì‚¬í•­ ìƒì„±
    if actual_hitachi > target_hitachi:
        validation_results['recommendations'].append(f"HITACHI ì—¬ì „íˆ {actual_hitachi - target_hitachi}ê±´ ì´ˆê³¼")
    if actual_simense > target_simense:
        validation_results['recommendations'].append(f"SIMENSE ì—¬ì „íˆ {actual_simense - target_simense}ê±´ ì´ˆê³¼")
    if actual_total > target_total:
        validation_results['recommendations'].append(f"ì´ ë°ì´í„° ì—¬ì „íˆ {actual_total - target_total}ê±´ ì´ˆê³¼")
    
    if validation_results['recommendations']:
        print(f"\nğŸ’¡ ì¶”ê°€ ê¶Œì¥ì‚¬í•­:")
        for rec in validation_results['recommendations']:
            print(f"  - {rec}")
    else:
        print(f"\nâœ… ëª©í‘œê°’ ë‹¬ì„±!")
    
    return validation_results

def validate_hitachi_location_targets(df_filtered: pd.DataFrame) -> None:
    """
    HITACHI ë²¤ë”ì— ëŒ€í•´ ìœ„ì¹˜ë³„ ëª©í‘œê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•˜ì—¬ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.
    ëª©í‘œê°’ì€ Pre Arrival ì œì™¸, í‘œì˜ ê°’ìœ¼ë¡œ í•˜ë“œì½”ë”©.
    """
    print("\nğŸ“‹ HITACHI ìœ„ì¹˜ë³„ ëª©í‘œê°’ ì¼ì¹˜ ê²€ì¦:")
    # ìœ„ì¹˜ë³„ ëª©í‘œê°’ (Pre Arrival ì œì™¸)
    hitachi_targets = {
        'AGI': 40,
        'DAS': 964,
        'MIR': 753,
        'SHU': 1304,
        'AAA  Storage': 392,
        'DHL Warehouse': 119,
        'DSV Al Markaz': 256,
        'DSV Indoor': 360,
        'DSV Outdoor': 788,
        'Hauler Indoor': 10,
        'MOSB': 38
    }
    # HITACHIë§Œ í•„í„°ë§
    df_hitachi = df_filtered[df_filtered['Vendor'] == 'HITACHI']
    # ìœ„ì¹˜ë³„ ì§‘ê³„
    actual_counts = df_hitachi['Status_Location'].value_counts().to_dict()
    total_actual = 0
    total_target = 0
    for loc, target in hitachi_targets.items():
        actual = actual_counts.get(loc, 0)
        match = 'âœ…' if actual == target else f'âŒ (ì°¨ì´: {actual - target:+d})'
        print(f"  {loc:<15} ëª©í‘œ: {target:<4} | ì‹¤ì œ: {actual:<4} {match}")
        total_actual += actual
        total_target += target
    print(f"  {'TOTAL':<15} ëª©í‘œ: {total_target:<4} | ì‹¤ì œ: {total_actual:<4} {'âœ…' if total_actual == total_target else f'âŒ (ì°¨ì´: {total_actual - total_target:+d})'}")

def summarize_location_pivot(
    df: pd.DataFrame,
    value_col: str = "Case No.",
    storage_col: str = "Status_Storage",
    location_col: str = "Status_Location",
    sublocation_col: str = None
) -> pd.DataFrame:
    """
    ì›ë³¸ ë°ì´í„°ì—ì„œ Status_Storage, Status_Location, (ì„ íƒ) ì„¸ë¶€ Locationë³„ë¡œ í•©ê³„ë¥¼ ìë™ ì§‘ê³„í•©ë‹ˆë‹¤.
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        value_col: ì§‘ê³„í•  ê°’ ì»¬ëŸ¼ëª… (ì˜ˆ: 'Case No.', 'í•©ê³„ : Pkg' ë“±)
        storage_col: 1ì°¨ ê·¸ë£¹í•‘ ì»¬ëŸ¼ (ì˜ˆ: 'Status_Storage')
        location_col: 2ì°¨ ê·¸ë£¹í•‘ ì»¬ëŸ¼ (ì˜ˆ: 'Status_Location')
        sublocation_col: 3ì°¨ ê·¸ë£¹í•‘ ì»¬ëŸ¼ (ì˜ˆ: 'Status_Location_DSV Indoor'), ì—†ìœ¼ë©´ 2ë‹¨ê³„ë§Œ
    Returns:
        pd.DataFrame: í”¼ë²—í…Œì´ë¸” í˜•íƒœì˜ ì§‘ê³„ ê²°ê³¼
    """
    group_cols = [storage_col, location_col]
    if sublocation_col and sublocation_col in df.columns:
        group_cols.append(sublocation_col)
    summary = (
        df.groupby(group_cols)[value_col]
        .count()
        .reset_index()
        .rename(columns={value_col: "count"})
    )
    return summary

def excel_style_pivot(
    df: pd.DataFrame,
    value_col: str = "Case No.",
    index_cols: list = None,
    columns_col: str = "total handling",
    aggfunc: str = "count"
) -> pd.DataFrame:
    """
    ì—‘ì…€ í”¼ë²—í…Œì´ë¸”(í–‰+ì—´+ê°’) êµ¬ì¡°ë¡œ ìë™ ì§‘ê³„
    Args:
        df: ì›ë³¸ ë°ì´í„°í”„ë ˆì„
        value_col: ê°’ í•„ë“œ (ì˜ˆ: 'í•©ê³„ : Pkg', 'Case No.')
        index_cols: í–‰ í•„ë“œ ë¦¬ìŠ¤íŠ¸
        columns_col: ì—´ í•„ë“œ (ì˜ˆ: 'total handling')
        aggfunc: ì§‘ê³„ í•¨ìˆ˜ ('count', 'sum' ë“±)
    Returns:
        pd.DataFrame: í”¼ë²—í…Œì´ë¸” ê²°ê³¼
    """
    if index_cols is None:
        index_cols = [
            "Status_Storage",
            "Status_Location",
            "Status_Location_DSV Indoor",
            "Status_Location_DSV Al Markaz"
        ]
    pivot = pd.pivot_table(
        df,
        index=index_cols,
        columns=columns_col,
        values=value_col,
        aggfunc=aggfunc,
        fill_value=0,
        margins=True,
        margins_name="ì´í•©ê³„"
    )
    return pivot

if __name__ == "__main__":
    # ë²¤ë”ë³„ íŒŒì¼ í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰
    hitachi_file = "data/HVDC WAREHOUSE_HITACHI(HE).xlsx"
    simense_file = "data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
    
    validation_results = validate_vendor_data_quality(hitachi_file, simense_file)
    
    # ìƒíƒœë³„ í•„í„°ë§ ë¶„ì„ ë° ì ìš©
    if 'error' not in validation_results['hitachi_stats'] and 'error' not in validation_results['simense_stats']:
        df_hitachi = pd.read_excel(hitachi_file)
        df_hitachi['Vendor'] = 'HITACHI'
        df_simense = pd.read_excel(simense_file)
        df_simense['Vendor'] = 'SIMENSE'
        df_combined = pd.concat([df_hitachi, df_simense], ignore_index=True)
        
        # ìƒíƒœë³„ í•„í„°ë§ ë¶„ì„
        status_analysis = analyze_status_filtering(df_combined)
        
        # ìƒíƒœë³„ í•„í„°ë§ ì ìš©
        df_filtered = apply_status_filtering(df_combined)
        
        # í•„í„°ë§ëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        filtered_validation = validate_filtered_data_quality(df_filtered)
        
        print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼:")
        print(f"  ì›ë³¸ ë°ì´í„°: {len(df_combined)}ê±´")
        print(f"  í•„í„°ë§ í›„: {len(df_filtered)}ê±´")
        print(f"  ì œê±°ëœ ë°ì´í„°: {len(df_combined) - len(df_filtered)}ê±´")
        
        # ëª©í‘œê°’ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
        target_total = 6979
        actual_total = len(df_filtered)
        if abs(actual_total - target_total) <= 10:  # 10ê±´ ì´ë‚´ ì˜¤ì°¨ í—ˆìš©
            print(f"  âœ… ëª©í‘œê°’ ë‹¬ì„±! (ì˜¤ì°¨: {actual_total - target_total:+d}ê±´)")
        else:
            print(f"  âš ï¸ ëª©í‘œê°’ ë¯¸ë‹¬ì„± (ì˜¤ì°¨: {actual_total - target_total:+d}ê±´)")
        
        # HITACHI ìœ„ì¹˜ë³„ ëª©í‘œê°’ ì¼ì¹˜ ê²€ì¦
        validate_hitachi_location_targets(df_filtered) 

    # RAW DATA ìë™ ì§‘ê³„ ê²°ê³¼ ê²€ì¦
    print("\nğŸ“Š [RAW DATA ìë™ ì§‘ê³„ ê²°ê³¼]")
    df_hitachi = pd.read_excel("data/HVDC WAREHOUSE_HITACHI(HE).xlsx")
    pivot = summarize_location_pivot(
        df_hitachi,
        value_col="Case No.",
        storage_col="Status_Storage",
        location_col="Status_Location",
        sublocation_col="Status_Location_DSV Indoor" if "Status_Location_DSV Indoor" in df_hitachi.columns else None
    )
    print(pivot) 

    # í”¼ë²—í…Œì´ë¸” ìë™ ì§‘ê³„ ë° ë¦¬í¬íŠ¸
    print("\nğŸ“Š [ì—‘ì…€ í”¼ë²—í…Œì´ë¸” êµ¬ì¡° ìë™ ì§‘ê³„ ê²°ê³¼]")
    df_hitachi = pd.read_excel("data/HVDC WAREHOUSE_HITACHI(HE).xlsx")
    value_col = "í•©ê³„ : Pkg" if "í•©ê³„ : Pkg" in df_hitachi.columns else "Case No."
    columns_col = "total handling" if "total handling" in df_hitachi.columns else None
    if columns_col:
        pivot = excel_style_pivot(
            df_hitachi,
            value_col=value_col,
            index_cols=[
                "Status_Storage",
                "Status_Location",
                "Status_Location_DSV Indoor",
                "Status_Location_DSV Al Markaz"
            ],
            columns_col=columns_col,
            aggfunc="sum" if value_col == "í•©ê³„ : Pkg" else "count"
        )
        print(pivot)
        pivot.to_csv("output/hitachi_pivot_report.csv", encoding="utf-8-sig")
        print("[ì €ì¥ ì™„ë£Œ] output/hitachi_pivot_report.csv")
    else:
        print("âš ï¸ 'total handling' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤. ì—´ í•„ë“œ ì—†ì´ í”¼ë²—ì„ ìƒì„±í•©ë‹ˆë‹¤.") 