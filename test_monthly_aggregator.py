#!/usr/bin/env python3
"""
TDD í…ŒìŠ¤íŠ¸: ì›”ë³„ ì§‘ê³„ ì „ìš© ì‹œìŠ¤í…œ
MACHO-GPT v3.4-miniâ”‚Samsung C&T Logistics
"""

import unittest
import pandas as pd
import numpy as np
from datetime import datetime
import os

class TestMonthlyAggregator(unittest.TestCase):
    """ì›”ë³„ ì§‘ê³„ ì „ìš© ì‹œìŠ¤í…œ TDD í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        self.expected_total_records = 7779  # HITACHI(5552) + SIMENSE(2227) - INVOICE íŒŒì¼ ì œì™¸
        self.expected_hitachi_records = 5552
        self.expected_simense_records = 2227
        
        # ì›”ë³„ ì§‘ê³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ì´ ë¶€ë¶„ì´ ì‹¤íŒ¨í•´ì•¼ í•¨
        try:
            from monthly_aggregator import MonthlyAggregator
            self.aggregator = MonthlyAggregator()
        except ImportError:
            self.aggregator = None
        
    def test_monthly_aggregator_initialization(self):
        """ì›”ë³„ ì§‘ê³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ - ì‹¤íŒ¨í•´ì•¼ í•¨"""
        # ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤íŒ¨í•´ì•¼ í•¨ (í´ë˜ìŠ¤ê°€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•ŠìŒ)
        self.assertIsNotNone(self.aggregator, "MonthlyAggregator í´ë˜ìŠ¤ê°€ êµ¬í˜„ë˜ì–´ì•¼ í•¨")
        
        # ê¸°ë³¸ ì†ì„± í™•ì¸
        self.assertTrue(hasattr(self.aggregator, 'load_complete_dataset'), 
                       "load_complete_dataset ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•¨")
        self.assertTrue(hasattr(self.aggregator, 'generate_warehouse_monthly_report'), 
                       "generate_warehouse_monthly_report ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•¨")
        self.assertTrue(hasattr(self.aggregator, 'generate_site_monthly_report'), 
                       "generate_site_monthly_report ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•¨")
        
    def test_complete_dataset_loading(self):
        """ì™„ì „í•œ ë°ì´í„°ì…‹ ë¡œë“œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ - ì‹¤íŒ¨í•´ì•¼ í•¨"""
        if self.aggregator is None:
            self.skipTest("MonthlyAggregator í´ë˜ìŠ¤ê°€ êµ¬í˜„ë˜ì§€ ì•ŠìŒ")
            
        # ì™„ì „í•œ ë°ì´í„°ì…‹ ë¡œë“œ
        merged_df = self.aggregator.load_complete_dataset()
        
        # ë°ì´í„° ê²€ì¦
        self.assertEqual(len(merged_df), self.expected_total_records, 
                        "ì´ 7,779ê±´ì˜ ë°ì´í„°ê°€ ë¡œë“œë˜ì–´ì•¼ í•¨")
        self.assertTrue('DATA_SOURCE' in merged_df.columns, 
                       "DATA_SOURCE ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨")
        
        # ì†ŒìŠ¤ë³„ ë¶„í¬ í™•ì¸
        hitachi_count = len(merged_df[merged_df['DATA_SOURCE'] == 'HITACHI'])
        simense_count = len(merged_df[merged_df['DATA_SOURCE'] == 'SIMENSE'])
        
        self.assertEqual(hitachi_count, self.expected_hitachi_records, 
                        "HITACHI 5,552ê±´ì´ì–´ì•¼ í•¨")
        self.assertEqual(simense_count, self.expected_simense_records, 
                        "SIMENSE 2,227ê±´ì´ì–´ì•¼ í•¨")
        
    def test_warehouse_monthly_report_generation(self):
        """ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ - ì‹¤íŒ¨í•´ì•¼ í•¨"""
        if self.aggregator is None:
            self.skipTest("MonthlyAggregator í´ë˜ìŠ¤ê°€ êµ¬í˜„ë˜ì§€ ì•ŠìŒ")
            
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ë” ì™„ì „í•œ êµ¬ì¡°)
        sample_data = pd.DataFrame({
            'Status_Location': ['DSV Indoor', 'DSV Outdoor', 'DSV Indoor', 'DSV Outdoor'],
            'DSV Indoor': [pd.Timestamp('2024-01-15'), pd.NaT, pd.Timestamp('2024-02-10'), pd.NaT],
            'DSV Outdoor': [pd.NaT, pd.Timestamp('2024-01-20'), pd.NaT, pd.Timestamp('2024-02-15')],
            'DSV Al Markaz': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'AAA Storage': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'AGI': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'DAS': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'MIR': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'SHU': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'Pkg': [100, 150, -80, -120],  # ìŒìˆ˜ëŠ” ì¶œê³ 
            'DATA_SOURCE': ['TEST', 'TEST', 'TEST', 'TEST']
        })
        
        # ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  ë¦¬í¬íŠ¸ ìƒì„±
        warehouse_report = self.aggregator.generate_warehouse_monthly_report(sample_data)
        
        # Multi-level í—¤ë” êµ¬ì¡° í™•ì¸
        self.assertIsInstance(warehouse_report.columns, pd.MultiIndex, 
                            "Multi-level í—¤ë”ì—¬ì•¼ í•¨")
        
        # ì…ê³ /ì¶œê³  ë ˆë²¨ í™•ì¸
        level_0_values = warehouse_report.columns.get_level_values(0).unique()
        self.assertTrue('ì…ê³ ' in level_0_values, "ì…ê³  ë ˆë²¨ì´ ìˆì–´ì•¼ í•¨")
        self.assertTrue('ì¶œê³ ' in level_0_values, "ì¶œê³  ë ˆë²¨ì´ ìˆì–´ì•¼ í•¨")
        
    def test_site_monthly_report_generation(self):
        """í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸ - ì‹¤íŒ¨í•´ì•¼ í•¨"""
        if self.aggregator is None:
            self.skipTest("MonthlyAggregator í´ë˜ìŠ¤ê°€ êµ¬í˜„ë˜ì§€ ì•ŠìŒ")
            
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (ë” ì™„ì „í•œ êµ¬ì¡°)
        sample_data = pd.DataFrame({
            'Status_Location': ['AGI', 'DAS', 'MIR', 'SHU'],
            'AGI': [pd.Timestamp('2024-01-15'), pd.NaT, pd.NaT, pd.NaT],
            'DAS': [pd.NaT, pd.Timestamp('2024-01-20'), pd.NaT, pd.NaT],
            'MIR': [pd.NaT, pd.NaT, pd.Timestamp('2024-02-10'), pd.NaT],
            'SHU': [pd.NaT, pd.NaT, pd.NaT, pd.Timestamp('2024-02-15')],
            'DSV Indoor': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'DSV Outdoor': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'DSV Al Markaz': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'AAA Storage': [pd.NaT, pd.NaT, pd.NaT, pd.NaT],
            'Pkg': [80, 120, 90, 110],
            'DATA_SOURCE': ['TEST', 'TEST', 'TEST', 'TEST']
        })
        
        # í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  ë¦¬í¬íŠ¸ ìƒì„±
        site_report = self.aggregator.generate_site_monthly_report(sample_data)
        
        # Multi-level í—¤ë” êµ¬ì¡° í™•ì¸
        self.assertIsInstance(site_report.columns, pd.MultiIndex, 
                            "Multi-level í—¤ë”ì—¬ì•¼ í•¨")
        
        # ì…ê³ /ì¬ê³  ë ˆë²¨ í™•ì¸
        level_0_values = site_report.columns.get_level_values(0).unique()
        self.assertTrue('ì…ê³ ' in level_0_values, "ì…ê³  ë ˆë²¨ì´ ìˆì–´ì•¼ í•¨")
        self.assertTrue('ì¬ê³ ' in level_0_values, "ì¬ê³  ë ˆë²¨ì´ ìˆì–´ì•¼ í•¨")
        
    def test_excel_export_functionality(self):
        """Excel ë‚´ë³´ë‚´ê¸° ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ - ì‹¤íŒ¨í•´ì•¼ í•¨"""
        if self.aggregator is None:
            self.skipTest("MonthlyAggregator í´ë˜ìŠ¤ê°€ êµ¬í˜„ë˜ì§€ ì•ŠìŒ")
            
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ (ë” ì™„ì „í•œ êµ¬ì¡°)
        sample_data = pd.DataFrame({
            'Status_Location': ['DSV Indoor', 'AGI'],
            'DSV Indoor': [pd.Timestamp('2024-01-15'), pd.NaT],
            'DSV Outdoor': [pd.NaT, pd.NaT],
            'DSV Al Markaz': [pd.NaT, pd.NaT],
            'AAA Storage': [pd.NaT, pd.NaT],
            'AGI': [pd.NaT, pd.Timestamp('2024-01-20')],
            'DAS': [pd.NaT, pd.NaT],
            'MIR': [pd.NaT, pd.NaT],
            'SHU': [pd.NaT, pd.NaT],
            'Pkg': [100, 80],
            'DATA_SOURCE': ['TEST', 'TEST']
        })
        
        # Excel íŒŒì¼ ìƒì„±
        output_file = self.aggregator.export_to_excel(sample_data)
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        self.assertTrue(os.path.exists(output_file), "Excel íŒŒì¼ì´ ìƒì„±ë˜ì–´ì•¼ í•¨")
        
        # íŒŒì¼ ë‚´ìš© í™•ì¸
        with pd.ExcelFile(output_file) as excel_file:
            sheet_names = excel_file.sheet_names
            
            # ì˜ˆìƒ ì‹œíŠ¸ í™•ì¸
            self.assertIn('ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', sheet_names, "ì°½ê³  ì‹œíŠ¸ê°€ ìˆì–´ì•¼ í•¨")
            self.assertIn('í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', sheet_names, "í˜„ì¥ ì‹œíŠ¸ê°€ ìˆì–´ì•¼ í•¨")
            self.assertIn('ë¦¬í¬íŠ¸_ì •ë³´', sheet_names, "ë¦¬í¬íŠ¸ ì •ë³´ ì‹œíŠ¸ê°€ ìˆì–´ì•¼ í•¨")
        
        # í…ŒìŠ¤íŠ¸ í›„ íŒŒì¼ ì‚­ì œ
        if os.path.exists(output_file):
            os.remove(output_file)
            
    def test_data_loading_complete_dataset(self):
        """ì™„ì „í•œ ë°ì´í„°ì…‹ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
        # ì˜¬ë°”ë¥¸ ê²½ë¡œì—ì„œ ì™„ì „í•œ ë°ì´í„°ì…‹ ë¡œë“œ
        hitachi_path = "hvdc_ontology_system/data/HVDC WAREHOUSE_HITACHI(HE).xlsx"
        simense_path = "hvdc_ontology_system/data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        self.assertTrue(os.path.exists(hitachi_path), "HITACHI ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨")
        self.assertTrue(os.path.exists(simense_path), "SIMENSE ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨")
        
        # ë°ì´í„° ë¡œë“œ ë° ë ˆì½”ë“œ ìˆ˜ í™•ì¸
        hitachi_df = pd.read_excel(hitachi_path)
        simense_df = pd.read_excel(simense_path)
        
        self.assertEqual(len(hitachi_df), self.expected_hitachi_records, "HITACHI 5,552ê±´ì´ì–´ì•¼ í•¨")
        self.assertEqual(len(simense_df), self.expected_simense_records, "SIMENSE 2,227ê±´ì´ì–´ì•¼ í•¨")
        
        # í†µí•© ë°ì´í„° í™•ì¸
        total_records = len(hitachi_df) + len(simense_df)
        self.assertEqual(total_records, self.expected_total_records, "ì´ 7,779ê±´ì´ì–´ì•¼ í•¨")
        
    def test_warehouse_monthly_sheet_structure(self):
        """ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  ì‹œíŠ¸ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        # ì˜ˆìƒ ì°½ê³ ë³„ Multi-level í—¤ë” êµ¬ì¡°
        expected_warehouses = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'AAA Storage']
        expected_structure = {
            'level_0': ['ì…ê³ ', 'ì…ê³ ', 'ì¶œê³ ', 'ì¶œê³ '],
            'level_1': ['DSV Indoor', 'DSV Outdoor', 'DSV Indoor', 'DSV Outdoor']
        }
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = pd.DataFrame({
            'ì…ê³ ì›”': ['2024-01', '2024-02', '2024-03'],
            'DSV Indoor_ì…ê³ ': [100, 150, 120],
            'DSV Outdoor_ì…ê³ ': [80, 90, 85],
            'DSV Indoor_ì¶œê³ ': [90, 140, 110],
            'DSV Outdoor_ì¶œê³ ': [75, 85, 80]
        })
        
        # Multi-level í—¤ë” ìƒì„± í…ŒìŠ¤íŠ¸
        multi_columns = pd.MultiIndex.from_tuples([
            ('ì…ê³ ', 'DSV Indoor'),
            ('ì…ê³ ', 'DSV Outdoor'),
            ('ì¶œê³ ', 'DSV Indoor'),
            ('ì¶œê³ ', 'DSV Outdoor')
        ])
        
        self.assertEqual(len(multi_columns), 4, "Multi-level í—¤ë”ëŠ” 4ê°œ ì»¬ëŸ¼ì´ì–´ì•¼ í•¨")
        self.assertEqual(multi_columns.levels[0].tolist(), ['ì…ê³ ', 'ì¶œê³ '], "ì²« ë²ˆì§¸ ë ˆë²¨ì€ ì…ê³ /ì¶œê³ ")
        
    def test_site_monthly_sheet_structure(self):
        """í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  ì‹œíŠ¸ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        # ì˜ˆìƒ í˜„ì¥ë³„ Multi-level í—¤ë” êµ¬ì¡°
        expected_sites = ['AGI', 'DAS', 'MIR', 'SHU']
        expected_structure = {
            'level_0': ['ì…ê³ ', 'ì…ê³ ', 'ì¬ê³ ', 'ì¬ê³ '],
            'level_1': ['AGI', 'DAS', 'AGI', 'DAS']
        }
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = pd.DataFrame({
            'ì…ê³ ì›”': ['2024-01', '2024-02', '2024-03'],
            'AGI_ì…ê³ ': [0, 0, 0],
            'DAS_ì…ê³ ': [280, 315, 290],
            'AGI_ì¬ê³ ': [0, 0, 0],
            'DAS_ì¬ê³ ': [280, 595, 885]
        })
        
        # Multi-level í—¤ë” ìƒì„± í…ŒìŠ¤íŠ¸
        multi_columns = pd.MultiIndex.from_tuples([
            ('ì…ê³ ', 'AGI'),
            ('ì…ê³ ', 'DAS'),
            ('ì¬ê³ ', 'AGI'),
            ('ì¬ê³ ', 'DAS')
        ])
        
        self.assertEqual(len(multi_columns), 4, "Multi-level í—¤ë”ëŠ” 4ê°œ ì»¬ëŸ¼ì´ì–´ì•¼ í•¨")
        self.assertEqual(multi_columns.levels[0].tolist(), ['ì…ê³ ', 'ì¬ê³ '], "ì²« ë²ˆì§¸ ë ˆë²¨ì€ ì…ê³ /ì¬ê³ ")
        
    def test_monthly_aggregation_accuracy(self):
        """ì›”ë³„ ì§‘ê³„ ì •í™•ì„± í…ŒìŠ¤íŠ¸"""
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = pd.DataFrame({
            'Status_Location': ['DSV Indoor', 'DSV Outdoor', 'AGI', 'DAS'],
            'DSV Indoor': [pd.Timestamp('2024-01-15'), pd.NaT, pd.NaT, pd.NaT],
            'DSV Outdoor': [pd.NaT, pd.Timestamp('2024-01-20'), pd.NaT, pd.NaT],
            'AGI': [pd.NaT, pd.NaT, pd.Timestamp('2024-02-10'), pd.NaT],
            'DAS': [pd.NaT, pd.NaT, pd.NaT, pd.Timestamp('2024-02-15')],
            'Pkg': [100, 150, 80, 120]
        })
        
        # ì›”ë³„ ì§‘ê³„ ê²°ê³¼ ì˜ˆìƒê°’
        expected_monthly = {
            '2024-01': {'DSV Indoor': 100, 'DSV Outdoor': 150},
            '2024-02': {'AGI': 80, 'DAS': 120}
        }
        
        # ì‹¤ì œ ì§‘ê³„ ë¡œì§ í…ŒìŠ¤íŠ¸ (êµ¬í˜„ í›„ í™œì„±í™”)
        # actual_monthly = self.aggregator.calculate_monthly_aggregation(sample_data)
        # self.assertEqual(actual_monthly, expected_monthly)
        
        # ì¼ë‹¨ êµ¬ì¡° ê²€ì¦
        self.assertEqual(len(sample_data), 4, "ìƒ˜í”Œ ë°ì´í„°ëŠ” 4ê±´ì´ì–´ì•¼ í•¨")
        self.assertEqual(sample_data['Pkg'].sum(), 450, "ì´ PkgëŠ” 450ì´ì–´ì•¼ í•¨")
        
    def test_excel_output_format(self):
        """Excel ì¶œë ¥ í˜•ì‹ í…ŒìŠ¤íŠ¸"""
        # ì˜ˆìƒ Excel íŒŒì¼ êµ¬ì¡°
        expected_sheets = ['ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', 'í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', 'ë¦¬í¬íŠ¸_ì •ë³´']
        
        # ì¶œë ¥ íŒŒì¼ëª… íŒ¨í„´ í…ŒìŠ¤íŠ¸
        expected_filename_pattern = r'MACHO_ì›”ë³„ì§‘ê³„_\d{8}_\d{6}\.xlsx'
        
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ëª… ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        test_filename = f"MACHO_ì›”ë³„ì§‘ê³„_{timestamp}.xlsx"
        
        # íŒŒì¼ëª… íŒ¨í„´ í™•ì¸
        import re
        self.assertTrue(re.match(expected_filename_pattern, test_filename), 
                       "íŒŒì¼ëª…ì´ ì˜ˆìƒ íŒ¨í„´ê³¼ ì¼ì¹˜í•´ì•¼ í•¨")
        
        # ì‹œíŠ¸ êµ¬ì¡° í™•ì¸
        self.assertEqual(len(expected_sheets), 3, "3ê°œ ì‹œíŠ¸ê°€ ìˆì–´ì•¼ í•¨")
        self.assertIn('ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', expected_sheets, "ì°½ê³  ì‹œíŠ¸ í¬í•¨")
        self.assertIn('í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', expected_sheets, "í˜„ì¥ ì‹œíŠ¸ í¬í•¨")
        
    def test_macho_gpt_integration(self):
        """MACHO-GPT í†µí•© ìš”êµ¬ì‚¬í•­ í…ŒìŠ¤íŠ¸"""
        # ì‹ ë¢°ë„ ì„ê³„ê°’ í™•ì¸
        min_confidence = 0.95
        
        # ì˜ˆìƒ ì²˜ë¦¬ ì„±ëŠ¥
        expected_processing_time = 30  # ì´ˆ
        
        # ëª…ë ¹ì–´ í†µí•© í™•ì¸
        expected_commands = [
            '/visualize-data monthly-trends',
            '/generate-report warehouse-summary',
            '/automate monthly-pipeline'
        ]
        
        # í…ŒìŠ¤íŠ¸ ì¡°ê±´ í™•ì¸
        self.assertGreaterEqual(min_confidence, 0.95, "ì‹ ë¢°ë„ëŠ” 95% ì´ìƒì´ì–´ì•¼ í•¨")
        self.assertLessEqual(expected_processing_time, 60, "ì²˜ë¦¬ ì‹œê°„ì€ 60ì´ˆ ì´í•˜ì—¬ì•¼ í•¨")
        self.assertEqual(len(expected_commands), 3, "3ê°œ ëª…ë ¹ì–´ ì¶”ì²œ")
        
    def test_error_handling(self):
        """ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # íŒŒì¼ ì—†ìŒ ì˜¤ë¥˜ ì²˜ë¦¬
        non_existent_path = "invalid/path/file.xlsx"
        self.assertFalse(os.path.exists(non_existent_path), "ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ë¡œ")
        
        # ë¹ˆ ë°ì´í„° ì²˜ë¦¬
        empty_df = pd.DataFrame()
        self.assertEqual(len(empty_df), 0, "ë¹ˆ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬")
        
        # ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜ ì²˜ë¦¬
        invalid_date = "invalid_date"
        converted_date = pd.to_datetime(invalid_date, errors='coerce')
        self.assertTrue(pd.isna(converted_date), "ì˜ëª»ëœ ë‚ ì§œëŠ” NaTë¡œ ë³€í™˜")

if __name__ == '__main__':
    print("ğŸ”´ TDD RED Phase: ì›”ë³„ ì§‘ê³„ ì „ìš© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    print("=" * 70)
    
    unittest.main(verbosity=2) 