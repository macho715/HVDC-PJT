#!/usr/bin/env python3
"""
HVDC Flow Code ê³µì‹ ê¸°ì¤€ ì™„ì „ ì¼ì¹˜ ê³„ì‚°ê¸°
MACHO-GPT v3.4-mini â”‚ Samsung C&T Ã— ADNOCÂ·DSV Partnership

ëª©í‘œ: ê³µì‹ ë³´ê³ ì„œì™€ 100% ì¼ì¹˜
- SIMENSE Code 4: 1,851ê±´
- HITACHI Code 3: 274ê±´, Code 4: 5ê±´
- ì´ ì¼€ì´ìŠ¤: 7,573ê°œ
"""

import pandas as pd
import numpy as np
import re
from typing import Dict, List, Optional, Tuple, Union
from pathlib import Path
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class FlowCodeExactCalculator:
    """ê³µì‹ ê¸°ì¤€ ì™„ì „ ì¼ì¹˜ Flow Code ê³„ì‚°ê¸°"""
    
    def __init__(self):
        self.case_id_col = None
        self.wh_cols = []
        self.mosb_cols = ['MOSB']
        
        # ê³µì‹ ê¸°ì¤€ íƒ€ê²Ÿ
        self.official_targets = {
            'HITACHI': {'total': 5346, 'code_0': 163, 'code_1': 2062, 'code_2': 2842, 'code_3': 274, 'code_4': 5},
            'SIMENSE': {'total': 2227, 'code_0': 384, 'code_1': 804, 'code_2': 805, 'code_3': 234, 'code_4': 1851}
        }
        
    @staticmethod
    def _clean_str(val) -> str:
        """ì „ê°ê³µë°± ì™„ì „ ì œê±° + NaN ì•ˆì „ ì²˜ë¦¬"""
        if pd.isna(val):
            return ''
        cleaned = str(val).replace('\u3000', ' ').replace('ã€€', ' ').strip()
        cleaned = re.sub(r'\s+', ' ', cleaned)
        return cleaned
    
    @classmethod
    def is_valid_data(cls, val) -> bool:
        """ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        if pd.isna(val):
            return False
        cleaned = cls._clean_str(val)
        return cleaned and cleaned.lower() not in {'nan', 'none', 'nat', ''}
    
    def detect_exact_case_column(self, df: pd.DataFrame, vendor_hint: str = None) -> str:
        """ì •í™•í•œ Case ì»¬ëŸ¼ ê°ì§€ (ê³µì‹ ê¸°ì¤€)"""
        
        logger.info(f"ğŸ” Case ì»¬ëŸ¼ ê°ì§€ ì‹œì‘ (ë²¤ë” íŒíŠ¸: {vendor_hint})")
        
        # ë²¤ë”ë³„ ìš°ì„ ìˆœìœ„ ì»¬ëŸ¼
        if vendor_hint == 'HITACHI':
            priority_cols = ['HVDC CODE', 'Case No.', 'HVDC_CODE', 'Case_No']
        elif vendor_hint == 'SIMENSE':
            priority_cols = ['SERIAL NO.', 'SERIAL_NO', 'SerialNo', 'HVDC CODE']
        else:
            # ì¼ë°˜ì  ìš°ì„ ìˆœìœ„
            priority_cols = ['HVDC CODE', 'SERIAL NO.', 'Case No.', 'HVDC_CODE', 'SERIAL_NO']
        
        # 1ë‹¨ê³„: ì§ì ‘ ë§¤ì¹­
        for col in priority_cols:
            if col in df.columns:
                unique_count = df[col].nunique()
                logger.info(f"âœ… ë°œê²¬: {col} ({unique_count:,}ê°œ ê³ ìœ ê°’)")
                
                # ê³µì‹ ê¸°ì¤€ ê²€ì¦
                if vendor_hint == 'HITACHI' and unique_count >= 5000:
                    return col
                elif vendor_hint == 'SIMENSE' and unique_count >= 2000:
                    return col
                elif unique_count >= 1000:
                    return col
        
        # 2ë‹¨ê³„: íŒ¨í„´ ë§¤ì¹­
        patterns = [r'HVDC.*CODE', r'SERIAL.*NO', r'Case.*No', r'.*ID$', r'.*CODE$']
        for pattern in patterns:
            matches = [col for col in df.columns if re.search(pattern, col, re.I)]
            for col in matches:
                unique_count = df[col].nunique()
                if unique_count >= 1000:
                    logger.info(f"âœ… íŒ¨í„´ ë§¤ì¹­: {col} ({unique_count:,}ê°œ)")
                    return col
        
        # 3ë‹¨ê³„: ìµœëŒ€ ê³ ìœ ê°’ ì»¬ëŸ¼
        max_col = None
        max_count = 0
        for col in df.columns:
            if df[col].dtype in ['object', 'int64', 'float64']:
                unique_count = df[col].nunique()
                if unique_count > max_count:
                    max_count = unique_count
                    max_col = col
        
        if max_col and max_count >= 500:
            logger.warning(f"âš ï¸ ìµœëŒ€ê°’ ì„ íƒ: {max_col} ({max_count:,}ê°œ)")
            return max_col
        
        raise ValueError(f"ì ì ˆí•œ Case ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {list(df.columns)}")
    
    def detect_exact_warehouse_columns(self, df: pd.DataFrame, vendor_hint: str = None) -> List[str]:
        """ì •í™•í•œ ì°½ê³  ì»¬ëŸ¼ ê°ì§€ (ê³µì‹ ê¸°ì¤€)"""
        
        logger.info(f"ğŸ¢ WH ì»¬ëŸ¼ ê°ì§€ ì‹œì‘ (ë²¤ë” íŒíŠ¸: {vendor_hint})")
        
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì •í™•í•œ ì»¬ëŸ¼ëª…ë“¤
        exact_columns = {
            'HITACHI': [
                'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor',
                'AAA  Storage',  # ê³µë°± 2ê°œ ì •í™•íˆ
                'AAA Storage',   # ê³µë°± 1ê°œ ë³€í˜•
                'Hauler Indoor', 'DSV MZP'
            ],
            'SIMENSE': [
                'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor',
                'DSV MZD', 'JDN MZD',
                'AAA  Storage',  # ê³µë°± 2ê°œ
                'AAA Storage'    # ê³µë°± 1ê°œ
            ],
            'COMMON': [
                'DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz',
                'AAA Storage', 'AAA  Storage',
                'Dangerous Storage', 'Waterfront', 'Vijay Tanks'
            ]
        }
        
        wh_cols = []
        
        # ë²¤ë”ë³„ ì •í™•í•œ ì»¬ëŸ¼ ë¨¼ì € í™•ì¸
        if vendor_hint in exact_columns:
            search_list = exact_columns[vendor_hint]
        else:
            search_list = exact_columns['COMMON']
        
        # 1ë‹¨ê³„: ì •í™•í•œ ë§¤ì¹­
        for exact_col in search_list:
            if exact_col in df.columns:
                wh_cols.append(exact_col)
                logger.info(f"âœ… ì •í™• ë§¤ì¹­: {exact_col}")
        
        # 2ë‹¨ê³„: íŒ¨í„´ ë§¤ì¹­ (ì¶”ê°€ ê°ì§€)
        wh_patterns = [
            r'^DSV\s+Indoor$', r'^DSV\s+Outdoor$', r'^DSV\s+Al\s+Markaz$',
            r'^DSV\s+MZP$', r'^DSV\s+MZD$', r'^JDN\s+MZD$',
            r'^AAA\s+Storage$', r'^AAA\s\s+Storage$',  # ê³µë°± 1ê°œ, 2ê°œ
            r'^Hauler\s+Indoor$', r'^Dangerous\s+Storage$'
        ]
        
        for col in df.columns:
            if col not in wh_cols:  # ì¤‘ë³µ ë°©ì§€
                col_clean = self._clean_str(col)
                for pattern in wh_patterns:
                    if re.match(pattern, col_clean, re.I):
                        wh_cols.append(col)
                        logger.info(f"âœ… íŒ¨í„´ ë§¤ì¹­: {col}")
                        break
        
        # 3ë‹¨ê³„: ìœ ì—°í•œ íŒ¨í„´ (ë°±ì—…)
        if len(wh_cols) < 3:
            flexible_patterns = [r'DSV', r'AAA', r'Hauler', r'MZP', r'MZD']
            for col in df.columns:
                if col not in wh_cols:
                    for pattern in flexible_patterns:
                        if re.search(pattern, col, re.I):
                            wh_cols.append(col)
                            logger.info(f"âš ï¸ ìœ ì—° ë§¤ì¹­: {col}")
                            break
        
        logger.info(f"ğŸ“‹ ìµœì¢… WH ì»¬ëŸ¼ ({len(wh_cols)}ê°œ): {wh_cols}")
        
        if len(wh_cols) < 3:
            logger.error(f"âŒ WH ì»¬ëŸ¼ ë¶€ì¡±: {len(wh_cols)}ê°œ")
            logger.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì»¬ëŸ¼: {list(df.columns)}")
        
        return wh_cols
    
    def build_exact_route(self, group: pd.DataFrame) -> List[str]:
        """ì •í™•í•œ ê²½ë¡œ êµ¬ì„± (ê³µì‹ ê¸°ì¤€)"""
        
        if 'Date' in group.columns:
            group = group.sort_values('Date')
        
        route = ['port']
        
        # ë°©ë¬¸í•œ ì°½ê³ ë“¤ ì¶”ì 
        visited_warehouses = set()
        
        for _, row in group.iterrows():
            for wh_col in self.wh_cols:
                if self.is_valid_data(row.get(wh_col)):
                    visited_warehouses.add(wh_col)
        
        # ì°½ê³  ë‹¨ê³„ ì¶”ê°€ (ê³ ìœ í•œ ì°½ê³  ìˆ˜ë§Œí¼)
        warehouse_count = len(visited_warehouses)
        route.extend(['warehouse'] * warehouse_count)
        
        # MOSB í™•ì¸
        mosb_present = False
        for _, row in group.iterrows():
            if self.is_valid_data(row.get('MOSB')):
                mosb_present = True
                break
        
        if mosb_present:
            route.append('offshore')
        
        route.append('site')
        
        return route
    
    def route_to_exact_flow_code(self, route: List[str]) -> int:
        """ê²½ë¡œë¥¼ ì •í™•í•œ Flow Codeë¡œ ë³€í™˜"""
        
        warehouse_count = route.count('warehouse')
        has_offshore = 'offshore' in route
        
        if warehouse_count == 0:
            return 1  # Port â†’ Site
        elif warehouse_count == 1 and not has_offshore:
            return 2  # Port â†’ WH â†’ Site
        elif warehouse_count == 1 and has_offshore:
            return 3  # Port â†’ WH â†’ MOSB â†’ Site
        elif warehouse_count >= 2 and has_offshore:
            return 4  # Port â†’ WH Ã— 2+ â†’ MOSB â†’ Site
        elif warehouse_count >= 2 and not has_offshore:
            return 2  # Port â†’ WH Ã— 2+ â†’ Site (ë³µìˆ˜ ì°½ê³ , offshore ì—†ìŒ)
        else:
            return 1
    
    def calculate_exact_flow_codes(self, df: pd.DataFrame, vendor_hint: str = None) -> pd.DataFrame:
        """ì •í™•í•œ Flow Code ê³„ì‚° (ê³µì‹ ê¸°ì¤€)"""
        
        logger.info(f"ğŸ¯ ê³µì‹ ê¸°ì¤€ Flow Code ê³„ì‚° ì‹œì‘ (ë²¤ë”: {vendor_hint})")
        
        # 1. ì •í™•í•œ Case ì»¬ëŸ¼ ê°ì§€
        self.case_id_col = self.detect_exact_case_column(df, vendor_hint)
        logger.info(f"ğŸ“‹ ì„ íƒëœ Case ì»¬ëŸ¼: {self.case_id_col}")
        
        # 2. ì •í™•í•œ WH ì»¬ëŸ¼ ê°ì§€
        self.wh_cols = self.detect_exact_warehouse_columns(df, vendor_hint)
        
        # 3. MOSB ì»¬ëŸ¼ ì²˜ë¦¬
        if 'MOSB' not in df.columns:
            df['MOSB'] = pd.NA
        
        # 4. Caseë³„ ê·¸ë£¹í™” ë° ê³„ì‚°
        total_cases = df[self.case_id_col].nunique()
        logger.info(f"ğŸ“Š ì´ Case ìˆ˜: {total_cases:,}ê°œ")
        
        # ê³µì‹ ê¸°ì¤€ê³¼ ë¹„êµ
        if vendor_hint in self.official_targets:
            expected = self.official_targets[vendor_hint]['total']
            if abs(total_cases - expected) > 100:
                logger.warning(f"âš ï¸ Case ìˆ˜ ì°¨ì´: ì‹¤ì œ {total_cases:,} vs ê¸°ëŒ€ {expected:,}")
        
        # Flow Code ê³„ì‚°
        flow_codes = []
        routes_debug = []
        
        for case_id, group in df.groupby(self.case_id_col):
            route = self.build_exact_route(group)
            flow_code = self.route_to_exact_flow_code(route)
            
            for _ in range(len(group)):
                flow_codes.append(flow_code)
                routes_debug.append(' â†’ '.join(route))
        
        df['Flow_Code_Exact'] = flow_codes
        df['Route_Debug'] = routes_debug
        
        # ê²°ê³¼ ê²€ì¦
        self.validate_exact_results(df, vendor_hint)
        
        return df
    
    def validate_exact_results(self, df: pd.DataFrame, vendor_hint: str = None):
        """ì •í™•í•œ ê²°ê³¼ ê²€ì¦"""
        
        flow_dist = df['Flow_Code_Exact'].value_counts().sort_index()
        
        logger.info(f"ğŸ“Š ê³„ì‚°ëœ Flow Code ë¶„í¬:")
        for code in range(5):
            count = flow_dist.get(code, 0)
            logger.info(f"   Code {code}: {count:,}ê±´")
        
        # ê³µì‹ ê¸°ì¤€ê³¼ ë¹„êµ
        if vendor_hint in self.official_targets:
            target = self.official_targets[vendor_hint]
            logger.info(f"\nğŸ¯ ê³µì‹ ê¸°ì¤€ ëŒ€ë¹„ ê²€ì¦ ({vendor_hint}):")
            
            for i in range(5):
                actual = flow_dist.get(i, 0)
                expected = target[f'code_{i}']
                diff = actual - expected
                accuracy = (actual / expected * 100) if expected > 0 else 100
                
                status = "âœ…" if abs(diff) <= 10 else "âš ï¸" if abs(diff) <= 50 else "âŒ"
                logger.info(f"   Code {i}: {actual:,} / {expected:,} ({diff:+,}) {status}")
        
        # Code 3-4 íŠ¹ë³„ ê²€ì¦
        code3_count = flow_dist.get(3, 0)
        code4_count = flow_dist.get(4, 0)
        
        if vendor_hint == 'SIMENSE' and code4_count < 1500:
            logger.error(f"âŒ SIMENSE Code 4 ë¶€ì¡±: {code4_count} < 1,851 (ê¸°ëŒ€)")
        elif vendor_hint == 'HITACHI' and code3_count < 200:
            logger.error(f"âŒ HITACHI Code 3 ë¶€ì¡±: {code3_count} < 274 (ê¸°ëŒ€)")
        else:
            logger.info(f"âœ… Code 3-4 ê²€ì¦ í†µê³¼")


def process_exact_file(file_path: str, vendor_hint: str = None) -> pd.DataFrame:
    """íŒŒì¼ë³„ ì •í™•í•œ ì²˜ë¦¬"""
    
    logger.info(f"ğŸ“„ íŒŒì¼ ì²˜ë¦¬: {file_path}")
    
    df = pd.read_excel(file_path)
    
    # ë²¤ë” íŒíŠ¸ ìë™ ê°ì§€
    if not vendor_hint:
        if 'HITACHI' in file_path.upper() or 'HE' in Path(file_path).stem:
            vendor_hint = 'HITACHI'
        elif 'SIMENSE' in file_path.upper() or 'SIM' in Path(file_path).stem:
            vendor_hint = 'SIMENSE'
    
    calculator = FlowCodeExactCalculator()
    df_result = calculator.calculate_exact_flow_codes(df, vendor_hint)
    
    # ë²¤ë” ì»¬ëŸ¼ ì¶”ê°€
    df_result['Vendor'] = vendor_hint if vendor_hint else 'UNKNOWN'
    
    return df_result


def generate_exact_summary(df: pd.DataFrame) -> pd.DataFrame:
    """ì •í™•í•œ ìš”ì•½ ìƒì„±"""
    
    # Flow Code ë¶„í¬ í”¼ë²—
    summary = pd.crosstab(
        df['Vendor'], 
        df['Flow_Code_Exact'], 
        margins=True, 
        margins_name='Total'
    )
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    summary.columns = [f'Code {int(c)}' if isinstance(c, (int, float)) else str(c) 
                      for c in summary.columns]
    
    return summary


def run_exact_match_analysis():
    """ê³µì‹ ê¸°ì¤€ ì™„ì „ ì¼ì¹˜ ë¶„ì„ ì‹¤í–‰"""
    
    print("ğŸ¯ Flow Code ê³µì‹ ê¸°ì¤€ ì™„ì „ ì¼ì¹˜ ë¶„ì„")
    print("=" * 60)
    
    input_files = [
        ("data/HVDC WAREHOUSE_HITACHI(HE).xlsx", "HITACHI"),
        ("data/HVDC WAREHOUSE_SIMENSE(SIM).xlsx", "SIMENSE")
    ]
    
    all_results = []
    
    for file_path, vendor in input_files:
        if Path(file_path).exists():
            try:
                df_result = process_exact_file(file_path, vendor)
                all_results.append(df_result)
                print(f"âœ… {vendor} ì²˜ë¦¬ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ {vendor} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_path}")
    
    if not all_results:
        print("âŒ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê²°ê³¼ í†µí•©
    combined_df = pd.concat(all_results, ignore_index=True)
    summary = generate_exact_summary(combined_df)
    
    print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼ (ê³µì‹ ê¸°ì¤€ ëŒ€ë¹„):")
    print(summary)
    
    # ìµœì¢… ê²€ì¦
    print(f"\nğŸ† ê³µì‹ ê¸°ì¤€ ë‹¬ì„± ì—¬ë¶€:")
    
    targets = {
        'HITACHI': {'Code 3': 274, 'Code 4': 5},
        'SIMENSE': {'Code 3': 234, 'Code 4': 1851}
    }
    
    success_count = 0
    total_checks = 4
    
    for vendor, target_codes in targets.items():
        if vendor in summary.index:
            for code, expected in target_codes.items():
                if code in summary.columns:
                    actual = summary.loc[vendor, code]
                    accuracy = (actual / expected * 100) if expected > 0 else 100
                    
                    if 90 <= accuracy <= 110:  # Â±10% í—ˆìš©
                        status = "âœ…"
                        success_count += 1
                    else:
                        status = "âŒ"
                    
                    print(f"   {vendor} {code}: {actual:,} / {expected:,} ({accuracy:.1f}%) {status}")
    
    overall_success = (success_count / total_checks) * 100
    print(f"\nğŸ“ˆ ì „ì²´ ë‹¬ì„±ë¥ : {overall_success:.1f}% ({success_count}/{total_checks})")
    
    if overall_success >= 75:
        print("ğŸ‰ ê³µì‹ ê¸°ì¤€ ë‹¬ì„± ì„±ê³µ!")
    else:
        print("âš ï¸ ì¶”ê°€ ì¡°ì • í•„ìš”")
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f"HVDC_FlowCode_EXACT_MATCH_{timestamp}.xlsx"
    
    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
        summary.to_excel(writer, sheet_name='ê³µì‹ê¸°ì¤€_ìš”ì•½')
        
        for vendor in ['HITACHI', 'SIMENSE']:
            vendor_data = combined_df[combined_df['Vendor'] == vendor]
            if not vendor_data.empty:
                vendor_data.head(1000).to_excel(writer, sheet_name=f'{vendor}_ìƒì„¸', index=False)
    
    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
    
    return combined_df, summary


if __name__ == "__main__":
    run_exact_match_analysis() 