#!/usr/bin/env python3
"""
MACHO-GPT v3.4-mini TDD Test: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í†µí•© ë³´ê³ ì„œ ìƒì„±
Real Data-Based Comprehensive Report Generation Test

ì‹¤ì œ ë°ì´í„° êµ¬ì¡°:
- ì´ 7,573ê±´ íŠ¸ëœì­ì…˜
- 74ê°œ ì»¬ëŸ¼ (ì‹¤ì œ ë¬¼ë¥˜ ë°ì´í„°)
- Flow Code ë¶„í¬: 0(2,845), 1(3,517), 2(1,131), 3(80)
- WH_HANDLING ë¶„í¬: 0(2,845), 1(3,517), 2(1,131), 3(80)
"""

import unittest
import pandas as pd
import numpy as np
import os
from datetime import datetime

class TestRealComprehensiveReport(unittest.TestCase):
    """ì‹¤ì œ MACHO ë°ì´í„° ê¸°ë°˜ í†µí•© ë³´ê³ ì„œ TDD í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """ì‹¤ì œ ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •"""
        self.data_file = 'MACHO_í†µí•©ê´€ë¦¬_20250702_205301/01_ì›ë³¸íŒŒì¼/MACHO_WH_HANDLING_ì „ì²´íŠ¸ëœì­ì…˜_SQM_STACKì¶”ê°€_20250702_200757.xlsx'
        self.output_dir = 'MACHO_í†µí•©ê´€ë¦¬_20250702_205301/02_í†µí•©ê²°ê³¼'
        
        # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
        self.df = pd.read_excel(self.data_file, sheet_name='ì „ì²´_íŠ¸ëœì­ì…˜_SQM_STACK')
        
    def test_real_data_should_have_correct_structure(self):
        """ì‹¤ì œ ë°ì´í„°ëŠ” ì˜¬ë°”ë¥¸ êµ¬ì¡°ë¥¼ ê°€ì ¸ì•¼ í•¨"""
        # Given: ì‹¤ì œ MACHO ë°ì´í„°
        df = self.df
        
        # Then: ì •í™•í•œ ë°ì´í„° êµ¬ì¡° í™•ì¸
        self.assertEqual(len(df), 7573, "ì´ 7,573ê±´ì˜ íŠ¸ëœì­ì…˜ì´ ìˆì–´ì•¼ í•¨")
        self.assertEqual(len(df.columns), 74, "74ê°œ ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•¨")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = [
            'FLOW_CODE', 'WH_HANDLING', 'SQM', 'CBM', 'Stack',
            'DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'MOSB',
            'MIR', 'SHU', 'DAS', 'AGI', 'VENDOR'
        ]
        
        for col in required_columns:
            self.assertIn(col, df.columns, f"ì»¬ëŸ¼ '{col}'ì´ ì¡´ì¬í•´ì•¼ í•¨")
    
    def test_flow_code_distribution_should_match_actual_data(self):
        """Flow Code ë¶„í¬ëŠ” ì‹¤ì œ ë°ì´í„°ì™€ ì¼ì¹˜í•´ì•¼ í•¨"""
        # Given: ì‹¤ì œ ë°ì´í„°
        df = self.df
        
        # When: Flow Code ë¶„í¬ í™•ì¸
        flow_dist = df['FLOW_CODE'].value_counts().sort_index()
        
        # Then: ì •í™•í•œ ë¶„í¬ í™•ì¸
        expected_distribution = {
            0: 2845,  # Pre Arrival
            1: 3517,  # Port â†’ Site
            2: 1131,  # Port â†’ Warehouse â†’ Site
            3: 80     # Port â†’ Warehouse â†’ MOSB â†’ Site
        }
        
        for code, expected_count in expected_distribution.items():
            actual_count = flow_dist.get(code, 0)
            self.assertEqual(actual_count, expected_count, 
                           f"Flow Code {code}ëŠ” {expected_count}ê±´ì´ì–´ì•¼ í•¨ (ì‹¤ì œ: {actual_count})")
    
    def test_wh_handling_should_match_flow_code(self):
        """WH_HANDLINGì€ FLOW_CODEì™€ ì¼ì¹˜í•´ì•¼ í•¨"""
        # Given: ì‹¤ì œ ë°ì´í„°
        df = self.df
        
        # When: WH_HANDLINGê³¼ FLOW_CODE ë¹„êµ
        wh_dist = df['WH_HANDLING'].value_counts().sort_index()
        flow_dist = df['FLOW_CODE'].value_counts().sort_index()
        
        # Then: ë¶„í¬ê°€ ì¼ì¹˜í•´ì•¼ í•¨
        for code in [0, 1, 2, 3]:
            wh_count = wh_dist.get(code, 0)
            flow_count = flow_dist.get(code, 0)
            self.assertEqual(wh_count, flow_count, 
                           f"WH_HANDLING {code}ì™€ FLOW_CODE {code}ê°€ ì¼ì¹˜í•´ì•¼ í•¨")
    
    def test_sqm_stack_analysis_should_use_real_data(self):
        """SQM Stack ë¶„ì„ì€ ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨"""
        # Given: ì‹¤ì œ ë°ì´í„°
        df = self.df
        
        # When: SQMê³¼ Stack ë°ì´í„° ë¶„ì„
        sqm_total = df['SQM'].sum()
        stack_avg = df['Stack'].mean()
        
        # Then: ì‹¤ì œ ê°’ í™•ì¸
        self.assertGreater(sqm_total, 0, "ì´ SQMì€ 0ë³´ë‹¤ ì»¤ì•¼ í•¨")
        self.assertGreater(stack_avg, 0, "í‰ê·  Stackì€ 0ë³´ë‹¤ ì»¤ì•¼ í•¨")
        
        # ì‹¤ì œ SQM í†µê³„ í™•ì¸
        sqm_stats = df['SQM'].describe()
        self.assertAlmostEqual(sqm_stats['mean'], 5.089673, places=5, 
                              msg="SQM í‰ê· ì€ ì‹¤ì œ ë°ì´í„°ì™€ ì¼ì¹˜í•´ì•¼ í•¨")
    
    def test_warehouse_location_analysis_should_use_actual_columns(self):
        """ì°½ê³  ìœ„ì¹˜ ë¶„ì„ì€ ì‹¤ì œ ì»¬ëŸ¼ì„ ì‚¬ìš©í•´ì•¼ í•¨"""
        # Given: ì‹¤ì œ ë°ì´í„°
        df = self.df
        
        # When: ì°½ê³  ì»¬ëŸ¼ í™•ì¸
        warehouse_columns = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'MOSB', 'DSV MZP']
        site_columns = ['MIR', 'SHU', 'DAS', 'AGI']
        
        # Then: ì‹¤ì œ ë°ì´í„° ì¡´ì¬ í™•ì¸
        for col in warehouse_columns:
            if col in df.columns:
                non_null_count = df[col].notna().sum()
                self.assertGreaterEqual(non_null_count, 0, f"ì°½ê³  '{col}' ë°ì´í„°ê°€ ì¡´ì¬í•´ì•¼ í•¨")
        
        for col in site_columns:
            if col in df.columns:
                non_null_count = df[col].notna().sum()
                self.assertGreaterEqual(non_null_count, 0, f"í˜„ì¥ '{col}' ë°ì´í„°ê°€ ì¡´ì¬í•´ì•¼ í•¨")
    
    def test_vendor_distribution_should_reflect_actual_data(self):
        """ë²¤ë” ë¶„í¬ëŠ” ì‹¤ì œ ë°ì´í„°ë¥¼ ë°˜ì˜í•´ì•¼ í•¨"""
        # Given: ì‹¤ì œ ë°ì´í„°
        df = self.df
        
        # When: ë²¤ë” ë¶„í¬ í™•ì¸
        if 'VENDOR' in df.columns:
            vendor_dist = df['VENDOR'].value_counts()
            
            # Then: ë²¤ë” ë°ì´í„° ì¡´ì¬ í™•ì¸
            self.assertGreater(len(vendor_dist), 0, "ë²¤ë” ë°ì´í„°ê°€ ì¡´ì¬í•´ì•¼ í•¨")
            
            # ì‹¤ì œ ë²¤ë” ë¹„ìœ¨ í™•ì¸
            total_with_vendor = df['VENDOR'].notna().sum()
            vendor_coverage = total_with_vendor / len(df)
            self.assertGreater(vendor_coverage, 0, "ë²¤ë” ì»¤ë²„ë¦¬ì§€ê°€ ìˆì–´ì•¼ í•¨")
    
    def test_comprehensive_report_generation_with_real_data(self):
        """ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        # Given: ì‹¤ì œ ë°ì´í„°ì™€ ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜
        df = self.df
        
        # When: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë³´ê³ ì„œ ìƒì„±
        report_data = self.create_real_comprehensive_report(df)
        
        # Then: ë³´ê³ ì„œ í’ˆì§ˆ ê²€ì¦
        self.assertIsNotNone(report_data, "ë³´ê³ ì„œ ë°ì´í„°ê°€ ìƒì„±ë˜ì–´ì•¼ í•¨")
        self.assertIn('dashboard', report_data, "ëŒ€ì‹œë³´ë“œ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨")
        self.assertIn('monthly_warehouse', report_data, "ì›”ë³„ ì°½ê³  ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨")
        self.assertIn('sqm_analysis', report_data, "SQM ë¶„ì„ ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨")
        self.assertIn('status_tracking', report_data, "ìƒíƒœ ì¶”ì  ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨")
        
        # ë°ì´í„° ì •í™•ì„± ê²€ì¦
        dashboard = report_data['dashboard']
        total_transactions = dashboard[dashboard['Metric'] == 'ì´ íŠ¸ëœì­ì…˜']['Value'].iloc[0]
        self.assertEqual(total_transactions, 7573, "ì´ íŠ¸ëœì­ì…˜ ìˆ˜ê°€ ì •í™•í•´ì•¼ í•¨")
    
    def create_real_comprehensive_report(self, df):
        """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        report_data = {}
        
        # 1. ëŒ€ì‹œë³´ë“œ ë°ì´í„°
        dashboard_data = []
        dashboard_data.append({
            'Category': 'ì „ì²´ í˜„í™©',
            'Metric': 'ì´ íŠ¸ëœì­ì…˜',
            'Value': len(df),
            'Unit': 'ê±´',
            'Description': 'ì „ì²´ ë¬¼ë¥˜ íŠ¸ëœì­ì…˜ ê±´ìˆ˜'
        })
        
        # Flow Code ë¶„í¬
        flow_dist = df['FLOW_CODE'].value_counts().sort_index()
        for code, count in flow_dist.items():
            percentage = count / len(df) * 100
            descriptions = {
                0: "Pre Arrival (ì‚¬ì „ ë„ì°© ëŒ€ê¸°)",
                1: "Port â†’ Site (ì§ì†¡)",
                2: "Port â†’ Warehouse â†’ Site (ì°½ê³  ê²½ìœ )",
                3: "Port â†’ Warehouse â†’ MOSB â†’ Site (í•´ìƒê¸°ì§€ í¬í•¨)"
            }
            
            dashboard_data.append({
                'Category': 'Flow Code',
                'Metric': f'Code {code}',
                'Value': count,
                'Unit': f'{percentage:.1f}%',
                'Description': descriptions.get(code, f'Code {code}')
            })
        
        # SQM ìš”ì•½
        total_sqm = df['SQM'].sum()
        avg_sqm = df['SQM'].mean()
        dashboard_data.append({
            'Category': 'SQM í˜„í™©',
            'Metric': 'ì´ ë©´ì ',
            'Value': f'{total_sqm:,.0f}',
            'Unit': 'ã¡',
            'Description': 'ì „ì²´ í™”ë¬¼ ì´ ë©´ì '
        })
        
        dashboard_data.append({
            'Category': 'SQM í˜„í™©',
            'Metric': 'í‰ê·  ë©´ì ',
            'Value': f'{avg_sqm:.2f}',
            'Unit': 'ã¡/ê±´',
            'Description': 'í™”ë¬¼ë‹¹ í‰ê·  ë©´ì '
        })
        
        report_data['dashboard'] = pd.DataFrame(dashboard_data)
        
        # 2. ì›”ë³„ ì°½ê³  ë°ì´í„° (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        warehouse_columns = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'MOSB', 'DSV MZP']
        monthly_data = []
        
        # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì›”ë³„ ì¶”ì •
        months = pd.date_range('2024-01', '2025-06', freq='ME').strftime('%Y-%m')
        for month in months:
            row_data = {'Month': month}
            for wh in warehouse_columns:
                if wh in df.columns:
                    wh_data = df[df[wh].notna()]
                    monthly_count = len(wh_data) // 12  # 12ê°œì›” ë¶„ì‚°
                    row_data[f'{wh}_ì‹¤ì œë°ì´í„°'] = monthly_count
                else:
                    row_data[f'{wh}_ì‹¤ì œë°ì´í„°'] = 0
            monthly_data.append(row_data)
        
        report_data['monthly_warehouse'] = pd.DataFrame(monthly_data)
        
        # 3. SQM ë¶„ì„ (ì‹¤ì œ ë°ì´í„°)
        sqm_analysis = []
        stack_groups = df.groupby('Stack')
        for stack_level, group in stack_groups:
            if pd.notna(stack_level) and len(group) > 0:
                original_sqm = group['SQM'].sum()
                optimized_sqm = original_sqm / stack_level if stack_level > 0 else original_sqm
                saving = original_sqm - optimized_sqm
                
                sqm_analysis.append({
                    'Stack_Level': f'{stack_level}-Level',
                    'Item_Count': len(group),
                    'Original_SQM': round(original_sqm, 2),
                    'Optimized_SQM': round(optimized_sqm, 2),
                    'Space_Saving': round(saving, 2),
                    'Saving_Percentage': round(saving/original_sqm*100, 1) if original_sqm > 0 else 0
                })
        
        report_data['sqm_analysis'] = pd.DataFrame(sqm_analysis)
        
        # 4. ìƒíƒœ ì¶”ì  (ì‹¤ì œ ë°ì´í„°)
        status_data = []
        site_columns = ['MIR', 'SHU', 'DAS', 'AGI']
        
        for idx, row in df.head(100).iterrows():  # ì²˜ìŒ 100ê°œ ì‹¤ì œ ë°ì´í„°
            # ì‹¤ì œ ìœ„ì¹˜ í™•ì¸
            final_location = 'Port'
            for site in site_columns:
                if site in df.columns and pd.notna(row[site]):
                    final_location = site
                    break
            
            status_data.append({
                'Case_No': row.get('Case No.', f'CASE_{idx}'),
                'Current_Location': final_location,
                'Flow_Code': row.get('FLOW_CODE', ''),
                'WH_Handling': row.get('WH_HANDLING', ''),
                'SQM': row.get('SQM', 0),
                'CBM': row.get('CBM', 0),
                'Stack': row.get('Stack', 0)
            })
        
        report_data['status_tracking'] = pd.DataFrame(status_data)
        
        return report_data

if __name__ == '__main__':
    print("ğŸ§ª MACHO-GPT v3.4-mini ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ TDD í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    print("ğŸ“‹ ëŒ€ìƒ: 7,573ê±´ ì‹¤ì œ íŠ¸ëœì­ì…˜ ë°ì´í„°")
    print("ğŸ”„ Flow Code ë¶„í¬: 0(2,845), 1(3,517), 2(1,131), 3(80)")
    print("=" * 80)
    
    unittest.main(verbosity=2) 