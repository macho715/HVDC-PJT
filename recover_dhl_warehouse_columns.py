#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DHL Warehouse ì»¬ëŸ¼ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
ëˆ„ë½ëœ DHL Warehouse ë° ê´€ë ¨ ì»¬ëŸ¼ë“¤ ë³µêµ¬
"""

import pandas as pd
from datetime import datetime

def recover_dhl_warehouse_columns():
    """DHL Warehouse ì»¬ëŸ¼ ë³µêµ¬"""
    
    print("ğŸ”§ DHL Warehouse ì»¬ëŸ¼ ë³µêµ¬ ì‹œì‘")
    print("=" * 60)
    
    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    hitachi_path = r'hvdc_macho_gpt\WAREHOUSE\data\HVDC WAREHOUSE_HITACHI(HE).xlsx'
    simense_path = r'hvdc_macho_gpt\WAREHOUSE\data\HVDC WAREHOUSE_SIMENSE(SIM).xlsx'
    used_data_path = r'MACHO_í†µí•©ê´€ë¦¬_20250702_205301\01_ì›ë³¸íŒŒì¼\MACHO_WH_HANDLING_ì „ì²´íŠ¸ëœì­ì…˜_SQM_STACKì¶”ê°€_20250702_200757.xlsx'
    
    print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    df_hitachi = pd.read_excel(hitachi_path)
    df_simense = pd.read_excel(simense_path)
    df_used = pd.read_excel(used_data_path)
    
    print(f"âœ… HITACHI ì›ë³¸: {df_hitachi.shape[0]}í–‰, {df_hitachi.shape[1]}ì»¬ëŸ¼")
    print(f"âœ… SIMENSE ì›ë³¸: {df_simense.shape[0]}í–‰, {df_simense.shape[1]}ì»¬ëŸ¼")
    print(f"âœ… ì‚¬ìš©ëœ ë°ì´í„°: {df_used.shape[0]}í–‰, {df_used.shape[1]}ì»¬ëŸ¼")
    
    # ëˆ„ë½ëœ ì»¬ëŸ¼ í™•ì¸
    missing_cols = ['DHL Warehouse', 'Stack_Status', 'ì—´2']
    
    print("\nğŸ” ëˆ„ë½ëœ ì»¬ëŸ¼ ìƒíƒœ í™•ì¸:")
    for col in missing_cols:
        in_hitachi = col in df_hitachi.columns
        in_simense = col in df_simense.columns
        in_used = col in df_used.columns
        
        print(f"  {col}: HITACHI({in_hitachi}) SIMENSE({in_simense}) ì‚¬ìš©ë¨({in_used})")
    
    # ë§¤ì¹­ í‚¤ ì»¬ëŸ¼ í™•ì¸
    matching_cols = []
    for col in ['no.', 'Shipment Invoice No.', 'HVDC CODE', 'HVDC CODE 1']:
        if col in df_hitachi.columns and col in df_used.columns:
            matching_cols.append(col)
    
    print(f"\nğŸ“‹ ë§¤ì¹­ í‚¤ ì»¬ëŸ¼: {matching_cols}")
    
    # DHL Warehouse ì»¬ëŸ¼ ë³µêµ¬
    if 'DHL Warehouse' in df_hitachi.columns and 'DHL Warehouse' not in df_used.columns:
        print("\nğŸ”§ DHL Warehouse ì»¬ëŸ¼ ë³µêµ¬ ì‹œì‘...")
        
        # DHL Warehouse ë°ì´í„° ì¶”ì¶œ
        dhl_mapping = df_hitachi[matching_cols + ['DHL Warehouse']].copy()
        dhl_mapping = dhl_mapping.drop_duplicates(subset=matching_cols)
        
        print(f"ğŸ“Š DHL Warehouse ë§¤í•‘ í…Œì´ë¸”: {dhl_mapping.shape[0]}í–‰")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        print("\nğŸ“‹ DHL Warehouse ìƒ˜í”Œ ë°ì´í„°:")
        sample_data = df_hitachi['DHL Warehouse'].head(10)
        print(f"  {sample_data.tolist()}")
        
        # ë°ì´í„° íƒ€ì… ë° í†µê³„ í™•ì¸
        print(f"\nğŸ“Š DHL Warehouse ë°ì´í„° ë¶„ì„:")
        print(f"  - ë°ì´í„° íƒ€ì…: {df_hitachi['DHL Warehouse'].dtype}")
        print(f"  - ìœ íš¨ ë°ì´í„°: {df_hitachi['DHL Warehouse'].notna().sum()}ê°œ")
        print(f"  - ëˆ„ë½ ë°ì´í„°: {df_hitachi['DHL Warehouse'].isna().sum()}ê°œ")
        
        # ê³ ìœ ê°’ í™•ì¸
        unique_values = df_hitachi['DHL Warehouse'].dropna().unique()
        print(f"  - ê³ ìœ ê°’ ê°œìˆ˜: {len(unique_values)}")
        if len(unique_values) <= 20:
            print(f"  - ê³ ìœ ê°’ë“¤: {unique_values}")
        
        # ì‚¬ìš©ëœ ë°ì´í„°ì™€ ë§¤ì¹­
        df_result = df_used.merge(dhl_mapping, on=matching_cols, how='left')
        
        print(f"\nâœ… DHL Warehouse ë³µêµ¬ ì™„ë£Œ")
        print(f"  - ê²°ê³¼ ë°ì´í„°: {df_result.shape[0]}í–‰, {df_result.shape[1]}ì»¬ëŸ¼")
        
        if 'DHL Warehouse' in df_result.columns:
            matched_count = df_result['DHL Warehouse'].notna().sum()
            print(f"  - ë³µêµ¬ëœ DHL Warehouse ë°ì´í„°: {matched_count}ê°œ")
    
    # Stack_Status ì»¬ëŸ¼ ë³µêµ¬
    if 'Stack_Status' in df_hitachi.columns and 'Stack_Status' not in df_used.columns:
        print("\nğŸ”§ Stack_Status ì»¬ëŸ¼ ë³µêµ¬ ì‹œì‘...")
        
        stack_mapping = df_hitachi[matching_cols + ['Stack_Status']].copy()
        stack_mapping = stack_mapping.drop_duplicates(subset=matching_cols)
        
        df_result = df_result.merge(stack_mapping, on=matching_cols, how='left')
        
        print(f"âœ… Stack_Status ë³µêµ¬ ì™„ë£Œ")
        if 'Stack_Status' in df_result.columns:
            stack_count = df_result['Stack_Status'].notna().sum()
            print(f"  - ë³µêµ¬ëœ Stack_Status ë°ì´í„°: {stack_count}ê°œ")
    
    # ì—´2 ì»¬ëŸ¼ ë³µêµ¬
    if 'ì—´2' in df_hitachi.columns and 'ì—´2' not in df_used.columns:
        print("\nğŸ”§ ì—´2 ì»¬ëŸ¼ ë³µêµ¬ ì‹œì‘...")
        
        col2_mapping = df_hitachi[matching_cols + ['ì—´2']].copy()
        col2_mapping = col2_mapping.drop_duplicates(subset=matching_cols)
        
        df_result = df_result.merge(col2_mapping, on=matching_cols, how='left')
        
        print(f"âœ… ì—´2 ë³µêµ¬ ì™„ë£Œ")
        if 'ì—´2' in df_result.columns:
            col2_count = df_result['ì—´2'].notna().sum()
            print(f"  - ë³µêµ¬ëœ ì—´2 ë°ì´í„°: {col2_count}ê°œ")
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f'HVDC_DHL_Warehouse_ì „ì²´ë³µêµ¬ì™„ë£Œ_{timestamp}.xlsx'
    
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # ì‹œíŠ¸ 1: ë³µêµ¬ëœ ì „ì²´ ë°ì´í„°
        df_result.to_excel(writer, sheet_name='DHL_ë³µêµ¬ì™„ë£Œ_ì „ì²´ë°ì´í„°', index=False)
        
        # ì‹œíŠ¸ 2: DHL Warehouse ë¶„ì„
        if 'DHL Warehouse' in df_result.columns:
            dhl_analysis = df_result.groupby('DHL Warehouse').size().reset_index(name='count')
            dhl_analysis.to_excel(writer, sheet_name='DHL_Warehouse_ë¶„ì„', index=False)
        
        # ì‹œíŠ¸ 3: ë³µêµ¬ ì „í›„ ë¹„êµ
        comparison_data = {
            'êµ¬ë¶„': ['ì›ë³¸ HITACHI', 'ì›ë³¸ SIMENSE', 'ì‚¬ìš©ëœ ë°ì´í„°', 'ë³µêµ¬ëœ ë°ì´í„°'],
            'ì´ í–‰ìˆ˜': [df_hitachi.shape[0], df_simense.shape[0], df_used.shape[0], df_result.shape[0]],
            'ì´ ì»¬ëŸ¼ìˆ˜': [df_hitachi.shape[1], df_simense.shape[1], df_used.shape[1], df_result.shape[1]],
            'DHL Warehouse': [
                'ìˆìŒ' if 'DHL Warehouse' in df_hitachi.columns else 'ì—†ìŒ',
                'ìˆìŒ' if 'DHL Warehouse' in df_simense.columns else 'ì—†ìŒ',
                'ìˆìŒ' if 'DHL Warehouse' in df_used.columns else 'ì—†ìŒ',
                'ë³µêµ¬ë¨' if 'DHL Warehouse' in df_result.columns else 'ì‹¤íŒ¨'
            ]
        }
        
        df_comparison = pd.DataFrame(comparison_data)
        df_comparison.to_excel(writer, sheet_name='ë³µêµ¬_ì „í›„_ë¹„êµ', index=False)
    
    print(f"\nğŸ“Š ìµœì¢… ë³µêµ¬ ì™„ë£Œ íŒŒì¼: {output_file}")
    
    return df_result, output_file

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    try:
        df_recovered, output_file = recover_dhl_warehouse_columns()
        
        print("\nâœ… DHL Warehouse ì»¬ëŸ¼ ë³µêµ¬ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“‹ ìµœì¢… ë°ì´í„°: {df_recovered.shape[0]}í–‰, {df_recovered.shape[1]}ì»¬ëŸ¼")
        print(f"ğŸ“Š ì¶œë ¥ íŒŒì¼: {output_file}")
        
        # ë³µêµ¬ëœ ì»¬ëŸ¼ë“¤ í™•ì¸
        recovered_cols = []
        for col in ['DHL Warehouse', 'Stack_Status', 'ì—´2']:
            if col in df_recovered.columns:
                valid_count = df_recovered[col].notna().sum()
                recovered_cols.append(f"{col}: {valid_count}ê°œ")
        
        print(f"ğŸ¯ ë³µêµ¬ëœ ì»¬ëŸ¼ ë°ì´í„°:")
        for col_info in recovered_cols:
            print(f"  - {col_info}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    main() 