#!/usr/bin/env python3
"""
í‘œì¤€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜ ë° ê²€ì¦
- í‘œì¤€í™”ëœ INVOICE ë°ì´í„° êµ¬ì¡° ì •ì˜
- ë°ì´í„° íƒ€ì… ë° ì œì•½ ì¡°ê±´ ê²€ì¦
- ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê²€ì¦
"""

import pandas as pd
import numpy as np
from datetime import datetime, date
import json
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, field
from enum import Enum

class DataType(Enum):
    """ë°ì´í„° íƒ€ì… ì •ì˜"""
    STRING = "string"
    INTEGER = "integer"
    FLOAT = "float"
    DATETIME = "datetime"
    BOOLEAN = "boolean"
    CATEGORICAL = "categorical"

class ValidationLevel(Enum):
    """ê²€ì¦ ìˆ˜ì¤€ ì •ì˜"""
    CRITICAL = "critical"    # í•„ìˆ˜ ê²€ì¦ (ì‹¤íŒ¨ì‹œ ë ˆì½”ë“œ ê±°ë¶€)
    WARNING = "warning"      # ê²½ê³  ìˆ˜ì¤€ (ë¡œê·¸ë§Œ ê¸°ë¡)
    INFO = "info"           # ì •ë³´ì„± (í†µê³„ë§Œ ìˆ˜ì§‘)

@dataclass
class FieldSchema:
    """í•„ë“œ ìŠ¤í‚¤ë§ˆ ì •ì˜"""
    name: str
    data_type: DataType
    nullable: bool = True
    min_value: Optional[Union[int, float]] = None
    max_value: Optional[Union[int, float]] = None
    min_length: Optional[int] = None
    max_length: Optional[int] = None
    allowed_values: Optional[List[str]] = None
    pattern: Optional[str] = None
    business_rules: List[str] = field(default_factory=list)
    validation_level: ValidationLevel = ValidationLevel.WARNING
    description: str = ""

@dataclass 
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    field_name: str
    record_index: int
    validation_level: ValidationLevel
    is_valid: bool
    error_message: str = ""
    actual_value: Any = None
    expected_constraint: str = ""

class StandardDataSchemaValidator:
    """í‘œì¤€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™” ë° ìŠ¤í‚¤ë§ˆ ì •ì˜"""
        self.schema = self._define_standard_schema()
        self.validation_results = []
        self.summary_stats = {}
        
    def _define_standard_schema(self) -> Dict[str, FieldSchema]:
        """í‘œì¤€ HVDC INVOICE ìŠ¤í‚¤ë§ˆ ì •ì˜"""
        
        schema = {
            # 1. ê³ ìœ  ì‹ë³„ì
            'record_id': FieldSchema(
                name='record_id',
                data_type=DataType.STRING,
                nullable=False,
                min_length=12,
                max_length=15,
                pattern=r'^HVDC_INV_\d{6}$',
                validation_level=ValidationLevel.CRITICAL,
                description='ê³ ìœ  ë ˆì½”ë“œ ì‹ë³„ì (HVDC_INV_nnnnnn í˜•ì‹)'
            ),
            
            # 2. ìš´ì˜ ì›”
            'operation_month': FieldSchema(
                name='operation_month',
                data_type=DataType.DATETIME,
                nullable=True,
                validation_level=ValidationLevel.WARNING,
                business_rules=['should_be_within_project_period'],
                description='í™”ë¬¼ ìš´ì˜ ë°œìƒ ì›”'
            ),
            
            # 3. HVDC í”„ë¡œì íŠ¸ ì½”ë“œ
            'hvdc_project_code': FieldSchema(
                name='hvdc_project_code',
                data_type=DataType.CATEGORICAL,
                nullable=False,
                allowed_values=['HVDC', 'HVDC_PROJECT'],
                validation_level=ValidationLevel.CRITICAL,
                description='HVDC í”„ë¡œì íŠ¸ ì‹ë³„ ì½”ë“œ'
            ),
            
            # 4. ì‘ì—… ìœ í˜•
            'work_type': FieldSchema(
                name='work_type',
                data_type=DataType.CATEGORICAL,
                nullable=True,
                allowed_values=['ADOPT', 'HANDLING', 'STORAGE', 'TRANSFER', 'UNKNOWN'],
                validation_level=ValidationLevel.INFO,
                description='ë¬¼ë¥˜ ì‘ì—… ìœ í˜•'
            ),
            
            # 5. í™”ë¬¼ ìœ í˜• (í‘œì¤€í™”ë¨)
            'cargo_type': FieldSchema(
                name='cargo_type',
                data_type=DataType.CATEGORICAL,
                nullable=False,
                allowed_values=['HITACHI', 'SIEMENS', 'SAMSUNG_CT', 'SCHNEIDER', 'PRYSMIAN', 'MOELLER', 'ALL_RENTAL'],
                validation_level=ValidationLevel.CRITICAL,
                business_rules=['cargo_warehouse_consistency'],
                description='í‘œì¤€í™”ëœ í™”ë¬¼ ìœ í˜• (ë¸Œëœë“œë³„)'
            ),
            
            # 6. ì°½ê³ ëª… (í‘œì¤€í™”ë¨)
            'warehouse_name': FieldSchema(
                name='warehouse_name',
                data_type=DataType.CATEGORICAL,
                nullable=False,
                allowed_values=['DSV_OUTDOOR', 'DSV_INDOOR', 'DSV_AL_MARKAZ', 'DSV_MZP', 'AAA_STORAGE', 'SHIFTING'],
                validation_level=ValidationLevel.CRITICAL,
                business_rules=['warehouse_specialization_check'],
                description='í‘œì¤€í™”ëœ ì°½ê³ ëª…'
            ),
            
            # 7. íŒ¨í‚¤ì§€ ìˆ˜
            'package_count': FieldSchema(
                name='package_count',
                data_type=DataType.INTEGER,
                nullable=True,
                min_value=0,
                max_value=10000,
                validation_level=ValidationLevel.WARNING,
                business_rules=['package_amount_correlation'],
                description='í™”ë¬¼ íŒ¨í‚¤ì§€ ìˆ˜'
            ),
            
            # 8. ì¤‘ëŸ‰ (kg)
            'weight_kg': FieldSchema(
                name='weight_kg',
                data_type=DataType.FLOAT,
                nullable=True,
                min_value=0.0,
                max_value=500000.0,  # 500í†¤ ì œí•œ
                validation_level=ValidationLevel.INFO,
                business_rules=['weight_volume_consistency'],
                description='í™”ë¬¼ ì¤‘ëŸ‰ (í‚¬ë¡œê·¸ë¨)'
            ),
            
            # 9. ë¶€í”¼ (CBM)
            'volume_cbm': FieldSchema(
                name='volume_cbm',
                data_type=DataType.FLOAT,
                nullable=True,
                min_value=0.0,
                max_value=10000.0,
                validation_level=ValidationLevel.INFO,
                description='í™”ë¬¼ ë¶€í”¼ (ì…ë°©ë¯¸í„°)'
            ),
            
            # 10. ë©´ì  (SQM)
            'area_sqm': FieldSchema(
                name='area_sqm',
                data_type=DataType.FLOAT,
                nullable=True,
                min_value=0.0,
                max_value=50000.0,
                validation_level=ValidationLevel.WARNING,
                business_rules=['area_rent_correlation'],
                description='ì°½ê³  ì ìœ  ë©´ì  (ì œê³±ë¯¸í„°)'
            ),
            
            # 11. ê¸ˆì•¡ (AED)
            'amount_aed': FieldSchema(
                name='amount_aed',
                data_type=DataType.FLOAT,
                nullable=True,
                min_value=0.0,
                max_value=1000000.0,  # 100ë§Œ AED ì œí•œ
                validation_level=ValidationLevel.CRITICAL,
                business_rules=['amount_reasonability_check'],
                description='ì²­êµ¬ ê¸ˆì•¡ (UAE ë””ë¥´í•¨)'
            ),
            
            # 12. ì…ê³  í•¸ë“¤ë§
            'handling_in': FieldSchema(
                name='handling_in',
                data_type=DataType.FLOAT,
                nullable=True,
                min_value=0.0,
                validation_level=ValidationLevel.INFO,
                description='ì…ê³  í•¸ë“¤ë§ ë¹„ìš©'
            ),
            
            # 13. ì¶œê³  í•¸ë“¤ë§
            'handling_out': FieldSchema(
                name='handling_out',
                data_type=DataType.FLOAT,
                nullable=True,
                min_value=0.0,
                validation_level=ValidationLevel.INFO,
                description='ì¶œê³  í•¸ë“¤ë§ ë¹„ìš©'
            ),
            
            # 14. ì²­êµ¬ ì›”
            'billing_month': FieldSchema(
                name='billing_month',
                data_type=DataType.DATETIME,
                nullable=True,
                validation_level=ValidationLevel.WARNING,
                business_rules=['billing_operation_sequence'],
                description='ì²­êµ¬ ë°œìƒ ì›”'
            ),
            
            # 15. ë°ì´í„° í’ˆì§ˆ ì ìˆ˜
            'data_quality_score': FieldSchema(
                name='data_quality_score',
                data_type=DataType.FLOAT,
                nullable=False,
                min_value=0.0,
                max_value=1.0,
                validation_level=ValidationLevel.INFO,
                description='ë ˆì½”ë“œ ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ (0.0-1.0)'
            )
        }
        
        return schema
    
    def validate_data(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ë°ì´í„° ì „ì²´ ê²€ì¦"""
        
        print("ğŸ” í‘œì¤€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹œì‘")
        print("=" * 50)
        
        self.validation_results = []
        validation_summary = {
            'total_records': len(data),
            'total_fields': len(self.schema),
            'validation_timestamp': datetime.now().isoformat(),
            'field_validation_results': {},
            'business_rule_results': {},
            'overall_quality_score': 0.0,
            'critical_errors': 0,
            'warnings': 0,
            'info_messages': 0
        }
        
        # 1. ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ê²€ì¦
        structure_result = self._validate_structure(data)
        validation_summary['structure_validation'] = structure_result
        
        # 2. í•„ë“œë³„ ë°ì´í„° íƒ€ì… ë° ì œì•½ ì¡°ê±´ ê²€ì¦
        for field_name, field_schema in self.schema.items():
            if field_name in data.columns:
                field_result = self._validate_field(data, field_name, field_schema)
                validation_summary['field_validation_results'][field_name] = field_result
        
        # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê²€ì¦
        business_rules_result = self._validate_business_rules(data)
        validation_summary['business_rule_results'] = business_rules_result
        
        # 4. ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        overall_score = self._calculate_overall_quality_score()
        validation_summary['overall_quality_score'] = overall_score
        
        # 5. ì—ëŸ¬ í†µê³„
        critical_count = sum(1 for r in self.validation_results if r.validation_level == ValidationLevel.CRITICAL and not r.is_valid)
        warning_count = sum(1 for r in self.validation_results if r.validation_level == ValidationLevel.WARNING and not r.is_valid)
        info_count = sum(1 for r in self.validation_results if r.validation_level == ValidationLevel.INFO and not r.is_valid)
        
        validation_summary.update({
            'critical_errors': critical_count,
            'warnings': warning_count,  
            'info_messages': info_count
        })
        
        print(f"\nğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½:")
        print(f"  âœ… ì „ì²´ ë ˆì½”ë“œ: {validation_summary['total_records']:,}ê±´")
        print(f"  âœ… ì „ì²´ í•„ë“œ: {validation_summary['total_fields']}ê°œ")
        print(f"  âœ… ì „ì²´ í’ˆì§ˆì ìˆ˜: {overall_score:.3f}")
        print(f"  âŒ ì¤‘ìš” ì˜¤ë¥˜: {critical_count:,}ê±´")
        print(f"  âš ï¸  ê²½ê³ : {warning_count:,}ê±´")  
        print(f"  â„¹ï¸  ì •ë³´: {info_count:,}ê±´")
        
        return validation_summary
    
    def _validate_structure(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ë°ì´í„° êµ¬ì¡° ê²€ì¦"""
        
        expected_columns = set(self.schema.keys())
        actual_columns = set(data.columns)
        
        missing_columns = expected_columns - actual_columns
        extra_columns = actual_columns - expected_columns
        matching_columns = expected_columns & actual_columns
        
        structure_result = {
            'expected_columns': len(expected_columns),
            'actual_columns': len(actual_columns),
            'matching_columns': len(matching_columns),
            'missing_columns': list(missing_columns),
            'extra_columns': list(extra_columns),
            'structure_compliance': len(matching_columns) / len(expected_columns) * 100
        }
        
        print(f"ğŸ“‹ êµ¬ì¡° ê²€ì¦:")
        print(f"  ì˜ˆìƒ ì»¬ëŸ¼: {len(expected_columns)}ê°œ")
        print(f"  ì‹¤ì œ ì»¬ëŸ¼: {len(actual_columns)}ê°œ")
        print(f"  ì¼ì¹˜ ì»¬ëŸ¼: {len(matching_columns)}ê°œ")
        print(f"  êµ¬ì¡° ì¤€ìˆ˜ìœ¨: {structure_result['structure_compliance']:.1f}%")
        
        if missing_columns:
            print(f"  âŒ ëˆ„ë½ ì»¬ëŸ¼: {', '.join(missing_columns)}")
        if extra_columns:
            print(f"  â• ì¶”ê°€ ì»¬ëŸ¼: {', '.join(extra_columns)}")
            
        return structure_result
    
    def _validate_field(self, data: pd.DataFrame, field_name: str, field_schema: FieldSchema) -> Dict[str, Any]:
        """ê°œë³„ í•„ë“œ ê²€ì¦"""
        
        field_data = data[field_name]
        field_result = {
            'field_name': field_name,
            'total_records': len(field_data),
            'null_count': field_data.isnull().sum(),
            'null_ratio': field_data.isnull().sum() / len(field_data),
            'valid_records': 0,
            'invalid_records': 0,
            'validation_errors': []
        }
        
        valid_count = 0
        invalid_count = 0
        
        for idx, value in field_data.items():
            is_valid, error_msg = self._validate_single_value(value, field_schema)
            
            if not is_valid:
                invalid_count += 1
                error_result = ValidationResult(
                    field_name=field_name,
                    record_index=idx,
                    validation_level=field_schema.validation_level,
                    is_valid=False,
                    error_message=error_msg,
                    actual_value=value
                )
                self.validation_results.append(error_result)
                field_result['validation_errors'].append({
                    'record_index': idx,
                    'error': error_msg,
                    'value': str(value)
                })
            else:
                valid_count += 1
        
        field_result.update({
            'valid_records': valid_count,
            'invalid_records': invalid_count,
            'validity_ratio': valid_count / len(field_data) if len(field_data) > 0 else 0
        })
        
        return field_result
    
    def _validate_single_value(self, value: Any, schema: FieldSchema) -> tuple[bool, str]:
        """ë‹¨ì¼ ê°’ ê²€ì¦"""
        
        # NULL ê°’ ê²€ì‚¬
        if pd.isna(value):
            if not schema.nullable:
                return False, f"NULL ê°’ì´ í—ˆìš©ë˜ì§€ ì•ŠìŒ"
            return True, ""
        
        # ë°ì´í„° íƒ€ì… ê²€ì¦
        if schema.data_type == DataType.STRING:
            if not isinstance(value, str):
                return False, f"ë¬¸ìì—´ì´ ì•„ë‹˜: {type(value)}"
            if schema.min_length and len(value) < schema.min_length:
                return False, f"ìµœì†Œ ê¸¸ì´ {schema.min_length} ë¯¸ë‹¬: {len(value)}"
            if schema.max_length and len(value) > schema.max_length:
                return False, f"ìµœëŒ€ ê¸¸ì´ {schema.max_length} ì´ˆê³¼: {len(value)}"
            if schema.pattern:
                import re
                if not re.match(schema.pattern, value):
                    return False, f"íŒ¨í„´ ë¯¸ì¼ì¹˜: {schema.pattern}"
                    
        elif schema.data_type == DataType.INTEGER:
            if not isinstance(value, (int, np.integer)):
                return False, f"ì •ìˆ˜ê°€ ì•„ë‹˜: {type(value)}"
            if schema.min_value is not None and value < schema.min_value:
                return False, f"ìµœì†Œê°’ {schema.min_value} ë¯¸ë‹¬: {value}"
            if schema.max_value is not None and value > schema.max_value:
                return False, f"ìµœëŒ€ê°’ {schema.max_value} ì´ˆê³¼: {value}"
                
        elif schema.data_type == DataType.FLOAT:
            if not isinstance(value, (int, float, np.number)):
                return False, f"ìˆ«ìê°€ ì•„ë‹˜: {type(value)}"
            float_value = float(value)
            if schema.min_value is not None and float_value < schema.min_value:
                return False, f"ìµœì†Œê°’ {schema.min_value} ë¯¸ë‹¬: {float_value}"
            if schema.max_value is not None and float_value > schema.max_value:
                return False, f"ìµœëŒ€ê°’ {schema.max_value} ì´ˆê³¼: {float_value}"
                
        elif schema.data_type == DataType.DATETIME:
            if not isinstance(value, (datetime, date, pd.Timestamp, np.datetime64)):
                return False, f"ë‚ ì§œí˜•ì´ ì•„ë‹˜: {type(value)}"
                
        elif schema.data_type == DataType.CATEGORICAL:
            if schema.allowed_values and str(value) not in schema.allowed_values:
                return False, f"í—ˆìš©ê°’ ë²”ìœ„ ë²—ì–´ë‚¨: {value} (í—ˆìš©: {schema.allowed_values})"
        
        return True, ""
    
    def _validate_business_rules(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê²€ì¦"""
        
        business_results = {
            'total_business_rules': 0,
            'passed_rules': 0,
            'failed_rules': 0,
            'rule_details': {}
        }
        
        # 1. í™”ë¬¼-ì°½ê³  ì¼ì¹˜ì„± ê²€ì¦
        if 'cargo_type' in data.columns and 'warehouse_name' in data.columns:
            cargo_warehouse_result = self._check_cargo_warehouse_consistency(data)
            business_results['rule_details']['cargo_warehouse_consistency'] = cargo_warehouse_result
            business_results['total_business_rules'] += 1
            if cargo_warehouse_result['compliance_rate'] >= 0.8:
                business_results['passed_rules'] += 1
            else:
                business_results['failed_rules'] += 1
        
        # 2. ê¸ˆì•¡ í•©ë¦¬ì„± ê²€ì¦
        if 'amount_aed' in data.columns and 'package_count' in data.columns:
            amount_reasonability_result = self._check_amount_reasonability(data)
            business_results['rule_details']['amount_reasonability'] = amount_reasonability_result
            business_results['total_business_rules'] += 1
            if amount_reasonability_result['reasonable_ratio'] >= 0.7:
                business_results['passed_rules'] += 1
            else:
                business_results['failed_rules'] += 1
        
        # 3. ì°½ê³  ì „ë¬¸í™” íŒ¨í„´ ê²€ì¦
        if 'warehouse_name' in data.columns and 'cargo_type' in data.columns:
            specialization_result = self._check_warehouse_specialization(data)
            business_results['rule_details']['warehouse_specialization'] = specialization_result
            business_results['total_business_rules'] += 1
            business_results['passed_rules'] += 1  # ì •ë³´ì„± ê²€ì¦
        
        print(f"\nğŸ¢ ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê²€ì¦:")
        print(f"  ì „ì²´ ë£°: {business_results['total_business_rules']}ê°œ")
        print(f"  í†µê³¼ ë£°: {business_results['passed_rules']}ê°œ")
        print(f"  ì‹¤íŒ¨ ë£°: {business_results['failed_rules']}ê°œ")
        
        return business_results
    
    def _check_cargo_warehouse_consistency(self, data: pd.DataFrame) -> Dict[str, Any]:
        """í™”ë¬¼-ì°½ê³  ì¼ì¹˜ì„± ê²€ì¦"""
        
        # ì „ë¬¸í™” ê·œì¹™ ì •ì˜
        specialization_rules = {
            'AAA_STORAGE': ['SCHNEIDER', 'PRYSMIAN'],  # ìœ„í—˜ë¬¼ ì „ìš©
            'DSV_AL_MARKAZ': ['ALL_RENTAL'],           # ë Œíƒˆ ì „ìš©
            'DSV_INDOOR': ['HITACHI', 'SIEMENS'],      # ì •ë°€ê¸°ê¸° ìš°ì„ 
        }
        
        consistent_count = 0
        total_count = 0
        violations = []
        
        for idx, row in data.iterrows():
            if pd.notna(row.get('warehouse_name')) and pd.notna(row.get('cargo_type')):
                warehouse = row['warehouse_name']
                cargo = row['cargo_type']
                total_count += 1
                
                if warehouse in specialization_rules:
                    allowed_cargo = specialization_rules[warehouse]
                    if cargo in allowed_cargo:
                        consistent_count += 1
                    else:
                        violations.append({
                            'record_index': idx,
                            'warehouse': warehouse,
                            'cargo': cargo,
                            'allowed': allowed_cargo
                        })
                else:
                    consistent_count += 1  # íŠ¹ë³„ ê·œì¹™ì´ ì—†ëŠ” ì°½ê³ ëŠ” ì¼ì¹˜ë¡œ ê°„ì£¼
        
        compliance_rate = consistent_count / total_count if total_count > 0 else 0
        
        return {
            'total_checked': total_count,
            'consistent_records': consistent_count,
            'violations': len(violations),
            'compliance_rate': compliance_rate,
            'violation_details': violations[:10]  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
        }
    
    def _check_amount_reasonability(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ê¸ˆì•¡ í•©ë¦¬ì„± ê²€ì¦"""
        
        reasonable_count = 0
        total_count = 0
        outliers = []
        
        # íŒ¨í‚¤ì§€ë‹¹ í‰ê·  ê¸ˆì•¡ ê³„ì‚°
        valid_data = data[(data['amount_aed'].notna()) & (data['package_count'].notna()) & (data['package_count'] > 0)]
        
        if len(valid_data) > 0:
            per_package_amounts = valid_data['amount_aed'] / valid_data['package_count']
            median_per_package = per_package_amounts.median()
            q1 = per_package_amounts.quantile(0.25)
            q3 = per_package_amounts.quantile(0.75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            for idx, row in valid_data.iterrows():
                total_count += 1
                per_package = row['amount_aed'] / row['package_count']
                
                if lower_bound <= per_package <= upper_bound:
                    reasonable_count += 1
                else:
                    outliers.append({
                        'record_index': idx,
                        'amount_aed': row['amount_aed'],
                        'package_count': row['package_count'],
                        'per_package': per_package,
                        'expected_range': f"{lower_bound:.2f} - {upper_bound:.2f}"
                    })
        
        reasonable_ratio = reasonable_count / total_count if total_count > 0 else 0
        
        return {
            'total_checked': total_count,
            'reasonable_records': reasonable_count,
            'outliers': len(outliers),
            'reasonable_ratio': reasonable_ratio,
            'median_per_package': median_per_package if len(valid_data) > 0 else 0,
            'outlier_details': outliers[:10]
        }
    
    def _check_warehouse_specialization(self, data: pd.DataFrame) -> Dict[str, Any]:
        """ì°½ê³  ì „ë¬¸í™” íŒ¨í„´ ë¶„ì„"""
        
        if 'warehouse_name' not in data.columns or 'cargo_type' not in data.columns:
            return {}
        
        specialization_analysis = {}
        
        for warehouse in data['warehouse_name'].unique():
            if pd.notna(warehouse):
                warehouse_data = data[data['warehouse_name'] == warehouse]
                cargo_distribution = warehouse_data['cargo_type'].value_counts(normalize=True)
                
                specialization_analysis[warehouse] = {
                    'total_records': len(warehouse_data),
                    'cargo_distribution': cargo_distribution.to_dict(),
                    'primary_cargo': cargo_distribution.index[0] if len(cargo_distribution) > 0 else None,
                    'specialization_ratio': cargo_distribution.iloc[0] if len(cargo_distribution) > 0 else 0
                }
        
        return specialization_analysis
    
    def _calculate_overall_quality_score(self) -> float:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        
        if not self.validation_results:
            return 1.0
        
        total_validations = len(self.validation_results)
        critical_failures = sum(1 for r in self.validation_results 
                              if r.validation_level == ValidationLevel.CRITICAL and not r.is_valid)
        warning_failures = sum(1 for r in self.validation_results 
                             if r.validation_level == ValidationLevel.WARNING and not r.is_valid)
        
        # ê°€ì¤‘ì¹˜ ì ìš©: CRITICAL 0.7, WARNING 0.3
        penalty = (critical_failures * 0.7 + warning_failures * 0.3) / total_validations
        quality_score = max(0.0, 1.0 - penalty)
        
        return quality_score
    
    def export_validation_report(self, validation_summary: Dict[str, Any], output_path: str = None) -> str:
        """ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        
        output_path = output_path or f"ìŠ¤í‚¤ë§ˆ_ê²€ì¦_ë¦¬í¬íŠ¸_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            
            # 1. ê²€ì¦ ìš”ì•½
            summary_df = pd.DataFrame([{
                'í•­ëª©': 'ì „ì²´ ë ˆì½”ë“œ ìˆ˜',
                'ê°’': validation_summary['total_records'],
                'ë‹¨ìœ„': 'ê±´'
            }, {
                'í•­ëª©': 'ì „ì²´ í•„ë“œ ìˆ˜',
                'ê°’': validation_summary['total_fields'],
                'ë‹¨ìœ„': 'ê°œ'
            }, {
                'í•­ëª©': 'ì „ì²´ í’ˆì§ˆì ìˆ˜',
                'ê°’': f"{validation_summary['overall_quality_score']:.3f}",
                'ë‹¨ìœ„': 'ì '
            }, {
                'í•­ëª©': 'ì¤‘ìš” ì˜¤ë¥˜',
                'ê°’': validation_summary['critical_errors'],
                'ë‹¨ìœ„': 'ê±´'
            }, {
                'í•­ëª©': 'ê²½ê³ ',
                'ê°’': validation_summary['warnings'],
                'ë‹¨ìœ„': 'ê±´'
            }])
            summary_df.to_excel(writer, sheet_name='ê²€ì¦_ìš”ì•½', index=False)
            
            # 2. í•„ë“œë³„ ê²€ì¦ ê²°ê³¼
            field_results = []
            for field_name, result in validation_summary['field_validation_results'].items():
                field_results.append({
                    'í•„ë“œëª…': field_name,
                    'ì „ì²´ë ˆì½”ë“œ': result['total_records'],
                    'ìœ íš¨ë ˆì½”ë“œ': result['valid_records'],
                    'ë¬´íš¨ë ˆì½”ë“œ': result['invalid_records'],
                    'ìœ íš¨ìœ¨': f"{result['validity_ratio']:.1%}",
                    'ê²°ì¸¡ë¥ ': f"{result['null_ratio']:.1%}"
                })
            
            if field_results:
                fields_df = pd.DataFrame(field_results)
                fields_df.to_excel(writer, sheet_name='í•„ë“œë³„_ê²€ì¦', index=False)
            
            # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê²€ì¦ ê²°ê³¼
            if validation_summary.get('business_rule_results'):
                business_results = []
                for rule_name, result in validation_summary['business_rule_results']['rule_details'].items():
                    if isinstance(result, dict) and 'compliance_rate' in result:
                        business_results.append({
                            'ë¹„ì¦ˆë‹ˆìŠ¤ë£°': rule_name,
                            'ê²€ì¦ëŒ€ìƒ': result.get('total_checked', 0),
                            'ì¤€ìˆ˜ê±´ìˆ˜': result.get('consistent_records', 0),
                            'ìœ„ë°˜ê±´ìˆ˜': result.get('violations', 0),
                            'ì¤€ìˆ˜ìœ¨': f"{result['compliance_rate']:.1%}"
                        })
                
                if business_results:
                    business_df = pd.DataFrame(business_results)
                    business_df.to_excel(writer, sheet_name='ë¹„ì¦ˆë‹ˆìŠ¤ë£°_ê²€ì¦', index=False)
        
        print(f"ğŸ“„ ê²€ì¦ ë¦¬í¬íŠ¸ ì¶œë ¥ ì™„ë£Œ: {output_path}")
        return output_path

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¯ í‘œì¤€ ë°ì´í„° ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹œì‘")
    print("=" * 60)
    
    try:
        # 1. ê²€ì¦ê¸° ì´ˆê¸°í™”
        validator = StandardDataSchemaValidator()
        
        # 2. í‘œì¤€í™”ëœ ë°ì´í„° ë¡œë“œ
        standardized_file = "HVDC_í‘œì¤€í™”_INVOICE_20250702_145255.xlsx"
        data = pd.read_excel(standardized_file, sheet_name='Cleaned_Data')
        
        print(f"ğŸ“‚ í‘œì¤€í™” ë°ì´í„° ë¡œë“œ: {len(data):,}ê±´")
        
        # 3. ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤í–‰
        validation_result = validator.validate_data(data)
        
        # 4. ê²€ì¦ ë¦¬í¬íŠ¸ ì¶œë ¥
        report_file = validator.export_validation_report(validation_result)
        
        print(f"\nğŸ† ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ!")
        print(f"  âœ… ë¦¬í¬íŠ¸ íŒŒì¼: {report_file}")
        print(f"  âœ… ì „ì²´ í’ˆì§ˆì ìˆ˜: {validation_result['overall_quality_score']:.3f}")
        
        return validation_result, report_file
        
    except Exception as e:
        print(f"\nâŒ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
        raise

if __name__ == "__main__":
    result, report = main()
    
    print(f"\nğŸ”§ **ì¶”ì²œ ëª…ë ¹ì–´:**")
    print(f"/analyze_quality_gaps [í’ˆì§ˆ ê²©ì°¨ ë¶„ì„]")
    print(f"/optimize_data_quality [ë°ì´í„° í’ˆì§ˆ ìµœì í™”]")
    print(f"/validate_business_rules [ë¹„ì¦ˆë‹ˆìŠ¤ ë£° ê°•í™”]") 