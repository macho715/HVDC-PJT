#!/usr/bin/env python3
"""
ì°½ê³  ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
ì…ê³  ë¡œì§ ì •í™•ë„ê°€ 39.1%ì¸ ì´ìœ  ë¶„ì„
"""

import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class WarehouseDataQualityAnalyzer:
    """ì°½ê³  ë°ì´í„° í’ˆì§ˆ ë¶„ì„ê¸°"""
    
    def __init__(self):
        print("ğŸ” ì°½ê³  ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹œì‘")
        print("=" * 60)
        
        # ë°ì´í„° ë¡œë“œ
        self.data_path = Path("data")
        self.hitachi_file = self.data_path / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        self.simense_file = self.data_path / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        
        self.warehouse_columns = [
            'DSV Outdoor', 'DSV Indoor', 'DSV Al Markaz', 'AAA  Storage',
            'DHL Warehouse', 'MOSB', 'Hauler Indoor'
        ]
        
        self.combined_data = None
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        combined_dfs = []
        
        if self.hitachi_file.exists():
            hitachi_data = pd.read_excel(self.hitachi_file, engine='openpyxl')
            combined_dfs.append(hitachi_data)
        
        if self.simense_file.exists():
            simense_data = pd.read_excel(self.simense_file, engine='openpyxl')
            combined_dfs.append(simense_data)
        
        if combined_dfs:
            self.combined_data = pd.concat(combined_dfs, ignore_index=True, sort=False)
            print(f"ğŸ“Š ì´ ë°ì´í„°: {len(self.combined_data):,}ê±´")
            return True
        return False
    
    def analyze_warehouse_column_quality(self):
        """ì°½ê³  ì»¬ëŸ¼ ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        print("\nğŸ¢ ì°½ê³  ì»¬ëŸ¼ ë°ì´í„° í’ˆì§ˆ ë¶„ì„")
        print("-" * 60)
        
        for warehouse in self.warehouse_columns:
            if warehouse not in self.combined_data.columns:
                continue
                
            print(f"\nğŸ“‹ {warehouse} ì»¬ëŸ¼ ë¶„ì„:")
            
            # ì „ì²´ ë°ì´í„° í˜„í™©
            total_count = len(self.combined_data)
            non_null_count = self.combined_data[warehouse].notna().sum()
            null_count = total_count - non_null_count
            
            print(f"   ì „ì²´ í–‰ ìˆ˜: {total_count:,}")
            print(f"   ë¹„ì–´ìˆì§€ ì•Šì€ ê°’: {non_null_count:,}ê±´ ({non_null_count/total_count*100:.1f}%)")
            print(f"   ë¹„ì–´ìˆëŠ” ê°’: {null_count:,}ê±´ ({null_count/total_count*100:.1f}%)")
            
            if non_null_count > 0:
                # ë°ì´í„° íƒ€ì… ë¶„ì„
                non_null_data = self.combined_data[warehouse].dropna()
                
                # ë‚ ì§œ í˜•ì‹ ì²´í¬
                date_count = 0
                non_date_count = 0
                non_date_samples = []
                
                for value in non_null_data:
                    try:
                        pd.to_datetime(value)
                        date_count += 1
                    except:
                        non_date_count += 1
                        if len(non_date_samples) < 5:
                            non_date_samples.append(str(value))
                
                print(f"   ë‚ ì§œ í˜•ì‹ ê°€ëŠ¥: {date_count:,}ê±´ ({date_count/non_null_count*100:.1f}%)")
                print(f"   ë‚ ì§œ í˜•ì‹ ë¶ˆê°€: {non_date_count:,}ê±´ ({non_date_count/non_null_count*100:.1f}%)")
                
                if non_date_samples:
                    print(f"   ë‚ ì§œ í˜•ì‹ ë¶ˆê°€ ìƒ˜í”Œ: {non_date_samples}")
                
                # ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜
                unique_count = non_null_data.nunique()
                print(f"   ìœ ë‹ˆí¬ ê°’ ê°œìˆ˜: {unique_count:,}")
                
                # ê°€ì¥ ë§ì€ ê°’ë“¤
                value_counts = non_null_data.value_counts().head(5)
                print(f"   ìƒìœ„ 5ê°œ ê°’:")
                for value, count in value_counts.items():
                    print(f"     '{value}': {count:,}ê±´")
    
    def analyze_final_location_impact(self):
        """Final_Location íŒŒìƒì´ ì…ê³  ë¡œì§ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„"""
        print("\nğŸ¯ Final_Location íŒŒìƒ ë¡œì§ ì˜í–¥ ë¶„ì„")
        print("-" * 60)
        
        # Status_Location ì»¬ëŸ¼ í™•ì¸
        if 'Status_Location' in self.combined_data.columns:
            print("âœ… Status_Location ì»¬ëŸ¼ ì¡´ì¬")
            
            # Status_Location ë¶„í¬
            status_location_counts = self.combined_data['Status_Location'].value_counts()
            print(f"ğŸ“Š Status_Location ë¶„í¬ (ìƒìœ„ 10ê°œ):")
            for location, count in status_location_counts.head(10).items():
                percentage = (count / len(self.combined_data)) * 100
                print(f"   {location}: {count:,}ê±´ ({percentage:.1f}%)")
        else:
            print("âŒ Status_Location ì»¬ëŸ¼ ì—†ìŒ")
        
        # Final_Location íŒŒìƒ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
        print(f"\nğŸ” Final_Location íŒŒìƒ ë¡œì§ ì‹œë®¬ë ˆì´ì…˜:")
        
        # DSV Al Markaz ìš°ì„  ì¡°ê±´
        dsv_al_markaz_condition = (
            self.combined_data['DSV Al Markaz'].notna() & 
            self.combined_data['DSV Al Markaz'].ne('')
        )
        dsv_al_markaz_count = dsv_al_markaz_condition.sum()
        
        # DSV Indoor ì°¨ìˆœìœ„ ì¡°ê±´
        dsv_indoor_condition = (
            (~dsv_al_markaz_condition) &
            self.combined_data['DSV Indoor'].notna() & 
            self.combined_data['DSV Indoor'].ne('')
        )
        dsv_indoor_count = dsv_indoor_condition.sum()
        
        # ë‚˜ë¨¸ì§€ (Status_Location ì‚¬ìš©)
        remaining_count = len(self.combined_data) - dsv_al_markaz_count - dsv_indoor_count
        
        print(f"   DSV Al Markaz ìš°ì„  ì„ íƒ: {dsv_al_markaz_count:,}ê±´")
        print(f"   DSV Indoor ì°¨ìˆœìœ„ ì„ íƒ: {dsv_indoor_count:,}ê±´")
        print(f"   Status_Location ì‚¬ìš©: {remaining_count:,}ê±´")
    
    def analyze_inbound_logic_accuracy(self):
        """ì…ê³  ë¡œì§ ì •í™•ë„ ë¶„ì„"""
        print("\nğŸ“Š ì…ê³  ë¡œì§ ì •í™•ë„ ë¶„ì„")
        print("-" * 60)
        
        # ì°½ê³ ë³„ ì‹¤ì œ ì—”íŠ¸ë¦¬ vs ë‚ ì§œ í˜•ì‹ ì—”íŠ¸ë¦¬ ë¹„êµ
        total_entries = 0
        total_date_entries = 0
        
        for warehouse in self.warehouse_columns:
            if warehouse not in self.combined_data.columns:
                continue
                
            # ì „ì²´ non-null ì—”íŠ¸ë¦¬
            non_null_count = self.combined_data[warehouse].notna().sum()
            total_entries += non_null_count
            
            # ë‚ ì§œ í˜•ì‹ ì—”íŠ¸ë¦¬
            date_count = 0
            if non_null_count > 0:
                non_null_data = self.combined_data[warehouse].dropna()
                for value in non_null_data:
                    try:
                        pd.to_datetime(value)
                        date_count += 1
                    except:
                        pass
            
            total_date_entries += date_count
            
            accuracy = (date_count / non_null_count * 100) if non_null_count > 0 else 0
            print(f"   {warehouse}:")
            print(f"     ì „ì²´ ì—”íŠ¸ë¦¬: {non_null_count:,}ê±´")
            print(f"     ë‚ ì§œ í˜•ì‹: {date_count:,}ê±´")
            print(f"     ì •í™•ë„: {accuracy:.1f}%")
        
        overall_accuracy = (total_date_entries / total_entries * 100) if total_entries > 0 else 0
        print(f"\nğŸ“ˆ ì „ì²´ ì…ê³  ë¡œì§ ì •í™•ë„:")
        print(f"   ì´ ì°½ê³  ì—”íŠ¸ë¦¬: {total_entries:,}ê±´")
        print(f"   ë‚ ì§œ í˜•ì‹ ì—”íŠ¸ë¦¬: {total_date_entries:,}ê±´")
        print(f"   ì •í™•ë„: {overall_accuracy:.1f}%")
    
    def suggest_improvements(self):
        """ê°œì„  ë°©ì•ˆ ì œì‹œ"""
        print("\nğŸ’¡ ì…ê³  ë¡œì§ ê°œì„  ë°©ì•ˆ")
        print("-" * 60)
        
        print("1. ğŸ“… ë‚ ì§œ í˜•ì‹ í‘œì¤€í™”:")
        print("   - ì°½ê³  ì»¬ëŸ¼ì˜ ë¹„ë‚ ì§œ ë°ì´í„° ì²˜ë¦¬ ë°©ì•ˆ ìˆ˜ë¦½")
        print("   - ë‚ ì§œ í˜•ì‹ ë³€í™˜ ë¡œì§ ê°œì„ ")
        
        print("\n2. ğŸ” ë°ì´í„° í’ˆì§ˆ ê°œì„ :")
        print("   - ì°½ê³  ì»¬ëŸ¼ ë°ì´í„° ì…ë ¥ ê·œì¹™ ì •ì˜")
        print("   - ë°ì´í„° ê²€ì¦ ë¡œì§ ì¶”ê°€")
        
        print("\n3. ğŸ¯ Final_Location ë¡œì§ ìµœì í™”:")
        print("   - Status_Location ê¸°ë°˜ ë¶„ë¥˜ ì •í™•ë„ í–¥ìƒ")
        print("   - ìš°ì„ ìˆœìœ„ ë¡œì§ ì¬ê²€í† ")
        
        print("\n4. ğŸ“Š ì…ê³  ë¡œì§ ëŒ€ì•ˆ:")
        print("   - ë‚ ì§œ í˜•ì‹ ì™¸ ë‹¤ë¥¸ ì…ê³  íŒë‹¨ ê¸°ì¤€ ê²€í† ")
        print("   - ë³µí•© ì¡°ê±´ ê¸°ë°˜ ì…ê³  ë¡œì§ ê°œë°œ")
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        if not self.load_data():
            return
        
        self.analyze_warehouse_column_quality()
        self.analyze_final_location_impact()
        self.analyze_inbound_logic_accuracy()
        self.suggest_improvements()


def main():
    analyzer = WarehouseDataQualityAnalyzer()
    analyzer.run_analysis()


if __name__ == "__main__":
    main() 