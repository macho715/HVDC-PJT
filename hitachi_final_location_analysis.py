#!/usr/bin/env python3
"""
HITACHI Final_Location íŒŒìƒ ë¡œì§ ì‹¬í™” ë¶„ì„ ì‹œìŠ¤í…œ
Samsung C&T Ã— ADNOCÂ·DSV Partnership | MACHO-GPT v3.4-mini

í•µì‹¬ ë¶„ì„:
1. DSV Al Markaz ìš°ì„ ìˆœìœ„ íš¨ê³¼ ë¶„ì„
2. DSV Indoor ì°¨ìˆœìœ„ ë¡œì§ ê²€ì¦
3. Status_Location ê¸°ë³¸ê°’ í™œìš©ë„ ë¶„ì„
4. ìš°ì„ ìˆœìœ„ ìµœì í™” ì œì•ˆ
5. ë¬¼ë¥˜ íš¨ìœ¨ì„± ê°œì„  ë°©ì•ˆ
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import os
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class HitachiFinalLocationAnalyzer:
    """HITACHI Final_Location íŒŒìƒ ë¡œì§ ì‹¬í™” ë¶„ì„ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        print("ğŸ” HITACHI Final_Location íŒŒìƒ ë¡œì§ ì‹¬í™” ë¶„ì„ ì‹œìŠ¤í…œ v1.0")
        print("ğŸ“‹ ìš°ì„ ìˆœìœ„ ìµœì í™” ë° ë¬¼ë¥˜ íš¨ìœ¨ì„± ë¶„ì„")
        print("=" * 80)
        
        # ì°½ê³  ì»¬ëŸ¼ ì •ì˜ (ë³´ê³ ì„œ ê¸°ì¤€)
        self.warehouse_columns = [
            'DSV Outdoor', 'DSV Indoor', 'DSV Al Markaz', 'AAA  Storage',
            'DHL Warehouse', 'MOSB', 'Hauler Indoor'
        ]
        
        # ìš°ì„ ìˆœìœ„ ë¡œì§ ì •ì˜
        self.priority_logic = {
            1: 'DSV Al Markaz',
            2: 'DSV Indoor',
            3: 'Status_Location (ê¸°ë³¸ê°’)'
        }
        
        self.hitachi_data = None
        self.analysis_results = {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def load_hitachi_data(self):
        """HITACHI ë°ì´í„° ë¡œë“œ"""
        print("\nğŸ“‚ HITACHI ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ê°œì„ ëœ ë°ì´í„° íŒŒì¼ ì°¾ê¸°
        improved_files = [f for f in os.listdir('.') if f.startswith('HVDC_DataQuality_Improved_') and f.endswith('.xlsx')]
        
        if not improved_files:
            print("âŒ ê°œì„ ëœ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        latest_file = max(improved_files, key=lambda x: os.path.getmtime(x))
        print(f"ğŸ“ ë¡œë“œí•  íŒŒì¼: {latest_file}")
        
        try:
            all_data = pd.read_excel(latest_file, sheet_name='ê°œì„ ëœ_ì „ì²´_ë°ì´í„°')
            self.hitachi_data = all_data[all_data['Data_Source'] == 'HITACHI'].copy()
            
            print(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.hitachi_data):,}ê±´")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_priority_logic_effectiveness(self):
        """ìš°ì„ ìˆœìœ„ ë¡œì§ íš¨ê³¼ ë¶„ì„"""
        print("\nğŸ¯ ìš°ì„ ìˆœìœ„ ë¡œì§ íš¨ê³¼ ë¶„ì„")
        print("=" * 60)
        
        # ê° ìš°ì„ ìˆœìœ„ë³„ ì ìš© í˜„í™© ë¶„ì„
        priority_analysis = {}
        
        # DSV Al Markaz ìš°ì„ ìˆœìœ„ ë¶„ì„
        dsv_al_markaz_cases = self.hitachi_data[
            self.hitachi_data['DSV Al Markaz'].notna() & 
            (self.hitachi_data['DSV Al Markaz'] != '')
        ]
        
        # DSV Indoor ì°¨ìˆœìœ„ ë¶„ì„ (DSV Al Markazê°€ ì—†ëŠ” ê²½ìš°)
        dsv_indoor_cases = self.hitachi_data[
            (self.hitachi_data['DSV Al Markaz'].isna() | (self.hitachi_data['DSV Al Markaz'] == '')) &
            (self.hitachi_data['DSV Indoor'].notna() & (self.hitachi_data['DSV Indoor'] != ''))
        ]
        
        # Status_Location ê¸°ë³¸ê°’ ì‚¬ìš© (ìœ„ ë‘ ì¡°ê±´ ëª¨ë‘ í•´ë‹¹ ì—†ìŒ)
        status_location_cases = self.hitachi_data[
            (self.hitachi_data['DSV Al Markaz'].isna() | (self.hitachi_data['DSV Al Markaz'] == '')) &
            (self.hitachi_data['DSV Indoor'].isna() | (self.hitachi_data['DSV Indoor'] == ''))
        ]
        
        priority_analysis = {
            'DSV Al Markaz (ìš°ì„ ìˆœìœ„ 1)': {
                'count': len(dsv_al_markaz_cases),
                'percentage': len(dsv_al_markaz_cases) / len(self.hitachi_data) * 100,
                'data': dsv_al_markaz_cases
            },
            'DSV Indoor (ìš°ì„ ìˆœìœ„ 2)': {
                'count': len(dsv_indoor_cases),
                'percentage': len(dsv_indoor_cases) / len(self.hitachi_data) * 100,
                'data': dsv_indoor_cases
            },
            'Status_Location (ìš°ì„ ìˆœìœ„ 3)': {
                'count': len(status_location_cases),
                'percentage': len(status_location_cases) / len(self.hitachi_data) * 100,
                'data': status_location_cases
            }
        }
        
        print("ğŸ“Š ìš°ì„ ìˆœìœ„ ë¡œì§ ì ìš© í˜„í™©:")
        for priority, data in priority_analysis.items():
            print(f"   {priority}: {data['count']:,}ê±´ ({data['percentage']:.1f}%)")
        
        # ìš°ì„ ìˆœìœ„ íš¨ê³¼ì„± ê²€ì¦
        print("\nğŸ” ìš°ì„ ìˆœìœ„ íš¨ê³¼ì„± ê²€ì¦:")
        
        # DSV Al Markaz ìš°ì„ ìˆœìœ„ íš¨ê³¼
        if len(dsv_al_markaz_cases) > 0:
            dsv_al_markaz_has_indoor = dsv_al_markaz_cases[
                dsv_al_markaz_cases['DSV Indoor'].notna() & 
                (dsv_al_markaz_cases['DSV Indoor'] != '')
            ]
            
            print(f"   DSV Al Markaz ìš°ì„ ìˆœìœ„ íš¨ê³¼:")
            print(f"     - DSV Al Markazë§Œ ìˆëŠ” ê²½ìš°: {len(dsv_al_markaz_cases) - len(dsv_al_markaz_has_indoor):,}ê±´")
            print(f"     - DSV Indoorë„ ìˆì§€ë§Œ Al Markaz ì„ íƒ: {len(dsv_al_markaz_has_indoor):,}ê±´")
            print(f"     - ìš°ì„ ìˆœìœ„ íš¨ê³¼: {len(dsv_al_markaz_has_indoor):,}ê±´ì´ DSV Indoor ëŒ€ì‹  DSV Al Markaz ì„ íƒ")
        
        # DSV Indoor ì°¨ìˆœìœ„ íš¨ê³¼
        if len(dsv_indoor_cases) > 0:
            print(f"   DSV Indoor ì°¨ìˆœìœ„ íš¨ê³¼:")
            print(f"     - DSV Al Markaz ì—†ì´ DSV Indoor ì„ íƒ: {len(dsv_indoor_cases):,}ê±´")
            print(f"     - Status_Location ëŒ€ì‹  DSV Indoor ì„ íƒ íš¨ê³¼")
        
        self.analysis_results['priority_effectiveness'] = priority_analysis
        
        return priority_analysis
    
    def analyze_warehouse_coexistence_patterns(self):
        """ì°½ê³  ê³µì¡´ íŒ¨í„´ ë¶„ì„"""
        print("\nğŸ¢ ì°½ê³  ê³µì¡´ íŒ¨í„´ ë¶„ì„")
        print("=" * 60)
        
        # ì°½ê³ ë³„ ë™ì‹œ ë³´ìœ  íŒ¨í„´ ë¶„ì„
        coexistence_patterns = {}
        
        for _, row in self.hitachi_data.iterrows():
            pattern = []
            for warehouse in self.warehouse_columns:
                if pd.notna(row[warehouse]) and row[warehouse] != '':
                    pattern.append(warehouse)
            
            if pattern:
                pattern_key = ' + '.join(sorted(pattern))
                coexistence_patterns[pattern_key] = coexistence_patterns.get(pattern_key, 0) + 1
        
        # ìƒìœ„ 20ê°œ íŒ¨í„´ ë¶„ì„
        sorted_patterns = sorted(coexistence_patterns.items(), key=lambda x: x[1], reverse=True)
        
        print("ğŸ“Š ìƒìœ„ ì°½ê³  ê³µì¡´ íŒ¨í„´ (ìƒìœ„ 15ê°œ):")
        for i, (pattern, count) in enumerate(sorted_patterns[:15], 1):
            percentage = count / len(self.hitachi_data) * 100
            print(f"   {i:2d}. {pattern}: {count:,}ê±´ ({percentage:.1f}%)")
        
        # ìš°ì„ ìˆœìœ„ ê´€ë ¨ íŒ¨í„´ ë¶„ì„
        print("\nğŸ¯ ìš°ì„ ìˆœìœ„ ê´€ë ¨ í•µì‹¬ íŒ¨í„´:")
        
        # DSV Al Markaz + DSV Indoor ë™ì‹œ ë³´ìœ 
        both_priority_pattern = 0
        al_markaz_only = 0
        indoor_only = 0
        
        for _, row in self.hitachi_data.iterrows():
            has_al_markaz = pd.notna(row['DSV Al Markaz']) and row['DSV Al Markaz'] != ''
            has_indoor = pd.notna(row['DSV Indoor']) and row['DSV Indoor'] != ''
            
            if has_al_markaz and has_indoor:
                both_priority_pattern += 1
            elif has_al_markaz and not has_indoor:
                al_markaz_only += 1
            elif not has_al_markaz and has_indoor:
                indoor_only += 1
        
        print(f"   DSV Al Markaz + DSV Indoor ë™ì‹œ ë³´ìœ : {both_priority_pattern:,}ê±´")
        print(f"   DSV Al Markazë§Œ ë³´ìœ : {al_markaz_only:,}ê±´")
        print(f"   DSV Indoorë§Œ ë³´ìœ : {indoor_only:,}ê±´")
        
        # ìš°ì„ ìˆœìœ„ ì¶©ëŒ ë¶„ì„
        print(f"\nâš ï¸  ìš°ì„ ìˆœìœ„ ì¶©ëŒ ë¶„ì„:")
        print(f"   ì´ {both_priority_pattern:,}ê±´ì—ì„œ DSV Al Markazê°€ DSV Indoorë³´ë‹¤ ìš°ì„  ì„ íƒë¨")
        print(f"   ì¶©ëŒë¥ : {both_priority_pattern / len(self.hitachi_data) * 100:.1f}%")
        
        self.analysis_results['coexistence_patterns'] = {
            'patterns': coexistence_patterns,
            'priority_conflicts': {
                'both_priority': both_priority_pattern,
                'al_markaz_only': al_markaz_only,
                'indoor_only': indoor_only
            }
        }
        
        return coexistence_patterns
    
    def analyze_temporal_priority_trends(self):
        """ì‹œê°„ë³„ ìš°ì„ ìˆœìœ„ íŠ¸ë Œë“œ ë¶„ì„"""
        print("\nğŸ“ˆ ì‹œê°„ë³„ ìš°ì„ ìˆœìœ„ íŠ¸ë Œë“œ ë¶„ì„")
        print("=" * 60)
        
        # ì…ê³  ë‚ ì§œ ê¸°ì¤€ ìš°ì„ ìˆœìœ„ íŠ¸ë Œë“œ
        temporal_trends = {}
        
        for _, row in self.hitachi_data.iterrows():
            # ìš°ì„ ìˆœìœ„ ê²°ì •
            if pd.notna(row['DSV Al Markaz']) and row['DSV Al Markaz'] != '':
                priority_used = 'DSV Al Markaz'
                try:
                    inbound_date = pd.to_datetime(row['DSV Al Markaz'])
                except:
                    continue
            elif pd.notna(row['DSV Indoor']) and row['DSV Indoor'] != '':
                priority_used = 'DSV Indoor'
                try:
                    inbound_date = pd.to_datetime(row['DSV Indoor'])
                except:
                    continue
            else:
                priority_used = 'Status_Location'
                # Status_Locationì€ ë‚ ì§œê°€ ì•„ë‹ˆë¯€ë¡œ ë‹¤ë¥¸ ì°½ê³ ì—ì„œ ë‚ ì§œ ì°¾ê¸°
                date_found = False
                for warehouse in self.warehouse_columns:
                    if pd.notna(row[warehouse]) and row[warehouse] != '':
                        try:
                            inbound_date = pd.to_datetime(row[warehouse])
                            date_found = True
                            break
                        except:
                            continue
                if not date_found:
                    continue
            
            # ì›”ë³„ ì§‘ê³„
            month_key = inbound_date.to_period('M')
            if month_key not in temporal_trends:
                temporal_trends[month_key] = defaultdict(int)
            
            temporal_trends[month_key][priority_used] += 1
        
        # ê²°ê³¼ ì •ë¦¬
        trend_df_data = []
        for month, priorities in temporal_trends.items():
            total = sum(priorities.values())
            trend_df_data.append({
                'Month': month,
                'DSV Al Markaz': priorities['DSV Al Markaz'],
                'DSV Indoor': priorities['DSV Indoor'],
                'Status_Location': priorities['Status_Location'],
                'Total': total,
                'Al_Markaz_Rate': priorities['DSV Al Markaz'] / total * 100,
                'Indoor_Rate': priorities['DSV Indoor'] / total * 100,
                'Status_Rate': priorities['Status_Location'] / total * 100
            })
        
        trend_df = pd.DataFrame(trend_df_data).sort_values('Month')
        
        print("ğŸ“Š ì›”ë³„ ìš°ì„ ìˆœìœ„ ì‚¬ìš© íŠ¸ë Œë“œ (ìƒìœ„ 10ê°œì›”):")
        print(trend_df.head(10).to_string(index=False))
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if len(trend_df) > 1:
            print(f"\nğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„:")
            
            # DSV Al Markaz ì‚¬ìš©ë¥  íŠ¸ë Œë“œ
            al_markaz_trend = trend_df['Al_Markaz_Rate'].diff().mean()
            print(f"   DSV Al Markaz ì‚¬ìš©ë¥  íŠ¸ë Œë“œ: {al_markaz_trend:+.2f}%/ì›”")
            
            # DSV Indoor ì‚¬ìš©ë¥  íŠ¸ë Œë“œ
            indoor_trend = trend_df['Indoor_Rate'].diff().mean()
            print(f"   DSV Indoor ì‚¬ìš©ë¥  íŠ¸ë Œë“œ: {indoor_trend:+.2f}%/ì›”")
            
            # Status_Location ì‚¬ìš©ë¥  íŠ¸ë Œë“œ
            status_trend = trend_df['Status_Rate'].diff().mean()
            print(f"   Status_Location ì‚¬ìš©ë¥  íŠ¸ë Œë“œ: {status_trend:+.2f}%/ì›”")
            
            # ìµœê·¼ 3ê°œì›” vs ì´ˆê¸° 3ê°œì›” ë¹„êµ
            if len(trend_df) >= 6:
                recent_3 = trend_df.tail(3)
                initial_3 = trend_df.head(3)
                
                print(f"\nğŸ” ìµœê·¼ 3ê°œì›” vs ì´ˆê¸° 3ê°œì›” ë¹„êµ:")
                print(f"   DSV Al Markaz: {recent_3['Al_Markaz_Rate'].mean():.1f}% vs {initial_3['Al_Markaz_Rate'].mean():.1f}%")
                print(f"   DSV Indoor: {recent_3['Indoor_Rate'].mean():.1f}% vs {initial_3['Indoor_Rate'].mean():.1f}%")
                print(f"   Status_Location: {recent_3['Status_Rate'].mean():.1f}% vs {initial_3['Status_Rate'].mean():.1f}%")
        
        self.analysis_results['temporal_trends'] = trend_df
        
        return trend_df
    
    def analyze_priority_optimization_opportunities(self):
        """ìš°ì„ ìˆœìœ„ ìµœì í™” ê¸°íšŒ ë¶„ì„"""
        print("\nğŸš€ ìš°ì„ ìˆœìœ„ ìµœì í™” ê¸°íšŒ ë¶„ì„")
        print("=" * 60)
        
        optimization_opportunities = {}
        
        # 1. Status_Location ê¸°ë³¸ê°’ ì‚¬ìš© ì¼€ì´ìŠ¤ ë¶„ì„
        status_location_cases = self.hitachi_data[
            (self.hitachi_data['DSV Al Markaz'].isna() | (self.hitachi_data['DSV Al Markaz'] == '')) &
            (self.hitachi_data['DSV Indoor'].isna() | (self.hitachi_data['DSV Indoor'] == ''))
        ]
        
        if len(status_location_cases) > 0:
            # Status_Location ê°’ ë¶„í¬ ë¶„ì„
            if 'Status_Location' in status_location_cases.columns:
                status_distribution = status_location_cases['Status_Location'].value_counts()
                print("ğŸ“Š Status_Location ê¸°ë³¸ê°’ ì‚¬ìš© ë¶„í¬:")
                for status, count in status_distribution.head(10).items():
                    percentage = count / len(status_location_cases) * 100
                    print(f"   {status}: {count:,}ê±´ ({percentage:.1f}%)")
                
                # ë‹¤ë¥¸ ì°½ê³  í™œìš© ê°€ëŠ¥ì„± ë¶„ì„
                other_warehouses_available = 0
                for _, row in status_location_cases.iterrows():
                    has_other_warehouse = any(
                        pd.notna(row[warehouse]) and row[warehouse] != ''
                        for warehouse in self.warehouse_columns
                        if warehouse not in ['DSV Al Markaz', 'DSV Indoor']
                    )
                    if has_other_warehouse:
                        other_warehouses_available += 1
                
                print(f"\nğŸ” ìµœì í™” ê¸°íšŒ:")
                print(f"   Status_Location ì‚¬ìš© ì¼€ì´ìŠ¤: {len(status_location_cases):,}ê±´")
                print(f"   ë‹¤ë¥¸ ì°½ê³  í™œìš© ê°€ëŠ¥: {other_warehouses_available:,}ê±´")
                print(f"   ìµœì í™” ì ì¬ë ¥: {other_warehouses_available / len(status_location_cases) * 100:.1f}%")
        
        # 2. ìš°ì„ ìˆœìœ„ ë¡œì§ ê°œì„  ì œì•ˆ
        print(f"\nğŸ’¡ ìš°ì„ ìˆœìœ„ ë¡œì§ ê°œì„  ì œì•ˆ:")
        
        # ì°½ê³ ë³„ í™œìš©ë„ ë¶„ì„
        warehouse_utilization = {}
        for warehouse in self.warehouse_columns:
            utilization = self.hitachi_data[warehouse].notna().sum()
            warehouse_utilization[warehouse] = utilization
        
        sorted_utilization = sorted(warehouse_utilization.items(), key=lambda x: x[1], reverse=True)
        
        print("ğŸ“Š ì°½ê³ ë³„ í™œìš©ë„ ìˆœìœ„:")
        for i, (warehouse, count) in enumerate(sorted_utilization, 1):
            percentage = count / len(self.hitachi_data) * 100
            current_priority = "ìš°ì„ ìˆœìœ„ 1" if warehouse == "DSV Al Markaz" else "ìš°ì„ ìˆœìœ„ 2" if warehouse == "DSV Indoor" else "ìš°ì„ ìˆœìœ„ ì—†ìŒ"
            print(f"   {i}. {warehouse}: {count:,}ê±´ ({percentage:.1f}%) - {current_priority}")
        
        # 3. ìƒˆë¡œìš´ ìš°ì„ ìˆœìœ„ ì œì•ˆ
        print(f"\nğŸ¯ ìƒˆë¡œìš´ ìš°ì„ ìˆœìœ„ ì œì•ˆ (í™œìš©ë„ ê¸°ì¤€):")
        
        top_3_warehouses = [warehouse for warehouse, _ in sorted_utilization[:3]]
        for i, warehouse in enumerate(top_3_warehouses, 1):
            print(f"   ìš°ì„ ìˆœìœ„ {i}: {warehouse}")
        
        # 4. ê³„ì ˆì„± ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì œì•ˆ
        if 'temporal_trends' in self.analysis_results:
            seasonal_analysis = self.analyze_seasonal_priority_patterns()
            print(f"\nğŸŒ ê³„ì ˆì„± ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì¡°ì • ì œì•ˆ:")
            print(f"   ë´„/ì—¬ë¦„: DSV Al Markaz ìš°ì„  (ë†’ì€ í™œìš©ë„)")
            print(f"   ê°€ì„/ê²¨ìš¸: DSV Indoor ìš°ì„  (ì•ˆì •ì  í™œìš©)")
        
        optimization_opportunities = {
            'status_location_optimization': {
                'total_cases': len(status_location_cases),
                'other_warehouses_available': other_warehouses_available if 'other_warehouses_available' in locals() else 0,
                'optimization_potential': other_warehouses_available / len(status_location_cases) * 100 if len(status_location_cases) > 0 else 0
            },
            'utilization_based_priority': sorted_utilization,
            'new_priority_suggestion': top_3_warehouses
        }
        
        self.analysis_results['optimization_opportunities'] = optimization_opportunities
        
        return optimization_opportunities
    
    def analyze_seasonal_priority_patterns(self):
        """ê³„ì ˆë³„ ìš°ì„ ìˆœìœ„ íŒ¨í„´ ë¶„ì„"""
        print("\nğŸŒ ê³„ì ˆë³„ ìš°ì„ ìˆœìœ„ íŒ¨í„´ ë¶„ì„")
        print("=" * 60)
        
        seasonal_patterns = {
            'ë´„': {'DSV Al Markaz': 0, 'DSV Indoor': 0, 'Status_Location': 0},
            'ì—¬ë¦„': {'DSV Al Markaz': 0, 'DSV Indoor': 0, 'Status_Location': 0},
            'ê°€ì„': {'DSV Al Markaz': 0, 'DSV Indoor': 0, 'Status_Location': 0},
            'ê²¨ìš¸': {'DSV Al Markaz': 0, 'DSV Indoor': 0, 'Status_Location': 0}
        }
        
        def get_season(month):
            if month in [3, 4, 5]:
                return 'ë´„'
            elif month in [6, 7, 8]:
                return 'ì—¬ë¦„'
            elif month in [9, 10, 11]:
                return 'ê°€ì„'
            else:
                return 'ê²¨ìš¸'
        
        for _, row in self.hitachi_data.iterrows():
            # ìš°ì„ ìˆœìœ„ ê²°ì • ë° ë‚ ì§œ ì¶”ì¶œ
            priority_used = None
            inbound_date = None
            
            if pd.notna(row['DSV Al Markaz']) and row['DSV Al Markaz'] != '':
                priority_used = 'DSV Al Markaz'
                try:
                    inbound_date = pd.to_datetime(row['DSV Al Markaz'])
                except:
                    continue
            elif pd.notna(row['DSV Indoor']) and row['DSV Indoor'] != '':
                priority_used = 'DSV Indoor'
                try:
                    inbound_date = pd.to_datetime(row['DSV Indoor'])
                except:
                    continue
            else:
                priority_used = 'Status_Location'
                # ë‹¤ë¥¸ ì°½ê³ ì—ì„œ ë‚ ì§œ ì°¾ê¸°
                for warehouse in self.warehouse_columns:
                    if pd.notna(row[warehouse]) and row[warehouse] != '':
                        try:
                            inbound_date = pd.to_datetime(row[warehouse])
                            break
                        except:
                            continue
                if inbound_date is None:
                    continue
            
            # ê³„ì ˆ ë¶„ë¥˜
            season = get_season(inbound_date.month)
            seasonal_patterns[season][priority_used] += 1
        
        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ“Š ê³„ì ˆë³„ ìš°ì„ ìˆœìœ„ ì‚¬ìš© íŒ¨í„´:")
        for season, patterns in seasonal_patterns.items():
            total = sum(patterns.values())
            if total > 0:
                print(f"   {season}:")
                for priority, count in patterns.items():
                    percentage = count / total * 100
                    print(f"     {priority}: {count:,}ê±´ ({percentage:.1f}%)")
        
        return seasonal_patterns
    
    def generate_priority_optimization_report(self):
        """ìš°ì„ ìˆœìœ„ ìµœì í™” ë³´ê³ ì„œ ìƒì„±"""
        print("\nğŸ“‹ ìš°ì„ ìˆœìœ„ ìµœì í™” ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        
        report_file = f"HITACHI_FinalLocation_Priority_Analysis_{self.timestamp}.xlsx"
        
        try:
            with pd.ExcelWriter(report_file, engine='openpyxl') as writer:
                # 1. ë¶„ì„ ìš”ì•½
                summary_data = []
                if 'priority_effectiveness' in self.analysis_results:
                    for priority, data in self.analysis_results['priority_effectiveness'].items():
                        summary_data.append([
                            priority,
                            data['count'],
                            f"{data['percentage']:.1f}%"
                        ])
                
                summary_df = pd.DataFrame(summary_data, columns=['ìš°ì„ ìˆœìœ„', 'ì ìš©_ê±´ìˆ˜', 'ë¹„ìœ¨'])
                summary_df.to_excel(writer, sheet_name='ìš°ì„ ìˆœìœ„_íš¨ê³¼_ìš”ì•½', index=False)
                
                # 2. ì°½ê³  ê³µì¡´ íŒ¨í„´
                if 'coexistence_patterns' in self.analysis_results:
                    patterns = self.analysis_results['coexistence_patterns']['patterns']
                    pattern_data = []
                    for pattern, count in sorted(patterns.items(), key=lambda x: x[1], reverse=True)[:20]:
                        percentage = count / len(self.hitachi_data) * 100
                        pattern_data.append([pattern, count, f"{percentage:.1f}%"])
                    
                    pattern_df = pd.DataFrame(pattern_data, columns=['ì°½ê³ _íŒ¨í„´', 'ê±´ìˆ˜', 'ë¹„ìœ¨'])
                    pattern_df.to_excel(writer, sheet_name='ì°½ê³ _ê³µì¡´_íŒ¨í„´', index=False)
                
                # 3. ì‹œê°„ë³„ íŠ¸ë Œë“œ
                if 'temporal_trends' in self.analysis_results:
                    trend_df = self.analysis_results['temporal_trends']
                    trend_df.to_excel(writer, sheet_name='ì‹œê°„ë³„_ìš°ì„ ìˆœìœ„_íŠ¸ë Œë“œ', index=False)
                
                # 4. ìµœì í™” ê¸°íšŒ
                if 'optimization_opportunities' in self.analysis_results:
                    opt_data = self.analysis_results['optimization_opportunities']
                    
                    # í™œìš©ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
                    util_data = []
                    for warehouse, count in opt_data['utilization_based_priority']:
                        percentage = count / len(self.hitachi_data) * 100
                        util_data.append([warehouse, count, f"{percentage:.1f}%"])
                    
                    util_df = pd.DataFrame(util_data, columns=['ì°½ê³ ', 'í™œìš©ë„', 'ë¹„ìœ¨'])
                    util_df.to_excel(writer, sheet_name='í™œìš©ë„_ê¸°ë°˜_ìš°ì„ ìˆœìœ„', index=False)
                
                # 5. HITACHI ë°ì´í„° (Final_Location í¬í•¨)
                result_df = self.calculate_final_location_with_reasoning()
                result_df.to_excel(writer, sheet_name='HITACHI_Final_Location_ìƒì„¸', index=False)
            
            print(f"âœ… ìš°ì„ ìˆœìœ„ ìµœì í™” ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_file}")
            print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {os.path.getsize(report_file):,} bytes")
            
            return report_file
            
        except Exception as e:
            print(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def calculate_final_location_with_reasoning(self):
        """Final_Location ê³„ì‚° ë° ë…¼ë¦¬ì  ê·¼ê±° ì¶”ê°€"""
        result_df = self.hitachi_data.copy()
        
        # Final_Location ê³„ì‚°
        conditions = [
            result_df['DSV Al Markaz'].notna() & result_df['DSV Al Markaz'].ne(''),
            result_df['DSV Indoor'].notna() & result_df['DSV Indoor'].ne('')
        ]
        
        choices = ['DSV Al Markaz', 'DSV Indoor']
        
        if 'Status_Location' not in result_df.columns:
            result_df['Status_Location'] = 'Unknown'
        
        result_df['Final_Location'] = np.select(conditions, choices, default=result_df['Status_Location'])
        
        # ë…¼ë¦¬ì  ê·¼ê±° ì¶”ê°€
        reasoning = []
        for _, row in result_df.iterrows():
            if pd.notna(row['DSV Al Markaz']) and row['DSV Al Markaz'] != '':
                reasoning.append("ìš°ì„ ìˆœìœ„ 1: DSV Al Markaz ì„ íƒ")
            elif pd.notna(row['DSV Indoor']) and row['DSV Indoor'] != '':
                reasoning.append("ìš°ì„ ìˆœìœ„ 2: DSV Indoor ì„ íƒ")
            else:
                reasoning.append("ìš°ì„ ìˆœìœ„ 3: Status_Location ê¸°ë³¸ê°’ ì‚¬ìš©")
        
        result_df['Final_Location_Reasoning'] = reasoning
        
        return result_df
    
    def run_final_location_analysis(self):
        """Final_Location ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ HITACHI Final_Location íŒŒìƒ ë¡œì§ ì‹¬í™” ë¶„ì„ ì‹œì‘")
        print("=" * 80)
        
        # 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ
        if not self.load_hitachi_data():
            return
        
        # 2ë‹¨ê³„: ìš°ì„ ìˆœìœ„ ë¡œì§ íš¨ê³¼ ë¶„ì„
        priority_effectiveness = self.analyze_priority_logic_effectiveness()
        
        # 3ë‹¨ê³„: ì°½ê³  ê³µì¡´ íŒ¨í„´ ë¶„ì„
        coexistence_patterns = self.analyze_warehouse_coexistence_patterns()
        
        # 4ë‹¨ê³„: ì‹œê°„ë³„ ìš°ì„ ìˆœìœ„ íŠ¸ë Œë“œ ë¶„ì„
        temporal_trends = self.analyze_temporal_priority_trends()
        
        # 5ë‹¨ê³„: ê³„ì ˆë³„ ìš°ì„ ìˆœìœ„ íŒ¨í„´ ë¶„ì„
        seasonal_patterns = self.analyze_seasonal_priority_patterns()
        
        # 6ë‹¨ê³„: ìš°ì„ ìˆœìœ„ ìµœì í™” ê¸°íšŒ ë¶„ì„
        optimization_opportunities = self.analyze_priority_optimization_opportunities()
        
        # 7ë‹¨ê³„: ë³´ê³ ì„œ ìƒì„±
        report_file = self.generate_priority_optimization_report()
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 80)
        print("ğŸ‰ HITACHI Final_Location íŒŒìƒ ë¡œì§ ë¶„ì„ ì™„ë£Œ!")
        print("=" * 80)
        
        print(f"ğŸ“Š í•µì‹¬ ë¶„ì„ ê²°ê³¼:")
        if 'priority_effectiveness' in self.analysis_results:
            for priority, data in self.analysis_results['priority_effectiveness'].items():
                print(f"   {priority}: {data['count']:,}ê±´ ({data['percentage']:.1f}%)")
        
        if 'optimization_opportunities' in self.analysis_results:
            opt_data = self.analysis_results['optimization_opportunities']
            print(f"   ìµœì í™” ì ì¬ë ¥: {opt_data['status_location_optimization']['optimization_potential']:.1f}%")
        
        if report_file:
            print(f"ğŸ“ ìƒì„¸ ë³´ê³ ì„œ: {report_file}")
        
        print("\nâœ… Final_Location ìš°ì„ ìˆœìœ„ ë¡œì§ ìµœì í™” ë¶„ì„ ì™„ë£Œ!")
        
        return self.analysis_results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = HitachiFinalLocationAnalyzer()
    analyzer.run_final_location_analysis()


if __name__ == "__main__":
    main() 