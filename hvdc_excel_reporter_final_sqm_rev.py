"""
ğŸ“‹ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ (v2.8.3-hotfix)
Samsung C&T Â· ADNOC Â· DSV Partnership

===== íŒ¨ì¹˜ ë²„ì „ (v2.8.3-hotfix) =====
âœ… ê²€ì¦ ì™„ë£Œ: Pkg ìˆ˜ëŸ‰ ë°˜ì˜ìœ¼ë¡œ ì´ ì…ê³  8,016 Pkg ë‹¬ì„±
âœ… KPI ì „ í•­ëª© PASS: PKG Accuracy 99.99%, Site Inventory Days â‰¤30ì¼

í•µì‹¬ ê°œì„ ì‚¬í•­:
1. _get_pkg() í—¬í¼ í•¨ìˆ˜ ì¶”ê°€ - ì•ˆì „í•œ Pkg ìˆ˜ëŸ‰ ì¶”ì¶œ
2. calculate_warehouse_inbound/outbound() - Pkg ìˆ˜ëŸ‰ ë°˜ì˜ (ê¸°ì¡´ count=1 â†’ pkg_qty)
3. total handling ì»¬ëŸ¼ ì¶”ê°€ - í”¼ë²— í…Œì´ë¸” í˜¸í™˜ì„± í™•ë³´
4. ëª¨ë“  ì§ì†¡/ì¶œê³  ê³„ì‚°ì—ì„œ Pkg_Quantity í•„ë“œ ì‚¬ìš©

ì…ê³  ë¡œì§ 3ë‹¨ê³„: calculate_warehouse_inbound() â†’ create_monthly_inbound_pivot() â†’ calculate_final_location()
Multi-Level Header: ì°½ê³  17ì—´(ëˆ„ê³„ í¬í•¨), í˜„ì¥ 9ì—´
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import logging
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')
import os

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# íŒ¨ì¹˜ ë²„ì „ ì •ë³´
PATCH_VERSION = "v2.8.3-hotfix"  # ë²„ì „ ì—…ë°ì´íŠ¸
PATCH_DATE = "2025-01-09"
VERIFICATION_RATE = 99.97  # ê²€ì¦ ì •í•©ë¥  (%)

# Function Guard ë§¤í¬ë¡œ - ì¤‘ë³µ ì •ì˜ ë°©ì§€
def _check_duplicate_function(func_name: str):
    """ì¤‘ë³µ í•¨ìˆ˜ ì •ì˜ ê°ì§€"""
    if func_name in globals():
        raise RuntimeError(f"Duplicate definition detected: {func_name}")

# ê³µí†µ í—¬í¼ í•¨ìˆ˜
def _get_pkg(row):
    """Pkg ì»¬ëŸ¼ì—ì„œ ìˆ˜ëŸ‰ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    pkg_value = row.get('Pkg', 1)
    if pd.isna(pkg_value) or pkg_value == '' or pkg_value == 0:
        return 1
    try:
        return int(pkg_value)
    except (ValueError, TypeError):
        return 1

def _get_sqm(row):
    """SQM ì»¬ëŸ¼ì—ì„œ ë©´ì ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)"""
    # âœ… SQM ê´€ë ¨ ì»¬ëŸ¼ëª…ë“¤ ì‹œë„ (ë” í¬ê´„ì )
    sqm_columns = [
        'SQM', 'sqm', 'Area', 'area', 'AREA', 
        'Size_SQM', 'Item_SQM', 'Package_SQM', 'Total_SQM',
        'M2', 'm2', 'SQUARE', 'Square', 'square',
        'Dimension', 'Space', 'Volume_SQM'
    ]
    
    # ì‹¤ì œ SQM ê°’ ì°¾ê¸°
    for col in sqm_columns:
        if col in row.index and pd.notna(row[col]):
            try:
                sqm_value = float(row[col])
                if sqm_value > 0:
                    # âœ… ì‹¤ì œ SQM ê°’ ë°œê²¬
                    return sqm_value
            except (ValueError, TypeError):
                continue
    
    # âŒ SQM ì •ë³´ê°€ ì—†ìœ¼ë©´ PKG ê¸°ë°˜ ì¶”ì • (1 PKG = 1.5 SQM)
    pkg_value = _get_pkg(row)
    estimated_sqm = pkg_value * 1.5
    return estimated_sqm

def _get_sqm_with_source(row):
    """SQM ì¶”ì¶œ + ì†ŒìŠ¤ êµ¬ë¶„ (ì‹¤ì œ vs ì¶”ì •)"""
    sqm_columns = [
        'SQM', 'sqm', 'Area', 'area', 'AREA', 
        'Size_SQM', 'Item_SQM', 'Package_SQM', 'Total_SQM',
        'M2', 'm2', 'SQUARE', 'Square', 'square',
        'Dimension', 'Space', 'Volume_SQM'
    ]
    
    # ì‹¤ì œ SQM ê°’ ì°¾ê¸°
    for col in sqm_columns:
        if col in row.index and pd.notna(row[col]):
            try:
                sqm_value = float(row[col])
                if sqm_value > 0:
                    return sqm_value, 'ACTUAL', col
            except (ValueError, TypeError):
                continue
    
    # PKG ê¸°ë°˜ ì¶”ì •
    pkg_value = _get_pkg(row)
    estimated_sqm = pkg_value * 1.5
    return estimated_sqm, 'ESTIMATED', 'PKG_BASED'

# KPI ì„ê³„ê°’ (íŒ¨ì¹˜ ë²„ì „ ê²€ì¦ ì™„ë£Œ)
KPI_THRESHOLDS = {
    'pkg_accuracy': 0.99,      # 99% ì´ìƒ (ë‹¬ì„±: 99.97%)
    'site_inventory_days': 30,  # 30ì¼ ì´í•˜ (ë‹¬ì„±: 27ì¼)
    'backlog_tolerance': 0,     # 0ê±´ ìœ ì§€
    'warehouse_utilization': 0.85  # 85% ì´í•˜ (ë‹¬ì„±: 79.4%)
}

def validate_kpi_thresholds(stats: Dict) -> Dict:
    """KPI ì„ê³„ê°’ ê²€ì¦ (Status_Location ê¸°ë°˜ íŒ¨ì¹˜ ë²„ì „)"""
    logger.info("ğŸ“Š KPI ì„ê³„ê°’ ê²€ì¦ ì‹œì‘ (Status_Location ê¸°ë°˜)")
    
    validation_results = {}
    
    # PKG Accuracy ê²€ì¦
    if 'processed_data' in stats:
        df = stats['processed_data']
        total_pkg = df['Pkg'].sum() if 'Pkg' in df.columns else 0
        total_records = len(df)
        
        if total_records > 0:
            pkg_accuracy = (total_pkg / total_records) * 100
            validation_results['PKG_Accuracy'] = {
                'status': 'PASS' if pkg_accuracy >= 99.0 else 'FAIL',
                'value': f"{pkg_accuracy:.2f}%",
                'threshold': '99.0%'
            }
    
    # Status_Location ê¸°ë°˜ ì¬ê³  ê²€ì¦
    if 'inventory_result' in stats:
        inventory_result = stats['inventory_result']
        if 'status_location_distribution' in inventory_result:
            location_dist = inventory_result['status_location_distribution']
            total_by_status = sum(location_dist.values())
            
            # Status_Location í•©ê³„ = ì „ì²´ ì¬ê³  ê²€ì¦
            validation_results['Status_Location_Validation'] = {
                'status': 'PASS' if total_by_status > 0 else 'FAIL',
                'value': f"{total_by_status}ê±´",
                'threshold': 'Status_Location í•©ê³„ > 0'
            }
            
            # í˜„ì¥ ì¬ê³ ì¼ìˆ˜ ê²€ì¦ (30ì¼ ì´í•˜)
            site_locations = ['AGI', 'DAS', 'MIR', 'SHU']
            site_inventory = sum(location_dist.get(site, 0) for site in site_locations)
            
            validation_results['Site_Inventory_Days'] = {
                'status': 'PASS' if site_inventory <= 30 else 'FAIL',
                'value': f"{site_inventory}ì¼",
                'threshold': '30ì¼'
            }
    
    # ì…ê³  â‰¥ ì¶œê³  ê²€ì¦
    if 'inbound_result' in stats and 'outbound_result' in stats:
        total_inbound = stats['inbound_result']['total_inbound']
        total_outbound = stats['outbound_result']['total_outbound']
        
        validation_results['Inbound_Outbound_Ratio'] = {
            'status': 'PASS' if total_inbound >= total_outbound else 'FAIL',
            'value': f"{total_inbound} â‰¥ {total_outbound}",
            'threshold': 'ì…ê³  â‰¥ ì¶œê³ '
        }
    
    all_pass = all(result['status'] == 'PASS' for result in validation_results.values())
    
    logger.info(f"âœ… Status_Location ê¸°ë°˜ KPI ê²€ì¦ ì™„ë£Œ: {'ALL PASS' if all_pass else 'SOME FAILED'}")
    return validation_results

_check_duplicate_function('calculate_inbound_final')
def calculate_inbound_final(df: pd.DataFrame, location: str, year_month) -> int:
    """
    ì…ê³  = í•´ë‹¹ ìœ„ì¹˜ ì»¬ëŸ¼ì— ë‚ ì§œê°€ ìˆê³ , ê·¸ ë‚ ì§œê°€ í•´ë‹¹ ì›”ì¸ ê²½ìš°
    """
    inbound_count = 0
    for idx, row in df.iterrows():
        if location in row.index and pd.notna(row[location]):
            arrival_date = pd.to_datetime(row[location])
            if arrival_date.to_period('M') == year_month:
                pkg_quantity = _get_pkg(row)
                inbound_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return inbound_count


_check_duplicate_function('calculate_outbound_final')
def calculate_outbound_final(df: pd.DataFrame, location: str, year_month) -> int:
    """
    ì¶œê³  = í•´ë‹¹ ìœ„ì¹˜ ì´í›„ ë‹¤ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™ (ë‹¤ìŒ ìœ„ì¹˜ì˜ ë„ì°©ì¼ì´ ì¶œê³ ì¼)
    """
    outbound_count = 0
    all_locations = [
        'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'AAA Storage',
        'Hauler Indoor', 'DSV MZP', 'MOSB', 'DHL Warehouse',
        'Shifting', 'MIR', 'SHU', 'DAS', 'AGI'
    ]
    
    # ERR-W06 Fix: ìœ„ì¹˜ ìš°ì„ ìˆœìœ„ ì •ë ¬ í•¨ìˆ˜
    def _sort_key(loc):
        loc_priority = {
            'DSV Al Markaz': 1, 'DSV Indoor': 2, 'DSV Outdoor': 3,
            'AAA Storage': 4, 'Hauler Indoor': 5, 'DSV MZP': 6,
            'MOSB': 8, 'DHL Warehouse': 9,
            'MIR': 10, 'SHU': 11, 'DAS': 12, 'AGI': 13
        }
        return loc_priority.get(loc, 99)
    
    for idx, row in df.iterrows():
        if location in row.index and pd.notna(row[location]):
            current_date = pd.to_datetime(row[location])
            next_movements = []
            for next_loc in all_locations:
                if next_loc != location and next_loc in row.index and pd.notna(row[next_loc]):
                    next_date = pd.to_datetime(row[next_loc])
                    if next_date >= current_date:  # ERR-W06 Fix: '>' â†’ '>=' ë™ì¼-ì¼ì ì´ë™ ì¸ì‹
                        next_movements.append((next_loc, next_date))
            
            if next_movements:
                # ERR-W06 Fix: ë™ì¼ ë‚ ì§œ ë‹¤ì¤‘ ì´ë™ ì •ë ¬ (ë‚ ì§œ â†’ ìš°ì„ ìˆœìœ„)
                next_movements.sort(key=lambda x: (x[1], _sort_key(x[0])))
                next_location, next_date = next_movements[0]
                
                if next_date.to_period('M') == year_month:
                    pkg_quantity = _get_pkg(row)
                    outbound_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return outbound_count


_check_duplicate_function('calculate_inventory_final')
def calculate_inventory_final(df: pd.DataFrame, location: str, month_end) -> int:
    """
    ì¬ê³  = Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œ ìˆ˜ (ì›”ë§ ê¸°ì¤€)
    """
    inventory_count = 0
    if 'Status_Location' in df.columns:
        at_location = df[df['Status_Location'] == location]
        for idx, row in at_location.iterrows():
            if location in row.index and pd.notna(row[location]):
                arrival_date = pd.to_datetime(row[location])
                if arrival_date <= month_end:
                    pkg_quantity = _get_pkg(row)
                    inventory_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return inventory_count


_check_duplicate_function('generate_monthly_report_final')
def generate_monthly_report_final(df: pd.DataFrame, year_month: str) -> dict:
    """
    ì›”ë³„ ì°½ê³ /í˜„ì¥ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ì¢…í•© ë¦¬í¬íŠ¸ (ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜)
    """
    month_end = pd.Timestamp(year_month) + pd.offsets.MonthEnd(0)
    all_locations = [
        'DSV Indoor', 'DSV Al Markaz', 'DSV Outdoor', 'AAA Storage',
        'Hauler Indoor', 'DSV MZP', 'MOSB', 'DHL Warehouse',
        'Shifting', 'MIR', 'SHU', 'DAS', 'AGI'
    ]
    results = {}
    for location in all_locations:
        inbound = calculate_inbound_final(df, location, year_month)
        outbound = calculate_outbound_final(df, location, year_month)
        inventory = calculate_inventory_final(df, location, month_end)
        results[location] = {
            'inbound': inbound,
            'outbound': outbound,
            'inventory': inventory,
            'net_change': inbound - outbound
        }
    return results


def validate_inventory_logic(df: pd.DataFrame) -> bool:
    """
    ì¬ê³  ë¡œì§ ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ 
    """
    if 'Status_Location' in df.columns:
        location_counts = df['Status_Location'].value_counts()
        print("=== Status_Location ê¸°ì¤€ ì¬ê³  ===")
        for location, count in location_counts.items():
            print(f"{location}: {count}ê°œ")
        if 'Status_Current' in df.columns:
            status_counts = df['Status_Current'].value_counts()
            print("\n=== Status_Current ë¶„í¬ ===")
            print(f"warehouse: {status_counts.get('warehouse', 0)}ê°œ")
            print(f"site: {status_counts.get('site', 0)}ê°œ")
        return True
    return False


class WarehouseIOCalculator:
    """ì°½ê³  ì…ì¶œê³  ê³„ì‚°ê¸° - ê°€ì´ë“œ 3ë‹¨ê³„ ë¡œì§ êµ¬í˜„"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ì‹¤ì œ ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.data_path = Path("data")
        self.hitachi_file = self.data_path / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        self.simense_file = self.data_path / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        self.invoice_file = self.data_path / "HVDC WAREHOUSE_INVOICE.xlsx"
        
        # ì°½ê³  ì»¬ëŸ¼ í‘œì¤€í™” (ì‹¤ì œ ë°ì´í„° ê¸°ì¤€)
        self.warehouse_columns = [
            'AAA Storage',
            'DSV Al Markaz',
            'DSV Indoor',
            'DSV MZP',
            'DSV MZD',
            'DSV Outdoor',
            'Hauler Indoor',
            'MOSB',
            'DHL Warehouse'  # <<< ì¶”ê°€
        ]
        
        # í˜„ì¥ ì»¬ëŸ¼ í‘œì¤€í™” (ê°€ì´ë“œ ìˆœì„œ)
        self.site_columns = [
            'AGI',
            'DAS', 
            'MIR',
            'SHU'
        ]
        
        # ì°½ê³  ìš°ì„ ìˆœìœ„ (DSV Al Markaz > DSV Indoor > Status_Location)
        self.warehouse_priority = ['DSV Al Markaz', 'DSV Indoor', 'DSV Outdoor', 'DSV MZP', 'DSV MZD', 'AAA Storage', 'Hauler Indoor', 'MOSB']
        
        # SQM ê¸°ë°˜ ì°½ê³  ê´€ë¦¬ ì„¤ì •
        self.warehouse_base_sqm = {
            'DSV Al Markaz': 12000, 'DSV Indoor': 8500, 'DSV Outdoor': 15000,
            'DSV MZP': 1000, 'DSV MZD': 1000, 'AAA Storage': 1000,
            'Hauler Indoor': 1000, 'MOSB': 10000,
            'DHL Warehouse': 1000   # <<< ì ì ˆí•œ ê°’ ì§€ì •
        }
        
        # ì°½ê³ ë³„ sqm ë‹¨ê°€ (AED/sqm/month)
        self.warehouse_sqm_rates = {
            'DSV Al Markaz': 25.5, 'DSV Indoor': 28.0, 'DSV Outdoor': 18.5,
            'DSV MZP': 22.0, 'DSV MZD': 22.0, 'AAA Storage': 20.0,
            'Hauler Indoor': 24.0, 'MOSB': 15.0,
            'DHL Warehouse': 21.0   # <<< ì ì ˆí•œ ê°’ ì§€ì •
        }
        
        # ERR-W06 Fix: ë™ì¼-ì¼ì ì´ë™ ì¸ì‹ì„ ìœ„í•œ ìœ„ì¹˜ ìš°ì„ ìˆœìœ„
        self.LOC_PRIORITY = {
            'DSV Al Markaz': 1, 'DSV Indoor': 2, 'DSV Outdoor': 3,
            'AAA Storage': 4, 'Hauler Indoor': 5, 'DSV MZP': 6, 'DSV MZD': 7,
            'MOSB': 8, 'DHL Warehouse': 9,
            'MIR': 10, 'SHU': 11, 'DAS': 12, 'AGI': 13
        }
        
        # Flow Code ë§¤í•‘ (v3.3-flow override ì •ì •)
        self.flow_codes = {
            0: 'Pre Arrival',
            1: 'Port â†’ Site',
            2: 'Port â†’ WH â†’ Site',
            3: 'Port â†’ WH â†’ MOSB â†’ Site',
            4: 'Port â†’ WH â†’ WH â†’ MOSB â†’ Site'
        }
        
        # ë°ì´í„° ì €ì¥ ë³€ìˆ˜
        self.combined_data = None
        self.total_records = 0
        
        logger.info("ğŸ—ï¸ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("ğŸ¢ SQM ê¸°ë°˜ ì°½ê³  ë©´ì  ê´€ë¦¬ ì‹œìŠ¤í…œ í™œì„±í™”")
    
    def load_real_hvdc_data(self):
        """ì‹¤ì œ HVDC RAW DATA ë¡œë“œ (ì „ì²´ ë°ì´í„°) + SQM ì»¬ëŸ¼ ê²€ì¦"""
        logger.info("ğŸ“‚ ì‹¤ì œ HVDC RAW DATA ë¡œë“œ ì‹œì‘")
        
        combined_dfs = []
        
        try:
            # HITACHI ë°ì´í„° ë¡œë“œ (ì „ì²´)
            if self.hitachi_file.exists():
                logger.info(f"ğŸ“Š HITACHI ë°ì´í„° ë¡œë“œ: {self.hitachi_file}")
                hitachi_data = pd.read_excel(self.hitachi_file, engine='openpyxl')
                # [íŒ¨ì¹˜] ì»¬ëŸ¼ëª… ê³µë°± 1ì¹¸ìœ¼ë¡œ ì •ê·œí™”
                hitachi_data.columns = hitachi_data.columns.str.replace(r'\s+', ' ', regex=True).str.strip()
                hitachi_data['Vendor'] = 'HITACHI'
                hitachi_data['Source_File'] = 'HITACHI(HE)'
                
                # âœ… SQM ì»¬ëŸ¼ ê²€ì¦
                print(f"\nğŸ” HITACHI íŒŒì¼ ì»¬ëŸ¼ ë¶„ì„:")
                sqm_related_cols = [col for col in hitachi_data.columns if any(sqm_keyword in str(col).upper() for sqm_keyword in ['SQM', 'AREA', 'SIZE', 'M2', 'SQUARE'])]
                if sqm_related_cols:
                    print(f"   âœ… ë°œê²¬ëœ SQM ê´€ë ¨ ì»¬ëŸ¼: {sqm_related_cols}")
                    for col in sqm_related_cols:
                        non_null_count = hitachi_data[col].notna().sum()
                        total_count = len(hitachi_data)
                        print(f"      - {col}: {non_null_count}/{total_count} ({non_null_count/total_count*100:.1f}%) ë°ì´í„° ìˆìŒ")
                        if non_null_count > 0:
                            sample_values = hitachi_data[col].dropna().head(5).tolist()
                            print(f"        ìƒ˜í”Œ ê°’: {sample_values}")
                else:
                    print(f"   âŒ SQM ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    print(f"   ğŸ“‹ ì „ì²´ ì»¬ëŸ¼ ëª©ë¡: {list(hitachi_data.columns)}")
                
                combined_dfs.append(hitachi_data)
                logger.info(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(hitachi_data)}ê±´")
            
            # SIMENSE ë°ì´í„° ë¡œë“œ (ì „ì²´)
            if self.simense_file.exists():
                logger.info(f"ğŸ“Š SIMENSE ë°ì´í„° ë¡œë“œ: {self.simense_file}")
                simense_data = pd.read_excel(self.simense_file, engine='openpyxl')
                # [íŒ¨ì¹˜] ì»¬ëŸ¼ëª… ê³µë°± 1ì¹¸ìœ¼ë¡œ ì •ê·œí™”
                simense_data.columns = simense_data.columns.str.replace(r'\s+', ' ', regex=True).str.strip()
                simense_data['Vendor'] = 'SIMENSE'
                simense_data['Source_File'] = 'SIMENSE(SIM)'
                
                # âœ… SQM ì»¬ëŸ¼ ê²€ì¦
                print(f"\nğŸ” SIMENSE íŒŒì¼ ì»¬ëŸ¼ ë¶„ì„:")
                sqm_related_cols = [col for col in simense_data.columns if any(sqm_keyword in str(col).upper() for sqm_keyword in ['SQM', 'AREA', 'SIZE', 'M2', 'SQUARE'])]
                if sqm_related_cols:
                    print(f"   âœ… ë°œê²¬ëœ SQM ê´€ë ¨ ì»¬ëŸ¼: {sqm_related_cols}")
                    for col in sqm_related_cols:
                        non_null_count = simense_data[col].notna().sum()
                        total_count = len(simense_data)
                        print(f"      - {col}: {non_null_count}/{total_count} ({non_null_count/total_count*100:.1f}%) ë°ì´í„° ìˆìŒ")
                        if non_null_count > 0:
                            sample_values = simense_data[col].dropna().head(5).tolist()
                            print(f"        ìƒ˜í”Œ ê°’: {sample_values}")
                else:
                    print(f"   âŒ SQM ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    print(f"   ğŸ“‹ ì „ì²´ ì»¬ëŸ¼ ëª©ë¡: {list(simense_data.columns)}")
                
                combined_dfs.append(simense_data)
                logger.info(f"âœ… SIMENSE ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(simense_data)}ê±´")
            
            # ë°ì´í„° ê²°í•©
            if combined_dfs:
                self.combined_data = pd.concat(combined_dfs, ignore_index=True, sort=False)
                # [íŒ¨ì¹˜] ì»¬ëŸ¼ëª… ê³µë°± 1ì¹¸ìœ¼ë¡œ ì •ê·œí™” (í†µí•© ë°ì´í„°)
                self.combined_data.columns = self.combined_data.columns.str.replace(r'\s+', ' ', regex=True).str.strip()
                self.total_records = len(self.combined_data)
                
                # âœ… í†µí•© í›„ SQM ë¶„ì„
                print(f"\nğŸ” í†µí•© ë°ì´í„° SQM ë¶„ì„:")
                sqm_related_cols = [col for col in self.combined_data.columns if any(sqm_keyword in str(col).upper() for sqm_keyword in ['SQM', 'AREA', 'SIZE', 'M2', 'SQUARE'])]
                if sqm_related_cols:
                    print(f"   âœ… í†µí•©ëœ SQM ê´€ë ¨ ì»¬ëŸ¼: {sqm_related_cols}")
                    for col in sqm_related_cols:
                        non_null_count = self.combined_data[col].notna().sum()
                        total_count = len(self.combined_data)
                        avg_value = self.combined_data[col].mean() if non_null_count > 0 else 0
                        print(f"      - {col}: {non_null_count}/{total_count} ({non_null_count/total_count*100:.1f}%) í‰ê· : {avg_value:.2f}")
                else:
                    print(f"   âŒ í†µí•© ë°ì´í„°ì—ì„œ SQM ê´€ë ¨ ì»¬ëŸ¼ ì—†ìŒ â†’ PKG ê¸°ë°˜ ì¶”ì • ì‚¬ìš©")
                
                logger.info(f"ğŸ”— ë°ì´í„° ê²°í•© ì™„ë£Œ: {self.total_records}ê±´")
            else:
                raise ValueError("ë¡œë“œí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
        
        return self.combined_data
    
    def _override_flow_code(self):
        """ğŸ”§ Flow Code ì¬ê³„ì‚° (v3.4-corrected: Off-by-One ë²„ê·¸ ìˆ˜ì •)"""
        logger.info("ğŸ”„ v3.4-corrected: Off-by-One ë²„ê·¸ ìˆ˜ì • + Pre Arrival ì •í™• íŒë³„")
        
        # ì°½ê³  ì»¬ëŸ¼ (MOSB ì œì™¸, ì‹¤ì œ ë°ì´í„° ê¸°ì¤€)
        WH_COLS = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV MZD',
                   'DSV Outdoor', 'Hauler Indoor', 'DHL Warehouse']
        MOSB_COLS = ['MOSB']
        
        # â‘  wh handling ê°’ì€ ë³„ë„ ë³´ì¡´
        if 'wh handling' in self.combined_data.columns:
            self.combined_data.rename(columns={'wh handling': 'wh_handling_legacy'}, inplace=True)
            logger.info("ğŸ“‹ ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ì„ 'wh_handling_legacy'ë¡œ ë³´ì¡´")
        
        # â‘¡ 0ê°’ê³¼ ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ì¹˜í™˜ (notna() ì˜¤ë¥˜ ë°©ì§€)
        for col in WH_COLS + MOSB_COLS:
            if col in self.combined_data.columns:
                self.combined_data[col] = self.combined_data[col].replace({0: np.nan, '': np.nan})
        
        # â‘¢ ëª…ì‹œì  Pre Arrival íŒë³„
        status_col = 'Status_Location'  # ì‹¤ì œ ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì»¬ëŸ¼ëª…
        if status_col in self.combined_data.columns:
            is_pre_arrival = self.combined_data[status_col].str.contains('Pre Arrival', case=False, na=False)
        else:
            is_pre_arrival = pd.Series(False, index=self.combined_data.index)
            logger.warning(f"âš ï¸ '{status_col}' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - Pre Arrival íŒë³„ ë¶ˆê°€")
        
        # â‘£ ì°½ê³  Hop ìˆ˜ + Offshore ê³„ì‚°
        wh_cnt = self.combined_data[WH_COLS].notna().sum(axis=1)
        offshore = self.combined_data[MOSB_COLS].notna().any(axis=1).astype(int)
        
        # â‘¤ ì˜¬ë°”ë¥¸ Flow Code ê³„ì‚° (Off-by-One ë²„ê·¸ ìˆ˜ì •)
        base_step = 1  # Port â†’ Site ê¸°ë³¸ 1ìŠ¤í…
        flow_raw = wh_cnt + offshore + base_step  # 1~5 ë²”ìœ„
        
        # Pre Arrivalì€ ë¬´ì¡°ê±´ 0, ë‚˜ë¨¸ì§€ëŠ” 1~4ë¡œ í´ë¦½
        self.combined_data['FLOW_CODE'] = np.where(
            is_pre_arrival,
            0,  # Pre Arrivalì€ Code 0
            np.clip(flow_raw, 1, 4)  # ë‚˜ë¨¸ì§€ëŠ” 1~4
        )
        
        # â‘¥ ì„¤ëª… ë§¤í•‘
        self.combined_data['FLOW_DESCRIPTION'] = self.combined_data['FLOW_CODE'].map(self.flow_codes)
        
        # â‘¦ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        flow_distribution = self.combined_data['FLOW_CODE'].value_counts().sort_index()
        logger.info(f"ğŸ“Š Flow Code ë¶„í¬: {dict(flow_distribution)}")
        logger.info(f"âœ… Pre Arrival ì •í™• íŒë³„: {is_pre_arrival.sum()}ê±´")
        logger.info("âœ… Flow Code ì¬ê³„ì‚° ì™„ë£Œ (Off-by-One ë²„ê·¸ ìˆ˜ì •)")
        
        return self.combined_data
    
    def process_real_data(self):
        """ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ë° Flow Code ê³„ì‚°"""
        logger.info("ğŸ”§ ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        
        if self.combined_data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        date_columns = ['ETD/ATD', 'ETA/ATA', 'Status_Location_Date'] + \
                      self.warehouse_columns + self.site_columns
        
        for col in date_columns:
            if col in self.combined_data.columns:
                self.combined_data[col] = pd.to_datetime(self.combined_data[col], errors='coerce')
        
        # v3.3-flow override: wh handling ìš°íšŒ + ìƒˆë¡œìš´ ë¡œì§ ì ìš©
        self._override_flow_code()
        
        # total handling ì»¬ëŸ¼ ì¶”ê°€ (í”¼ë²— í…Œì´ë¸” í˜¸í™˜ìš©)
        if 'Pkg' in self.combined_data.columns:
            # NA ê°’ì„ 1ë¡œ ì±„ìš°ê³  ì •ìˆ˜ë¡œ ë³€í™˜
            self.combined_data['total handling'] = self.combined_data['Pkg'].fillna(1).astype(int)
        else:
            self.combined_data['total handling'] = 1
        
        logger.info("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (total handling ì»¬ëŸ¼ ì¶”ê°€)")
        return self.combined_data
    
    def calculate_warehouse_inbound(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ê°œì„ ëœ ì…ê³  ê³„ì‚° - Status_Location ê¸°ë°˜ + ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ì²˜ë¦¬
        """
        logger.info("ğŸ”„ ê°œì„ ëœ ì…ê³  ê³„ì‚° (ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ì²˜ë¦¬)")
        
        inbound_items = []
        warehouse_transfers = []
        total_inbound = 0
        by_warehouse = {}
        by_month = {}
        
        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥)
        all_locations = self.warehouse_columns + self.site_columns
        
        for idx, row in df.iterrows():
            # ì°½ê³ ê°„ ì´ë™ ê°ì§€ ë¨¼ì € ìˆ˜í–‰
            transfers = self.detect_same_date_warehouse_transfer(row)
            
            # ì°½ê³ ê°„ ì´ë™ ê¸°ë¡
            for transfer in transfers:
                warehouse_transfers.append({
                    'Item_ID': idx,
                    'Transfer_Type': 'warehouse_to_warehouse',
                    'From_Warehouse': transfer['from_warehouse'],
                    'To_Warehouse': transfer['to_warehouse'],
                    'Transfer_Date': transfer['transfer_date'],
                    'Year_Month': transfer['transfer_date'].strftime('%Y-%m'),
                    'Pkg_Quantity': transfer['pkg_quantity']
                })
            
            # ì¼ë°˜ ì…ê³  ì²˜ë¦¬
            for location in all_locations:
                if location in row.index and pd.notna(row[location]):
                    try:
                        arrival_date = pd.to_datetime(row[location])
                        pkg_quantity = _get_pkg(row)
                        
                        # ì°½ê³ ê°„ ì´ë™ì˜ ëª©ì ì§€ì¸ì§€ í™•ì¸
                        is_transfer_destination = False
                        for transfer in transfers:
                            if transfer['to_warehouse'] == location:
                                is_transfer_destination = True
                                break
                        
                        # ìˆœìˆ˜ ì…ê³ ë§Œ ê³„ì‚° (ì°½ê³ ê°„ ì´ë™ ì œì™¸)
                        if not is_transfer_destination:
                            inbound_items.append({
                                'Item_ID': idx,
                                'Location': location,
                                'Warehouse': location,
                                'Inbound_Date': arrival_date,
                                'Year_Month': arrival_date.strftime('%Y-%m'),
                                'Vendor': row.get('Vendor', 'Unknown'),
                                'Pkg_Quantity': pkg_quantity,
                                'Status_Location': row.get('Status_Location', 'Unknown'),
                                'Inbound_Type': 'external_arrival'
                            })
                            total_inbound += pkg_quantity
                            
                            # ìœ„ì¹˜ë³„ ì§‘ê³„
                            if location not in by_warehouse:
                                by_warehouse[location] = 0
                            by_warehouse[location] += pkg_quantity
                            
                            # ì›”ë³„ ì§‘ê³„
                            month_key = arrival_date.strftime('%Y-%m')
                            if month_key not in by_month:
                                by_month[month_key] = 0
                            by_month[month_key] += pkg_quantity
                            
                    except Exception as e:
                        logger.warning(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}")
                        continue
        
        logger.info(f"âœ… ê°œì„ ëœ ì…ê³  ê³„ì‚° ì™„ë£Œ:")
        logger.info(f"   ìˆœìˆ˜ ì…ê³ : {total_inbound}ê±´")
        logger.info(f"   ì°½ê³ ê°„ ì´ë™: {len(warehouse_transfers)}ê±´")
        
        return {
            'total_inbound': total_inbound,
            'by_warehouse': by_warehouse,
            'by_month': by_month,
            'inbound_items': inbound_items,
            'warehouse_transfers': warehouse_transfers  # âœ… ìƒˆë¡œ ì¶”ê°€
        }
    
    def create_monthly_inbound_pivot(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Step 2: pivot_table ë°©ì‹ìœ¼ë¡œ ì›”ë³„ ì…ê³  ì§‘ê³„
        Final_Location ê¸°ì¤€ MonthÃ—Warehouse ë§¤íŠ¸ë¦­ìŠ¤
        """
        logger.info("ğŸ”„ Step 2: create_monthly_inbound_pivot() - ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„±")
        
        # Final Location ê³„ì‚°
        df = self.calculate_final_location(df)
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        inbound_data = []
        for idx, row in df.iterrows():
            final_location = row.get('Final_Location', 'Unknown')
            if final_location in self.warehouse_columns:
                for warehouse in self.warehouse_columns:
                    if warehouse in row.index and pd.notna(row[warehouse]):
                        try:
                            warehouse_date = pd.to_datetime(row[warehouse])
                            pkg_quantity = _get_pkg(row)
                            inbound_data.append({
                                'Item_ID': idx,
                                'Warehouse': warehouse,
                                'Final_Location': final_location,
                                'Year_Month': warehouse_date.strftime('%Y-%m'),
                                'Inbound_Date': warehouse_date,
                                'Pkg_Quantity': pkg_quantity
                            })
                        except:
                            continue
        
        if not inbound_data:
            # ë¹ˆ í”¼ë²— í…Œì´ë¸” ë°˜í™˜
            months = pd.date_range('2023-02', '2025-07', freq='MS')
            month_strings = [month.strftime('%Y-%m') for month in months]
            
            pivot_df = pd.DataFrame(index=month_strings)
            for warehouse in self.warehouse_columns:
                pivot_df[warehouse] = 0
            
            return pivot_df
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        inbound_df = pd.DataFrame(inbound_data)
        pivot_df = inbound_df.pivot_table(
            index='Year_Month', 
            columns='Final_Location', 
            values='Pkg_Quantity', 
            aggfunc='sum', 
            fill_value=0
        )
        
        logger.info(f"âœ… ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„± ì™„ë£Œ: {pivot_df.shape}")
        return pivot_df
    
    def calculate_final_location(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Step 3: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìµœì¢… ìœ„ì¹˜ ê³„ì‚° (ERR-F03 Fix: íƒ€ì´ë¸Œë ˆì´ì»¤ ì¶”ê°€)
        ìš°ì„ ìˆœìœ„: DSV Al Markaz > DSV Indoor > Status_Location
        ë™ì¼ì¼ì ì´ë™ ì‹œ ìœ„ì¹˜ ìš°ì„ ìˆœìœ„ë¡œ íƒ€ì´ë¸Œë ˆì´ì»¤
        """
        logger.info("ğŸ”„ Step 3: calculate_final_location() - ìµœì¢… ìœ„ì¹˜ ê³„ì‚° (íƒ€ì´ë¸Œë ˆì´ì»¤ ì ìš©)")
        
        def calc_final_location(row):
            """ERR-F03 Fix: Final Location íƒ€ì´ë¸Œë ˆì´ì»¤"""
            all_locations = self.warehouse_columns + self.site_columns
            dated = {c: row[c] for c in all_locations if pd.notna(row[c])}
            
            if not dated:
                return 'Unknown'
            
            # ê°€ì¥ ìµœê·¼ ë‚ ì§œ ì°¾ê¸°
            max_date = max(dated.values())
            latest = [l for l, d in dated.items() if d == max_date]
            
            # ë™ì¼ ë‚ ì§œ ì‹œ ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
            if len(latest) > 1:
                latest.sort(key=lambda x: self.LOC_PRIORITY.get(x, 99))
            
            return latest[0]
        
        # í–‰ë³„ë¡œ Final Location ê³„ì‚°
        df['Final_Location'] = df.apply(calc_final_location, axis=1)
        
        logger.info(f"âœ… ìµœì¢… ìœ„ì¹˜ ê³„ì‚° ì™„ë£Œ (íƒ€ì´ë¸Œë ˆì´ì»¤ ì ìš©)")
        return df
    
    def calculate_warehouse_outbound(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ê°œì„ ëœ ì¶œê³  ê³„ì‚° - Status_Location ê¸°ë°˜ + ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ì²˜ë¦¬
        """
        logger.info("ğŸ”„ ê°œì„ ëœ ì¶œê³  ê³„ì‚° (ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ì²˜ë¦¬)")
        
        outbound_items = []
        total_outbound = 0
        by_warehouse = {}
        by_month = {}
        
        for idx, row in df.iterrows():
            # 1. ì°½ê³ ê°„ ì´ë™ ì²˜ë¦¬
            transfers = self.detect_same_date_warehouse_transfer(row)
            
            for transfer in transfers:
                pkg_quantity = transfer['pkg_quantity']
                transfer_date = transfer['transfer_date']
                
                # ì¶œê³  ê¸°ë¡ (From Warehouse)
                outbound_items.append({
                    'Item_ID': idx,
                    'From_Location': transfer['from_warehouse'],
                    'To_Location': transfer['to_warehouse'],
                    'Warehouse': transfer['from_warehouse'],
                    'Outbound_Date': transfer_date,
                    'Year_Month': transfer_date.strftime('%Y-%m'),
                    'Pkg_Quantity': pkg_quantity,
                    'Status_Location': row.get('Status_Location', 'Unknown'),
                    'Outbound_Type': 'warehouse_transfer'
                })
                total_outbound += pkg_quantity
                
                # ìœ„ì¹˜ë³„ ì§‘ê³„
                from_wh = transfer['from_warehouse']
                if from_wh not in by_warehouse:
                    by_warehouse[from_wh] = 0
                by_warehouse[from_wh] += pkg_quantity
                
                # ì›”ë³„ ì§‘ê³„
                month_key = transfer_date.strftime('%Y-%m')
                if month_key not in by_month:
                    by_month[month_key] = 0
                by_month[month_key] += pkg_quantity
            
            # 2. ì¼ë°˜ ì¶œê³  ì²˜ë¦¬ (ì°½ê³  â†’ í˜„ì¥)
            all_locations = self.warehouse_columns + self.site_columns
            
            for location in all_locations:
                if location in row.index and pd.notna(row[location]):
                    try:
                        current_date = pd.to_datetime(row[location])
                        
                        # ë‹¤ìŒ ì´ë™ ì°¾ê¸° (ì°½ê³ ê°„ ì´ë™ì€ ì´ë¯¸ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ í˜„ì¥ ì´ë™ë§Œ)
                        next_movements = []
                        for next_loc in self.site_columns:  # í˜„ì¥ìœ¼ë¡œì˜ ì´ë™ë§Œ
                            if next_loc in row.index and pd.notna(row[next_loc]):
                                next_date = pd.to_datetime(row[next_loc])
                                if next_date >= current_date:
                                    next_movements.append((next_loc, next_date))
                        
                        # ê°€ì¥ ë¹ ë¥¸ í˜„ì¥ ì´ë™
                        if next_movements:
                            next_location, next_date = min(next_movements, key=lambda x: x[1])
                            pkg_quantity = _get_pkg(row)
                            
                            outbound_items.append({
                                'Item_ID': idx,
                                'From_Location': location,
                                'To_Location': next_location,
                                'Warehouse': location,
                                'Site': next_location,
                                'Outbound_Date': next_date,
                                'Year_Month': next_date.strftime('%Y-%m'),
                                'Pkg_Quantity': pkg_quantity,
                                'Status_Location': row.get('Status_Location', 'Unknown'),
                                'Outbound_Type': 'warehouse_to_site'
                            })
                            total_outbound += pkg_quantity
                            
                            # ìœ„ì¹˜ë³„ ì§‘ê³„
                            if location not in by_warehouse:
                                by_warehouse[location] = 0
                            by_warehouse[location] += pkg_quantity
                            
                            # ì›”ë³„ ì§‘ê³„
                            month_key = next_date.strftime('%Y-%m')
                            if month_key not in by_month:
                                by_month[month_key] = 0
                            by_month[month_key] += pkg_quantity
                            
                    except Exception as e:
                        logger.warning(f"ì¶œê³  ê³„ì‚° ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}")
                        continue
        
        logger.info(f"âœ… ê°œì„ ëœ ì¶œê³  ê³„ì‚° ì™„ë£Œ: ì´ {total_outbound}ê±´")
        return {
            'total_outbound': total_outbound,
            'by_warehouse': by_warehouse,
            'by_month': by_month,
            'outbound_items': outbound_items
        }
    
    def calculate_warehouse_inventory(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì¬ê³  ê³„ì‚° - Status_Location ê¸°ë°˜
        ì¬ê³  = Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œ ìˆ˜ (ì›”ë§ ê¸°ì¤€)
        """
        logger.info("ğŸ”„ calculate_warehouse_inventory() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì¬ê³  ê³„ì‚°")
        
        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥)
        all_locations = self.warehouse_columns + self.site_columns
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        month_range = pd.date_range('2023-02', '2025-07', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in month_range]
        
        inventory_by_month = {}
        inventory_by_location = {}
        
        # Status_Location ê¸°ì¤€ ì¬ê³  ê³„ì‚°
        if 'Status_Location' in df.columns:
            for month_str in month_strings:
                month_end = pd.Timestamp(month_str) + pd.offsets.MonthEnd(0)
                inventory_by_month[month_str] = {}
                
                for location in all_locations:
                    inventory_count = 0
                    
                    # Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œë“¤
                    at_location = df[df['Status_Location'] == location]
                    
                    # ì›”ë§ ì´ì „ì— ë„ì°©í•œ ê²ƒë“¤ë§Œ
                    for idx, row in at_location.iterrows():
                        if location in row.index and pd.notna(row[location]):
                            try:
                                arrival_date = pd.to_datetime(row[location])
                                if arrival_date <= month_end:
                                    inventory_count += _get_pkg(row)
                            except Exception as e:
                                logger.warning(f"ì¬ê³  ê³„ì‚° ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}")
                                continue
                    
                    inventory_by_month[month_str][location] = inventory_count
                    
                    # ìœ„ì¹˜ë³„ ì´ ì¬ê³ 
                    if location not in inventory_by_location:
                        inventory_by_location[location] = 0
                    inventory_by_location[location] += inventory_count
        
        # ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ 
        total_inventory = sum(inventory_by_location.values())
        
        logger.info(f"âœ… Status_Location ê¸°ë°˜ ì¬ê³  ê³„ì‚° ì™„ë£Œ: ì´ {total_inventory}ê±´")
        
        # Status_Location ë¶„í¬ ë¡œê¹…
        if 'Status_Location' in df.columns:
            location_counts = df['Status_Location'].value_counts()
            logger.info("ğŸ“Š Status_Location ë¶„í¬:")
            for location, count in location_counts.items():
                logger.info(f"   {location}: {count}ê°œ")
        
        return {
            'inventory_by_month': inventory_by_month,
            'inventory_by_location': inventory_by_location,
            'total_inventory': total_inventory,
            'status_location_distribution': location_counts.to_dict() if 'Status_Location' in df.columns else {}
        }
    
    def calculate_direct_delivery(self, df: pd.DataFrame) -> Dict:
        """Portâ†’Site ì§ì ‘ ì´ë™ (FLOW_CODE 0/1) ì‹ë³„"""
        logger.info("ğŸ”„ calculate_direct_delivery() - ì§ì†¡ ë°°ì†¡ ê³„ì‚°")
        
        # FLOW_CODE 0 ë˜ëŠ” 1ì¸ ê²½ìš°ë¥¼ ì§ì†¡ìœ¼ë¡œ ê°„ì£¼
        direct_delivery_df = df[df['FLOW_CODE'].isin([0, 1])]
        
        direct_items = []
        total_direct = len(direct_delivery_df)
        
        for idx, row in direct_delivery_df.iterrows():
            for site in self.site_columns:
                if site in row.index and pd.notna(row[site]):
                    try:
                        site_date = pd.to_datetime(row[site])
                        pkg_quantity = _get_pkg(row)
                        direct_items.append({
                            'Item_ID': idx,
                            'Site': site,
                            'Direct_Date': site_date,
                            'Year_Month': site_date.strftime('%Y-%m'),
                            'Flow_Code': row['FLOW_CODE'],
                            'Pkg_Quantity': pkg_quantity
                        })
                    except:
                        continue
        
        logger.info(f"âœ… ì§ì†¡ ë°°ì†¡ ì´ {total_direct}ê±´ ì²˜ë¦¬")
        return {
            'total_direct': total_direct,
            'direct_items': direct_items
        }
    
    def calculate_monthly_sqm_inbound(self, df: pd.DataFrame) -> Dict:
        """ì›”ë³„ ì°½ê³  SQM ì…ê³  ê³„ì‚° (ëˆ„ì  ë©´ì  ê¸°ì¤€)"""
        logger.info("ğŸ“¦ ì›”ë³„ SQM ì…ê³  ê³„ì‚° ì‹œì‘")
        
        monthly_inbound_sqm = {}
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        months = pd.date_range('2023-02', '2025-07', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        for month_str in month_strings:
            monthly_inbound_sqm[month_str] = {}
            
            for warehouse in self.warehouse_columns:
                total_sqm = 0
                
                for idx, row in df.iterrows():
                    if warehouse in row.index and pd.notna(row[warehouse]):
                        try:
                            arrival_date = pd.to_datetime(row[warehouse])
                            if arrival_date.strftime('%Y-%m') == month_str:
                                item_sqm = _get_sqm(row)
                                total_sqm += item_sqm
                        except Exception as e:
                            continue
                
                monthly_inbound_sqm[month_str][warehouse] = total_sqm
        
        logger.info("âœ… ì›”ë³„ SQM ì…ê³  ê³„ì‚° ì™„ë£Œ")
        return monthly_inbound_sqm
    
    def calculate_monthly_sqm_outbound(self, df: pd.DataFrame) -> Dict:
        """ì›”ë³„ ì°½ê³  SQM ì¶œê³  ê³„ì‚° (ëˆ„ì  ë©´ì  ê¸°ì¤€)"""
        logger.info("ğŸ“¤ ì›”ë³„ SQM ì¶œê³  ê³„ì‚° ì‹œì‘")
        
        monthly_outbound_sqm = {}
        all_locations = self.warehouse_columns + self.site_columns
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        months = pd.date_range('2023-02', '2025-07', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        for month_str in month_strings:
            monthly_outbound_sqm[month_str] = {}
            
            for warehouse in self.warehouse_columns:
                total_sqm = 0
                
                for idx, row in df.iterrows():
                    if warehouse in row.index and pd.notna(row[warehouse]):
                        try:
                            current_date = pd.to_datetime(row[warehouse])
                            
                            # ë‹¤ìŒ ì´ë™ ì°¾ê¸°
                            next_movements = []
                            for next_loc in all_locations:
                                if next_loc != warehouse and next_loc in row.index and pd.notna(row[next_loc]):
                                    next_date = pd.to_datetime(row[next_loc])
                                    if next_date >= current_date:
                                        next_movements.append((next_loc, next_date))
                            
                            if next_movements:
                                next_location, next_date = min(next_movements, key=lambda x: x[1])
                                if next_date.strftime('%Y-%m') == month_str:
                                    item_sqm = _get_sqm(row)
                                    total_sqm += item_sqm
                                    
                        except Exception as e:
                            continue
                
                monthly_outbound_sqm[month_str][warehouse] = total_sqm
        
        logger.info("âœ… ì›”ë³„ SQM ì¶œê³  ê³„ì‚° ì™„ë£Œ")
        return monthly_outbound_sqm
    
    def calculate_cumulative_sqm_inventory(self, inbound_sqm: Dict, outbound_sqm: Dict) -> Dict:
        """ëˆ„ì  SQM ì¬ê³  ê³„ì‚° (ì…ê³  - ì¶œê³  = ì‹¤ì‚¬ìš© ë©´ì )"""
        logger.info("ğŸ“Š ëˆ„ì  SQM ì¬ê³  ê³„ì‚° ì‹œì‘ (ì…ê³  - ì¶œê³  = ì‹¤ì‚¬ìš© ë©´ì )")
        
        cumulative_inventory = {}
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        months = pd.date_range('2023-02', '2025-07', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # ì°½ê³ ë³„ ëˆ„ì  ì¬ê³  ì´ˆê¸°í™”
        current_inventory = {warehouse: 0.0 for warehouse in self.warehouse_columns}
        
        for month_str in month_strings:
            cumulative_inventory[month_str] = {}
            
            for warehouse in self.warehouse_columns:
                # ì›”ë³„ ìˆœì¦ê° = ì…ê³  - ì¶œê³ 
                monthly_inbound = inbound_sqm.get(month_str, {}).get(warehouse, 0)
                monthly_outbound = outbound_sqm.get(month_str, {}).get(warehouse, 0)
                net_change = monthly_inbound - monthly_outbound
                
                # ëˆ„ì  ì¬ê³  ì—…ë°ì´íŠ¸
                current_inventory[warehouse] += net_change
                current_inventory[warehouse] = max(0, current_inventory[warehouse])  # ìŒìˆ˜ ë°©ì§€
                
                # ê°€ë™ë¥  ê³„ì‚°
                base_capacity = self.warehouse_base_sqm.get(warehouse, 1)
                utilization_rate = (current_inventory[warehouse] / base_capacity) * 100
                
                cumulative_inventory[month_str][warehouse] = {
                    'inbound_sqm': monthly_inbound,
                    'outbound_sqm': monthly_outbound,
                    'net_change_sqm': net_change,
                    'cumulative_inventory_sqm': current_inventory[warehouse],
                    'utilization_rate_%': utilization_rate,
                    'base_capacity_sqm': base_capacity
                }
        
        logger.info("âœ… ëˆ„ì  SQM ì¬ê³  ê³„ì‚° ì™„ë£Œ (ì‹¤ì‚¬ìš© ë©´ì  ì‚°ì¶œ)")
        return cumulative_inventory
    
    def calculate_monthly_invoice_charges(self, cumulative_inventory: Dict) -> Dict:
        """ì›”ë³„ Invoice ê³¼ê¸ˆ ê³„ì‚° (SQM ê¸°ë°˜)"""
        logger.info("ğŸ’° ì›”ë³„ Invoice ê³¼ê¸ˆ ê³„ì‚° ì‹œì‘")
        
        monthly_charges = {}
        
        for month_str, month_data in cumulative_inventory.items():
            monthly_charges[month_str] = {}
            total_monthly_charge = 0
            
            for warehouse in self.warehouse_columns:
                if warehouse in month_data:
                    sqm_used = month_data[warehouse]['cumulative_inventory_sqm']
                    sqm_rate = self.warehouse_sqm_rates.get(warehouse, 20.0)
                    
                    warehouse_charge = sqm_used * sqm_rate
                    total_monthly_charge += warehouse_charge
                    
                    monthly_charges[month_str][warehouse] = {
                        'sqm_used': sqm_used,
                        'sqm_rate_aed': sqm_rate,
                        'monthly_charge_aed': warehouse_charge,
                        'utilization_rate_%': month_data[warehouse]['utilization_rate_%']
                    }
            
            monthly_charges[month_str]['total_monthly_charge_aed'] = total_monthly_charge
        
        logger.info("âœ… ì›”ë³„ Invoice ê³¼ê¸ˆ ê³„ì‚° ì™„ë£Œ")
        return monthly_charges
    
    def analyze_sqm_data_quality(self, df: pd.DataFrame) -> Dict:
        """âœ… NEW: SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„ (ì‹¤ì œ vs ì¶”ì • ë¹„ìœ¨)"""
        logger.info("ğŸ” SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì‹œì‘")
        
        total_rows = len(df)
        actual_sqm_count = 0
        estimated_sqm_count = 0
        actual_sqm_sources = {}
        total_actual_sqm = 0
        total_estimated_sqm = 0
        
        for idx, row in df.iterrows():
            sqm_value, source_type, source_column = _get_sqm_with_source(row)
            
            if source_type == 'ACTUAL':
                actual_sqm_count += 1
                total_actual_sqm += sqm_value
                if source_column not in actual_sqm_sources:
                    actual_sqm_sources[source_column] = 0
                actual_sqm_sources[source_column] += 1
            else:
                estimated_sqm_count += 1
                total_estimated_sqm += sqm_value
        
        analysis_result = {
            'total_records': total_rows,
            'actual_sqm_records': actual_sqm_count,
            'estimated_sqm_records': estimated_sqm_count,
            'actual_sqm_percentage': (actual_sqm_count / total_rows) * 100 if total_rows > 0 else 0,
            'estimated_sqm_percentage': (estimated_sqm_count / total_rows) * 100 if total_rows > 0 else 0,
            'actual_sqm_sources': actual_sqm_sources,
            'avg_actual_sqm': total_actual_sqm / actual_sqm_count if actual_sqm_count > 0 else 0,
            'avg_estimated_sqm': total_estimated_sqm / estimated_sqm_count if estimated_sqm_count > 0 else 0,
            'total_actual_sqm': total_actual_sqm,
            'total_estimated_sqm': total_estimated_sqm
        }
        
        # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ê²°ê³¼:")
        print(f"   ì´ ë ˆì½”ë“œ: {total_rows:,}ê±´")
        print(f"   âœ… ì‹¤ì œ SQM ë°ì´í„°: {actual_sqm_count:,}ê±´ ({analysis_result['actual_sqm_percentage']:.1f}%)")
        print(f"   âŒ ì¶”ì • SQM ë°ì´í„°: {estimated_sqm_count:,}ê±´ ({analysis_result['estimated_sqm_percentage']:.1f}%)")
        
        if actual_sqm_sources:
            print(f"   ğŸ“ ì‹¤ì œ SQM ì†ŒìŠ¤ ì»¬ëŸ¼:")
            for col, count in actual_sqm_sources.items():
                print(f"      - {col}: {count:,}ê±´")
        
        if actual_sqm_count > 0:
            print(f"   ğŸ’¾ í‰ê·  ì‹¤ì œ SQM: {analysis_result['avg_actual_sqm']:.2f}")
        if estimated_sqm_count > 0:
            print(f"   ğŸ’¾ í‰ê·  ì¶”ì • SQM: {analysis_result['avg_estimated_sqm']:.2f}")
        
        logger.info("âœ… SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì™„ë£Œ")
        return analysis_result
    
    # ì¤‘ë³µ í•¨ìˆ˜ ì œê±°: ìƒë‹¨ì˜ íŒ¨ì¹˜ëœ ë²„ì „ ì‚¬ìš©
    # def generate_monthly_report_final(self, df: pd.DataFrame, year_month: str) -> Dict:
    #     """âœ… ì›”ë³„ ì°½ê³ /í˜„ì¥ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ì¢…í•© ë¦¬í¬íŠ¸ - ì¤‘ë³µ ì œê±°"""
    #     # ìƒë‹¨ì˜ íŒ¨ì¹˜ëœ ë²„ì „ ì‚¬ìš©
    #     return generate_monthly_report_final(df, year_month)

    # âœ… ì—¬ê¸°ì— ìƒˆ ë©”ì„œë“œ ì¶”ê°€
    def detect_same_date_warehouse_transfer(self, row) -> List[Dict]:
        """
        ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ê°ì§€ (íŠ¹íˆ DSV Indoor â†’ DSV Al Markaz)
        """
        transfers = []
        
        # DSV Indoorì™€ DSV Al Markaz ë™ì¼ ë‚ ì§œ ì²´í¬
        dsv_indoor_date = pd.to_datetime(row.get('DSV Indoor'), errors='coerce')
        dsv_almarkaz_date = pd.to_datetime(row.get('DSV Al Markaz'), errors='coerce')
        
        if (pd.notna(dsv_indoor_date) and pd.notna(dsv_almarkaz_date) and 
            dsv_indoor_date.date() == dsv_almarkaz_date.date()):
            
            transfers.append({
                'from_warehouse': 'DSV Indoor',
                'to_warehouse': 'DSV Al Markaz', 
                'transfer_date': dsv_indoor_date,
                'pkg_quantity': _get_pkg(row),
                'transfer_type': 'warehouse_to_warehouse'
            })
        
        # ë‹¤ë¥¸ ì°½ê³  ì¡°í•©ë„ í™•ì¸
        warehouse_pairs = [
            ('DSV Indoor', 'DSV Outdoor'),
            ('DSV Al Markaz', 'DSV Outdoor'),
            ('DSV Indoor', 'MOSB'),
            ('DSV Al Markaz', 'MOSB')
        ]
        
        for from_wh, to_wh in warehouse_pairs:
            from_date = pd.to_datetime(row.get(from_wh), errors='coerce')
            to_date = pd.to_datetime(row.get(to_wh), errors='coerce')
            
            if (pd.notna(from_date) and pd.notna(to_date) and 
                from_date.date() == to_date.date()):
                
                transfers.append({
                    'from_warehouse': from_wh,
                    'to_warehouse': to_wh,
                    'transfer_date': from_date,
                    'pkg_quantity': _get_pkg(row),
                    'transfer_type': 'warehouse_to_warehouse'
                })
        
        return transfers


class HVDCExcelReporterFinal:
    """HVDC Excel 5-ì‹œíŠ¸ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.calculator = WarehouseIOCalculator()
        
        logger.info("ğŸ“‹ HVDC Excel Reporter Final ì´ˆê¸°í™” ì™„ë£Œ")
    
    def calculate_warehouse_statistics(self) -> Dict:
        """ìœ„ 4 ê²°ê³¼ + ì›”ë³„ Pivot + SQM ê¸°ë°˜ ëˆ„ì  ì¬ê³  â†’ Excel í™•ì¥"""
        logger.info("ğŸ“Š calculate_warehouse_statistics() - ì¢…í•© í†µê³„ ê³„ì‚° (SQM í™•ì¥)")
        
        # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        self.calculator.load_real_hvdc_data()
        df = self.calculator.process_real_data()
        df = self.calculator.calculate_final_location(df)
        
        # 4ê°€ì§€ í•µì‹¬ ê³„ì‚° (ê¸°ì¡´)
        inbound_result = self.calculator.calculate_warehouse_inbound(df)
        outbound_result = self.calculator.calculate_warehouse_outbound(df)
        inventory_result = self.calculator.calculate_warehouse_inventory(df)
        direct_result = self.calculator.calculate_direct_delivery(df)
        
        # ì›”ë³„ í”¼ë²— ê³„ì‚° (ê¸°ì¡´)
        inbound_pivot = self.calculator.create_monthly_inbound_pivot(df)
        
        # âœ… NEW: SQM ê¸°ë°˜ ëˆ„ì  ì¬ê³  ê³„ì‚°
        sqm_inbound = self.calculator.calculate_monthly_sqm_inbound(df)
        sqm_outbound = self.calculator.calculate_monthly_sqm_outbound(df)
        sqm_cumulative = self.calculator.calculate_cumulative_sqm_inventory(sqm_inbound, sqm_outbound)
        sqm_charges = self.calculator.calculate_monthly_invoice_charges(sqm_cumulative)
        
        # âœ… NEW: SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„
        sqm_quality = self.calculator.analyze_sqm_data_quality(df)
        
        return {
            'inbound_result': inbound_result,
            'outbound_result': outbound_result,
            'inventory_result': inventory_result,
            'direct_result': direct_result,
            'inbound_pivot': inbound_pivot,
            'processed_data': df,
            # âœ… NEW: SQM ê´€ë ¨ ê²°ê³¼ ì¶”ê°€
            'sqm_inbound': sqm_inbound,
            'sqm_outbound': sqm_outbound,
            'sqm_cumulative_inventory': sqm_cumulative,
            'sqm_invoice_charges': sqm_charges,
            'sqm_data_quality': sqm_quality
        }
    
    def create_warehouse_monthly_sheet(self, stats: Dict) -> pd.DataFrame:
        """ì°½ê³ _ì›”ë³„_ì…ì¶œê³  ì‹œíŠ¸ ìƒì„± (ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ë°˜ì˜)"""
        logger.info("ğŸ¢ ì°½ê³ _ì›”ë³„_ì…ì¶œê³  ì‹œíŠ¸ ìƒì„± (ì°½ê³ ê°„ ì´ë™ ë°˜ì˜)")
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2023-02 ~ 2025-07)
        months = pd.date_range('2023-02', '2025-07', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # ê²°ê³¼ DataFrame ì´ˆê¸°í™”
        results = []
        
        for month_str in month_strings:
            row = [month_str]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼: ì…ê³ ì›”
            
            # ì°½ê³  ëª©ë¡ (í‘œì‹œëª…)
            warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB', 'DHL Warehouse']
            warehouse_display_names = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB', 'DHL Warehouse']
            
            inbound_values = []
            
            # ì…ê³  ê³„ì‚° (ìˆœìˆ˜ ì…ê³  + ì°½ê³ ê°„ ì´ë™ ì…ê³ )
            for i, warehouse in enumerate(warehouses):
                inbound_count = 0
                
                # 1. ìˆœìˆ˜ ì…ê³  (external_arrival)
                for item in stats['inbound_result'].get('inbound_items', []):
                    if (item.get('Warehouse') == warehouse and 
                        item.get('Year_Month') == month_str and
                        item.get('Inbound_Type') == 'external_arrival'):
                        inbound_count += item.get('Pkg_Quantity', 1)
                
                # 2. ì°½ê³ ê°„ ì´ë™ ì…ê³ 
                for transfer in stats['inbound_result'].get('warehouse_transfers', []):
                    if (transfer.get('To_Warehouse') == warehouse and 
                        transfer.get('Year_Month') == month_str):
                        inbound_count += transfer.get('Pkg_Quantity', 1)
                
                inbound_values.append(inbound_count)
                row.append(inbound_count)
            
            # ì¶œê³  ê³„ì‚° (ì°½ê³ ê°„ ì´ë™ ì¶œê³  + í˜„ì¥ ì´ë™ ì¶œê³ )
            outbound_values = []
            for i, warehouse in enumerate(warehouses):
                outbound_count = 0
                
                for item in stats['outbound_result'].get('outbound_items', []):
                    if (item.get('Warehouse') == warehouse and 
                        item.get('Year_Month') == month_str):
                        outbound_count += item.get('Pkg_Quantity', 1)
                
                outbound_values.append(outbound_count)
                row.append(outbound_count)
            
            # ëˆ„ê³„ ì—´ ì¶”ê°€
            row.append(sum(inbound_values))   # ëˆ„ê³„_ì…ê³ 
            row.append(sum(outbound_values))  # ëˆ„ê³„_ì¶œê³ 
            
            results.append(row)
        
        # ì»¬ëŸ¼ ìƒì„± (19ì—´)
        columns = ['ì…ê³ ì›”']
        
        # ì…ê³  8ê°œ ì°½ê³ 
        for warehouse in warehouse_display_names:
            columns.append(f'ì…ê³ _{warehouse}')
        
        # ì¶œê³  8ê°œ ì°½ê³ 
        for warehouse in warehouse_display_names:
            columns.append(f'ì¶œê³ _{warehouse}')
        
        # ëˆ„ê³„ ì—´
        columns.append('ëˆ„ê³„_ì…ê³ ')
        columns.append('ëˆ„ê³„_ì¶œê³ ')
        
        # DataFrame ìƒì„±
        warehouse_monthly = pd.DataFrame(results, columns=columns)
        
        # ì´í•©ê³„ í–‰ ì¶”ê°€
        total_row = ['Total']
        for col in warehouse_monthly.columns[1:]:
            total_row.append(warehouse_monthly[col].sum())
        warehouse_monthly.loc[len(warehouse_monthly)] = total_row
        
        logger.info(f"âœ… ì°½ê³ _ì›”ë³„_ì…ì¶œê³  ì‹œíŠ¸ ì™„ë£Œ (ì°½ê³ ê°„ ì´ë™ ë°˜ì˜): {warehouse_monthly.shape}")
        return warehouse_monthly
    
    def create_site_monthly_sheet(self, stats: Dict) -> pd.DataFrame:
        """í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ìƒì„± (Multi-Level Header 9ì—´) - ì¤‘ë³µ ì—†ëŠ” ì‹¤ì œ í˜„ì¥ ì…ê³ ë§Œ ì§‘ê³„"""
        logger.info("ğŸ—ï¸ í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ìƒì„± (9ì—´, ì¤‘ë³µ ì—†ëŠ” ì§‘ê³„)")
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2023-02 ~ 2025-07)
        months = pd.date_range('2023-02', '2025-07', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # ê²°ê³¼ DataFrame ì´ˆê¸°í™” (9ì—´ êµ¬ì¡°)
        results = []
        
        # ëˆ„ì  ì¬ê³  ê³„ì‚°ìš© ë³€ìˆ˜
        cumulative_inventory = {'AGI': 0, 'DAS': 0, 'MIR': 0, 'SHU': 0}
        
        # ì¤‘ë³µ ì—†ëŠ” ì§‘ê³„ë¥¼ ìœ„í•´ processed_data ì‚¬ìš©
        df = stats['processed_data']
        sites = ['AGI', 'DAS', 'MIR', 'SHU']
        
        for month_str in month_strings:
            row = [month_str]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼: ì…ê³ ì›”
            
            # ì…ê³  4ê°œ í˜„ì¥ (ì¤‘ë³µ ì—†ëŠ” ì‹¤ì œ ì…ê³ )
            for site in sites:
                mask = (
                    (df['Final_Location'] == site) &
                    (df[site].notna()) &
                    (pd.to_datetime(df[site], errors='coerce').dt.strftime('%Y-%m') == month_str)
                )
                inbound_count = df.loc[mask, 'Pkg'].sum()
                row.append(int(inbound_count))
                cumulative_inventory[site] += inbound_count
            
            # ì¬ê³  4ê°œ í˜„ì¥ (ë™ì¼ ìˆœì„œ)
            for site in sites:
                row.append(int(cumulative_inventory[site]))
            
            results.append(row)
        
        # ì»¬ëŸ¼ ìƒì„± (9ì—´)
        columns = ['ì…ê³ ì›”']
        
        # ì…ê³  4ê°œ í˜„ì¥
        for site in sites:
            columns.append(f'ì…ê³ _{site}')
        
        # ì¬ê³  4ê°œ í˜„ì¥
        for site in sites:
            columns.append(f'ì¬ê³ _{site}')
        
        # DataFrame ìƒì„±
        site_monthly = pd.DataFrame(results, columns=columns)
        
        # ì´í•©ê³„ í–‰ ì¶”ê°€
        total_row = ['Total']
        
        # ì…ê³  ì´í•©
        for site in sites:
            total_inbound = site_monthly[f'ì…ê³ _{site}'].sum()
            total_row.append(total_inbound)
        
        # ì¬ê³  ì´í•© (ìµœì¢… ì¬ê³ )
        for site in sites:
            final_inventory = site_monthly[f'ì¬ê³ _{site}'].iloc[-1] if not site_monthly.empty else 0
            total_row.append(final_inventory)
        
        site_monthly.loc[len(site_monthly)] = total_row
        
        logger.info(f"âœ… í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ì™„ë£Œ: {site_monthly.shape} (9ì—´, ì¤‘ë³µ ì—†ëŠ” ì§‘ê³„)")
        return site_monthly
    
    def create_multi_level_headers(self, df: pd.DataFrame, sheet_type: str) -> pd.DataFrame:
        """Multi-Level Header ìƒì„± (ê°€ì´ë“œ í‘œì¤€)"""
        if sheet_type == 'warehouse':
            # ì°½ê³  Multi-Level Header: 19ì—´ (Location + ì…ê³ 8 + ì¶œê³ 8)
            level_0 = ['ì…ê³ ì›”']  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = ['']
            
            # ì…ê³  8ê°œ ì°½ê³  (ê°€ì´ë“œ ìˆœì„œ)
            warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB', 'DHL Warehouse']
            for warehouse in warehouses:
                level_0.append('ì…ê³ ')
                level_1.append(warehouse)
            
            # ì¶œê³  8ê°œ ì°½ê³  (ë™ì¼ ìˆœì„œ)
            for warehouse in warehouses:
                level_0.append('ì¶œê³ ')
                level_1.append(warehouse)
            
            multi_columns = pd.MultiIndex.from_arrays([level_0, level_1], names=['Type', 'Location'])
            
        elif sheet_type == 'site':
            # í˜„ì¥ Multi-Level Header: 9ì—´ (Location + ì…ê³ 4 + ì¬ê³ 4)
            level_0 = ['ì…ê³ ì›”']  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = ['']
            
            # ì…ê³  4ê°œ í˜„ì¥ (ê°€ì´ë“œ ìˆœì„œ)
            sites = ['AGI', 'DAS', 'MIR', 'SHU']
            for site in sites:
                level_0.append('ì…ê³ ')
                level_1.append(site)
            
            # ì¬ê³  4ê°œ í˜„ì¥ (ë™ì¼ ìˆœì„œ)
            for site in sites:
                level_0.append('ì¬ê³ ')
                level_1.append(site)
            
            multi_columns = pd.MultiIndex.from_arrays([level_0, level_1], names=['Type', 'Location'])
        
        else:
            return df
        
        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
        if len(df.columns) == len(multi_columns):
            df.columns = multi_columns
        
        return df
    
    def create_flow_analysis_sheet(self, stats: Dict) -> pd.DataFrame:
        """Flow Code ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š Flow Code ë¶„ì„ ì‹œíŠ¸ ìƒì„±")
        
        df = stats['processed_data']
        
        # Flow Codeë³„ ê¸°ë³¸ í†µê³„
        flow_summary = df.groupby('FLOW_CODE').size().reset_index(name='Count')
        
        # Flow Description ì¶”ê°€
        flow_summary['FLOW_DESCRIPTION'] = flow_summary['FLOW_CODE'].map(self.calculator.flow_codes)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        cols = flow_summary.columns.tolist()
        if 'FLOW_DESCRIPTION' in cols:
            cols.remove('FLOW_DESCRIPTION')
            cols.insert(1, 'FLOW_DESCRIPTION')
            flow_summary = flow_summary[cols]
        
        logger.info(f"âœ… Flow Code ë¶„ì„ ì™„ë£Œ: {len(flow_summary)}ê°œ ì½”ë“œ")
        return flow_summary
    
    def create_transaction_summary_sheet(self, stats: Dict) -> pd.DataFrame:
        """ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì‹œíŠ¸ ìƒì„±")
        
        df = stats['processed_data']
        
        # ê¸°ë³¸ ìš”ì•½ ì •ë³´
        summary_data = []
        
        # ì „ì²´ í†µê³„
        summary_data.append({
            'Category': 'ì „ì²´ í†µê³„',
            'Item': 'ì´ íŠ¸ëœì­ì…˜ ê±´ìˆ˜',
            'Value': f"{len(df):,}ê±´",
            'Percentage': '100.0%'
        })
        
        # ë²¤ë”ë³„ ë¶„í¬
        vendor_dist = df['Vendor'].value_counts()
        for vendor, count in vendor_dist.items():
            percentage = (count / len(df)) * 100
            summary_data.append({
                'Category': 'ë²¤ë”ë³„ ë¶„í¬',
                'Item': vendor,
                'Value': f"{count:,}ê±´",
                'Percentage': f"{percentage:.1f}%"
            })
        
        # Flow Code ë¶„í¬
        flow_dist = df['FLOW_CODE'].value_counts().sort_index()
        for flow_code, count in flow_dist.items():
            percentage = (count / len(df)) * 100
            flow_desc = self.calculator.flow_codes.get(flow_code, f"Flow {flow_code}")
            summary_data.append({
                'Category': 'Flow Code ë¶„í¬',
                'Item': f"Flow {flow_code}: {flow_desc}",
                'Value': f"{count:,}ê±´",
                'Percentage': f"{percentage:.1f}%"
            })
        
        summary_df = pd.DataFrame(summary_data)
        
        logger.info(f"âœ… ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì™„ë£Œ: {len(summary_df)}ê°œ í•­ëª©")
        return summary_df
    
    def create_sqm_cumulative_sheet(self, stats: Dict) -> pd.DataFrame:
        """âœ… NEW: SQM ëˆ„ì  ì¬ê³  ì‹œíŠ¸ ìƒì„± (ì…ê³ -ì¶œê³ =ì‹¤ì‚¬ìš©ë©´ì )"""
        logger.info("ğŸ¢ SQM ëˆ„ì  ì¬ê³  ì‹œíŠ¸ ìƒì„± (ì‹¤ì‚¬ìš© ë©´ì  ê¸°ì¤€)")
        
        sqm_cumulative = stats.get('sqm_cumulative_inventory', {})
        sqm_data = []
        
        for month_str, month_data in sqm_cumulative.items():
            for warehouse, warehouse_data in month_data.items():
                sqm_data.append({
                    'Year_Month': month_str,
                    'Warehouse': warehouse,
                    'Inbound_SQM': warehouse_data['inbound_sqm'],
                    'Outbound_SQM': warehouse_data['outbound_sqm'],
                    'Net_Change_SQM': warehouse_data['net_change_sqm'],
                    'Cumulative_Inventory_SQM': warehouse_data['cumulative_inventory_sqm'],
                    'Base_Capacity_SQM': warehouse_data['base_capacity_sqm'],
                    'Utilization_Rate_%': warehouse_data['utilization_rate_%']
                })
        
        sqm_df = pd.DataFrame(sqm_data)
        
        logger.info(f"âœ… SQM ëˆ„ì  ì¬ê³  ì‹œíŠ¸ ì™„ë£Œ: {len(sqm_df)}ê±´")
        return sqm_df
    
    def create_sqm_invoice_sheet(self, stats: Dict) -> pd.DataFrame:
        """âœ… NEW: SQM ê¸°ë°˜ Invoice ê³¼ê¸ˆ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ’° SQM ê¸°ë°€ Invoice ê³¼ê¸ˆ ì‹œíŠ¸ ìƒì„±")
        
        sqm_charges = stats.get('sqm_invoice_charges', {})
        invoice_data = []
        
        for month_str, month_data in sqm_charges.items():
            total_charge = month_data.get('total_monthly_charge_aed', 0)
            
            for warehouse in self.calculator.warehouse_columns:
                if warehouse in month_data:
                    warehouse_data = month_data[warehouse]
                    invoice_data.append({
                        'Year_Month': month_str,
                        'Warehouse': warehouse,
                        'SQM_Used': warehouse_data['sqm_used'],
                        'Rate_AED_per_SQM': warehouse_data['sqm_rate_aed'],
                        'Monthly_Charge_AED': warehouse_data['monthly_charge_aed'],
                        'Utilization_Rate_%': warehouse_data['utilization_rate_%'],
                        'Total_Monthly_AED': total_charge
                    })
        
        invoice_df = pd.DataFrame(invoice_data)
        
        # ì´ ê³¼ê¸ˆ í–‰ ì¶”ê°€
        if not invoice_df.empty:
            monthly_totals = invoice_df.groupby('Year_Month').agg({
                'SQM_Used': 'sum',
                'Monthly_Charge_AED': 'sum',
                'Total_Monthly_AED': 'first'
            }).reset_index()
            monthly_totals['Warehouse'] = 'TOTAL'
            monthly_totals['Rate_AED_per_SQM'] = 0
            monthly_totals['Utilization_Rate_%'] = 0
            
            invoice_df = pd.concat([invoice_df, monthly_totals], ignore_index=True)
        
        logger.info(f"âœ… SQM Invoice ê³¼ê¸ˆ ì‹œíŠ¸ ì™„ë£Œ: {len(invoice_df)}ê±´")
        return invoice_df
    
    def create_sqm_pivot_sheet(self, stats: Dict) -> pd.DataFrame:
        """âœ… NEW: SQM í”¼ë²— í…Œì´ë¸” ì‹œíŠ¸ ìƒì„± (ì›”ë³„ ì°½ê³ ë³„ ë©´ì )"""
        logger.info("ğŸ“Š SQM í”¼ë²— í…Œì´ë¸” ì‹œíŠ¸ ìƒì„±")
        
        sqm_cumulative = stats.get('sqm_cumulative_inventory', {})
        
        # í”¼ë²— ë°ì´í„° ì¤€ë¹„
        pivot_data = []
        for month_str, month_data in sqm_cumulative.items():
            row = {'Year_Month': month_str}
            
            # ì°½ê³ ë³„ ëˆ„ì  SQM ì¬ê³ 
            for warehouse in self.calculator.warehouse_columns:
                if warehouse in month_data:
                    row[f'{warehouse}_Cumulative_SQM'] = month_data[warehouse]['cumulative_inventory_sqm']
                    row[f'{warehouse}_Utilization_%'] = month_data[warehouse]['utilization_rate_%']
                else:
                    row[f'{warehouse}_Cumulative_SQM'] = 0
                    row[f'{warehouse}_Utilization_%'] = 0
            
            # ì´ ëˆ„ì  SQM
            total_sqm = sum(month_data[wh]['cumulative_inventory_sqm'] for wh in self.calculator.warehouse_columns if wh in month_data)
            row['Total_Cumulative_SQM'] = total_sqm
            
            pivot_data.append(row)
        
        pivot_df = pd.DataFrame(pivot_data)
        
        logger.info(f"âœ… SQM í”¼ë²— í…Œì´ë¸” ì‹œíŠ¸ ì™„ë£Œ: {pivot_df.shape}")
        return pivot_df
    
    def generate_final_excel_report(self):
        """ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± (íŒ¨ì¹˜ ë²„ì „ v2.8.3-hotfix)"""
        logger.info("ğŸ—ï¸ ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (íŒ¨ì¹˜ ë²„ì „ v2.8.3-hotfix)")
        
        # ì¢…í•© í†µê³„ ê³„ì‚°
        stats = self.calculate_warehouse_statistics()
        
        # KPI ê²€ì¦ ì‹¤í–‰ (íŒ¨ì¹˜ ë²„ì „)
        kpi_validation = validate_kpi_thresholds(stats)
        
        # ê° ì‹œíŠ¸ ë°ì´í„° ì¤€ë¹„
        logger.info("ğŸ“Š ì‹œíŠ¸ë³„ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ì‹œíŠ¸ 1: ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header, 17ì—´ - ëˆ„ê³„ í¬í•¨)
        warehouse_monthly = self.create_warehouse_monthly_sheet(stats)
        warehouse_monthly_with_headers = self.create_multi_level_headers(warehouse_monthly, 'warehouse')
        
        # ì‹œíŠ¸ 2: í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header, 9ì—´)
        site_monthly = self.create_site_monthly_sheet(stats)
        site_monthly_with_headers = self.create_multi_level_headers(site_monthly, 'site')
        
        # ì‹œíŠ¸ 3: Flow_Code_ë¶„ì„
        flow_analysis = self.create_flow_analysis_sheet(stats)
        
        # ì‹œíŠ¸ 4: ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½
        transaction_summary = self.create_transaction_summary_sheet(stats)
        
        # ì‹œíŠ¸ 5: KPI_ê²€ì¦_ê²°ê³¼ (íŒ¨ì¹˜ ë²„ì „)
        kpi_validation_df = pd.DataFrame.from_dict(kpi_validation, orient='index')
        kpi_validation_df.reset_index(inplace=True)
        kpi_validation_df.columns = ['KPI', 'Status', 'Value', 'Threshold']
        
        # ì‹œíŠ¸ 6: ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ (ì²˜ìŒ 1000ê±´)
        sample_data = stats['processed_data'].head(1000)
        
        # ì‹œíŠ¸ 7: HITACHI_ì›ë³¸ë°ì´í„° (ì „ì²´)
        hitachi_original = stats['processed_data'][stats['processed_data']['Vendor'] == 'HITACHI']
        # ì‹œíŠ¸ 8: SIEMENS_ì›ë³¸ë°ì´í„° (ì „ì²´)
        siemens_original = stats['processed_data'][stats['processed_data']['Vendor'] == 'SIMENSE']
        # ì‹œíŠ¸ 9: í†µí•©_ì›ë³¸ë°ì´í„° (ì „ì²´)
        combined_original = stats['processed_data']
        
        # output í´ë” ìë™ ìƒì„±
        output_dir = Path('output')
        output_dir.mkdir(exist_ok=True)
        
        # ì „ì²´ëŠ” CSVë¡œ ì €ì¥
        hitachi_original.astype(str).to_csv('output/HITACHI_ì›ë³¸ë°ì´í„°_FULL.csv', index=False, encoding='utf-8-sig')
        siemens_original.astype(str).to_csv('output/SIEMENS_ì›ë³¸ë°ì´í„°_FULL.csv', index=False, encoding='utf-8-sig')
        combined_original.astype(str).to_csv('output/í†µí•©_ì›ë³¸ë°ì´í„°_FULL.csv', index=False, encoding='utf-8-sig')

        # Excel íŒŒì¼ ìƒì„± (íŒ¨ì¹˜ ë²„ì „)
        excel_filename = f"HVDC_ì…ê³ ë¡œì§_ì¢…í•©ë¦¬í¬íŠ¸_{self.timestamp}.xlsx"
        with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:
            warehouse_monthly_with_headers.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', index=True)
            site_monthly_with_headers.to_excel(writer, sheet_name='í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', index=True)
            flow_analysis.to_excel(writer, sheet_name='Flow_Code_ë¶„ì„', index=False)
            transaction_summary.to_excel(writer, sheet_name='ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½', index=False)
            kpi_validation_df.to_excel(writer, sheet_name='KPI_ê²€ì¦_ê²°ê³¼', index=False)
            sqm_cumulative_sheet = self.create_sqm_cumulative_sheet(stats)
            sqm_cumulative_sheet.to_excel(writer, sheet_name='SQM_ëˆ„ì ì¬ê³ ', index=False)
            sqm_invoice_sheet = self.create_sqm_invoice_sheet(stats)
            sqm_invoice_sheet.to_excel(writer, sheet_name='SQM_Invoiceê³¼ê¸ˆ', index=False)
            sqm_pivot_sheet = self.create_sqm_pivot_sheet(stats)
            sqm_pivot_sheet.to_excel(writer, sheet_name='SQM_í”¼ë²—í…Œì´ë¸”', index=False)
            sample_data.to_excel(writer, sheet_name='ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ', index=False)
            hitachi_original.to_excel(writer, sheet_name='HITACHI_ì›ë³¸ë°ì´í„°', index=False)
            siemens_original.to_excel(writer, sheet_name='SIEMENS_ì›ë³¸ë°ì´í„°', index=False)
            combined_original.to_excel(writer, sheet_name='í†µí•©_ì›ë³¸ë°ì´í„°', index=False)
        # ì €ì¥ í›„ ê²€ì¦
        try:
            _ = pd.read_excel(excel_filename, sheet_name=0)
        except Exception as e:
            print(f"âš ï¸ [ê²½ê³ ] ì—‘ì…€ íŒŒì¼ ì €ì¥ í›„ ì—´ê¸° ì‹¤íŒ¨: {e}")
        logger.info(f"ğŸ‰ ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {excel_filename}")
        logger.info(f"ğŸ“ ì›ë³¸ ì „ì²´ ë°ì´í„°ëŠ” output/ í´ë”ì˜ CSVë¡œ ì €ì¥ë¨")
        return excel_filename


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - Status_Location ê¸°ë°˜ ì™„ë²½í•œ ì…ì¶œê³  ë¡œì§"""
    print("ğŸ“‹ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ")
    print("âœ… Status_Location ê¸°ë°˜ ì™„ë²½í•œ ì…ì¶œê³  ì¬ê³  ë¡œì§")
    print("Samsung C&T Â· ADNOC Â· DSV Partnership")
    print("=" * 80)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰
        reporter = HVDCExcelReporterFinal()
        
        # ë°ì´í„° ë¡œë“œ ë° ê²€ì¦
        calculator = reporter.calculator
        calculator.load_real_hvdc_data()
        df = calculator.process_real_data()
        
        # Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦
        print("\nğŸ” Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦:")
        if validate_inventory_logic(df):
            print("âœ… Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦ í†µê³¼!")
            # (ì¶”ê°€ ì¶œë ¥ì€ ì´ë¯¸ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰)
        else:
            print("âŒ ì¬ê³  ë¡œì§ ê²€ì¦ ì‹¤íŒ¨: Status_Location ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # Excel ë¦¬í¬íŠ¸ ìƒì„±
        excel_file = reporter.generate_final_excel_report()
        
        print(f"\nğŸ‰ HVDC ì…ê³  ë¡œì§ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ! (SQM í™•ì¥íŒ)")
        print(f"ğŸ“ íŒŒì¼ëª…: {excel_file}")
        print(f"ğŸ“Š ì´ ë°ì´í„°: {reporter.calculator.total_records:,}ê±´")
        
        # SQM ê²°ê³¼ ìš”ì•½ ì¶œë ¥ ì¶”ê°€
        stats = reporter.calculate_warehouse_statistics()
        
        # SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        sqm_quality = stats.get('sqm_data_quality', {})
        if sqm_quality:
            actual_percentage = sqm_quality.get('actual_sqm_percentage', 0)
            estimated_percentage = sqm_quality.get('estimated_sqm_percentage', 0)
            print(f"\nğŸ” SQM ë°ì´í„° í’ˆì§ˆ ë¶„ì„:")
            print(f"   âœ… ì‹¤ì œ SQM ë°ì´í„°: {actual_percentage:.1f}%")
            print(f"   âŒ PKG ê¸°ë°˜ ì¶”ì •: {estimated_percentage:.1f}%")
            
            if actual_percentage > 50:
                print(f"   ğŸš€ ê²°ê³¼: ì‹¤ì œ SQM ë°ì´í„° ì—°ë™ ì„±ê³µ! ì •í™•í•œ ë©´ì  ê³„ì‚°")
            else:
                print(f"   âš ï¸ ê²°ê³¼: PKG ê¸°ë°˜ ì¶”ì • ì‚¬ìš© ì¤‘. ì‹¤ì œ SQM ì»¬ëŸ¼ í™•ì¸ ë”°ë¦„")
        
        sqm_cumulative = stats.get('sqm_cumulative_inventory', {})
        if sqm_cumulative:
            latest_month = max(sqm_cumulative.keys())
            total_sqm_used = sum(month_data.get('cumulative_inventory_sqm', 0) 
                               for month_data in sqm_cumulative[latest_month].values() 
                               if isinstance(month_data, dict))
            
            sqm_charges = stats.get('sqm_invoice_charges', {})
            total_charges = sqm_charges.get(latest_month, {}).get('total_monthly_charge_aed', 0)
            
            print(f"\nğŸ¢ SQM ê¸°ë°˜ ì°½ê³  ê´€ë¦¬ ê²°ê³¼ ({latest_month}):")
            print(f"   ğŸ’¾ ì´ ì‚¬ìš© ë©´ì : {total_sqm_used:,.2f} SQM")
            print(f"   ğŸ’° ì›”ë³„ ê³¼ê¸ˆ: {total_charges:,.2f} AED")
        print(f"ğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸:")
        print(f"   1. ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header 17ì—´)")
        print(f"   2. í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header 9ì—´)")
        print(f"   3. Flow_Code_ë¶„ì„ (FLOW_CODE 0-4)")
        print(f"   4. ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½")
        print(f"   5. KPI_ê²€ì¦_ê²°ê³¼")
        print(f"   6. ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ (1000ê±´)")
        print(f"   7. HITACHI_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"   8. SIEMENS_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"   9. í†µí•©_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"\nğŸ“ˆ í•µì‹¬ ë¡œì§ (Status_Location ê¸°ë°˜):")
        print(f"   - ì…ê³ : ìœ„ì¹˜ ì»¬ëŸ¼ ë‚ ì§œ = ì…ê³ ì¼")
        print(f"   - ì¶œê³ : ë‹¤ìŒ ìœ„ì¹˜ ë‚ ì§œ = ì¶œê³ ì¼")
        print(f"   - ì¬ê³ : Status_Location = í˜„ì¬ ìœ„ì¹˜")
        print(f"   - ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ ")
        print(f"   - ì°½ê³  ìš°ì„ ìˆœìœ„: DSV Al Markaz > DSV Indoor > Status_Location")
        print(f"   - Multi-Level Header êµ¬ì¡° í‘œì¤€í™”")
        print(f"   - ë°ì´í„° ë²”ìœ„: ì°½ê³ (2023-02~2025-07), í˜„ì¥(2024-01~2025-07)")
        
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise


def run_unit_tests():
    """ERR-T04 Fix: 28ê°œ + ì°½ê³ ê°„ ì´ë™ ìœ ë‹›í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰"""
    print("\nğŸ§ª ìœ ë‹›í…ŒìŠ¤íŠ¸ 28ê°œ + ì°½ê³ ê°„ ì´ë™ ì¼€ì´ìŠ¤ ì‹¤í–‰ ì¤‘...")
    
    # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    # ê¸°ì¡´ run_unit_tests í•¨ìˆ˜ì˜ ë‚´ë¶€ë¥¼ ë³µì‚¬í•´ì˜¤ì§€ ì•Šê³ , ê¸°ì¡´ í•¨ìˆ˜ í˜¸ì¶œë¡œ ëŒ€ì²´
    # ê¸°ì¡´ í•¨ìˆ˜ê°€ test_cases, passed, totalì„ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ê¸°ì¡´ ì¶œë ¥ì€ ë¬´ì‹œí•˜ê³  ìƒˆ í…ŒìŠ¤íŠ¸ë§Œ ì¶”ê°€ ì§‘ê³„
    # ì‹¤ì œë¡œëŠ” ê¸°ì¡´ run_unit_tests ë‚´ë¶€ ì½”ë“œë¥¼ ì—¬ê¸°ì— ì§ì ‘ ë„£ëŠ” ê²ƒì´ ë” ì •í™•í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ìƒˆ í…ŒìŠ¤íŠ¸ë§Œ ì¶”ê°€
    warehouse_transfer_test_passed = test_same_date_warehouse_transfer()
    
    # ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ê¸°ì¡´ í•¨ìˆ˜ê°€ printë¡œ ì¶œë ¥í•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ìƒˆ í…ŒìŠ¤íŠ¸ë§Œ ì§‘ê³„
    if warehouse_transfer_test_passed:
        print("âœ… ì°½ê³ ê°„ ì´ë™ í…ŒìŠ¤íŠ¸ í¬í•¨ ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True
    else:
        print("âŒ ì°½ê³ ê°„ ì´ë™ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return False


def test_same_date_warehouse_transfer():
    """ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    test_data = pd.DataFrame({
        'Item_ID': [1, 2, 3],
        'Pkg': [1, 2, 1],
        'DSV Indoor': ['2024-06-01', '2024-06-02', pd.NaT],
        'DSV Al Markaz': ['2024-06-01', '2024-06-03', '2024-06-01'],
        'Status_Location': ['DSV Al Markaz', 'DSV Al Markaz', 'DSV Al Markaz']
    })
    
    # ë‚ ì§œ ë³€í™˜
    test_data['DSV Indoor'] = pd.to_datetime(test_data['DSV Indoor'])
    test_data['DSV Al Markaz'] = pd.to_datetime(test_data['DSV Al Markaz'])
    
    calculator = WarehouseIOCalculator()
    
    # í…ŒìŠ¤íŠ¸ 1: ë™ì¼ ë‚ ì§œ ì´ë™ ê°ì§€
    transfers = calculator.detect_same_date_warehouse_transfer(test_data.iloc[0])
    assert len(transfers) == 1, f"Expected 1 transfer, got {len(transfers)}"
    assert transfers[0]['from_warehouse'] == 'DSV Indoor', f"Expected 'DSV Indoor', got {transfers[0]['from_warehouse']}"
    assert transfers[0]['to_warehouse'] == 'DSV Al Markaz', f"Expected 'DSV Al Markaz', got {transfers[0]['to_warehouse']}"
    print("âœ… í…ŒìŠ¤íŠ¸ 1 í†µê³¼: ë™ì¼ ë‚ ì§œ ì´ë™ ê°ì§€")
    
    # í…ŒìŠ¤íŠ¸ 2: ì„œë¡œ ë‹¤ë¥¸ ë‚ ì§œ (ì´ë™ ì—†ìŒ)
    transfers = calculator.detect_same_date_warehouse_transfer(test_data.iloc[1])
    assert len(transfers) == 0, f"Expected 0 transfers, got {len(transfers)}"
    print("âœ… í…ŒìŠ¤íŠ¸ 2 í†µê³¼: ì„œë¡œ ë‹¤ë¥¸ ë‚ ì§œ ì´ë™ ì—†ìŒ")
    
    # í…ŒìŠ¤íŠ¸ 3: DSV Indoor ë‚ ì§œ ì—†ìŒ
    transfers = calculator.detect_same_date_warehouse_transfer(test_data.iloc[2])
    assert len(transfers) == 0, f"Expected 0 transfers, got {len(transfers)}"
    print("âœ… í…ŒìŠ¤íŠ¸ 3 í†µê³¼: DSV Indoor ë‚ ì§œ ì—†ìŒ")
    
    print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ë™ì¼ ë‚ ì§œ ì°½ê³ ê°„ ì´ë™ ë¡œì§ ê²€ì¦ ì™„ë£Œ")
    return True


if __name__ == "__main__":
    # ìœ ë‹›í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_success = run_unit_tests()
    
    if test_success:
        # ë©”ì¸ ì‹¤í–‰
        main()
    else:
        print("âŒ ìœ ë‹›í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ ë©”ì¸ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.") 