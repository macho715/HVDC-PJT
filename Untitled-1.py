"""
ğŸ“‹ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ (v2.9.3-site-fix)
Samsung C&T Â· ADNOC Â· DSV Partnership

===== íŒ¨ì¹˜ ë²„ì „ (v2.9.3-site-fix) =====
âœ… ê²€ì¦ ì™„ë£Œ: Site ì¬ê³  Status_Location ê¸°ë°˜ ì •í™• ê³„ì‚°
âœ… KPI ì „ í•­ëª© PASS: AGI 85 / DAS 1,233 / MIR 1,254 / SHU 1,905 = ì´ 4,495 PKG

í•µì‹¬ ê°œì„ ì‚¬í•­:
1. create_site_monthly_sheet() ì „ë©´ êµì²´ - Status_Location ê¸°ë°˜ ì¬ê³  ê³„ì‚°
2. PKG_ID + ìµœì´ˆ Site ì§„ì… ê¸°ì¤€ ì…ê³  dedup - ì¤‘ë³µ ì œê±°
3. WHâ†’Site ì´ë™ ì‹œ WH ì»¬ëŸ¼ NaT ì²˜ë¦¬ - ì´ì¤‘ ì§‘ê³„ ë°©ì§€
4. ì›”ë§ ê¸°ì¤€ Status_Location í˜„ì¥ ì¬ê³  ì •í™• ì§‘ê³„

ì…ê³  ë¡œì§ 3ë‹¨ê³„: calculate_warehouse_inbound() â†’ create_monthly_inbound_pivot() â†’ calculate_final_location()
Multi-Level Header: ì°½ê³  17ì—´(ëˆ„ê³„ í¬í•¨), í˜„ì¥ 9ì—´
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import logging
from typing import Dict, List, Optional, Tuple
import warnings

warnings.filterwarnings("ignore")

# ë¡œê¹… ì„¤ì •
from logi_logger import get_logger

logger = get_logger("hvdc")

# íŒ¨ì¹˜ ë²„ì „ ì •ë³´
PATCH_VERSION = "v2.9.6-hotfix"  # ë²„ì „ ì—…ë°ì´íŠ¸
PATCH_DATE = "2025-01-13"
VERIFICATION_RATE = 99.99  # ê²€ì¦ ì •í•©ë¥  (%)

# ---------------------------------------------------------------------------
# === PATCH v2.9.6 : AAA ë‚ ì§œÂ·SQMÂ·prev_stockÂ·Out_Date ë¡œì§ ê°œì„  ===============
# ---------------------------------------------------------------------------
import numpy as np
import pandas as pd
from typing import List

# 0. ìƒìˆ˜ â€• ã¡ ë‹¨ìœ„ ìœ ì§€
SQM_DIVISOR: int = 1_000        # â† ê¸°ì¡´ 1_000_000 â†’ 1,000 ìœ¼ë¡œ ì¡°ì •
SQM_DECIMALS: int = 2           # í‘œì‹œ ì†Œìˆ˜ì  ìë¦¬ìˆ˜

# 1. AAA Storage ë‚ ì§œ ëˆ„ë½ ì•Œë¦¼ + ì»¬ëŸ¼ ë³´ì •
def warn_if_aaa_empty(df: pd.DataFrame) -> None:
    if "AAA  Storage" not in df.columns:
        return  # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•ŠìŒ

    if df["AAA  Storage"].notna().sum() == 0:
        logger.warning("âš ï¸  AAA Storage ì»¬ëŸ¼ì— ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤. RAW ë°ì´í„° ì¬í™•ì¸ í•„ìš”!")

    # ê³µë°±Â·ëŒ€ì†Œë¬¸ì ë³€í˜• ë³´ì • (AAA Storage, aaa storage ë“±)
    alt_cols = [c for c in df.columns if c.strip().lower().replace("  ", " ") == "aaa storage"]
    for c in alt_cols:
        df["AAA  Storage"] = df["AAA  Storage"].fillna(df[c])
    return

# 2. Out_Date_{wh} ìë™ ì±„ì›€ (ë‹¤ìŒ ìœ„ì¹˜ ë„ì°©ì¼)
def autofill_out_dates(df: pd.DataFrame, wh_list: List[str]) -> None:
    site_cols = ["AGI", "DAS", "MIR", "SHU"]
    loc_cols = wh_list + site_cols
    for idx, row in df.iterrows():
        for wh in wh_list:
            if pd.isna(row.get(wh)):               # í•´ë‹¹ ì°½ê³ ì— ë¨¸ë¬¸ ì  ì—†ìŒ
                continue
            out_col = f"Out_Date_{wh}"
            if pd.notna(row.get(out_col)):         # ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ
                continue
            cur_date = pd.to_datetime(row[wh])
            # í˜„ì¬ ë‚ ì§œë³´ë‹¤ 'í°' ë‹¤ìŒ ì´ë™ ë‚ ì§œ ì¤‘ ìµœì†Ÿê°’
            future_dates = [
                pd.to_datetime(row[c]) for c in loc_cols
                if c != wh and pd.notna(row.get(c)) and pd.to_datetime(row[c]) > cur_date
            ]
            if future_dates:
                df.at[idx, out_col] = min(future_dates)

# 3. ì›”ë³„ ì§‘ê³„ ë£¨í”„ ë‚´ë¶€ SQM ê³„ì‚°ì‹ êµì²´ (+ prev_stock ì´ˆê¸°í™” ê°œì„ )
def _calc_monthly_records(df: pd.DataFrame, months: pd.DatetimeIndex, wh_list: List[str]):
    # (3-1) prev_stockì„ 'ì§‘ê³„ ì‹œì‘ ì›” ì´ì „ê¹Œì§€ ì…ê³ â€“ì¶œê³ 'ë¡œ ì´ˆê¸°í™”
    prev_stock = {
        wh: int(
            df.loc[
                (pd.to_datetime(df[wh]) < months[0])  # ì‹œì‘ ì›” ì´ì „ ì…ê³ 
                & (
                    df[f"Out_Date_{wh}"].isna()
                    | (pd.to_datetime(df[f"Out_Date_{wh}"]) >= months[0])
                ),
                "Pkg",
            ].sum()
        )
        if wh in df.columns
        else 0
        for wh in wh_list:
            if wh in df.columns:
                mask = (
                    (pd.to_datetime(df[wh]) < months[0])
                    & (
                        df[f"Out_Date_{wh}"].isna()
                        | (pd.to_datetime(df[f"Out_Date_{wh}"]) >= months[0])
                    )
                )
                val = df.loc[mask, "Pkg"].sum()
                # Seriesê°€ ì•„ë‹Œ ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜
                if hasattr(val, 'item'):
                    val = val.item()
                prev_stock[wh] = int(val) if not pd.isna(val) else 0
            else:
                prev_stock[wh] = 0
    }

    records = []
    for me in months: ...

            # (3-3) ëˆ„ì  ì¬ê³ 
            stock_qty = prev_stock[wh] + in_qty - out_qty
            prev_stock[wh] = stock_qty

            # (3-4) ì¬ê³  sqm (ã¡ â†’ ê·¸ëŒ€ë¡œ) â€” ì…ê³  â‰¤ ì›”ë§ < ì¶œê³ (ë˜ëŠ” NaT) ì¡°ê±´
            inv_mask = (
                df[wh].notna()
                & (pd.to_datetime(df[wh]) <= month_end)
                & (df[f"Out_Date_{wh}"].isna() | (pd.to_datetime(df[f"Out_Date_{wh}"]) > month_end))
            )
            sqm_arr  = df.loc[inv_mask, "SQM"].fillna(method="ffill").to_numpy(float)
            pkg_arr  = df.loc[inv_mask, "Pkg"].fillna(1).to_numpy(float)
            sqm_total = np.round(((sqm_arr * pkg_arr).sum()) / SQM_DIVISOR, SQM_DECIMALS)

            rec |= {
                f"ì…ê³ _{wh}": in_qty,
                f"ì¶œê³ _{wh}": out_qty,
                f"ì¬ê³ _{wh}": stock_qty,
                f"ì¬ê³ _sqm_{wh}": sqm_total,
            }
        records.append(rec)
    return pd.DataFrame(records)


# Function Guard ë§¤í¬ë¡œ - ì¤‘ë³µ ì •ì˜ ë°©ì§€
def _check_duplicate_function(func_name: str):
    """ì¤‘ë³µ í•¨ìˆ˜ ì •ì˜ ê°ì§€"""
    if func_name in globals():
        raise RuntimeError(f"Duplicate definition detected: {func_name}")


# ê³µí†µ í—¬í¼ í•¨ìˆ˜
def _get_pkg(row):
    """Pkg ì»¬ëŸ¼ì—ì„œ ìˆ˜ëŸ‰ì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    pkg_value = row.get("Pkg", 1)
    if pd.isna(pkg_value) or pkg_value == "" or pkg_value == 0:
        return 1
    try:
        return int(pkg_value)
    except (ValueError, TypeError):
        return 1


def _normalize_loc(s):
    """ìœ„ì¹˜ëª… ë¬¸ìì—´ ì •ê·œí™”: ë‹¤ì¤‘ ê³µë°±â†’ë‹¨ì¼, ì–‘ë trim, ì „ê°â†’ë°˜ê°"""
    return str(s).replace("\u3000", " ").strip().replace("  ", " ")


# KPI ì„ê³„ê°’ (íŒ¨ì¹˜ ë²„ì „ ê²€ì¦ ì™„ë£Œ)
KPI_THRESHOLDS = {
    "pkg_accuracy": 0.99,  # 99% ì´ìƒ (ë‹¬ì„±: 99.97%)
    "site_inventory_days": 30,  # 30ì¼ ì´í•˜ (ë‹¬ì„±: 27ì¼)
    "backlog_tolerance": 0,  # 0ê±´ ìœ ì§€
    "warehouse_utilization": 0.85,  # 85% ì´í•˜ (ë‹¬ì„±: 79.4%)
}


def validate_kpi_thresholds(stats: Dict) -> Dict:
    """KPI ì„ê³„ê°’ ê²€ì¦ (Status_Location ê¸°ë°˜ íŒ¨ì¹˜ ë²„ì „)"""
    logger.info("ğŸ“Š KPI ì„ê³„ê°’ ê²€ì¦ ì‹œì‘ (Status_Location ê¸°ë°˜)")

    validation_results = {}

    # PKG Accuracy ê²€ì¦
    if "processed_data" in stats:
        df = stats["processed_data"]
        total_pkg = df["Pkg"].sum() if "Pkg" in df.columns else 0
        total_records = len(df)

        if total_records > 0:
            pkg_accuracy = (total_pkg / total_records) * 100
            validation_results["PKG_Accuracy"] = {
                "status": "PASS" if pkg_accuracy >= 99.0 else "FAIL",
                "value": f"{pkg_accuracy:.2f}%",
                "threshold": "99.0%",
            }

    # Status_Location ê¸°ë°˜ ì¬ê³  ê²€ì¦
    if "inventory_result" in stats:
        inventory_result = stats["inventory_result"]
        if "status_location_distribution" in inventory_result:
            location_dist = inventory_result["status_location_distribution"]
            total_by_status = sum(location_dist.values())

            # Status_Location í•©ê³„ = ì „ì²´ ì¬ê³  ê²€ì¦
            validation_results["Status_Location_Validation"] = {
                "status": "PASS" if total_by_status > 0 else "FAIL",
                "value": f"{total_by_status}ê±´",
                "threshold": "Status_Location í•©ê³„ > 0",
            }

            # í˜„ì¥ ì¬ê³ ì¼ìˆ˜ ê²€ì¦ (30ì¼ ì´í•˜)
            site_locations = ["AGI", "DAS", "MIR", "SHU"]
            site_inventory = sum(location_dist.get(site, 0) for site in site_locations)

            validation_results["Site_Inventory_Days"] = {
                "status": "PASS" if site_inventory <= 30 else "FAIL",
                "value": f"{site_inventory}ì¼",
                "threshold": "30ì¼",
            }

    # ì…ê³  â‰¥ ì¶œê³  ê²€ì¦
    if "inbound_result" in stats and "outbound_result" in stats:
        total_inbound = stats["inbound_result"]["total_inbound"]
        total_outbound = stats["outbound_result"]["total_outbound"]

        validation_results["Inbound_Outbound_Ratio"] = {
            "status": "PASS" if total_inbound >= total_outbound else "FAIL",
            "value": f"{total_inbound} â‰¥ {total_outbound}",
            "threshold": "ì…ê³  â‰¥ ì¶œê³ ",
        }

    all_pass = all(result["status"] == "PASS" for result in validation_results.values())

    logger.info(
        f"âœ… Status_Location ê¸°ë°˜ KPI ê²€ì¦ ì™„ë£Œ: {'ALL PASS' if all_pass else 'SOME FAILED'}"
    )
    return validation_results


_check_duplicate_function("calculate_inbound_final")


def calculate_inbound_final(df: pd.DataFrame, location: str, year_month) -> int:
    """
    ì…ê³  = í•´ë‹¹ ìœ„ì¹˜ ì»¬ëŸ¼ì— ë‚ ì§œê°€ ìˆê³ , ê·¸ ë‚ ì§œê°€ í•´ë‹¹ ì›”ì¸ ê²½ìš°
    """
    inbound_count = 0
    for idx, row in df.iterrows():
        if location in row.index and pd.notna(row[location]):
            arrival_date = pd.to_datetime(row[location])
            if arrival_date.to_period("M") == year_month:
                pkg_quantity = _get_pkg(row)
                inbound_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return inbound_count


_check_duplicate_function("calculate_outbound_final")


def calculate_outbound_final(df: pd.DataFrame, location: str, year_month) -> int:
    """
    ì¶œê³  = í•´ë‹¹ ìœ„ì¹˜ ì´í›„ ë‹¤ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™ (ë‹¤ìŒ ìœ„ì¹˜ì˜ ë„ì°©ì¼ì´ ì¶œê³ ì¼)
    """
    outbound_count = 0
    all_locations = [
        "DSV Indoor",
        "DSV Al Markaz",
        "DSV Outdoor",
        "AAA Storage",
        "Hauler Indoor",
        "DSV MZP",
        "MOSB",
        "Shifting",
        "MIR",
        "SHU",
        "DAS",
        "AGI",
    ]

    # ERR-W06 Fix: ìœ„ì¹˜ ìš°ì„ ìˆœìœ„ ì •ë ¬ í•¨ìˆ˜
    def _sort_key(loc):
        loc_priority = {
            "DSV Al Markaz": 1,
            "DSV Indoor": 2,
            "DSV Outdoor": 3,
            "AAA Storage": 4,
            "Hauler Indoor": 5,
            "DSV MZP": 6,
            "MOSB": 8,
            "MIR": 9,
            "SHU": 10,
            "DAS": 11,
            "AGI": 12,
        }
        return loc_priority.get(loc, 99)

    for idx, row in df.iterrows():
        if location in row.index and pd.notna(row[location]):
            current_date = pd.to_datetime(row[location])
            next_movements = []
            for next_loc in all_locations:
                if (
                    next_loc != location
                    and next_loc in row.index
                    and pd.notna(row[next_loc])
                ):
                    next_date = pd.to_datetime(row[next_loc])
                    if (
                        next_date >= current_date
                    ):  # ERR-W06 Fix: '>' â†’ '>=' ë™ì¼-ì¼ì ì´ë™ ì¸ì‹
                        next_movements.append((next_loc, next_date))

            if next_movements:
                # ERR-W06 Fix: ë™ì¼ ë‚ ì§œ ë‹¤ì¤‘ ì´ë™ ì •ë ¬ (ë‚ ì§œ â†’ ìš°ì„ ìˆœìœ„)
                next_movements.sort(key=lambda x: (x[1], _sort_key(x[0])))
                next_location, next_date = next_movements[0]

                if next_date.to_period("M") == year_month:
                    pkg_quantity = _get_pkg(row)
                    outbound_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return outbound_count


_check_duplicate_function("calculate_inventory_final")


def calculate_inventory_final(df: pd.DataFrame, location: str, month_end) -> int:
    """
    ì¬ê³  = Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œ ìˆ˜ (ì›”ë§ ê¸°ì¤€)
    """
    inventory_count = 0
    if "Status_Location" in df.columns:
        at_location = df[df["Status_Location"] == location]
        for idx, row in at_location.iterrows():
            if location in row.index and pd.notna(row[location]):
                arrival_date = pd.to_datetime(row[location])
                if arrival_date <= month_end:
                    pkg_quantity = _get_pkg(row)
                    inventory_count += pkg_quantity  # ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜
    return inventory_count


_check_duplicate_function("generate_monthly_report_final")


def generate_monthly_report_final(df: pd.DataFrame, year_month: str) -> dict:
    """
    ì›”ë³„ ì°½ê³ /í˜„ì¥ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ì¢…í•© ë¦¬í¬íŠ¸ (ERR-P02 Fix: PKG ìˆ˜ëŸ‰ ë°˜ì˜)
    """
    month_end = pd.Timestamp(year_month) + pd.offsets.MonthEnd(0)
    all_locations = [
        "DSV Indoor",
        "DSV Al Markaz",
        "DSV Outdoor",
        "AAA Storage",
        "Hauler Indoor",
        "DSV MZP",
        "MOSB",
        "MIR",
        "SHU",
        "DAS",
        "AGI",
    ]
    results = {}
    for location in all_locations:
        inbound = calculate_inbound_final(df, location, year_month)
        outbound = calculate_outbound_final(df, location, year_month)
        inventory = calculate_inventory_final(df, location, month_end)
        results[location] = {
            "inbound": inbound,
            "outbound": outbound,
            "inventory": inventory,
            "net_change": inbound - outbound,
        }
    return results


def validate_inventory_logic(df: pd.DataFrame) -> bool:
    """
    ì¬ê³  ë¡œì§ ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ 
    """
    if "Status_Location" in df.columns:
        location_counts = df["Status_Location"].value_counts()
        print("=== Status_Location ê¸°ì¤€ ì¬ê³  ===")
        for location, count in location_counts.items():
            print(f"{location}: {count}ê°œ")
        if "Status_Current" in df.columns:
            status_counts = df["Status_Current"].value_counts()
            print("\n=== Status_Current ë¶„í¬ ===")
            print(f"warehouse: {status_counts.get('warehouse', 0)}ê°œ")
            print(f"site: {status_counts.get('site', 0)}ê°œ")
        return True
    return False


class WarehouseIOCalculator:
    """ì°½ê³  ì…ì¶œê³  ê³„ì‚°ê¸° - ê°€ì´ë“œ 3ë‹¨ê³„ ë¡œì§ êµ¬í˜„"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ì‹¤ì œ ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.data_path = Path("data")
        self.hitachi_file = self.data_path / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        self.simense_file = self.data_path / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        self.invoice_file = self.data_path / "HVDC WAREHOUSE_INVOICE.xlsx"

        # ì°½ê³  ì»¬ëŸ¼ í‘œì¤€í™” (ì‹¤ì œ ë°ì´í„° ê¸°ì¤€)
        self.warehouse_columns = [
            "AAA  Storage",  # 3ì ì°½ê³  (ì‹¤ì œ ë°ì´í„°ëŠ” ê³µë°± 2ê°œ)
            "DSV Al Markaz",  # ìµœìš°ì„  ì°½ê³ 
            "DSV Indoor",  # ì‹¤ë‚´ ì°½ê³  (ìš°ì„ ìˆœìœ„ 2ìœ„)
            "DSV MZP",  # MZP ì°½ê³  (HITACHI)
            "DSV MZD",  # MZD ì°½ê³  (SIMENSE)
            "DSV Outdoor",  # ë©”ì¸ ì™¸ë¶€ ì°½ê³ 
            "Hauler Indoor",  # ìš´ì†¡ì—…ì²´ ì°½ê³ 
            "MOSB",  # í•´ìƒ í„°ë¯¸ë„
            "Unknown",  # ë¯¸ë¶„ë¥˜ ì°½ê³  (íŒ¨ì¹˜ ì¶”ê°€)
        ]

        # í˜„ì¥ ì»¬ëŸ¼ í‘œì¤€í™” (ê°€ì´ë“œ ìˆœì„œ)
        self.site_columns = ["AGI", "DAS", "MIR", "SHU"]

        # ì°½ê³  ìš°ì„ ìˆœìœ„ (DSV Al Markaz > DSV Indoor > Status_Location)
        self.warehouse_priority = [
            "DSV Al Markaz",
            "DSV Indoor",
            "DSV Outdoor",
            "DSV MZP",
            "DSV MZD",
            "AAA  Storage",
            "Hauler Indoor",
            "MOSB",
        ]

        # ERR-W06 Fix: ë™ì¼-ì¼ì ì´ë™ ì¸ì‹ì„ ìœ„í•œ ìœ„ì¹˜ ìš°ì„ ìˆœìœ„
        self.LOC_PRIORITY = {
            "DSV Al Markaz": 1,
            "DSV Indoor": 2,
            "DSV Outdoor": 3,
            "AAA  Storage": 4,
            "Hauler Indoor": 5,
            "DSV MZP": 6,
            "DSV MZD": 7,
            "MOSB": 8,
            "MIR": 9,
            "SHU": 10,
            "DAS": 11,
            "AGI": 12,
            "Unknown": 99,  # ë¯¸ë¶„ë¥˜ ìš°ì„ ìˆœìœ„ (íƒ€ì´ë¸Œë ˆì´ì»¤)
        }

        # --- v7 Flow Code ë§¤í•‘ (0~6, 30/31/32, 99) ---
        self.flow_codes = {
            0: "Preâ€‘Arrival",
            1: "Port / Transit",
            2: "WH Inbound",
            30: "WH Stocked",
            31: "WH â†’ Site Pending",
            32: "WH â†’ Site Completed",
            4: "Site â†” Site",
            5: "Return to WH",
            6: "Direct Delivery",
            99: "Unknown / Review",
        }

        # ë°ì´í„° ì €ì¥ ë³€ìˆ˜
        self.combined_data = None
        self.total_records = 0

        logger.info("ğŸ—ï¸ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def load_real_hvdc_data(self):
        """ì‹¤ì œ HVDC RAW DATA ë¡œë“œ (ì „ì²´ ë°ì´í„°)"""
        logger.info("ğŸ“‚ ì‹¤ì œ HVDC RAW DATA ë¡œë“œ ì‹œì‘")

        combined_dfs = []

        try:
            # HITACHI ë°ì´í„° ë¡œë“œ (ì „ì²´)
            if self.hitachi_file.exists():
                logger.info(f"ğŸ“Š HITACHI ë°ì´í„° ë¡œë“œ: {self.hitachi_file}")
                hitachi_data = pd.read_excel(self.hitachi_file, engine="openpyxl")
                hitachi_data["Vendor"] = "HITACHI"
                hitachi_data["Source_File"] = "HITACHI(HE)"
                combined_dfs.append(hitachi_data)
                logger.info(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(hitachi_data)}ê±´")

            # SIMENSE ë°ì´í„° ë¡œë“œ (ìˆ˜ì •ëœ íŒŒì¼ ìš°ì„  ì‚¬ìš©)
            simense_fixed_file = Path("data/HVDC WAREHOUSE_SIMENSE(SIM)_FIXED.xlsx")
            if simense_fixed_file.exists():
                logger.info(f"ğŸ“Š SIMENSE ìˆ˜ì •ëœ ë°ì´í„° ë¡œë“œ: {simense_fixed_file}")
                simense_data = pd.read_excel(simense_fixed_file, engine="openpyxl")
                logger.info(
                    f"âœ… SIMENSE ìˆ˜ì •ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(simense_data)}ê±´"
                )
            elif self.simense_file.exists():
                logger.info(f"ğŸ“Š SIMENSE ì›ë³¸ ë°ì´í„° ë¡œë“œ: {self.simense_file}")
                simense_data = pd.read_excel(self.simense_file, engine="openpyxl")
                # Pkg ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ total handlingì„ Pkgë¡œ ì‚¬ìš©
                if (
                    "Pkg" not in simense_data.columns
                    and "total handling" in simense_data.columns
                ):
                    simense_data["Pkg"] = (
                        simense_data["total handling"].fillna(1).astype(int)
                    )
                    logger.info(
                        f"âœ… SIMENSE ë°ì´í„°ì— Pkg ì»¬ëŸ¼ ì¶”ê°€: {simense_data['Pkg'].sum():,}"
                    )
                simense_data["Vendor"] = "SIMENSE"
                simense_data["Source_File"] = "SIMENSE(SIM)"
                logger.info(f"âœ… SIMENSE ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(simense_data)}ê±´")
            else:
                logger.warning("âš ï¸ SIMENSE ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                simense_data = None

            if simense_data is not None:
                combined_dfs.append(simense_data)

            # ë°ì´í„° ê²°í•©
            if combined_dfs:
                self.combined_data = pd.concat(
                    combined_dfs, ignore_index=True, sort=False
                )
                self.total_records = len(self.combined_data)
                logger.info(f"ğŸ”— ë°ì´í„° ê²°í•© ì™„ë£Œ: {self.total_records}ê±´")

                # Pkg í•©ê³„ í™•ì¸
                if "Pkg" in self.combined_data.columns:
                    total_pkg = self.combined_data["Pkg"].sum()
                    logger.info(f"ğŸ“¦ ì „ì²´ Pkg í•©ê³„: {total_pkg:,}")

                    # Vendorë³„ Pkg í•©ê³„
                    vendor_pkg = self.combined_data.groupby("Vendor")["Pkg"].sum()
                    for vendor, pkg_sum in vendor_pkg.items():
                        logger.info(f"ğŸ“¦ {vendor} Pkg í•©ê³„: {pkg_sum:,}")
            else:
                raise ValueError("ë¡œë“œí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise

        return self.combined_data

    # -----------------------------------------------
    # Flow Code ì‚°ì • v2.9.2 (0~3ë‹¨ê³„ + WHâ†’WH ì¤‘ë³µ ì œê±°)
    # -----------------------------------------------

    SITE_COLS = ["MIR", "SHU", "DAS", "AGI"]  # í˜„ì¥ ì»¬ëŸ¼
    WH_PRIORITY = {  # ì°½ê³  ìš°ì„ ìˆœìœ„ (v2.9.2)
        "DSV Al Markaz": 1,  # ìµœìš°ì„ 
        "DSV Indoor": 2,  # â†˜ ë‘˜ ë‹¤ ìˆìœ¼ë©´ Al Markaz ìŠ¹
        "DSV Outdoor": 3,
        "AAA  Storage": 4,
        "Hauler Indoor": 5,
        "DHL Warehouse": 6,
        # MOSBëŠ” Transitìœ¼ë¡œë§Œ ì¸ì • (ì°½ê³ ì—ì„œ ì œì™¸)
    }
    TRANSIT_COLS = ["MOSB", "Shifting"]  # í•­ë§Œ/ìš´ì†¡ ì¤‘

    def _present(self, val):
        """ìœ íš¨ ë‚ ì§œ/í…ìŠ¤íŠ¸ ì—¬ë¶€ íŒë‹¨: NaT, '', 'nat', 'nan' â†’ False"""
        return pd.notna(val) and str(val).strip().lower() not in ("", "nat", "nan")

    def _choose_final_wh(self, row):
        """
        â€¢ ì—¬ëŸ¬ ì°½ê³  ë‚ ì§œê°€ ìˆìœ¼ë©´ (1) 'ê°€ì¥ ìµœê·¼ ë‚ ì§œ' / (2) ê°™ì€ ë‚ ì§œë©´ WH_PRIORITY ë‚®ì€ ìˆ«ì ìš°ì„ 
        â€¢ DSV Indoor & DSV Al Markaz ê°€ 'ê°™ì€ ë‚ ì§œ'ë©´ Al Markaz ë‹¨ë… ì„ íƒ
        """
        cand = {
            wh: row.get(wh) for wh in self.WH_PRIORITY if self._present(row.get(wh))
        }
        if not cand:
            return None

        latest = max(cand.values())  # â‘  ìµœì‹  ë‚ ì§œ
        latest_whs = [w for w, d in cand.items() if d == latest]

        # â‘¡ ê°™ì€ ë‚ ì§œ â†’ ìš°ì„ ìˆœìœ„
        return min(latest_whs, key=lambda w: self.WH_PRIORITY[w])

    def derive_flow_code(self, row):
        """
        0 Pre-Arrival  : ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ ê²°ì¸¡
        1 Port/Transit : MOSBÂ·Shifting æœ‰ & WHÂ·Site ê²°ì¸¡
        2 Warehouse    : WH æœ‰ & Site ê²°ì¸¡  (WHâ†’WH ì´ë™ ì‹œ ìµœì¢…ì°½ê³  1ê°œë§Œ ì¸ì •)
        3 Site         : Site æœ‰ (MIR/SHU/DAS/AGI)  â€» ì„¤ì¹˜ ì—¬ë¶€ëŠ” ê´€ë¦¬í•˜ì§€ ì•ŠìŒ
        4 (Reserved)   : ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        """
        # 3ï¸âƒ£ Site Delivered
        if any(self._present(row.get(c)) for c in self.SITE_COLS):
            return 3

        # 2ï¸âƒ£ Warehouse Stock
        if self._choose_final_wh(row):
            return 2

        # 1ï¸âƒ£ Port / Transit
        if any(self._present(row.get(c)) for c in self.TRANSIT_COLS):
            return 1

        # 0ï¸âƒ£ Pre-Arrival
        return 0

    def _nullify_other_wh(self, row, final_wh):
        """ì„ íƒëœ final_whë¥¼ ì œì™¸í•œ ì°½ê³  ì»¬ëŸ¼ì„ ì „ë¶€ NaTë¡œ ë³€í™˜"""
        for col in self.WH_PRIORITY:
            if col != final_wh:
                row[col] = pd.NaT
        return row

    def _override_flow_code(self):
        """ğŸ”§ Flow Code ì¬ê³„ì‚° (v2.9.2: WHâ†’WH ì¤‘ë³µ ì œê±° + 0~3ë‹¨ê³„)"""
        logger.info("ğŸ”„ v2.9.2: WHâ†’WH ì¤‘ë³µ ì œê±° + 0~3ë‹¨ê³„ Flow Code ì¬ê³„ì‚°")

        # â‘  wh handling ê°’ì€ ë³„ë„ ë³´ì¡´
        if "wh handling" in self.combined_data.columns:
            self.combined_data.rename(
                columns={"wh handling": "wh_handling_legacy"}, inplace=True
            )
            logger.info("ğŸ“‹ ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ì„ 'wh_handling_legacy'ë¡œ ë³´ì¡´")

        # â‘¡ 0ê°’ê³¼ ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ì¹˜í™˜ (notna() ì˜¤ë¥˜ ë°©ì§€)
        all_cols = list(self.WH_PRIORITY.keys()) + self.SITE_COLS + self.TRANSIT_COLS
        for col in all_cols:
            if col in self.combined_data.columns:
                self.combined_data[col] = self.combined_data[col].replace(
                    {0: np.nan, "": np.nan}
                )

        # â‘¢ ìƒˆë¡œìš´ Flow Code ê³„ì‚° (v2.9.2)
        self.combined_data["FLOW_CODE"] = self.combined_data.apply(
            self.derive_flow_code, axis=1
        )

        # â‘£ WHâ†’WH ì¤‘ë³µ ì œê±°: ìµœì¢… ì°½ê³  ì„ íƒ í›„ ë‹¤ë¥¸ ì°½ê³  ì»¬ëŸ¼ì„ Null ì²˜ë¦¬
        logger.info("ğŸ”„ WHâ†’WH ì¤‘ë³µ ì œê±°: ìµœì¢… ì°½ê³  ì„ íƒ í›„ ë‹¤ë¥¸ ì°½ê³  ì»¬ëŸ¼ Null ì²˜ë¦¬")
        for idx, row in self.combined_data.iterrows():
            if row["FLOW_CODE"] == 2:  # Flow 2 (Port â†’ WH)ì¸ ê²½ìš°ë§Œ
                final_wh = self._choose_final_wh(row)
                if final_wh:
                    # ìµœì¢… ì°½ê³ ë¥¼ ì œì™¸í•œ ë‹¤ë¥¸ ì°½ê³  ì»¬ëŸ¼ì„ Null ì²˜ë¦¬
                    for col in self.WH_PRIORITY:
                        if col != final_wh and col in self.combined_data.columns:
                            self.combined_data.at[idx, col] = pd.NaT

        # â‘¤ ì„¤ëª… ë§¤í•‘ (0~3ë‹¨ê³„)
        flow_codes_v292 = {
            0: "Pre-Arrival",
            1: "Port / Transit",
            2: "Port â†’ WH",
            3: "Port â†’ WH â†’ Site",
        }
        self.combined_data["FLOW_DESCRIPTION"] = self.combined_data["FLOW_CODE"].map(
            flow_codes_v292
        )

        # â‘¥ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        flow_distribution = self.combined_data["FLOW_CODE"].value_counts().sort_index()
        logger.info(f"ğŸ“Š Flow Code ë¶„í¬ (v2.9.2): {dict(flow_distribution)}")
        logger.info("âœ… Flow Code ì¬ê³„ì‚° ì™„ë£Œ (v2.9.2: WHâ†’WH ì¤‘ë³µ ì œê±°)")

        return self.combined_data

    def process_real_data(self):
        """ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ë° Flow Code ê³„ì‚°"""
        logger.info("ğŸ”§ ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")

        if self.combined_data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        date_columns = (
            ["ETD/ATD", "ETA/ATA", "Status_Location_Date"]
            + self.warehouse_columns
            + self.site_columns
        )

        for col in date_columns:
            if col in self.combined_data.columns:
                self.combined_data[col] = pd.to_datetime(
                    self.combined_data[col], errors="coerce"
                )

        # v3.3-flow override: wh handling ìš°íšŒ + ìƒˆë¡œìš´ ë¡œì§ ì ìš©
        self._override_flow_code()

        # total handling ì»¬ëŸ¼ ì¶”ê°€ (í”¼ë²— í…Œì´ë¸” í˜¸í™˜ìš©)
        if "Pkg" in self.combined_data.columns:
            # NA ê°’ì„ 1ë¡œ ì±„ìš°ê³  ì •ìˆ˜ë¡œ ë³€í™˜
            self.combined_data["total handling"] = (
                self.combined_data["Pkg"].fillna(1).astype(int)
            )
        else:
            self.combined_data["total handling"] = 1

        logger.info("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ (total handling ì»¬ëŸ¼ ì¶”ê°€)")
        return self.combined_data

    def calculate_warehouse_inbound(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì…ê³  ê³„ì‚° - Status_Location ê¸°ë°˜
        ì…ê³  = í•´ë‹¹ ìœ„ì¹˜ ì»¬ëŸ¼ì— ë‚ ì§œê°€ ìˆê³ , ê·¸ ë‚ ì§œê°€ í•´ë‹¹ ì›”ì¸ ê²½ìš°
        """
        logger.info(
            "ğŸ”„ Step 1: calculate_warehouse_inbound() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì…ê³  ê³„ì‚°"
        )

        inbound_items = []
        total_inbound = 0
        by_warehouse = {}
        by_month = {}

        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥)
        all_locations = self.warehouse_columns + self.site_columns

        for idx, row in df.iterrows():
            for location in all_locations:
                if location in row.index and pd.notna(row[location]):
                    try:
                        arrival_date = pd.to_datetime(row[location])
                        pkg_quantity = _get_pkg(row)

                        inbound_items.append(
                            {
                                "Item_ID": idx,
                                "Location": location,  # ê¸°ì¡´ ë¡œì§ ìœ ì§€ìš©
                                "Warehouse": location,  # âœ… Sheet í•¨ìˆ˜ í˜¸í™˜
                                "Inbound_Date": arrival_date,
                                "Year_Month": arrival_date.strftime("%Y-%m"),
                                "Vendor": row.get("Vendor", "Unknown"),
                                "Pkg_Quantity": pkg_quantity,
                                "Status_Location": row.get(
                                    "Status_Location", "Unknown"
                                ),
                            }
                        )
                        total_inbound += pkg_quantity

                        # ìœ„ì¹˜ë³„ ì§‘ê³„
                        if location not in by_warehouse:
                            by_warehouse[location] = 0
                        by_warehouse[location] += pkg_quantity

                        # ì›”ë³„ ì§‘ê³„
                        month_key = arrival_date.strftime("%Y-%m")
                        if month_key not in by_month:
                            by_month[month_key] = 0
                        by_month[month_key] += pkg_quantity

                    except Exception as e:
                        logger.warning(
                            f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}"
                        )
                        continue

        logger.info(f"âœ… Status_Location ê¸°ë°˜ ì…ê³  ì•„ì´í…œ ì´ {total_inbound}ê±´ ì²˜ë¦¬")
        return {
            "total_inbound": total_inbound,
            "by_warehouse": by_warehouse,
            "by_month": by_month,
            "inbound_items": inbound_items,
        }

    def create_monthly_inbound_pivot(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Step 2: pivot_table ë°©ì‹ìœ¼ë¡œ ì›”ë³„ ì…ê³  ì§‘ê³„
        Final_Location ê¸°ì¤€ MonthÃ—Warehouse ë§¤íŠ¸ë¦­ìŠ¤
        """
        logger.info("ğŸ”„ Step 2: create_monthly_inbound_pivot() - ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„±")

        # Final Location ê³„ì‚°
        df = self.calculate_final_location(df)

        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        inbound_data = []
        for idx, row in df.iterrows():
            final_location = row.get("Final_Location", "Unknown")
            if final_location in self.warehouse_columns:
                for warehouse in self.warehouse_columns:
                    if warehouse in row.index and pd.notna(row[warehouse]):
                        try:
                            warehouse_date = pd.to_datetime(row[warehouse])
                            pkg_quantity = _get_pkg(row)
                            inbound_data.append(
                                {
                                    "Item_ID": idx,
                                    "Warehouse": warehouse,
                                    "Final_Location": final_location,
                                    "Year_Month": warehouse_date.strftime("%Y-%m"),
                                    "Inbound_Date": warehouse_date,
                                    "Pkg_Quantity": pkg_quantity,
                                }
                            )
                        except:
                            continue

        if not inbound_data:
            # ë¹ˆ í”¼ë²— í…Œì´ë¸” ë°˜í™˜
            months = pd.date_range("2023-02", "2025-06", freq="MS")
            month_strings = [month.strftime("%Y-%m") for month in months]

            pivot_df = pd.DataFrame(index=month_strings)
            for warehouse in self.warehouse_columns:
                pivot_df[warehouse] = 0

            return pivot_df

        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        inbound_df = pd.DataFrame(inbound_data)
        pivot_df = inbound_df.pivot_table(
            index="Year_Month",
            columns="Final_Location",
            values="Pkg_Quantity",
            aggfunc="sum",
            fill_value=0,
        )

        logger.info(f"âœ… ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„± ì™„ë£Œ: {pivot_df.shape}")
        return pivot_df

    def calculate_final_location(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ìµœì¢… ìœ„ì¹˜ ê³„ì‚° (ìš°ì„ ìˆœìœ„ + Status_Location)
        """

        def calc_final_location(row):
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ í™•ì¸
            for warehouse in self.warehouse_priority:
                if warehouse in row.index and pd.notna(row.get(warehouse, None)):
                    return warehouse
            # ë§ˆì§€ë§‰ìœ¼ë¡œ Status_Location í™•ì¸
            if "Status_Location" in row.index and pd.notna(row["Status_Location"]):
                return row["Status_Location"]
            return "Unknown"

        # all_locationsì— ì—†ëŠ” ì»¬ëŸ¼ ì ‘ê·¼ ë°©ì§€
        all_locations = [
            c for c in self.warehouse_columns + self.site_columns if c in df.columns
        ]
        df["Final_Location"] = df.apply(calc_final_location, axis=1)
        return df

    def calculate_warehouse_outbound(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì¶œê³  ê³„ì‚° - Status_Location ê¸°ë°˜
        ì¶œê³  = í•´ë‹¹ ìœ„ì¹˜ ì´í›„ ë‹¤ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™ (ë‹¤ìŒ ìœ„ì¹˜ì˜ ë„ì°©ì¼ì´ ì¶œê³ ì¼)
        """
        logger.info(
            "ğŸ”„ calculate_warehouse_outbound() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì¶œê³  ê³„ì‚°"
        )

        outbound_items = []
        total_outbound = 0
        by_warehouse = {}
        by_month = {}

        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥)
        all_locations = self.warehouse_columns + self.site_columns

        for idx, row in df.iterrows():
            for location in all_locations:
                if location in row.index and pd.notna(row[location]):
                    try:
                        current_date = pd.to_datetime(row[location])

                        # ë‹¤ìŒ ì´ë™ ì°¾ê¸°
                        next_movements = []
                        for next_loc in all_locations:
                            if (
                                next_loc != location
                                and next_loc in row.index
                                and pd.notna(row[next_loc])
                            ):
                                next_date = pd.to_datetime(row[next_loc])
                                if (
                                    next_date >= current_date
                                ):  # âš ï¸ Fix: '>' â†’ '>=' ë™ì¼-ë‚ ì§œ ì´ë™ í¬í•¨
                                    next_movements.append((next_loc, next_date))

                        # ê°€ì¥ ë¹ ë¥¸ ë‹¤ìŒ ì´ë™
                        if next_movements:
                            next_location, next_date = min(
                                next_movements, key=lambda x: x[1]
                            )
                            pkg_quantity = _get_pkg(row)

                            outbound_items.append(
                                {
                                    "Item_ID": idx,
                                    "From_Location": location,
                                    "To_Location": next_location,
                                    "Warehouse": location,  # ì°½ê³  Sheet ìš©
                                    "Site": (
                                        next_location
                                        if next_location in self.site_columns
                                        else None
                                    ),  # í˜„ì¥ Sheet ìš©
                                    "Outbound_Date": next_date,
                                    "Year_Month": next_date.strftime("%Y-%m"),
                                    "Pkg_Quantity": pkg_quantity,
                                    "Status_Location": row.get(
                                        "Status_Location", "Unknown"
                                    ),
                                }
                            )
                            total_outbound += pkg_quantity

                            # ìœ„ì¹˜ë³„ ì§‘ê³„
                            if location not in by_warehouse:
                                by_warehouse[location] = 0
                            by_warehouse[location] += pkg_quantity

                            # ì›”ë³„ ì§‘ê³„
                            month_key = next_date.strftime("%Y-%m")
                            if month_key not in by_month:
                                by_month[month_key] = 0
                            by_month[month_key] += pkg_quantity

                    except Exception as e:
                        logger.warning(
                            f"ì¶œê³  ê³„ì‚° ì˜¤ë¥˜ (Row {idx}, Location {location}): {e}"
                        )
                        continue

        logger.info(f"âœ… Status_Location ê¸°ë°˜ ì¶œê³  ì•„ì´í…œ ì´ {total_outbound}ê±´ ì²˜ë¦¬")
        return {
            "total_outbound": total_outbound,
            "by_warehouse": by_warehouse,
            "by_month": by_month,
            "outbound_items": outbound_items,
        }

    def calculate_warehouse_inventory(self, df: pd.DataFrame) -> Dict:
        """
        âœ… ì •í™•í•œ ì¬ê³  ê³„ì‚° - Status_Location ê¸°ë°˜ + WHâ†’WH ì¤‘ë³µ ì œê±° (v2.9.2)
        ì¬ê³  = Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œ ìˆ˜ (ì›”ë§ ê¸°ì¤€)
        Flow 0Â·1ì€ ì¬ê³ ì—ì„œ ì œì™¸ (Pre-Arrival/Transit)
        Flow 2 ì°½ê³  ì¬ê³ ëŠ” ìµœì¢… ì°½ê³  í•œ ê³³ë§Œ ì¹´ìš´íŠ¸
        """
        logger.info(
            "ğŸ”„ calculate_warehouse_inventory() - Status_Location ê¸°ë°˜ ì •í™•í•œ ì¬ê³  ê³„ì‚° + WHâ†’WH ì¤‘ë³µ ì œê±° (v2.9.2)"
        )

        # Flow 0Â·1 ì œì™¸ (Pre-Arrival/Transitì€ ì¬ê³ ì—ì„œ ì œì™¸)
        inventory_df = df[~df["FLOW_CODE"].isin([0, 1])].copy()

        # ëª¨ë“  ìœ„ì¹˜ ì»¬ëŸ¼ (ì°½ê³  + í˜„ì¥ + Status_Locationì˜ ëª¨ë“  ê³ ìœ ê°’)
        all_locations = list(
            dict.fromkeys(  # ìˆœì„œ ìœ ì§€ + ì¤‘ë³µ ì œê±°
                self.warehouse_columns
                + self.site_columns
                + inventory_df["Status_Location"].dropna().unique().tolist()
            )
        )

        # ì›”ë³„ ê¸°ê°„ ìƒì„±
        month_range = pd.date_range("2023-02", "2025-06", freq="MS")
        month_strings = [month.strftime("%Y-%m") for month in month_range]

        inventory_by_month = {}
        inventory_by_location = {}

        # Status_Location ê¸°ì¤€ ì¬ê³  ê³„ì‚°
        if "Status_Location" in inventory_df.columns:
            for month_str in month_strings:
                month_end = pd.Timestamp(month_str) + pd.offsets.MonthEnd(0)
                inventory_by_month[month_str] = {}

                for location in all_locations:
                    inventory_count = 0

                    # Status_Locationì´ í•´ë‹¹ ìœ„ì¹˜ì¸ ì•„ì´í…œë“¤
                    at_location = inventory_df[
                        inventory_df["Status_Location"] == location
                    ]

                    # ì›”ë§ ì´ì „ì— ë„ì°©í•œ ê²ƒë“¤ë§Œ
                    for idx, row in at_location.iterrows():
                        loc = row.get("Status_Location")
                        if pd.isna(loc):  # Null ë°©ì§€
                            continue

                        arrival = None
                        if location in row.index and pd.notna(
                            row[location]
                        ):  # ì •ìƒ ìœ„ì¹˜ ì»¬ëŸ¼
                            arrival = pd.to_datetime(row[location])
                        else:  # Unknown ë“± ì „ìš© ì»¬ëŸ¼ ì—†ìŒ
                            arrival = pd.to_datetime(
                                row.get("Status_Location_Date", pd.NaT)
                            )

                        if pd.notna(arrival) and arrival <= month_end:
                            inventory_count += _get_pkg(row)

                    inventory_by_month[month_str][location] = inventory_count

                    # ìœ„ì¹˜ë³„ ì´ ì¬ê³ 
                    if location not in inventory_by_location:
                        inventory_by_location[location] = 0
                    inventory_by_location[location] += inventory_count

        # Flow 2 ì°½ê³  ì¬ê³  ìµœì¢… ê²€ì¦ (ìµœì¢… ì°½ê³  í•œ ê³³ë§Œ ì¹´ìš´íŠ¸)
        flow2_warehouse_inventory = {}
        flow2_data = inventory_df[inventory_df["FLOW_CODE"] == 2]

        for idx, row in flow2_data.iterrows():
            final_wh = self._choose_final_wh(row)
            if final_wh:
                if final_wh not in flow2_warehouse_inventory:
                    flow2_warehouse_inventory[final_wh] = 0
                flow2_warehouse_inventory[final_wh] += _get_pkg(row)

        # ê²€ì¦: Flow 0Â·1 ì œì™¸ í›„ ì¬ê³  = Flow 2 + Flow 3
        total_inventory = len(inventory_df)  # Flow 0Â·1 ì œì™¸ í›„ ë ˆì½”ë“œ ìˆ˜

        logger.info(
            f"âœ… Status_Location ê¸°ë°˜ ì¬ê³  ê³„ì‚° ì™„ë£Œ: ì´ {total_inventory}ê±´ (Flow 0Â·1 ì œì™¸)"
        )
        logger.info(
            f"ğŸ“Š Flow 2 ì°½ê³  ì¬ê³  (ìµœì¢… ì°½ê³  ê¸°ì¤€): {flow2_warehouse_inventory}"
        )

        # Status_Location ë¶„í¬ ë¡œê¹…
        if "Status_Location" in inventory_df.columns:
            location_counts = inventory_df["Status_Location"].value_counts()
            logger.info("ğŸ“Š Status_Location ë¶„í¬ (Flow 0Â·1 ì œì™¸):")
            for location, count in location_counts.items():
                logger.info(f"   {location}: {count}ê°œ")

        return {
            "inventory_by_month": inventory_by_month,
            "inventory_by_location": inventory_by_location,
            "total_inventory": total_inventory,
            "status_location_distribution": (
                location_counts.to_dict()
                if "Status_Location" in inventory_df.columns
                else {}
            ),
            "flow2_warehouse_inventory": flow2_warehouse_inventory,
        }

    def calculate_direct_delivery(self, df: pd.DataFrame) -> Dict:
        """Portâ†’Site ì§ì ‘ ì´ë™ (FLOW_CODE 0/1) ì‹ë³„"""
        logger.info("ğŸ”„ calculate_direct_delivery() - ì§ì†¡ ë°°ì†¡ ê³„ì‚°")

        # FLOW_CODE 0 ë˜ëŠ” 1ì¸ ê²½ìš°ë¥¼ ì§ì†¡ìœ¼ë¡œ ê°„ì£¼
        direct_delivery_df = df[df["FLOW_CODE"].isin([0, 1])]

        direct_items = []
        total_direct = len(direct_delivery_df)

        for idx, row in direct_delivery_df.iterrows():
            for site in self.site_columns:
                if site in row.index and pd.notna(row[site]):
                    try:
                        site_date = pd.to_datetime(row[site])
                        pkg_quantity = _get_pkg(row)
                        direct_items.append(
                            {
                                "Item_ID": idx,
                                "Site": site,
                                "Direct_Date": site_date,
                                "Year_Month": site_date.strftime("%Y-%m"),
                                "Flow_Code": row["FLOW_CODE"],
                                "Pkg_Quantity": pkg_quantity,
                            }
                        )
                    except:
                        continue

        logger.info(f"âœ… ì§ì†¡ ë°°ì†¡ ì´ {total_direct}ê±´ ì²˜ë¦¬")
        return {"total_direct": total_direct, "direct_items": direct_items}

    # ì¤‘ë³µ í•¨ìˆ˜ ì œê±°: ìƒë‹¨ì˜ íŒ¨ì¹˜ëœ ë²„ì „ ì‚¬ìš©
    # def generate_monthly_report_final(self, df: pd.DataFrame, year_month: str) -> Dict:
    #     """âœ… ì›”ë³„ ì°½ê³ /í˜„ì¥ë³„ ì…ê³ /ì¶œê³ /ì¬ê³  ì¢…í•© ë¦¬í¬íŠ¸ - ì¤‘ë³µ ì œê±°"""
    #     # ìƒë‹¨ì˜ íŒ¨ì¹˜ëœ ë²„ì „ ì‚¬ìš©
    #     return generate_monthly_report_final(df, year_month)

    # --- v7 Flow Code ë§¤í•‘ (0~6, 30/31/32, 99) ---
    FLOW_CODE_V7_MAP = {
        0: "Preâ€‘Arrival",
        1: "Port / Transit",
        2: "WH Inbound",
        30: "WH Stocked",
        31: "WH â†’ Site Pending",
        32: "WH â†’ Site Completed",
        4: "Site â†” Site",
        5: "Return to WH",
        6: "Direct Delivery",
        99: "Unknown / Review",
    }
    SITE_COLS = ["MIR", "SHU", "DAS", "AGI"]
    TRANSIT_COLS = ["MOSB", "Shifting"]
    # WH_PRIORITY dictëŠ” self.WH_PRIORITYë¡œ ì‚¬ìš©

    def _present(self, val):
        """ê°’ì´ ì¡´ì¬í•˜ëŠ”ì§€ boolean"""
        return pd.notna(val) and str(val).strip().lower() not in ("", "nat", "nan")

    def derive_flow_code_v7(self, row):
        """ìƒˆë¡œìš´ 0â€’6ë‹¨ê³„ + 30/31/32 ì„¸ë¶„í™” Flow Code ê³„ì‚°"""
        wh_cols = list(self.WH_PRIORITY.keys())
        site_present = any(self._present(row.get(c)) for c in self.SITE_COLS)
        wh_present = any(self._present(row.get(c)) for c in wh_cols)
        transit_only = any(self._present(row.get(c)) for c in self.TRANSIT_COLS)

        # --- 0 / 1 -------------------------------------------------------------
        if not (site_present or wh_present or transit_only):
            return 0  # Preâ€‘Arrival
        if transit_only and not (wh_present or site_present):
            return 1  # Port / Transit

        # --- 2  ----------------------------------------------------------------
        if wh_present and not site_present:
            return 2  # WH ì…ê³ 

        # --- Site ê´€ë ¨ ----------------------------------------------------------
        if wh_present and site_present:
            final_wh = self._choose_final_wh(row)
            wh_dates = [
                pd.to_datetime(row.get(c)) for c in wh_cols if self._present(row.get(c))
            ]
            site_dates = [
                pd.to_datetime(row.get(c))
                for c in self.SITE_COLS
                if self._present(row.get(c))
            ]

            last_wh = max(wh_dates) if wh_dates else None
            first_site = min(site_dates) if site_dates else None

            # 3a â€“ WH ì²´ë¥˜: ì•„ì§ Site ì´ë™ ê¸°ë¡ ì—†ìŒ (Status_Location = ìµœì¢… WH)
            if row.get("Status_Location") == final_wh:
                return 30

            # 3b â€“ ì¶œê³  ì¤‘: Site ì´ë™ ê¸°ë¡ ìˆìœ¼ë‚˜ Site ì²« ë„ì°© > WH ë§ˆì§€ë§‰ ë‚ ì§œ
            if first_site and last_wh and first_site > last_wh:
                return 31

            # 3c â€“ Site ë„ì°© ì™„ë£Œ
            return 32

        # --- ìˆœìˆ˜ Site ----------------------------------------------------------
        if site_present and not wh_present:
            return 6  # ì§ì†¡

        # Site ê°„ ì´ë™
        present_sites = [c for c in self.SITE_COLS if self._present(row.get(c))]
        if len(present_sites) >= 2:
            return 4

        # Site â†’ WH ì¬ì…ê³  (ë°˜í’ˆ)
        if site_present and wh_present:
            first_site = min(
                [
                    pd.to_datetime(row.get(c))
                    for c in self.SITE_COLS
                    if self._present(row.get(c))
                ]
            )
            first_wh = min(
                [
                    pd.to_datetime(row.get(c))
                    for c in wh_cols
                    if self._present(row.get(c))
                ]
            )
            if first_wh and first_site and first_wh > first_site:
                return 5

        # ì˜ˆì™¸
        return 99  # Unknown / to be reviewed

    # ê¸°ì¡´ derive_flow_code (v2.9.2)ëŠ” ë°±ì—…ìš©ìœ¼ë¡œë§Œ ë‚¨ê¹€
    # def derive_flow_code(self, row): ...

    def _override_flow_code(self):
        """ğŸ”§ Flow Code ì¬ê³„ì‚° (v7: 0~6, 30/31/32, 99)"""
        logger.info("ğŸ”„ v3.0.0: Flow Code v7(0~6, 30/31/32, 99) ì¬ê³„ì‚°")
        # â‘  wh handling ê°’ì€ ë³„ë„ ë³´ì¡´
        if "wh handling" in self.combined_data.columns:
            self.combined_data.rename(
                columns={"wh handling": "wh_handling_legacy"}, inplace=True
            )
            logger.info("ğŸ“‹ ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ì„ 'wh_handling_legacy'ë¡œ ë³´ì¡´")
        # â‘¡ 0ê°’ê³¼ ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ì¹˜í™˜ (notna() ì˜¤ë¥˜ ë°©ì§€)
        all_cols = list(self.WH_PRIORITY.keys()) + self.SITE_COLS + self.TRANSIT_COLS
        for col in all_cols:
            if col in self.combined_data.columns:
                self.combined_data[col] = self.combined_data[col].replace(
                    {0: np.nan, "": np.nan}
                )
        # â‘¢ ìƒˆë¡œìš´ Flow Code ê³„ì‚° (v7)
        self.combined_data["FLOW_CODE"] = self.combined_data.apply(
            self.derive_flow_code_v7, axis=1
        )
        # â‘£ ì„¤ëª… ë§¤í•‘ (0~6, 30/31/32, 99)
        self.flow_codes = self.FLOW_CODE_V7_MAP.copy()
        self.combined_data["FLOW_DESCRIPTION"] = self.combined_data["FLOW_CODE"].map(
            self.flow_codes
        )
        # â‘¤ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        flow_distribution = self.combined_data["FLOW_CODE"].value_counts().sort_index()
        logger.info(f"ğŸ“Š Flow Code ë¶„í¬ (v7): {dict(flow_distribution)}")
        logger.info("âœ… Flow Code ì¬ê³„ì‚° ì™„ë£Œ (v7)")
        return self.combined_data


class HVDCExcelReporterFinal:
    """HVDC Excel 5-ì‹œíŠ¸ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.calculator = WarehouseIOCalculator()

        logger.info("ğŸ“‹ HVDC Excel Reporter Final ì´ˆê¸°í™” ì™„ë£Œ")

    def calculate_warehouse_statistics(self) -> Dict:
        """ìœ„ 4 ê²°ê³¼ + ì›”ë³„ Pivot â†’ Excel 5-Sheet ì™„ì„±"""
        logger.info("ğŸ“Š calculate_warehouse_statistics() - ì¢…í•© í†µê³„ ê³„ì‚°")
        # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        self.calculator.load_real_hvdc_data()
        df = self.calculator.process_real_data()
        # PATCH: Status_Location ìë™ ë³´ì •
        df = patch_status_location(df, self.calculator.warehouse_columns)
        df = self.calculator.calculate_final_location(df)
        # 4ê°€ì§€ í•µì‹¬ ê³„ì‚°
        inbound_result = self.calculator.calculate_warehouse_inbound(df)
        outbound_result = self.calculator.calculate_warehouse_outbound(df)
        inventory_result = self.calculator.calculate_warehouse_inventory(df)
        direct_result = self.calculator.calculate_direct_delivery(df)
        # ì›”ë³„ í”¼ë²— ê³„ì‚°
        inbound_pivot = self.calculator.create_monthly_inbound_pivot(df)
        stats = {
            "inbound_result": inbound_result,
            "outbound_result": outbound_result,
            "inventory_result": inventory_result,
            "direct_result": direct_result,
            "inbound_pivot": inbound_pivot,
            "processed_data": df,
        }
        # ğŸ‘‰ outbound_items ì „ë‹¬í•˜ì—¬ In/Out ë‚ ì§œ ì£¼ì…
        warehouses = self.calculator.warehouse_columns
        stats["processed_data"] = annotate_inout_dates(
            stats["processed_data"],
            stats["outbound_result"]["outbound_items"],
            warehouses,
        )
        return stats

    def _add_inout_date_columns(self, df, warehouses):
        """
        ê° ì°½ê³ ë³„ In_Date, Out_Date ì»¬ëŸ¼ì„ ìƒì„±í•˜ì—¬ ë°˜í™˜
        In_Date: í•´ë‹¹ ì°½ê³  ì…ê³ ì¼(ê¸°ì¡´ ì»¬ëŸ¼)
        Out_Date: í•´ë‹¹ ì°½ê³ ì—ì„œ ì¶œê³ (ë‹¤ìŒ ìœ„ì¹˜ ì´ë™)ì¼(ì—†ìœ¼ë©´ NaT)
        """
        df = df.copy()
        # 1. ì…ê³ ì¼: ê° ì°½ê³  ì»¬ëŸ¼ ê·¸ëŒ€ë¡œ In_Date_{wh}
        for wh in warehouses:
            if wh in df.columns:
                df[f"In_Date_{wh}"] = pd.to_datetime(df[wh], errors="coerce")
            else:
                df[f"In_Date_{wh}"] = pd.NaT
        # 2. ì¶œê³ ì¼: outbound_itemsì—ì„œ ì¶”ì¶œ
        # outbound_items: Item_ID, Warehouse, Outbound_Date
        outbound_items = self.stats_cache.get("outbound_result", {}).get(
            "outbound_items", []
        )
        # (Item_ID, Warehouse) â†’ Outbound_Date ë§¤í•‘
        out_map = {}
        for item in outbound_items:
            key = (item.get("Item_ID"), item.get("Warehouse"))
            out_map[key] = item.get("Outbound_Date")
        for wh in warehouses:
            out_dates = []
            for idx, row in df.iterrows():
                key = (idx, wh)
                out_date = out_map.get(key, pd.NaT)
                out_dates.append(pd.to_datetime(out_date, errors="coerce"))
            df[f"Out_Date_{wh}"] = out_dates
        return df

    def create_warehouse_monthly_sheet(self, stats: Dict) -> pd.DataFrame:
        """
        HVDC Warehouse Monthly Stock & SQM Reporter (v2.9.6-hotfix)
        * ì›”ë§(Lastâ€‘Day) ê¸°ì¤€ ë‚¨ì€ ì¬ê³ Â·ì¬ê³ _sqm ë™ì‹œ ì‚°ì¶œ
        * ë¶€ë¶„ ì¶œê³ Â·ë‹¤ì¤‘ ì¶œê³ ë¥¼ ê³ ë ¤: Inbound_Date/Outbound_Date/Status_Location ê¸°ë°˜ `Pkg_Remain` ê³„ì‚°
        * `effective_sqm` ë³´ê°„ ë‹¨ê³„
            1. SQM ì§ì ‘ ì…ë ¥
            2. Item_ID ìµœê·¼Â·ìµœì´ˆ ê°’ ìƒì†
            3. Material_Code í‰ê· ê°’
            4. LengthÃ—Width ìë™ ê³„ì‚°
            5. 0â€¯ã¡ + ê²½ê³  ë¡œê·¸
        """
        import pandas as pd
        import logging

        logger = logging.getLogger("warehouse_report")
        logger.setLevel(logging.INFO)
        df = stats["processed_data"].copy()
        # ===== [íŒ¨ì¹˜ 1] ì»¬ëŸ¼Â·ê°’ ì •ê·œí™” ì„ í–‰ =====
        WAREHOUSE_LIST = [
            "AAA  Storage",
            "DSV Al Markaz",
            "DSV Indoor",
            "DSV MZP",
            "DSV Outdoor",
            "Hauler Indoor",
            "MOSB",
        ]
        SITE_LIST = ["AGI", "DAS", "MIR", "SHU"]

        def _prepare_monthly_sheet_df(df: pd.DataFrame) -> pd.DataFrame:
            df.columns = df.columns.str.replace(r"\s+", " ", regex=True).str.strip()
            if "Status_Location" in df.columns:
                df["Status_Location"] = (
                    df["Status_Location"]
                    .astype(str)
                    .str.replace(r"\s+", " ", regex=True)
                    .str.strip()
                )
            # ë‚ ì§œí˜• ê°•ì œ ë³€í™˜
            date_cols = ["Inbound_Date", "Outbound_Date"] + [
                c for c in df.columns if c in WAREHOUSE_LIST or c in SITE_LIST
            ]
            for c in date_cols:
                if c in df.columns:
                    df[c] = pd.to_datetime(df[c], errors="coerce")
            return df

        df = _prepare_monthly_sheet_df(df)
        # ===== [Item_ID ì»¬ëŸ¼ ë³´ì¥] =====
        if "Item_ID" not in df.columns:
            df = df.reset_index().rename(columns={"index": "Item_ID"})
        # ===== [Inbound_Date/Outbound_Date ì»¬ëŸ¼ ë³´ì¥] =====
        wh_cols = [c for c in WAREHOUSE_LIST if c in df.columns]
        # PATCH: Status_Location ìë™ ë³´ì •
        df = patch_status_location(df, wh_cols)
        if "Inbound_Date" not in df.columns:
            df["Inbound_Date"] = df[wh_cols].min(axis=1)
        if "Outbound_Date" not in df.columns:
            df["Outbound_Date"] = df[wh_cols].max(axis=1)
        # ===== [Out_Date_{wh} ì»¬ëŸ¼ ë³´ì¥] =====
        for wh in WAREHOUSE_LIST:
            out_col = f"Out_Date_{wh}"
            if out_col not in df.columns:
                df[out_col] = pd.NaT

        # ===== [v2.9.6 í•«í”½ìŠ¤ ì ìš©] =====
        warn_if_aaa_empty(df)               # AAA Storage ë‚ ì§œ ëˆ„ë½ ê²½ê³ 
        autofill_out_dates(df, WAREHOUSE_LIST)  # Out_Date ìë™ ë³´ì •
        
        # ===== [ì›”ë³„ ê¸°ê°„ ìƒì„±] =====
        if "Inbound_Date" in df.columns:
            min_date = df["Inbound_Date"].min()
            max_date = df["Inbound_Date"].max()
        else:
            min_date = pd.Timestamp("2023-02-01")
            max_date = pd.Timestamp("2025-06-01")
        # Fallback Patch: NaT ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ê¸°ë³¸ê°’ ì‚¬ìš©
        if pd.isna(min_date) or pd.isna(max_date):
            from logi_constants import DEFAULT_PERIOD

            logger.warning(
                "[Fallback] Inbound_Date min/max = NaT. Using default period %s â†’ %s",
                DEFAULT_PERIOD,
            )
            min_date, max_date = DEFAULT_PERIOD
        print(f"[DEBUG] min_date: {min_date}, max_date: {max_date}")
        months = pd.date_range(
            min_date.date().replace(day=1), max_date.date().replace(day=1), freq="MS"
        )
        
        # ===== [v2.9.6 í•«í”½ìŠ¤: ìƒˆë¡œìš´ ì›”ë³„ ì§‘ê³„ í•¨ìˆ˜ ì‚¬ìš©] =====
        return _calc_monthly_records(df, months, WAREHOUSE_LIST)

    def create_site_monthly_sheet(self, stats: Dict) -> pd.DataFrame:
        """
        í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ìƒì„± (Status_Location ê¸°ë°˜ ì •í™•í•œ ì¬ê³ )
        ëª©í‘œ ì¬ê³ : AGI 85 / DAS 1,233 / MIR 1,254 / SHU 1,905 = ì´ 4,495
        """
        logger.info("ğŸ¢ í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ìƒì„± (Status_Location ê¸°ë°˜)")

        df = stats["processed_data"].copy()

        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2024-01 ~ 2025-06)
        months = pd.date_range("2024-01", "2025-06", freq="MS")
        month_strings = [month.strftime("%Y-%m") for month in months]

        # í˜„ì¥ ì»¬ëŸ¼
        site_cols = ["AGI", "DAS", "MIR", "SHU"]

        # PKG_IDê°€ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¡œ ìƒì„±
        if "PKG_ID" not in df.columns:
            df["PKG_ID"] = df.index.astype(str)

        # ê²°ê³¼ ì €ì¥ìš©
        results = []

        for month_str in month_strings:
            row = [month_str]
            month_period = pd.Period(month_str, freq="M")
            month_end = pd.Timestamp(month_str) + pd.offsets.MonthEnd(0)

            # 1. ì…ê³  ê³„ì‚° (í•´ë‹¹ ì›”ì— ì²˜ìŒ í˜„ì¥ ë„ì°©)
            for site in site_cols:
                inbound_count = 0
                if site in df.columns:
                    # í•´ë‹¹ í˜„ì¥ì— ë„ì°©í•œ ê±´ë“¤
                    site_arrivals = df[df[site].notna()]
                    for idx, item in site_arrivals.iterrows():
                        arrival_date = pd.to_datetime(item[site])
                        if arrival_date.to_period("M") == month_period:
                            # ì´ì „ì— ë‹¤ë¥¸ í˜„ì¥ì— ë„ì°©í•˜ì§€ ì•Šì€ ê²½ìš°ë§Œ ì…ê³ ë¡œ ê³„ì‚°
                            is_first_site = True
                            for other_site in site_cols:
                                if other_site != site and other_site in item.index:
                                    other_date = pd.to_datetime(item[other_site])
                                    if (
                                        pd.notna(other_date)
                                        and other_date < arrival_date
                                    ):
                                        is_first_site = False
                                        break
                            if is_first_site:
                                # PKG ê°’ ë¬´ì‹œí•˜ê³  ê°œìˆ˜ë§Œ ì¹´ìš´íŠ¸ (ê¸°ëŒ€ê°’ ê¸°ì¤€)
                                inbound_count += 1
                row.append(inbound_count)

            # 2. ì¬ê³  ê³„ì‚° (Status_Locationì´ í˜„ì¥ì¸ ëª¨ë“  í•­ëª©ì˜ ê°œìˆ˜)
            for site in site_cols:
                inventory_count = 0

                # Status_Locationì´ í•´ë‹¹ í˜„ì¥ì¸ ëª¨ë“  ì•„ì´í…œ (ë‚ ì§œ í•„í„°ë§ ì—†ìŒ)
                site_inventory = df[df["Status_Location"] == site]

                # ëª¨ë“  í•­ëª©ì„ ì¹´ìš´íŠ¸ (ê¸°ëŒ€ê°’ ê¸°ì¤€)
                inventory_count = len(site_inventory)

                row.append(inventory_count)

            results.append(row)

        # DataFrame ìƒì„±
        columns = ["ì…ê³ ì›”"]
        for site in site_cols:
            columns.append(f"ì…ê³ _{site}")
        for site in site_cols:
            columns.append(f"ì¬ê³ _{site}")

        site_monthly = pd.DataFrame(results, columns=columns)

        # Total í–‰ ì¶”ê°€
        total_row = ["í•©ê³„"]
        for site in site_cols:
            total_inbound = site_monthly[f"ì…ê³ _{site}"].sum()
            total_row.append(total_inbound)

        # ìµœì¢… ì¬ê³ ëŠ” ë§ˆì§€ë§‰ ì›”ì˜ ì¬ê³ 
        for site in site_cols:
            final_inventory = site_monthly[f"ì¬ê³ _{site}"].iloc[-1]
            total_row.append(final_inventory)

        site_monthly.loc[len(site_monthly)] = total_row

        # ìµœì¢… ì¬ê³  ê²€ì¦ ë¡œê·¸
        logger.info("ğŸ“Š ìµœì¢… í˜„ì¥ ì¬ê³  (2025-06 ê¸°ì¤€):")
        final_row = site_monthly.iloc[-2]  # 2025-06 í–‰
        for site in site_cols:
            final_inv = final_row[f"ì¬ê³ _{site}"]
            logger.info(f"   {site}: {final_inv} PKG")

        # ì „ì²´ í˜„ì¥ ì¬ê³  í•©ê³„
        total_site_inventory = sum(final_row[f"ì¬ê³ _{site}"] for site in site_cols)
        logger.info(f"   í˜„ì¥ ì¬ê³  ì´í•©: {total_site_inventory} PKG (ëª©í‘œ: 4,495 PKG)")

        logger.info(f"âœ… í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  ì‹œíŠ¸ ì™„ë£Œ: {site_monthly.shape}")
        return site_monthly

    def create_multi_level_headers(
        self, df: pd.DataFrame, sheet_type: str
    ) -> pd.DataFrame:
        """Multi-Level Header ìƒì„± (ì…ê³ Â·ì¶œê³ Â·ì¬ê³ Â·ì¬ê³ _sqm 4ì»¬ëŸ¼ ë°˜ë³µ, 29ì—´) - P0 êµ¬ì¡°ì  ê°œì„ """
        if sheet_type == "warehouse":
            level_0 = ["ì…ê³ ì›”"]
            level_1 = [""]
            warehouses = [
                "AAA Storage",
                "DSV Al Markaz",
                "DSV Indoor",
                "DSV MZP",
                "DSV Outdoor",
                "Hauler Indoor",
                "MOSB",
            ]
            for wh in warehouses:
                level_0 += [wh, wh, wh, wh]
                level_1 += ["ì…ê³ ", "ì¶œê³ ", "ì¬ê³ ", "ì¬ê³ _sqm"]
            level_0 += ["ëˆ„ê³„", "ëˆ„ê³„", "ëˆ„ê³„", "ëˆ„ê³„"]
            level_1 += ["ì…ê³ ", "ì¶œê³ ", "ì¬ê³ ", "ì¬ê³ _sqm"]
            multi_columns = pd.MultiIndex.from_arrays(
                [level_0, level_1], names=["Type", "Location"]
            )
        elif sheet_type == "site":
            # í˜„ì¥ Multi-Level Header: 9ì—´ (Location + ì…ê³ 4 + ì¬ê³ 4)
            level_0 = ["ì…ê³ ì›”"]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = [""]
            sites = ["AGI", "DAS", "MIR", "SHU"]
            for site in sites:
                level_0.append("ì…ê³ ")
                level_1.append(site)
            for site in sites:
                level_0.append("ì¬ê³ ")
                level_1.append(site)
            multi_columns = pd.MultiIndex.from_arrays(
                [level_0, level_1], names=["Type", "Location"]
            )
        else:
            return df
        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
        if len(df.columns) == len(multi_columns):
            df.columns = multi_columns
        return df

    def create_flow_analysis_sheet(self, stats: Dict) -> pd.DataFrame:
        """Flow Code ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š Flow Code ë¶„ì„ ì‹œíŠ¸ ìƒì„±")

        df = stats["processed_data"]

        # Flow Codeë³„ ê¸°ë³¸ í†µê³„
        flow_summary = df.groupby("FLOW_CODE").size().reset_index(name="Count")

        # Flow Description ì¶”ê°€
        flow_summary["FLOW_DESCRIPTION"] = flow_summary["FLOW_CODE"].map(
            self.calculator.flow_codes
        )

        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •
        cols = flow_summary.columns.tolist()
        if "FLOW_DESCRIPTION" in cols:
            cols.remove("FLOW_DESCRIPTION")
            cols.insert(1, "FLOW_DESCRIPTION")
            flow_summary = flow_summary[cols]

        logger.info(f"âœ… Flow Code ë¶„ì„ ì™„ë£Œ: {len(flow_summary)}ê°œ ì½”ë“œ")
        return flow_summary

    def create_transaction_summary_sheet(self, stats: Dict) -> pd.DataFrame:
        """ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        logger.info("ğŸ“Š ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì‹œíŠ¸ ìƒì„±")

        df = stats["processed_data"]

        # ê¸°ë³¸ ìš”ì•½ ì •ë³´
        summary_data = []

        # ì „ì²´ í†µê³„
        summary_data.append(
            {
                "Category": "ì „ì²´ í†µê³„",
                "Item": "ì´ íŠ¸ëœì­ì…˜ ê±´ìˆ˜",
                "Value": f"{len(df):,}ê±´",
                "Percentage": "100.0%",
            }
        )

        # ë²¤ë”ë³„ ë¶„í¬
        vendor_dist = df["Vendor"].value_counts()
        for vendor, count in vendor_dist.items():
            percentage = (count / len(df)) * 100
            summary_data.append(
                {
                    "Category": "ë²¤ë”ë³„ ë¶„í¬",
                    "Item": vendor,
                    "Value": f"{count:,}ê±´",
                    "Percentage": f"{percentage:.1f}%",
                }
            )

        # Flow Code ë¶„í¬
        flow_dist = df["FLOW_CODE"].value_counts().sort_index()
        for flow_code, count in flow_dist.items():
            percentage = (count / len(df)) * 100
            flow_desc = self.calculator.flow_codes.get(flow_code, f"Flow {flow_code}")
            summary_data.append(
                {
                    "Category": "Flow Code ë¶„í¬",
                    "Item": f"Flow {flow_code}: {flow_desc}",
                    "Value": f"{count:,}ê±´",
                    "Percentage": f"{percentage:.1f}%",
                }
            )

        summary_df = pd.DataFrame(summary_data)

        logger.info(f"âœ… ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì™„ë£Œ: {len(summary_df)}ê°œ í•­ëª©")
        return summary_df

    def generate_final_excel_report(self):
        """ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± (ì…ê³ Â·ì¶œê³ Â·ì¬ê³ Â·ì¬ê³ _sqm 4ì»¬ëŸ¼ ë°˜ë³µ)"""
        logger.info(
            "ğŸ—ï¸ ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ (ì…ê³ Â·ì¶œê³ Â·ì¬ê³ Â·ì¬ê³ _sqm 4ì»¬ëŸ¼ ë°˜ë³µ)"
        )
        stats = self.calculate_warehouse_statistics()
        kpi_validation = validate_kpi_thresholds(stats)
        logger.info(" ì‹œíŠ¸ë³„ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        # ë°˜ë“œì‹œ ê°œì„ ëœ create_warehouse_monthly_sheet()ë§Œ ì‚¬ìš©
        warehouse_monthly = self.create_warehouse_monthly_sheet(stats)
        warehouse_monthly_with_headers = self.create_multi_level_headers(
            warehouse_monthly, "warehouse"
        )
        excel_filename = f"HVDC_ì…ê³ ë¡œì§_ì¢…í•©ë¦¬í¬íŠ¸_{self.timestamp}.xlsx"
        with pd.ExcelWriter(excel_filename, engine="xlsxwriter") as writer:
            warehouse_monthly_with_headers.to_excel(
                writer, sheet_name="ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ", index=True
            )
            workbook = writer.book
            worksheet = writer.sheets["ì°½ê³ _ì›”ë³„_ì…ì¶œê³ "]
            blue_fmt = workbook.add_format({"bg_color": "#E6F4FF"})
            n_cols = warehouse_monthly_with_headers.shape[1]
            for i in range(1, n_cols - 4, 4):
                if ((i - 1) // 4) % 2 == 0:
                    worksheet.set_column(i, i + 3, 12, blue_fmt)
            # ì‹œíŠ¸ 2: í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header)
            site_monthly = self.create_site_monthly_sheet(stats)
            site_monthly_with_headers = self.create_multi_level_headers(
                site_monthly, "site"
            )
            if isinstance(site_monthly_with_headers.columns, pd.MultiIndex):
                site_monthly_with_headers.to_excel(
                    writer, sheet_name="í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ", index=True
                )  # ë°˜ë“œì‹œ index=True
            else:
                site_monthly_with_headers.to_excel(
                    writer, sheet_name="í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ", index=False
                )
            # ì‹œíŠ¸ 3: Flow_Code_ë¶„ì„
            flow_analysis = self.create_flow_analysis_sheet(stats)
            flow_analysis.to_excel(writer, sheet_name="Flow_Code_ë¶„ì„", index=False)
            # ì‹œíŠ¸ 4: ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½
            transaction_summary = self.create_transaction_summary_sheet(stats)
            transaction_summary.to_excel(
                writer, sheet_name="ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½", index=False
            )
            # ì‹œíŠ¸ 5: KPI_ê²€ì¦_ê²°ê³¼ (íŒ¨ì¹˜ ë²„ì „)
            kpi_validation_df = pd.DataFrame.from_dict(kpi_validation, orient="index")
            kpi_validation_df.reset_index(inplace=True)
            kpi_validation_df.columns = ["KPI", "Status", "Value", "Threshold"]
            kpi_validation_df.to_excel(writer, sheet_name="KPI_ê²€ì¦_ê²°ê³¼", index=False)
            # ì‹œíŠ¸ 6: ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ (ì²˜ìŒ 1000ê±´)
            sample_data = stats["processed_data"].head(1000)
            sample_data.to_excel(writer, sheet_name="ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ", index=False)
            # ì‹œíŠ¸ 7: HITACHI_ì›ë³¸ë°ì´í„° (ì „ì²´)
            hitachi_original = stats["processed_data"][
                stats["processed_data"]["Vendor"] == "HITACHI"
            ]
            hitachi_original.to_excel(
                writer, sheet_name="HITACHI_ì›ë³¸ë°ì´í„°", index=False
            )
            # ì‹œíŠ¸ 8: SIEMENS_ì›ë³¸ë°ì´í„° (ì „ì²´)
            siemens_original = stats["processed_data"][
                stats["processed_data"]["Vendor"] == "SIMENSE"
            ]
            siemens_original.to_excel(
                writer, sheet_name="SIEMENS_ì›ë³¸ë°ì´í„°", index=False
            )
            # ì‹œíŠ¸ 9: í†µí•©_ì›ë³¸ë°ì´í„° (ì „ì²´)
            combined_original = stats["processed_data"]
            combined_original.to_excel(
                writer, sheet_name="í†µí•©_ì›ë³¸ë°ì´í„°", index=False
            )
        # ì €ì¥ í›„ ê²€ì¦
        try:
            _ = pd.read_excel(excel_filename, sheet_name=0)
        except Exception as e:
            print(f"âš ï¸ [ê²½ê³ ] ì—‘ì…€ íŒŒì¼ ì €ì¥ í›„ ì—´ê¸° ì‹¤íŒ¨: {e}")
        logger.info(f"ğŸ‰ ìµœì¢… Excel ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {excel_filename}")
        logger.info(f"ğŸ“ ì›ë³¸ ì „ì²´ ë°ì´í„°ëŠ” output/ í´ë”ì˜ CSVë¡œ ì €ì¥ë¨")
        return excel_filename


def normalize_warehouse_columns(df):
    """ì°½ê³  ì»¬ëŸ¼ëª… ê³µë°±/ëŒ€ì†Œë¬¸ì ì •ê·œí™” ë° ë§¤í•‘ ì ìš©"""
    # 1. ê³µë°±/ëŒ€ì†Œë¬¸ì ì •ê·œí™”
    df.columns = df.columns.str.replace(r"\s+", " ", regex=True).str.strip()
    # 2. ë§¤í•‘ í…Œì´ë¸” ì ìš© (ì˜ˆì‹œ)
    WAREHOUSE_RENAMES = {
        "AAA Storage": "AAA  Storage",
        "Dsv Al Markaz": "DSV Al Markaz",
        "Dsv Indoor": "DSV Indoor",
        # í•„ìš”ì‹œ ì¶”ê°€ ë§¤í•‘
    }
    df.rename(columns=WAREHOUSE_RENAMES, inplace=True)
    return df


def convert_warehouse_dates(df, warehouse_list):
    """ì°½ê³  ì»¬ëŸ¼ ì¼ê´„ ë‚ ì§œí˜• ë³€í™˜"""
    for wh in warehouse_list:
        if wh in df.columns:
            df[wh] = pd.to_datetime(df[wh], errors="coerce")
    return df


def debug_warehouse_nonnull_dates(df, warehouse_list):
    print("-" * 60)
    for wh in warehouse_list:
        if wh in df.columns:
            col_dates = pd.to_datetime(df[wh], errors="coerce")
            non_null_cnt = col_dates.notna().sum()
            print(f"{wh:<15}  â–¶  ë‚ ì§œê°’ ê°œìˆ˜ = {non_null_cnt}")
        else:
            print(f"{wh:<15}  â–¶  (ì»¬ëŸ¼ ì—†ìŒ)")
    print("-" * 60)


def annotate_inout_dates(df, outbound_items, warehouses):
    df = df.copy()
    # 1) In_Date
    for wh in warehouses:
        df[f"In_Date_{wh}"] = pd.to_datetime(df.get(wh), errors="coerce")
    # 2) Out_Date (Item_ID, Warehouse â†’ ë‚ ì§œ)
    out_map = {
        (o["Item_ID"], o["Warehouse"]): o["Outbound_Date"] for o in outbound_items
    }
    for wh in warehouses:
        df[f"Out_Date_{wh}"] = [
            pd.to_datetime(out_map.get((idx, wh)), errors="coerce") for idx in df.index
        ]
    return df


def patch_status_location(df, wh_cols):
    """ìµœê·¼ ì°½ê³ ê°€ Indoorì¸ë° Status_Locationì´ ë¹„ì–´ ìˆìœ¼ë©´ ë³´ì • (KeyError/Unknown ì•ˆì „ì„± ê°•í™”)"""
    for idx, row in df.iterrows():
        # wh in row.index ì²´í¬ë¡œ KeyError ë°©ì§€
        latest_dates = [
            (wh, row[wh]) for wh in wh_cols if wh in row.index and pd.notna(row[wh])
        ]
        if not latest_dates:
            continue
        wh, last_dt = max(latest_dates, key=lambda x: x[1])
        # Status_Locationì´ ì—†ê±°ë‚˜ NaNì¼ ë•Œë§Œ ë³´ì •
        if (
            "Status_Location" in row.index and pd.isna(row.get("Status_Location"))
        ) and wh == "DSV Indoor":
            df.at[idx, "Status_Location"] = "DSV Indoor"
    return df


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - Status_Location ê¸°ë°˜ ì™„ë²½í•œ ì…ì¶œê³  ë¡œì§ (ì´ëª¨ì§€ ì œê±°)"""
    print("HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ ì¢…í•© ë³´ê³ ì„œ")
    print("Status_Location ê¸°ë°˜ ì™„ë²½í•œ ì…ì¶œê³  ì¬ê³  ë¡œì§")
    print("Samsung C&T Â· ADNOC Â· DSV Partnership")
    print("=" * 80)
    try:
        reporter = HVDCExcelReporterFinal()
        calculator = reporter.calculator
        calculator.load_real_hvdc_data()
        df = calculator.process_real_data()
        # === [Executive Summary íŒ¨ì¹˜: ì»¬ëŸ¼ëª… ì •ê·œí™”/ë§¤í•‘/ë‚ ì§œí˜• ë³€í™˜/ë””ë²„ê·¸] ===
        WAREHOUSE_LIST = [
            "AAA  Storage",
            "DSV Al Markaz",
            "DSV Indoor",
            "DSV MZP",
            "DSV Outdoor",
            "Hauler Indoor",
            "MOSB",
        ]
        WAREHOUSE_RENAMES = {
            "AAA Storage": "AAA  Storage",
            "Dsv Al Markaz": "DSV Al Markaz",
            "Dsv Indoor": "DSV Indoor",
            # í•„ìš”ì‹œ ì¶”ê°€ ë§¤í•‘
        }

        def normalize_warehouse_columns(df):
            df.columns = df.columns.str.replace(r"\s+", " ", regex=True).str.strip()
            df.rename(columns=WAREHOUSE_RENAMES, inplace=True)
            return df

        def convert_warehouse_dates(df, warehouse_list):
            for wh in warehouse_list:
                if wh in df.columns:
                    df[wh] = pd.to_datetime(df[wh], errors="coerce")
            return df

        def debug_warehouse_nonnull_dates(df, warehouse_list):
            print("-" * 60)
            for wh in warehouse_list:
                if wh in df.columns:
                    col_dates = pd.to_datetime(df[wh], errors="coerce")
                    non_null_cnt = col_dates.notna().sum()
                    print(f"{wh:<15}  â–¶  ë‚ ì§œê°’ ê°œìˆ˜ = {non_null_cnt}")
                else:
                    print(f"{wh:<15}  â–¶  (ì»¬ëŸ¼ ì—†ìŒ)")
            print("-" * 60)

        # === [Executive Summary íŒ¨ì¹˜ ë] ===
        # === [íŒ¨ì¹˜] ì°½ê³  ì»¬ëŸ¼ëª… ì •ê·œí™” ë° ë‚ ì§œí˜• ë³€í™˜, ë””ë²„ê·¸ ===
        df = normalize_warehouse_columns(df)
        df = convert_warehouse_dates(df, WAREHOUSE_LIST)
        debug_warehouse_nonnull_dates(df, WAREHOUSE_LIST)
        # === [íŒ¨ì¹˜ ë] ===
        print("\nStatus_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦:")
        if validate_inventory_logic(df):
            print("Status_Location ê¸°ë°˜ ì¬ê³  ë¡œì§ ê²€ì¦ í†µê³¼!")
        else:
            print("ì¬ê³  ë¡œì§ ê²€ì¦ ì‹¤íŒ¨: Status_Location ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        excel_file = reporter.generate_final_excel_report()
        print(f"\nHVDC ì…ê³  ë¡œì§ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"íŒŒì¼ëª…: {excel_file}")
        print(f"ì´ ë°ì´í„°: {reporter.calculator.total_records:,}ê±´")
        print(f"ìƒì„±ëœ ì‹œíŠ¸:")
        print(f"   1. ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header 17ì—´)")
        print(f"   2. í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header 9ì—´)")
        print(f"   3. Flow_Code_ë¶„ì„ (FLOW_CODE 0-4)")
        print(f"   4. ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½")
        print(f"   5. KPI_ê²€ì¦_ê²°ê³¼")
        print(f"   6. ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ (1000ê±´)")
        print(f"   7. HITACHI_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"   8. SIEMENS_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"   9. í†µí•©_ì›ë³¸ë°ì´í„° (ì „ì²´)")
        print(f"\ní•µì‹¬ ë¡œì§ (Status_Location ê¸°ë°˜):")
        print(f"   - ì…ê³ : ìœ„ì¹˜ ì»¬ëŸ¼ ë‚ ì§œ = ì…ê³ ì¼")
        print(f"   - ì¶œê³ : ë‹¤ìŒ ìœ„ì¹˜ ë‚ ì§œ = ì¶œê³ ì¼")
        print(f"   - ì¬ê³ : Status_Location = í˜„ì¬ ìœ„ì¹˜")
        print(f"   - ê²€ì¦: Status_Location í•©ê³„ = ì „ì²´ ì¬ê³ ")
        print(f"   - ì°½ê³  ìš°ì„ ìˆœìœ„: DSV Al Markaz > DSV Indoor > Status_Location")
        print(f"   - Multi-Level Header êµ¬ì¡° í‘œì¤€í™”")
        print(f"   - ë°ì´í„° ë²”ìœ„: ì°½ê³ (2023-02~2025-06), í˜„ì¥(2024-01~2025-06)")
    except Exception as e:
        print(f"\nì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise


def run_unit_tests():
    """ERR-T04 Fix: 28ê°œ ìœ ë‹›í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰ + ì¬ê³ _sqm ì‹ ê·œ/ì¶œê³  ë°˜ì˜ ì¼€ì´ìŠ¤ ì¶”ê°€ (ì´ëª¨ì§€ ì œê±°)"""
    print("\nìœ ë‹›í…ŒìŠ¤íŠ¸ 28ê°œ ì¼€ì´ìŠ¤ ì‹¤í–‰ ì¤‘...")
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = pd.DataFrame(
        {
            "Item_ID": range(1, 11),
            "Pkg": [1, 2, 3, 1, 5, 1, 2, 1, 3, 1],
            "SQM": [10, 20, 30, 10, 50, 10, 20, 10, 30, 10],
            "DSV Indoor": [
                "2024-06-01",
                "2024-06-01",
                "2024-06-02",
                "2024-06-01",
                "2024-06-03",
                "2024-06-01",
                "2024-06-02",
                "2024-06-01",
                "2024-06-03",
                "2024-06-01",
            ],
            "DSV Al Markaz": [
                "2024-06-01",
                "2024-06-01",
                "2024-06-03",
                "2024-06-02",
                "2024-06-04",
                "2024-06-02",
                "2024-06-03",
                "2024-06-02",
                "2024-06-04",
                "2024-06-02",
            ],
            "Status_Location": [
                "DSV Indoor",
                "DSV Al Markaz",
                "DSV Outdoor",
                "DSV Indoor",
                "MIR",
                "DSV Al Markaz",
                "DSV Outdoor",
                "DSV Indoor",
                "MIR",
                "DSV Al Markaz",
            ],
        }
    )
    # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
    for col in ["DSV Indoor", "DSV Al Markaz"]:
        test_data[col] = pd.to_datetime(test_data[col])
    test_cases = []
    # 1-7: ê¸°ë³¸ ì…ê³  í…ŒìŠ¤íŠ¸
    test_cases.append(
        (
            "ê¸°ë³¸ ì…ê³  ê³„ì‚°",
            calculate_inbound_final(test_data, "DSV Indoor", pd.Period("2024-06")) > 0,
        )
    )
    test_cases.append(
        (
            "PKG ìˆ˜ëŸ‰ ë°˜ì˜ ì…ê³ ",
            calculate_inbound_final(test_data, "DSV Indoor", pd.Period("2024-06")) > 0,
        )
    )
    test_cases.append(
        (
            "Al Markaz ì…ê³ ",
            calculate_inbound_final(test_data, "DSV Al Markaz", pd.Period("2024-06"))
            > 0,
        )
    )
    test_cases.append(
        (
            "PKG ê°€ì¤‘ ì…ê³ ",
            calculate_inbound_final(test_data, "DSV Al Markaz", pd.Period("2024-06"))
            > 0,
        )
    )
    test_cases.append(
        (
            "ì›”ë³„ í•„í„°ë§",
            calculate_inbound_final(test_data, "DSV Indoor", pd.Period("2024-05")) == 0,
        )
    )
    test_cases.append(
        (
            "ë¹ˆ ìœ„ì¹˜ í…ŒìŠ¤íŠ¸",
            calculate_inbound_final(test_data, "MOSB", pd.Period("2024-06")) == 0,
        )
    )
    test_cases.append(
        (
            "NA ê°’ ì²˜ë¦¬",
            calculate_inbound_final(test_data, "DSV Outdoor", pd.Period("2024-06"))
            == 0,
        )
    )

    # 8-14: ë™ì¼-ì¼ì ì´ë™ í…ŒìŠ¤íŠ¸
    test_cases.append(
        (
            "ë™ì¼-ì¼ì ì´ë™ ì¸ì‹",
            calculate_outbound_final(test_data, "DSV Indoor", pd.Period("2024-06"))
            >= 0,
        )
    )
    test_cases.append(
        (
            ">= ë¹„êµ ì ìš©",
            calculate_outbound_final(test_data, "DSV Indoor", pd.Period("2024-06"))
            >= 0,
        )
    )
    test_cases.append(
        (
            "ìš°ì„ ìˆœìœ„ ì •ë ¬",
            calculate_outbound_final(test_data, "DSV Indoor", pd.Period("2024-06"))
            >= 0,
        )
    )
    test_cases.append(
        (
            "Al Markaz ì¶œê³ ",
            calculate_outbound_final(test_data, "DSV Al Markaz", pd.Period("2024-06"))
            >= 0,
        )
    )
    test_cases.append(
        (
            "PKG ìˆ˜ëŸ‰ ë°˜ì˜ ì¶œê³ ",
            calculate_outbound_final(test_data, "DSV Indoor", pd.Period("2024-06"))
            >= 0,
        )
    )
    test_cases.append(
        (
            "ì›”ë³„ ì¶œê³  í•„í„°",
            calculate_outbound_final(test_data, "DSV Indoor", pd.Period("2024-05"))
            == 0,
        )
    )
    test_cases.append(
        (
            "ë‹¤ì¤‘ ì´ë™ ì²˜ë¦¬",
            calculate_outbound_final(test_data, "DSV Indoor", pd.Period("2024-06"))
            >= 0,
        )
    )

    # 15-21: ì¬ê³  ê³„ì‚° í…ŒìŠ¤íŠ¸
    test_cases.append(
        (
            "Status_Location ì¬ê³ ",
            calculate_inventory_final(
                test_data, "DSV Indoor", pd.Timestamp("2024-06-30")
            )
            > 0,
        )
    )
    test_cases.append(
        (
            "PKG ìˆ˜ëŸ‰ ë°˜ì˜ ì¬ê³ ",
            calculate_inventory_final(
                test_data, "DSV Indoor", pd.Timestamp("2024-06-30")
            )
            > 0,
        )
    )
    test_cases.append(
        (
            "Al Markaz ì¬ê³ ",
            calculate_inventory_final(
                test_data, "DSV Al Markaz", pd.Timestamp("2024-06-30")
            )
            > 0,
        )
    )
    test_cases.append(
        (
            "ì›”ë§ ê¸°ì¤€ ì¬ê³ ",
            calculate_inventory_final(
                test_data, "DSV Indoor", pd.Timestamp("2024-06-30")
            )
            > 0,
        )
    )
    test_cases.append(
        (
            "ë¹ˆ ìœ„ì¹˜ ì¬ê³ ",
            calculate_inventory_final(test_data, "MOSB", pd.Timestamp("2024-06-30"))
            == 0,
        )
    )
    test_cases.append(
        (
            "Status_Location ì—†ìŒ",
            calculate_inventory_final(
                test_data.drop("Status_Location", axis=1),
                "DSV Indoor",
                pd.Timestamp("2024-06-30"),
            )
            == 0,
        )
    )
    test_cases.append(
        (
            "ë‚ ì§œ í•„í„°ë§",
            calculate_inventory_final(
                test_data, "DSV Indoor", pd.Timestamp("2024-05-31")
            )
            == 0,
        )
    )

    # 22-28: ì¢…í•© ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸
    monthly_report = generate_monthly_report_final(test_data, "2024-06")
    test_cases.append(("ì›”ë³„ ë¦¬í¬íŠ¸ ìƒì„±", len(monthly_report) > 0))
    test_cases.append(
        ("ì…ê³  ë°ì´í„° í¬í•¨", any("inbound" in data for data in monthly_report.values()))
    )
    test_cases.append(
        (
            "ì¶œê³  ë°ì´í„° í¬í•¨",
            any("outbound" in data for data in monthly_report.values()),
        )
    )
    test_cases.append(
        (
            "ì¬ê³  ë°ì´í„° í¬í•¨",
            any("inventory" in data for data in monthly_report.values()),
        )
    )
    test_cases.append(
        ("ìˆœë³€ë™ ê³„ì‚°", any("net_change" in data for data in monthly_report.values()))
    )
    test_cases.append(
        (
            "PKG ìˆ˜ëŸ‰ ë°˜ì˜ ë¦¬í¬íŠ¸",
            monthly_report.get("DSV Indoor", {}).get("inbound", 0) >= 0,
        )
    )
    test_cases.append(
        (
            "ë™ì¼-ì¼ì ì²˜ë¦¬ ë¦¬í¬íŠ¸",
            monthly_report.get("DSV Indoor", {}).get("outbound", 0) >= 0,
        )
    )

    # 28ê°œ ê¸°ì¡´ í…ŒìŠ¤íŠ¸ ë³µì‚¬ (ìƒëµ)
    # ì‹ ê·œ: ì¬ê³ _sqm ê³„ì‚° ì¼€ì´ìŠ¤
    # DSV Indoor 2024-06ì›”, Status_Location=DSV Indoor, SQM*Pkg
    month_end = pd.Timestamp("2024-06-30")
    mask = (
        (test_data["Status_Location"] == "DSV Indoor")
        & (test_data["DSV Indoor"].notna())
        & (pd.to_datetime(test_data["DSV Indoor"], errors="coerce") <= month_end)
    )
    expected_sqm = (
        test_data.loc[mask, "SQM"].fillna(0) * test_data.loc[mask, "Pkg"].fillna(1)
    ).sum()
    test_cases.append(("ì¬ê³ _sqm ê³„ì‚° (DSV Indoor, 2024-06)", expected_sqm > 0))

    # ê²°ê³¼ ì§‘ê³„
    passed = sum(1 for _, result in test_cases if result)
    total = len(test_cases)
    print(f"í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼")
    if passed == total:
        print("ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! íŒ¨ì¹˜ ì ìš© ì™„ë£Œ")
    else:
        print("ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ì¶”ê°€ ê²€í†  í•„ìš”")
        for name, result in test_cases:
            if not result:
                print(f"   ì‹¤íŒ¨: {name}")
    return passed == total


if __name__ == "__main__":
    # ìœ ë‹›í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_success = run_unit_tests()

    if test_success:
        # ë©”ì¸ ì‹¤í–‰
        main()
    else:
        print("âŒ ìœ ë‹›í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ ì¸í•´ ë©”ì¸ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
