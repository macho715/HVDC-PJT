#!/usr/bin/env python3
"""
MACHO-GPT v3.4-mini: ìµœì¢… ë°ì´í„° ê¸°ë°˜ ì›”ë³„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°
- ì…ë ¥: complete_transaction_data...py ê°€ ìƒì„±í•œ ìµœì¢… íŠ¸ëœì­ì…˜ ë°ì´í„°
- ì¶œë ¥: ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì´ë¯¸ì§€ í˜•ì‹ê³¼ 100% ë™ì¼í•œ Excel ë¦¬í¬íŠ¸
"""

import pandas as pd
from datetime import datetime
import os
import glob

class FinalReportGenerator:
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.source_dir = '.' # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ì°¾ë„ë¡ ìˆ˜ì •
        self.output_dir = 'HVDC_PJT/MACHO_í†µí•©ê´€ë¦¬_20250702_205301/02_í†µí•©ê²°ê³¼'
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

    def find_latest_source_file(self):
        """ê°€ì¥ ìµœì‹ ì˜ ì „ì²´ íŠ¸ëœì­ì…˜ ë°ì´í„° íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
        pattern = os.path.join(self.source_dir, 'MACHO_WH_HANDLING_ì „ì²´íŠ¸ëœì­ì…˜ë°ì´í„°_*.xlsx')
        files = glob.glob(pattern)
        if not files:
            print(f"âŒ ì›ë³¸ íŠ¸ëœì­ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pattern}")
            return None
        latest_file = max(files, key=os.path.getmtime)
        print(f"âœ… ìµœì‹  ì›ë³¸ íŒŒì¼ ì‚¬ìš©: {os.path.basename(latest_file)}")
        return latest_file

    def load_data(self):
        """ìµœì¢… íŠ¸ëœì­ì…˜ ë°ì´í„° ë¡œë“œ"""
        source_file = self.find_latest_source_file()
        if source_file:
            return pd.read_excel(source_file)
        return None

    @staticmethod
    def classify_location(row):
        """í–‰ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„ì¹˜(Site/Warehouse) ë¶„ë¥˜"""
        # ì´ ë¡œì§ì€ ì‹¤ì œ ë°ì´í„°ì˜ ì»¬ëŸ¼ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”
        site_cols = ['AGI', 'DAS', 'MIR', 'SHU']
        wh_cols = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'Hauler Indoor', 'DSV MZP', 'MOSB', 'AAA  Storage']
        
        # ë‚ ì§œê°€ ìˆëŠ” ì²«ë²ˆì§¸ ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ìœ„ì¹˜ë¥¼ ì°¾ìŒ
        for col in wh_cols + site_cols:
            if col in row.index and pd.notna(row[col]):
                if col in site_cols:
                    return 'Site', col
                else:
                    return 'Warehouse', col
        return 'ê¸°íƒ€', 'ì•Œ ìˆ˜ ì—†ìŒ'

    @staticmethod
    def get_first_valid_date(row):
        date_columns = [col for col in row.index if any(x in str(col).upper() for x in ['DSV', 'AGI', 'DAS', 'MIR', 'SHU', 'HAULER', 'AAA', 'JDN'])]
        for col in date_columns:
            if pd.notna(row[col]):
                return pd.to_datetime(row[col], errors='coerce')
        return pd.NaT

    def process_data(self, df):
        """
        ë°ì´í„° ì²˜ë¦¬ ë¡œì§ V2: Meltì™€ íë¦„ ì¶”ì ì„ í†µí•´ ì…/ì¶œê³ ë¥¼ ëª…í™•íˆ êµ¬ë¶„
        1. ë°ì´í„°ë¥¼ long-formatìœ¼ë¡œ ë³€í™˜ (Melt)
        2. ì¼€ì´ìŠ¤ë³„ë¡œ ë‚ ì§œìˆœ ì •ë ¬í•˜ì—¬ ì´ë™ ê²½ë¡œ ì¶”ì 
        3. ì´ë™ì´ ë°œìƒí•˜ë©´ ì´ì „ ìœ„ì¹˜ì—ì„œ 'ì¶œê³ ', ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ 'ì…ê³ 'ë¥¼ ìƒì„±
        """
        wh_cols = ['DSV Indoor', 'DSV Outdoor', 'DSV Al Markaz', 'Hauler Indoor', 'DSV MZP', 'MOSB', 'AAA  Storage', 'JDN']
        site_cols = ['AGI', 'DAS', 'MIR', 'SHU']
        location_cols = wh_cols + site_cols
        
        # ì‹¤ì œ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ìœ„ì¹˜ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        value_cols = [col for col in location_cols if col in df.columns]
        
        # ì‹ë³„ì ì»¬ëŸ¼ ì„¤ì •
        case_col = 'Case No.'
        if case_col not in df.columns and 'S/No' in df.columns:
            case_col = 'S/No'
        
        pkg_col = 'Pkg'
        if pkg_col not in df.columns:
            df[pkg_col] = 1

        # id_varsì—ì„œ pkg_col ì œì™¸
        id_vars = [c for c in [case_col, 'Vendor Name'] if c in df.columns]

        # ë°ì´í„° ì¦í­ ë°©ì§€ë¥¼ ìœ„í•œ ê³ ìœ  ID ìƒì„±
        df['__temp_id__'] = range(len(df))
        id_vars_with_temp = id_vars + ['__temp_id__']

        # ë°ì´í„° êµ¬ì¡° ë³€í™˜ (Wide to Long)
        melted = df.melt(id_vars=id_vars_with_temp, value_vars=value_cols, var_name='Location', value_name='Date')
        melted.dropna(subset=['Date'], inplace=True)
        
        # Pkg ì •ë³´ ë‹¤ì‹œ ë§¤í•‘ (ê³ ìœ  ID ì‚¬ìš©)
        melted = pd.merge(melted, df[id_vars_with_temp + [pkg_col]], on=id_vars_with_temp, how='left')
        melted.drop(columns=['__temp_id__'], inplace=True)

        melted['Date'] = pd.to_datetime(melted['Date'], errors='coerce')
        melted.dropna(subset=['Date'], inplace=True)
        melted.sort_values(by=[case_col, 'Date'], inplace=True)

        # ëª¨ë“  ì´ë²¤íŠ¸ë¥¼ 'ì…ê³ 'ë¡œ ê¸°ë¡
        inbounds = melted.copy()
        inbounds.rename(columns={pkg_col: 'ì…ê³ '}, inplace=True)
        inbounds['ì¶œê³ '] = 0

        # 'ì¶œê³ ' ì´ë²¤íŠ¸ ìƒì„±
        # ê·¸ë£¹ ë‚´ì—ì„œ ë‹¤ìŒ ì´ë²¤íŠ¸ê°€ ìˆìœ¼ë©´ í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì¶œê³ ëœ ê²ƒì„
        if not melted.empty:
            outbounds = melted.groupby(case_col).apply(lambda g: g.iloc[:-1]).reset_index(drop=True)
            if not outbounds.empty:
                outbounds.rename(columns={pkg_col: 'ì¶œê³ '}, inplace=True)
                outbounds['ì…ê³ '] = 0
                # ì¶œê³ ì¼ìëŠ” ë‹¤ìŒ ì…ê³ ì¼ìì™€ ë™ì¼
                outbounds['Date'] = melted.groupby(case_col)['Date'].shift(-1).dropna().values
            else:
                outbounds = pd.DataFrame(columns=inbounds.columns) # No outbounds, create empty DF with same columns
        else:
            outbounds = pd.DataFrame(columns=inbounds.columns)


        # ì…ê³ , ì¶œê³  ë°ì´í„° í†µí•©
        final_df = pd.concat([inbounds[['Date', 'Location', 'ì…ê³ ', 'ì¶œê³ ']], outbounds[['Date', 'Location', 'ì…ê³ ', 'ì¶œê³ ']]], ignore_index=True)
        final_df.fillna(0, inplace=True)

        # ìœ„ì¹˜ íƒ€ì…(ì°½ê³ /í˜„ì¥) ë¶„ë¥˜
        def classify_type(location):
            if location in site_cols: return 'Site'
            if location in wh_cols: return 'Warehouse'
            return 'ê¸°íƒ€'
        final_df['êµ¬ë¶„'] = final_df['Location'].apply(classify_type)
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ì ìš©: í˜„ì¥(Site)ì—ì„œëŠ” ì¶œê³ ê°€ ì—†ìŒ
        final_df.loc[(final_df['êµ¬ë¶„'] == 'Site') & (final_df['ì¶œê³ '] > 0), 'ì¶œê³ '] = 0

        # ì¬ê³  ê³„ì‚°
        final_df['ì…ê³ ì›”'] = pd.to_datetime(final_df['Date']).dt.to_period('M').astype(str)
        final_df.sort_values(by=['êµ¬ë¶„', 'Location', 'Date'], inplace=True)
        final_df['ì¬ê³ ë³€ë™'] = final_df['ì…ê³ '] - final_df['ì¶œê³ ']
        final_df['ëˆ„ì ì¬ê³ '] = final_df.groupby(['êµ¬ë¶„', 'Location'])['ì¬ê³ ë³€ë™'].cumsum()
        
        return final_df

    def create_report(self, original_df, processed_df):
        """ìš”ì²­ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ë¦¬í¬íŠ¸ ìƒì„±"""
        # --- ì°½ê³  ë¦¬í¬íŠ¸ (ê°€ê³µëœ ë°ì´í„° ì‚¬ìš©) ---
        wh_df = processed_df[processed_df['êµ¬ë¶„'] == 'Warehouse']
        wh_inbound = wh_df.pivot_table(index='ì…ê³ ì›”', columns='Location', values='ì…ê³ ', aggfunc='sum', fill_value=0)
        wh_outbound = wh_df.pivot_table(index='ì…ê³ ì›”', columns='Location', values='ì¶œê³ ', aggfunc='sum', fill_value=0)
        
        wh_inbound.columns = pd.MultiIndex.from_product([['ì…ê³ '], wh_inbound.columns])
        wh_outbound.columns = pd.MultiIndex.from_product([['ì¶œê³ '], wh_outbound.columns])
        
        df_report_wh = pd.concat([wh_inbound, wh_outbound], axis=1).sort_index(axis=1)
        df_report_wh.loc['Total'] = df_report_wh.sum().astype(int)

        # --- í˜„ì¥ ë¦¬í¬íŠ¸ ---
        site_df = processed_df[processed_df['êµ¬ë¶„'] == 'Site']
        site_inbound = site_df.pivot_table(index='ì…ê³ ì›”', columns='Location', values='ì…ê³ ', aggfunc='sum', fill_value=0)
        site_stock = site_df.pivot_table(index='ì…ê³ ì›”', columns='Location', values='ëˆ„ì ì¬ê³ ', aggfunc='last', fill_value=0).ffill()

        site_inbound.columns = pd.MultiIndex.from_product([['ì…ê³ '], site_inbound.columns])
        site_stock.columns = pd.MultiIndex.from_product([['ì¬ê³ '], site_stock.columns])

        df_report_site = pd.concat([site_inbound, site_stock], axis=1).sort_index(axis=1)
        if not df_report_site.empty:
            df_report_site.loc['í•©ê³„'] = df_report_site.iloc[:-1].sum().astype(int) # ëˆ„ì ì¬ê³  í•©ê³„ëŠ” ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ ì œì™¸

        # --- Excel ì €ì¥ ---
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_filename = os.path.join(self.output_dir, f'MACHO_Final_Report_{timestamp}.xlsx')
        
        with pd.ExcelWriter(output_filename, engine='xlsxwriter') as writer:
            original_df.to_excel(writer, sheet_name='ì „ì²´_íŠ¸ëœì­ì…˜_ë°ì´í„°', index=False)
            df_report_wh.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ')
            df_report_site.to_excel(writer, sheet_name='í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ')

        print(f"âœ… ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_filename}")
        return output_filename

    def run(self):
        """ì „ì²´ ì‹¤í–‰"""
        original_df = self.load_data()
        if original_df is not None:
            # ì›ë³¸ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ ë³µì‚¬ë³¸ì„ ì „ë‹¬
            processed_df = self.process_data(original_df.copy())
            self.create_report(original_df, processed_df)

def main():
    print("ğŸš€ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
    generator = FinalReportGenerator()
    generator.run()
    print("âœ… ì‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    main() 