#!/usr/bin/env python3
"""
HVDC Project ì°¸ì¡° ê´€ê³„ ìƒì„¸ ë¶„ì„ ë„êµ¬
MACHO-GPT v3.4-mini â”‚ Samsung C&T Logistics
Reference Audit & Safe Cleanup Strategy
"""

import os
import json
import re
from pathlib import Path
from collections import defaultdict, Counter

class ReferenceAuditor:
    def __init__(self, project_root="."):
        self.project_root = os.path.abspath(project_root)
        self.backup_patterns = [
            'backup', 'bak', 'old', 'archive', 'temp', 'tmp',
            'v2.6_20250626', 'v2.8.1_1751267433', 'Clean_Project_Backup'
        ]
        self.active_directories = []
        self.backup_directories = []
        self.reference_map = defaultdict(list)
        
    def is_backup_path(self, filepath):
        """ê²½ë¡œê°€ ë°±ì—… ë””ë ‰í† ë¦¬ì¸ì§€ íŒë‹¨"""
        path_lower = filepath.lower()
        return any(pattern.lower() in path_lower for pattern in self.backup_patterns)
    
    def classify_directories(self):
        """ë””ë ‰í† ë¦¬ë¥¼ í™œì„±/ë°±ì—…ìœ¼ë¡œ ë¶„ë¥˜"""
        for root, dirs, files in os.walk(self.project_root):
            # ì œì™¸í•  ë””ë ‰í† ë¦¬
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['venv', '__pycache__']]
            
            if self.is_backup_path(root):
                self.backup_directories.append(root)
            else:
                self.active_directories.append(root)
    
    def analyze_file_references(self, target_file, suggestions_data):
        """íŠ¹ì • íŒŒì¼ì˜ ì°¸ì¡° ê´€ê³„ ë¶„ì„"""
        filename = os.path.basename(target_file)
        basename = os.path.splitext(filename)[0]
        
        # ê²€ìƒ‰ íŒ¨í„´ ì •ì˜
        search_patterns = [
            filename,  # ì „ì²´ íŒŒì¼ëª…
            basename,  # í™•ì¥ì ì—†ëŠ” ì´ë¦„
            f"from {basename} import",  # Python import
            f"import {basename}",  # Python import
            f'"{filename}"',  # ë¬¸ìì—´ ì°¸ì¡°
            f"'{filename}'",  # ë¬¸ìì—´ ì°¸ì¡°
            f"{basename}.",  # ëª¨ë“ˆ ì ‘ê·¼
            f"/{filename}",  # ê²½ë¡œ ì°¸ì¡°
            f"\\{filename}",  # Windows ê²½ë¡œ ì°¸ì¡°
        ]
        
        references = {
            'active_references': [],
            'backup_references': [],
            'self_references': [],
            'import_references': [],
            'string_references': [],
            'path_references': []
        }
        
        # í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“  íŒŒì¼ ê²€ìƒ‰
        for root, dirs, files in os.walk(self.project_root):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['venv', '__pycache__']]
            
            for file in files:
                if file.endswith(('.py', '.md', '.json', '.txt', '.bat', '.sh', '.yml', '.yaml')):
                    file_path = os.path.join(root, file)
                    
                    # ìê¸° ìì‹ ì€ ì œì™¸
                    if os.path.abspath(file_path) == os.path.abspath(target_file):
                        continue
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                        
                        found_patterns = []
                        for pattern in search_patterns:
                            if pattern in content:
                                found_patterns.append(pattern)
                        
                        if found_patterns:
                            ref_info = {
                                'file': file_path,
                                'patterns': found_patterns,
                                'is_backup': self.is_backup_path(file_path),
                                'line_count': self._count_pattern_occurrences(content, found_patterns)
                            }
                            
                            # ì°¸ì¡° ìœ í˜•ë³„ ë¶„ë¥˜
                            if self.is_backup_path(file_path):
                                references['backup_references'].append(ref_info)
                            else:
                                references['active_references'].append(ref_info)
                            
                            # ì°¸ì¡° íŒ¨í„´ë³„ ë¶„ë¥˜
                            for pattern in found_patterns:
                                if 'import' in pattern:
                                    references['import_references'].append(ref_info)
                                elif pattern.startswith('"') or pattern.startswith("'"):
                                    references['string_references'].append(ref_info)
                                elif '/' in pattern or '\\' in pattern:
                                    references['path_references'].append(ref_info)
                    
                    except Exception as e:
                        continue
        
        return references
    
    def _count_pattern_occurrences(self, content, patterns):
        """íŒ¨í„´ ë°œìƒ íšŸìˆ˜ ê³„ì‚°"""
        total_count = 0
        for pattern in patterns:
            total_count += content.count(pattern)
        return total_count
    
    def analyze_all_duplicates(self, suggestions_file='duplicate_cleanup_suggestions.json'):
        """ëª¨ë“  ì¤‘ë³µ íŒŒì¼ì˜ ì°¸ì¡° ê´€ê³„ ë¶„ì„"""
        
        if not os.path.exists(suggestions_file):
            print(f"âŒ ì œì•ˆ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {suggestions_file}")
            return None
        
        with open(suggestions_file, 'r', encoding='utf-8') as f:
            suggestions = json.load(f)
        
        print("ğŸ” MACHO-GPT v3.4-mini ì°¸ì¡° ê´€ê³„ ìƒì„¸ ë¶„ì„")
        print("=" * 80)
        
        # ë””ë ‰í† ë¦¬ ë¶„ë¥˜
        self.classify_directories()
        
        print(f"ğŸ“ í™œì„± ë””ë ‰í† ë¦¬: {len(self.active_directories)}ê°œ")
        print(f"ğŸ“¦ ë°±ì—… ë””ë ‰í† ë¦¬: {len(self.backup_directories)}ê°œ")
        
        analysis_results = {
            'safe_to_delete': [],
            'risky_to_delete': [],
            'backup_only_references': [],
            'active_references': [],
            'summary': {}
        }
        
        for i, suggestion in enumerate(suggestions, 1):
            keep_file = suggestion['keep']
            delete_files = suggestion['delete']
            
            print(f"\nğŸ” ê·¸ë£¹ {i}: {os.path.basename(keep_file)}")
            
            group_analysis = {
                'group_id': i,
                'keep_file': keep_file,
                'delete_files': [],
                'safety_level': 'SAFE',  # SAFE, RISKY, DANGEROUS
                'reasons': []
            }
            
            for delete_file in delete_files:
                if not os.path.exists(delete_file):
                    print(f"   â„¹ï¸ íŒŒì¼ ì—†ìŒ: {os.path.basename(delete_file)}")
                    continue
                
                # ì°¸ì¡° ë¶„ì„
                refs = self.analyze_file_references(delete_file, suggestions)
                
                file_analysis = {
                    'file': delete_file,
                    'active_refs': len(refs['active_references']),
                    'backup_refs': len(refs['backup_references']),
                    'import_refs': len(refs['import_references']),
                    'total_refs': len(refs['active_references']) + len(refs['backup_references']),
                    'is_backup_file': self.is_backup_path(delete_file),
                    'safety_assessment': 'SAFE'
                }
                
                # ì•ˆì „ì„± í‰ê°€
                if refs['active_references']:
                    # í™œì„± ì°¸ì¡°ê°€ ìˆëŠ” ê²½ìš°
                    active_non_backup = [r for r in refs['active_references'] if not self.is_backup_path(r['file'])]
                    if active_non_backup:
                        file_analysis['safety_assessment'] = 'DANGEROUS'
                        group_analysis['safety_level'] = 'DANGEROUS'
                        group_analysis['reasons'].append(f"{os.path.basename(delete_file)}: í™œì„± íŒŒì¼ì—ì„œ {len(active_non_backup)}íšŒ ì°¸ì¡°")
                        print(f"   âŒ ìœ„í—˜: {os.path.basename(delete_file)} - í™œì„± ì°¸ì¡° {len(active_non_backup)}ê°œ")
                    else:
                        file_analysis['safety_assessment'] = 'RISKY'
                        if group_analysis['safety_level'] == 'SAFE':
                            group_analysis['safety_level'] = 'RISKY'
                        group_analysis['reasons'].append(f"{os.path.basename(delete_file)}: ë°±ì—… ë‚´ ì°¸ì¡°ë§Œ ì¡´ì¬")
                        print(f"   âš ï¸ ì£¼ì˜: {os.path.basename(delete_file)} - ë°±ì—… ë‚´ ì°¸ì¡°ë§Œ {len(refs['active_references'])}ê°œ")
                else:
                    # ë°±ì—… ì°¸ì¡°ë§Œ ìˆê±°ë‚˜ ì°¸ì¡° ì—†ìŒ
                    if refs['backup_references']:
                        print(f"   âœ… ì•ˆì „: {os.path.basename(delete_file)} - ë°±ì—… ì°¸ì¡°ë§Œ {len(refs['backup_references'])}ê°œ")
                    else:
                        print(f"   âœ… ì•ˆì „: {os.path.basename(delete_file)} - ì°¸ì¡° ì—†ìŒ")
                
                # ìƒì„¸ ì°¸ì¡° ì •ë³´ ì¶œë ¥
                if refs['active_references']:
                    print(f"      ğŸ“‹ í™œì„± ì°¸ì¡° ìƒì„¸:")
                    for ref in refs['active_references'][:3]:  # ì²˜ìŒ 3ê°œë§Œ
                        rel_path = os.path.relpath(ref['file'], self.project_root)
                        print(f"         â€¢ {rel_path} ({ref['line_count']}íšŒ)")
                
                group_analysis['delete_files'].append(file_analysis)
            
            # ê·¸ë£¹ë³„ ë¶„ë¥˜
            if group_analysis['safety_level'] == 'SAFE':
                analysis_results['safe_to_delete'].append(group_analysis)
            elif group_analysis['safety_level'] == 'RISKY':
                analysis_results['risky_to_delete'].append(group_analysis)
            else:
                analysis_results['active_references'].append(group_analysis)
            
            print(f"   ğŸ¯ ê·¸ë£¹ ì•ˆì „ë„: {group_analysis['safety_level']}")
        
        # ê²°ê³¼ ìš”ì•½
        analysis_results['summary'] = {
            'total_groups': len(suggestions),
            'safe_groups': len(analysis_results['safe_to_delete']),
            'risky_groups': len(analysis_results['risky_to_delete']),
            'dangerous_groups': len(analysis_results['active_references']),
            'backup_directories': len(self.backup_directories),
            'active_directories': len(self.active_directories)
        }
        
        return analysis_results
    
    def generate_safe_cleanup_plan(self, analysis_results):
        """ì•ˆì „í•œ ì •ë¦¬ ê³„íš ìƒì„±"""
        
        print("\n" + "=" * 80)
        print("ğŸ“Š ì°¸ì¡° ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        
        summary = analysis_results['summary']
        print(f"âœ… ì•ˆì „í•œ ê·¸ë£¹: {summary['safe_groups']}ê°œ")
        print(f"âš ï¸ ì£¼ì˜ ê·¸ë£¹: {summary['risky_groups']}ê°œ")
        print(f"âŒ ìœ„í—˜í•œ ê·¸ë£¹: {summary['dangerous_groups']}ê°œ")
        
        # ì•ˆì „í•œ ì‚­ì œ ì œì•ˆ ìƒì„±
        if analysis_results['safe_to_delete']:
            safe_suggestions = []
            for group in analysis_results['safe_to_delete']:
                # ì›ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                safe_suggestions.append({
                    'keep': group['keep_file'],
                    'delete': [f['file'] for f in group['delete_files']],
                    'reason': f"ì•ˆì „: í™œì„± ì°¸ì¡° ì—†ìŒ"
                })
            
            # ì•ˆì „í•œ ì œì•ˆ ì €ì¥
            with open('safe_cleanup_plan.json', 'w', encoding='utf-8') as f:
                json.dump(safe_suggestions, f, indent=2, ensure_ascii=False)
            
            print(f"\nâœ… ì•ˆì „í•œ ì‚­ì œ ê³„íš ì €ì¥: safe_cleanup_plan.json")
            print(f"   ğŸ“Š ì•ˆì „í•œ ì‚­ì œ ëŒ€ìƒ: {len(safe_suggestions)}ê°œ ê·¸ë£¹")
        
        # ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥
        with open('reference_audit_report.json', 'w', encoding='utf-8') as f:
            json.dump(analysis_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ: reference_audit_report.json")
        
        # ê¶Œì¥ì‚¬í•­ ì¶œë ¥
        print(f"\nğŸ¯ ê¶Œì¥ì‚¬í•­:")
        if summary['safe_groups'] > 0:
            print(f"   âœ… {summary['safe_groups']}ê°œ ê·¸ë£¹ì€ ì•ˆì „í•˜ê²Œ ì‚­ì œ ê°€ëŠ¥")
            print(f"   âœ… python execute_cleanup.py --suggestions-file safe_cleanup_plan.json")
        
        if summary['risky_groups'] > 0:
            print(f"   âš ï¸ {summary['risky_groups']}ê°œ ê·¸ë£¹ì€ ë°±ì—… ê²€ì¦ í›„ ì‚­ì œ")
            print(f"   âš ï¸ ë°±ì—… í´ë”ê°€ ì‹¤ì œ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸ í•„ìš”")
        
        if summary['dangerous_groups'] > 0:
            print(f"   âŒ {summary['dangerous_groups']}ê°œ ê·¸ë£¹ì€ ì‚­ì œ ê¸ˆì§€")
            print(f"   âŒ í™œì„± ì°¸ì¡°ê°€ ìˆì–´ ì‚­ì œ ì‹œ ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥")
        
        return analysis_results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ MACHO-GPT v3.4-mini ì°¸ì¡° ê´€ê³„ ìƒì„¸ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    auditor = ReferenceAuditor()
    
    # ì „ì²´ ì¤‘ë³µ íŒŒì¼ ë¶„ì„
    analysis_results = auditor.analyze_all_duplicates()
    
    if analysis_results:
        # ì•ˆì „í•œ ì •ë¦¬ ê³„íš ìƒì„±
        auditor.generate_safe_cleanup_plan(analysis_results)
        
        print(f"\nğŸ“‹ ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ë¥¼ í™•ì¸í•œ í›„ ì•ˆì „í•œ íŒŒì¼ë§Œ ì‚­ì œí•˜ì„¸ìš”.")
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨. ì¤‘ë³µ íŒŒì¼ ì œì•ˆì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main() 