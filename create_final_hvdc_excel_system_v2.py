"""
ğŸ—ï¸ ìµœì¢… HVDC Real Data Excel System v2.0
TDD ê²€ì¦ëœ ê°œì„  ë¡œì§ + ì…ê³  ë¡œì§ 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ êµ¬í˜„
Samsung C&T Â· ADNOC Â· DSV Partnership
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
import logging
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ v2.0


class HVDCRealDataExcelSystemV2:
    """
    ìµœì¢… HVDC Real Data Excel System v2.0
    ê°œì„ ëœ ì°½ê³  ì…ì¶œê³  ê³„ì‚° ë¡œì§ ì ìš©
    """
    
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ì‹¤ì œ ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.data_path = Path("hvdc_ontology_system/data")
        self.hitachi_file = self.data_path / "HVDC WAREHOUSE_HITACHI(HE).xlsx"
        self.simense_file = self.data_path / "HVDC WAREHOUSE_SIMENSE(SIM).xlsx"
        self.invoice_file = self.data_path / "HVDC WAREHOUSE_INVOICE.xlsx"
        
        # ì‹¤ì œ ë°ì´í„° êµ¬ì¡° ê¸°ë°˜ ë§¤í•‘ (ê°€ì´ë“œ ìˆœì„œëŒ€ë¡œ)
        self.real_warehouse_columns = {
            'AAA Storage': 'AAA_Storage',
            'DSV Al Markaz': 'DSV_Al_Markaz',
            'DSV Indoor': 'DSV_Indoor',
            'DSV MZP': 'DSV_MZP',
            'DSV Outdoor': 'DSV_Outdoor',
            'Hauler Indoor': 'Hauler_Indoor',
            'MOSB': 'MOSB'
        }
        
        self.real_site_columns = {
            'AGI': 'AGI',
            'DAS': 'DAS',
            'MIR': 'MIR',
            'SHU': 'SHU'
        }
        
        # ì°½ê³  ìš°ì„ ìˆœìœ„ ì •ì˜ (DSV Al Markaz > DSV Indoor > Status_Location)
        self.warehouse_priority = ['DSV Al Markaz', 'DSV Indoor', 'DSV Outdoor', 'DSV MZP', 'AAA Storage', 'Hauler Indoor', 'MOSB']
        
        # Flow Code ë§¤í•‘ (ì‹¤ì œ wh handling ê¸°ë°˜)
        self.flow_codes = {
            0: 'Pre Arrival',
            1: 'Port â†’ WH (1ê°œ)',
            2: 'Port â†’ WH (2ê°œ)',
            3: 'Port â†’ WH (3ê°œ)',
            4: 'Port â†’ WH (4ê°œ+)'
        }
        
        # ë°ì´í„° ì €ì¥ ë³€ìˆ˜
        self.combined_data = None
        self.total_records = 0
        
        logger.info("ğŸ—ï¸ HVDC Real Data Excel System v2.0 ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_real_hvdc_data(self):
        """ì‹¤ì œ HVDC RAW DATA ë¡œë“œ (ë¬¼ë¥˜ íŠ¸ëœì­ì…˜ë§Œ)"""
        logger.info("ğŸ“‚ ì‹¤ì œ HVDC RAW DATA ë¡œë“œ ì‹œì‘")
        
        combined_dfs = []
        
        try:
            # HITACHI ë°ì´í„° ë¡œë“œ
            if self.hitachi_file.exists():
                logger.info(f"ğŸ“Š HITACHI ë°ì´í„° ë¡œë“œ: {self.hitachi_file}")
                hitachi_data = pd.read_excel(self.hitachi_file, engine='openpyxl')
                hitachi_data['Vendor'] = 'HITACHI'
                hitachi_data['Source_File'] = 'HITACHI(HE)'
                combined_dfs.append(hitachi_data)
                logger.info(f"âœ… HITACHI ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(hitachi_data)}ê±´")
            
            # SIMENSE ë°ì´í„° ë¡œë“œ
            if self.simense_file.exists():
                logger.info(f"ğŸ“Š SIMENSE ë°ì´í„° ë¡œë“œ: {self.simense_file}")
                simense_data = pd.read_excel(self.simense_file, engine='openpyxl')
                simense_data['Vendor'] = 'SIMENSE'
                simense_data['Source_File'] = 'SIMENSE(SIM)'
                combined_dfs.append(simense_data)
                logger.info(f"âœ… SIMENSE ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(simense_data)}ê±´")
            
            # ë°ì´í„° ê²°í•© (INVOICE íŒŒì¼ ì œì™¸)
            if combined_dfs:
                self.combined_data = pd.concat(combined_dfs, ignore_index=True, sort=False)
                self.total_records = len(self.combined_data)
                logger.info(f"ğŸ”— ë°ì´í„° ê²°í•© ì™„ë£Œ: {self.total_records}ê±´")
            else:
                raise ValueError("ë¡œë“œí•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
        
        return self.combined_data
    
    def process_real_data(self):
        """ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ë° Flow Code ê³„ì‚°"""
        logger.info("ğŸ”§ ì‹¤ì œ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        
        if self.combined_data is None:
            raise ValueError("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
        date_columns = ['ETD/ATD', 'ETA/ATA', 'Status_Location_Date'] + \
                      list(self.real_warehouse_columns.keys()) + \
                      list(self.real_site_columns.keys())
        
        for col in date_columns:
            if col in self.combined_data.columns:
                self.combined_data[col] = pd.to_datetime(self.combined_data[col], errors='coerce')
        
        # Flow Code ê³„ì‚° (ê¸°ì¡´ wh handling ì»¬ëŸ¼ ìš°ì„  í™œìš©)
        if 'wh handling' in self.combined_data.columns:
            logger.info("ğŸ“Š ê¸°ì¡´ 'wh handling' ì»¬ëŸ¼ í™œìš©")
            self.combined_data['FLOW_CODE'] = self.combined_data['wh handling'].fillna(0).astype(int)
            self.combined_data['FLOW_CODE'] = self.combined_data['FLOW_CODE'].clip(0, 4)
        else:
            logger.info("ğŸ”„ wh handling ì»¬ëŸ¼ ì§ì ‘ ê³„ì‚°")
            self.combined_data['FLOW_CODE'] = 0
            for col in self.real_warehouse_columns.keys():
                if col in self.combined_data.columns:
                    self.combined_data['FLOW_CODE'] += self.combined_data[col].notna().astype(int)
            self.combined_data['FLOW_CODE'] = self.combined_data['FLOW_CODE'].clip(0, 4)
        
        # Flow Description ì¶”ê°€
        self.combined_data['FLOW_DESCRIPTION'] = self.combined_data['FLOW_CODE'].map(self.flow_codes)
        
        # ë²¤ë”ë³„ ë¶„í¬ í™•ì¸
        vendor_dist = self.combined_data['Vendor'].value_counts()
        logger.info(f"ğŸ“ˆ ë²¤ë”ë³„ ë¶„í¬: {vendor_dist.to_dict()}")
        
        # Flow Code ë¶„í¬ í™•ì¸
        flow_dist = self.combined_data['FLOW_CODE'].value_counts().sort_index()
        logger.info(f"ğŸ“Š Flow Code ë¶„í¬: {flow_dist.to_dict()}")
        
        logger.info("âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
        return self.combined_data
    
    def calculate_warehouse_inbound(self, df: pd.DataFrame) -> Dict:
        """
        ì…ê³  ë¡œì§ 3ë‹¨ê³„ - Step 1: ì°½ê³  ì»¬ëŸ¼ ë‚ ì§œ ì¡´ì¬ â†’ ì…ê³  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸í™”
        ë°˜í™˜: total_inbound, by_warehouse, by_month
        """
        logger.info("ğŸ”„ ì…ê³  ë¡œì§ Step 1: ì°½ê³  ì…ê³  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸í™”")
        
        inbound_items = []
        total_inbound = 0
        by_warehouse = {}
        by_month = {}
        
        for idx, row in df.iterrows():
            for warehouse in self.real_warehouse_columns.keys():
                if warehouse in row.index and pd.notna(row[warehouse]):
                    try:
                        warehouse_date = pd.to_datetime(row[warehouse])
                        inbound_items.append({
                            'Item_ID': idx,
                            'Warehouse': warehouse,
                            'Inbound_Date': warehouse_date,
                            'Year_Month': warehouse_date.strftime('%Y-%m'),
                            'Vendor': row.get('Vendor', 'Unknown')
                        })
                        total_inbound += 1
                        
                        # ì°½ê³ ë³„ ì§‘ê³„
                        if warehouse not in by_warehouse:
                            by_warehouse[warehouse] = 0
                        by_warehouse[warehouse] += 1
                        
                        # ì›”ë³„ ì§‘ê³„
                        month_key = warehouse_date.strftime('%Y-%m')
                        if month_key not in by_month:
                            by_month[month_key] = 0
                        by_month[month_key] += 1
                        
                    except:
                        continue
        
        logger.info(f"âœ… ì…ê³  ì•„ì´í…œ ì´ {total_inbound}ê±´ ì²˜ë¦¬")
        return {
            'total_inbound': total_inbound,
            'by_warehouse': by_warehouse,
            'by_month': by_month,
            'inbound_items': inbound_items
        }
    
    def create_monthly_inbound_pivot(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì…ê³  ë¡œì§ 3ë‹¨ê³„ - Step 2: pivot_table ë°©ì‹ìœ¼ë¡œ ì›”ë³„ ì…ê³  ì§‘ê³„
        Final_Location ê¸°ì¤€ MonthÃ—Warehouse ë§¤íŠ¸ë¦­ìŠ¤
        """
        logger.info("ğŸ”„ ì…ê³  ë¡œì§ Step 2: ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„±")
        
        # Final Location ê³„ì‚°
        df = self.calculate_final_location(df)
        
        # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
        inbound_data = []
        for idx, row in df.iterrows():
            final_location = row.get('Final_Location', 'Unknown')
            if final_location != 'Unknown':
                for warehouse in self.real_warehouse_columns.keys():
                    if warehouse in row.index and pd.notna(row[warehouse]):
                        try:
                            warehouse_date = pd.to_datetime(row[warehouse])
                            inbound_data.append({
                                'Item_ID': idx,
                                'Warehouse': warehouse,
                                'Final_Location': final_location,
                                'Year_Month': warehouse_date.strftime('%Y-%m'),
                                'Inbound_Date': warehouse_date
                            })
                        except:
                            continue
        
        if not inbound_data:
            # ë¹ˆ í”¼ë²— í…Œì´ë¸” ë°˜í™˜
            months = pd.date_range('2023-02', '2025-06', freq='MS')
            month_strings = [month.strftime('%Y-%m') for month in months]
            
            pivot_df = pd.DataFrame(index=month_strings)
            for warehouse in self.real_warehouse_columns.keys():
                pivot_df[warehouse] = 0
            
            return pivot_df
        
        # í”¼ë²— í…Œì´ë¸” ìƒì„±
        inbound_df = pd.DataFrame(inbound_data)
        pivot_df = inbound_df.pivot_table(
            index='Year_Month', 
            columns='Final_Location', 
            values='Item_ID', 
            aggfunc='count', 
            fill_value=0
        )
        
        logger.info(f"âœ… ì›”ë³„ ì…ê³  í”¼ë²— ìƒì„± ì™„ë£Œ: {pivot_df.shape}")
        return pivot_df
    
    def calculate_final_location(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ì…ê³  ë¡œì§ 3ë‹¨ê³„ - Step 3: ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìµœì¢… ìœ„ì¹˜ ê³„ì‚°
        ìš°ì„ ìˆœìœ„: DSV Al Markaz > DSV Indoor > Status_Location
        """
        logger.info("ğŸ”„ ì…ê³  ë¡œì§ Step 3: ìµœì¢… ìœ„ì¹˜ ê³„ì‚° (ìš°ì„ ìˆœìœ„ ì ìš©)")
        
        def get_final_location(row):
            # ìš°ì„ ìˆœìœ„ ìˆœì„œë¡œ í™•ì¸
            for warehouse in self.warehouse_priority:
                if warehouse in row.index and pd.notna(row[warehouse]):
                    return warehouse
            
            # ë§ˆì§€ë§‰ìœ¼ë¡œ Status_Location í™•ì¸
            if 'Status_Location' in row.index and pd.notna(row['Status_Location']):
                return 'Status_Location'
            
            return 'Unknown'
        
        # np.select ê³ ì„±ëŠ¥ ê³„ì‚° í™œìš©
        conditions = []
        choices = []
        
        for warehouse in self.warehouse_priority:
            if warehouse in df.columns:
                conditions.append(df[warehouse].notna())
                choices.append(warehouse)
        
        # Status_Location ì¡°ê±´ ì¶”ê°€
        if 'Status_Location' in df.columns:
            conditions.append(df['Status_Location'].notna())
            choices.append('Status_Location')
        
        # ì¡°ê±´ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì²˜ë¦¬
        if not conditions:
            df['Final_Location'] = 'Unknown'
        else:
            df['Final_Location'] = np.select(conditions, choices, default='Unknown')
        
        logger.info(f"âœ… ìµœì¢… ìœ„ì¹˜ ê³„ì‚° ì™„ë£Œ")
        return df
    
    def calculate_warehouse_outbound(self, df: pd.DataFrame) -> Dict:
        """ì°½ê³  ì¶œê³  ë¡œì§ - Site ì»¬ëŸ¼ ë‚ ì§œ ì¡´ì¬ â†’ ì¶œê³  ì§‘ê³„"""
        logger.info("ğŸ”„ ì°½ê³  ì¶œê³  ê³„ì‚° ì‹œì‘")
        
        outbound_items = []
        total_outbound = 0
        by_warehouse = {}
        by_month = {}
        
        for idx, row in df.iterrows():
            for site in self.real_site_columns.keys():
                if site in row.index and pd.notna(row[site]):
                    try:
                        site_date = pd.to_datetime(row[site])
                        # í•´ë‹¹ ì•„ì´í…œì´ ì–´ëŠ ì°½ê³ ì—ì„œ ì¶œê³ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        final_location = row.get('Final_Location', 'Unknown')
                        
                        if final_location in self.real_warehouse_columns:
                            outbound_items.append({
                                'Item_ID': idx,
                                'Warehouse': final_location,
                                'Site': site,
                                'Outbound_Date': site_date,
                                'Year_Month': site_date.strftime('%Y-%m')
                            })
                            total_outbound += 1
                            
                            # ì°½ê³ ë³„ ì§‘ê³„
                            if final_location not in by_warehouse:
                                by_warehouse[final_location] = 0
                            by_warehouse[final_location] += 1
                            
                            # ì›”ë³„ ì§‘ê³„
                            month_key = site_date.strftime('%Y-%m')
                            if month_key not in by_month:
                                by_month[month_key] = 0
                            by_month[month_key] += 1
                            
                    except:
                        continue
        
        logger.info(f"âœ… ì¶œê³  ì•„ì´í…œ ì´ {total_outbound}ê±´ ì²˜ë¦¬")
        return {
            'total_outbound': total_outbound,
            'by_warehouse': by_warehouse,
            'by_month': by_month,
            'outbound_items': outbound_items
        }
    
    def calculate_warehouse_inventory(self, df: pd.DataFrame) -> Dict:
        """ì°½ê³  ì¬ê³  ë¡œì§ - In â€“ Out ëˆ„ì  = ì›”ë§ ì¬ê³ """
        logger.info("ğŸ”„ ì°½ê³  ì¬ê³  ê³„ì‚° ì‹œì‘")
        
        # ì…ê³  ë° ì¶œê³  ê³„ì‚°
        inbound_result = self.calculate_warehouse_inbound(df)
        outbound_result = self.calculate_warehouse_outbound(df)
        
        # ì›”ë³„ ì¬ê³  ê³„ì‚°
        inventory_by_month = {}
        all_months = set()
        
        # ëª¨ë“  ì›” ìˆ˜ì§‘
        all_months.update(inbound_result['by_month'].keys())
        all_months.update(outbound_result['by_month'].keys())
        
        # ì›”ë³„ ì¬ê³  ê³„ì‚°
        for month in sorted(all_months):
            inbound_count = inbound_result['by_month'].get(month, 0)
            outbound_count = outbound_result['by_month'].get(month, 0)
            inventory_by_month[month] = inbound_count - outbound_count
        
        # ì°½ê³ ë³„ ì¬ê³  ê³„ì‚°
        inventory_by_warehouse = {}
        for warehouse in self.real_warehouse_columns.keys():
            inbound_count = inbound_result['by_warehouse'].get(warehouse, 0)
            outbound_count = outbound_result['by_warehouse'].get(warehouse, 0)
            inventory_by_warehouse[warehouse] = inbound_count - outbound_count
        
        return {
            'inventory_by_month': inventory_by_month,
            'inventory_by_warehouse': inventory_by_warehouse,
            'total_inventory': sum(inventory_by_warehouse.values())
        }
    
    def calculate_direct_delivery(self, df: pd.DataFrame) -> Dict:
        """ì§ì†¡ ë¡œì§ - Portâ†’Site ì§ì ‘ ì´ë™ (FLOW_CODE 0/1) ì‹ë³„"""
        logger.info("ğŸ”„ ì§ì†¡ ë°°ì†¡ ê³„ì‚° ì‹œì‘")
        
        # FLOW_CODE 0 ë˜ëŠ” 1ì¸ ê²½ìš°ë¥¼ ì§ì†¡ìœ¼ë¡œ ê°„ì£¼
        direct_delivery_df = df[df['FLOW_CODE'].isin([0, 1])]
        
        direct_items = []
        total_direct = len(direct_delivery_df)
        
        for idx, row in direct_delivery_df.iterrows():
            for site in self.real_site_columns.keys():
                if site in row.index and pd.notna(row[site]):
                    try:
                        site_date = pd.to_datetime(row[site])
                        direct_items.append({
                            'Item_ID': idx,
                            'Site': site,
                            'Direct_Date': site_date,
                            'Year_Month': site_date.strftime('%Y-%m'),
                            'Flow_Code': row['FLOW_CODE']
                        })
                    except:
                        continue
        
        logger.info(f"âœ… ì§ì†¡ ë°°ì†¡ ì´ {total_direct}ê±´ ì²˜ë¦¬")
        return {
            'total_direct': total_direct,
            'direct_items': direct_items
        }
    

    
    def calculate_warehouse_outbound_real(self, df: pd.DataFrame, warehouse_name: str, period: pd.Timestamp) -> int:
        """
        TDD ê²€ì¦ëœ ì‹œê°„ ìˆœì„œ ê¸°ë°˜ ì •í™•í•œ ì¶œê³  ê³„ì‚°
        ê°œë³„ ì¼€ì´ìŠ¤ë³„ë¡œ ì°½ê³  â†’ ë‹¤ìŒ ë‹¨ê³„ ì´ë™ ì¶”ì 
        """
        # ë¹ˆ DataFrame ì²˜ë¦¬
        if df.empty or warehouse_name not in df.columns:
            return 0
        
        outbound_count = 0
        
        # Step 1: í•´ë‹¹ ì°½ê³  ë°©ë¬¸ ì¼€ì´ìŠ¤ í•„í„°ë§
        warehouse_visited = df[df[warehouse_name].notna()].copy()
        
        if len(warehouse_visited) == 0:
            return 0
        
        # Step 2: ê° ì¼€ì´ìŠ¤ë³„ ê°œë³„ ì¶”ì 
        for idx, row in warehouse_visited.iterrows():
            warehouse_date = row[warehouse_name]  # ì°½ê³  ë„ì°© ì‹œì 
            
            # Step 3: ë‹¤ìŒ ë‹¨ê³„ ì´ë™ ë‚ ì§œ íƒìƒ‰
            next_dates = []
            
            # 3-1: ë‹¤ë¥¸ ì°½ê³ ë¡œ ì´ë™ í™•ì¸
            for other_wh in self.real_warehouse_columns.keys():
                if other_wh != warehouse_name and other_wh in row.index:
                    other_date = row[other_wh]
                    if pd.notna(other_date) and other_date > warehouse_date:
                        next_dates.append(other_date)
            
            # 3-2: í˜„ì¥ìœ¼ë¡œ ì´ë™ í™•ì¸
            for site_name in self.real_site_columns.keys():
                if site_name in row.index:
                    site_date = row[site_name]
                    if pd.notna(site_date) and site_date > warehouse_date:
                        next_dates.append(site_date)
            
            # Step 4: ê°€ì¥ ë¹ ë¥¸ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì¶œê³  ì‹œì  ê²°ì •
            if next_dates:
                earliest_next_date = min(next_dates)
                if earliest_next_date.to_period('M') == period.to_period('M'):
                    outbound_count += 1
                    
        return outbound_count
    
    def calculate_site_inventory_real(self, df: pd.DataFrame, site_name: str, period: pd.Timestamp) -> int:
        """
        í˜„ì¥ë³„ ëˆ„ì  ì¬ê³  ì •í™• ê³„ì‚°
        í•´ë‹¹ ì›” ë§ê¹Œì§€ í˜„ì¥ì— ëˆ„ì ëœ ê±´ìˆ˜
        """
        if df.empty or site_name not in df.columns:
            return 0
        
        # í•´ë‹¹ ì›” ë§ê¹Œì§€ í˜„ì¥ì— ë„ì°©í•œ ëˆ„ì  ê±´ìˆ˜
        site_dates = df[site_name].dropna()
        month_end = period + pd.DateOffset(months=1) - pd.DateOffset(days=1)
        arrived_by_month_end = (site_dates <= month_end).sum()
        
        # í˜„ì¬ Status_Locationê³¼ êµì°¨ ê²€ì¦
        current_at_site = 0
        if 'Status_Location' in df.columns:
            current_at_site = (df['Status_Location'] == site_name).sum()
        
        # ë³´ìˆ˜ì  ì ‘ê·¼ (ë” ì‘ì€ ê°’ ì„ íƒ)
        return min(arrived_by_month_end, current_at_site) if current_at_site > 0 else arrived_by_month_end
    
    def calculate_warehouse_monthly_real(self) -> pd.DataFrame:
        """
        ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  ê³„ì‚° (ê°€ì´ë“œ í‘œì¤€)
        3ë‹¨ê³„ ì…ê³  ë¡œì§ ì ìš© + Multi-Level Header êµ¬ì¡° (15ì—´)
        """
        logger.info("ğŸ“Š ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  ê³„ì‚° (ê°€ì´ë“œ 3ë‹¨ê³„ ë¡œì§)")
        
        df = self.combined_data.copy()
        
        # 3ë‹¨ê³„ ì…ê³  ë¡œì§ ì ìš©
        df = self.calculate_final_location(df)
        inbound_result = self.calculate_warehouse_inbound(df)
        outbound_result = self.calculate_warehouse_outbound(df)
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2023-02 ~ 2025-06)
        months = pd.date_range('2023-02', '2025-06', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # ê²°ê³¼ DataFrame ì´ˆê¸°í™” (15ì—´ êµ¬ì¡°)
        results = []
        
        for month_str in month_strings:
            row = [month_str]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼: ì…ê³ ì›”
            
            # ì…ê³  7ê°œ ì°½ê³  (ê°€ì´ë“œ ìˆœì„œ)
            warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB']
            for warehouse in warehouses:
                # ì›”ë³„ ì…ê³  ê³„ì‚°
                inbound_count = 0
                for item in inbound_result.get('inbound_items', []):
                    if item.get('Warehouse') == warehouse and item.get('Year_Month') == month_str:
                        inbound_count += 1
                row.append(inbound_count)
            
            # ì¶œê³  7ê°œ ì°½ê³  (ë™ì¼ ìˆœì„œ)
            for warehouse in warehouses:
                # ì›”ë³„ ì¶œê³  ê³„ì‚°
                outbound_count = 0
                for item in outbound_result.get('outbound_items', []):
                    if item.get('Warehouse') == warehouse and item.get('Year_Month') == month_str:
                        outbound_count += 1
                row.append(outbound_count)
            
            results.append(row)
        
        # ì»¬ëŸ¼ ìƒì„± (15ì—´)
        columns = ['ì…ê³ ì›”']
        
        # ì…ê³  7ê°œ ì°½ê³ 
        warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB']
        for warehouse in warehouses:
            columns.append(f'ì…ê³ _{warehouse}')
        
        # ì¶œê³  7ê°œ ì°½ê³ 
        for warehouse in warehouses:
            columns.append(f'ì¶œê³ _{warehouse}')
        
        # DataFrame ìƒì„±
        warehouse_monthly = pd.DataFrame(results, columns=columns)
        
        # ì´í•©ê³„ í–‰ ì¶”ê°€
        total_row = ['Total']
        
        # ì…ê³  ì´í•©
        for warehouse in warehouses:
            total_inbound = warehouse_monthly[f'ì…ê³ _{warehouse}'].sum()
            total_row.append(total_inbound)
        
        # ì¶œê³  ì´í•©
        for warehouse in warehouses:
            total_outbound = warehouse_monthly[f'ì¶œê³ _{warehouse}'].sum()
            total_row.append(total_outbound)
        
        warehouse_monthly.loc[len(warehouse_monthly)] = total_row
        
        logger.info(f"âœ… ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  ê³„ì‚° ì™„ë£Œ: {warehouse_monthly.shape} (15ì—´)")
        return warehouse_monthly
    
    def calculate_site_monthly_real(self) -> pd.DataFrame:
        """
        í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  ê³„ì‚° (ê°€ì´ë“œ í‘œì¤€)
        Multi-Level Header êµ¬ì¡° (9ì—´) + ì§ì†¡ ë¡œì§ ì ìš©
        """
        logger.info("ğŸ“Š í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  ê³„ì‚° (ê°€ì´ë“œ í‘œì¤€)")
        
        df = self.combined_data.copy()
        
        # ì§ì†¡ ë°°ì†¡ ê³„ì‚°
        direct_result = self.calculate_direct_delivery(df)
        
        # ì›”ë³„ ê¸°ê°„ ìƒì„± (2024-01 ~ 2025-06)
        months = pd.date_range('2024-01', '2025-06', freq='MS')
        month_strings = [month.strftime('%Y-%m') for month in months]
        
        # ê²°ê³¼ DataFrame ì´ˆê¸°í™” (9ì—´ êµ¬ì¡°)
        results = []
        
        # ëˆ„ì  ì¬ê³  ê³„ì‚°ìš© ë³€ìˆ˜
        cumulative_inventory = {'AGI': 0, 'DAS': 0, 'MIR': 0, 'SHU': 0}
        
        for month_str in month_strings:
            row = [month_str]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼: ì…ê³ ì›”
            
            # ì…ê³  4ê°œ í˜„ì¥ (ê°€ì´ë“œ ìˆœì„œ)
            sites = ['AGI', 'DAS', 'MIR', 'SHU']
            for site in sites:
                # ì›”ë³„ ì…ê³  ê³„ì‚° (ì§ì†¡ ë°°ì†¡ í¬í•¨)
                inbound_count = 0
                for item in direct_result.get('direct_items', []):
                    if item.get('Site') == site and item.get('Year_Month') == month_str:
                        inbound_count += 1
                
                # í˜„ì¥ë³„ ì…ê³  ì¶”ê°€ (ì¼ë°˜ ë°°ì†¡)
                if site in df.columns:
                    site_dates = df[site].dropna()
                    for date in site_dates:
                        try:
                            if pd.to_datetime(date).strftime('%Y-%m') == month_str:
                                inbound_count += 1
                        except:
                            continue
                
                row.append(inbound_count)
                
                # ëˆ„ì  ì¬ê³  ì—…ë°ì´íŠ¸
                cumulative_inventory[site] += inbound_count
            
            # ì¬ê³  4ê°œ í˜„ì¥ (ë™ì¼ ìˆœì„œ)
            for site in sites:
                # ì›”ë³„ ì†Œë¹„ (ì…ê³ ëŸ‰ì˜ 5% ì†Œë¹„)
                consumption = int(cumulative_inventory[site] * 0.05)
                cumulative_inventory[site] = max(0, cumulative_inventory[site] - consumption)
                row.append(cumulative_inventory[site])
            
            results.append(row)
        
        # ì»¬ëŸ¼ ìƒì„± (9ì—´)
        columns = ['ì…ê³ ì›”']
        
        # ì…ê³  4ê°œ í˜„ì¥
        sites = ['AGI', 'DAS', 'MIR', 'SHU']
        for site in sites:
            columns.append(f'ì…ê³ _{site}')
        
        # ì¬ê³  4ê°œ í˜„ì¥
        for site in sites:
            columns.append(f'ì¬ê³ _{site}')
        
        # DataFrame ìƒì„±
        site_monthly = pd.DataFrame(results, columns=columns)
        
        # ì´í•©ê³„ í–‰ ì¶”ê°€
        total_row = ['Total']
        
        # ì…ê³  ì´í•©
        for site in sites:
            total_inbound = site_monthly[f'ì…ê³ _{site}'].sum()
            total_row.append(total_inbound)
        
        # ì¬ê³  ì´í•© (ìµœì¢… ì¬ê³ )
        for site in sites:
            final_inventory = site_monthly[f'ì¬ê³ _{site}'].iloc[-1] if not site_monthly.empty else 0
            total_row.append(final_inventory)
        
        site_monthly.loc[len(site_monthly)] = total_row
        
        logger.info(f"âœ… í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  ê³„ì‚° ì™„ë£Œ: {site_monthly.shape} (9ì—´)")
        return site_monthly
    
    def create_flow_analysis_real(self) -> pd.DataFrame:
        """ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ Flow Code ë¶„ì„"""
        logger.info("ğŸ“Š Flow Code ë¶„ì„ ì‹œì‘")
        
        df = self.combined_data.copy()
        
        # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì•ˆì „ í•„í„°ë§
        potential_numeric_columns = ['CBM', 'N.W(kgs)', 'G.W(kgs)', 'SQM', 'Pkg']
        available_numeric_columns = []
        
        for col in potential_numeric_columns:
            if col in df.columns:
                # ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                try:
                    test_series = pd.to_numeric(df[col], errors='coerce')
                    if not test_series.isna().all():  # ëª¨ë‘ NaNì´ ì•„ë‹ˆë©´ ì‚¬ìš© ê°€ëŠ¥
                        # ì‹¤ì œ ë°ì´í„°ë¥¼ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
                        df[col] = test_series
                        available_numeric_columns.append(col)
                        logger.info(f"âœ… ìˆ˜ì¹˜ ì»¬ëŸ¼ í™•ì¸: {col}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ìˆ˜ì¹˜ ì»¬ëŸ¼ ë³€í™˜ ì‹¤íŒ¨: {col} - {str(e)}")
        
        # Flow Codeë³„ ê¸°ë³¸ í†µê³„
        if available_numeric_columns:
            # ì•ˆì „í•œ ì§‘ê³„ ì‹¤í–‰
            agg_dict = {}
            
            # Case ì¹´ìš´íŠ¸ ì¶”ê°€
            case_column = 'Case No.' if 'Case No.' in df.columns else df.columns[0]
            agg_dict[case_column] = 'count'
            
            # ìˆ˜ì¹˜ ì»¬ëŸ¼ ì§‘ê³„ ì¶”ê°€
            for col in available_numeric_columns:
                agg_dict[col] = ['sum', 'mean']
            
            try:
                flow_summary = df.groupby('FLOW_CODE').agg(agg_dict).round(2)
                flow_summary.columns = ['_'.join(str(col)).strip() for col in flow_summary.columns]
                flow_summary = flow_summary.reset_index()
            except Exception as e:
                logger.warning(f"âš ï¸ ìƒì„¸ ì§‘ê³„ ì‹¤íŒ¨, ê¸°ë³¸ ì§‘ê³„ ì‚¬ìš©: {str(e)}")
                flow_summary = df.groupby('FLOW_CODE').size().reset_index(name='Count')
        else:
            logger.info("ğŸ“Š ìˆ˜ì¹˜ ì»¬ëŸ¼ì´ ì—†ì–´ ê¸°ë³¸ ì§‘ê³„ ì‚¬ìš©")
            flow_summary = df.groupby('FLOW_CODE').size().reset_index(name='Count')
        
        # Flow Description ì¶”ê°€
        flow_summary['FLOW_DESCRIPTION'] = flow_summary['FLOW_CODE'].map(self.flow_codes)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì¡°ì • (FLOW_DESCRIPTIONì„ ì•ìª½ìœ¼ë¡œ)
        cols = flow_summary.columns.tolist()
        if 'FLOW_DESCRIPTION' in cols:
            cols.remove('FLOW_DESCRIPTION')
            cols.insert(1, 'FLOW_DESCRIPTION')  # FLOW_CODE ë‹¤ìŒì— ìœ„ì¹˜
            flow_summary = flow_summary[cols]
        
        logger.info(f"âœ… Flow Code ë¶„ì„ ì™„ë£Œ: {len(flow_summary)}ê°œ ì½”ë“œ")
        return flow_summary
    
    def create_transaction_summary(self) -> pd.DataFrame:
        """ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½"""
        logger.info("ğŸ“Š ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ìƒì„±")
        
        df = self.combined_data.copy()
        
        # ê¸°ë³¸ ìš”ì•½ ì •ë³´
        summary_data = []
        
        # ì „ì²´ í†µê³„
        summary_data.append({
            'Category': 'ì „ì²´ í†µê³„',
            'Item': 'ì´ íŠ¸ëœì­ì…˜ ê±´ìˆ˜',
            'Value': f"{len(df):,}ê±´",
            'Percentage': '100.0%'
        })
        
        # ë²¤ë”ë³„ ë¶„í¬
        vendor_dist = df['Vendor'].value_counts()
        for vendor, count in vendor_dist.items():
            percentage = (count / len(df)) * 100
            summary_data.append({
                'Category': 'ë²¤ë”ë³„ ë¶„í¬',
                'Item': vendor,
                'Value': f"{count:,}ê±´",
                'Percentage': f"{percentage:.1f}%"
            })
        
        # Flow Code ë¶„í¬
        flow_dist = df['FLOW_CODE'].value_counts().sort_index()
        for flow_code, count in flow_dist.items():
            percentage = (count / len(df)) * 100
            flow_desc = self.flow_codes.get(flow_code, f"Flow {flow_code}")
            summary_data.append({
                'Category': 'Flow Code ë¶„í¬',
                'Item': f"Flow {flow_code}: {flow_desc}",
                'Value': f"{count:,}ê±´",
                'Percentage': f"{percentage:.1f}%"
            })
        
        # ì°½ê³ ë³„ ë°©ë¬¸ í˜„í™©
        for warehouse_name in self.real_warehouse_columns.keys():
            if warehouse_name in df.columns:
                visited_count = df[warehouse_name].notna().sum()
                percentage = (visited_count / len(df)) * 100
                summary_data.append({
                    'Category': 'ì°½ê³ ë³„ ë°©ë¬¸ í˜„í™©',
                    'Item': warehouse_name,
                    'Value': f"{visited_count:,}ê±´",
                    'Percentage': f"{percentage:.1f}%"
                })
        
        # í˜„ì¥ë³„ ë„ì°© í˜„í™©
        for site_name in self.real_site_columns.keys():
            if site_name in df.columns:
                arrived_count = df[site_name].notna().sum()
                percentage = (arrived_count / len(df)) * 100
                summary_data.append({
                    'Category': 'í˜„ì¥ë³„ ë„ì°© í˜„í™©',
                    'Item': site_name,
                    'Value': f"{arrived_count:,}ê±´",
                    'Percentage': f"{percentage:.1f}%"
                })
        
        summary_df = pd.DataFrame(summary_data)
        
        logger.info(f"âœ… ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½ ì™„ë£Œ: {len(summary_df)}ê°œ í•­ëª©")
        return summary_df
    
    def create_multi_level_headers(self, df: pd.DataFrame, sheet_type: str) -> pd.DataFrame:
        """Multi-Level Header ìƒì„± (ê°€ì´ë“œ í‘œì¤€)"""
        if sheet_type == 'warehouse':
            # ì°½ê³  Multi-Level Header: 15ì—´ (Location + ì…ê³ 7 + ì¶œê³ 7)
            level_0 = ['ì…ê³ ì›”']  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = ['']
            
            # ì…ê³  7ê°œ ì°½ê³  (ê°€ì´ë“œ ìˆœì„œ)
            warehouses = ['AAA Storage', 'DSV Al Markaz', 'DSV Indoor', 'DSV MZP', 'DSV Outdoor', 'Hauler Indoor', 'MOSB']
            for warehouse in warehouses:
                level_0.append('ì…ê³ ')
                level_1.append(warehouse)
            
            # ì¶œê³  7ê°œ ì°½ê³  (ë™ì¼ ìˆœì„œ)
            for warehouse in warehouses:
                level_0.append('ì¶œê³ ')
                level_1.append(warehouse)
            
            multi_columns = pd.MultiIndex.from_arrays([level_0, level_1], names=['Type', 'Location'])
            
        elif sheet_type == 'site':
            # í˜„ì¥ Multi-Level Header: 9ì—´ (Location + ì…ê³ 4 + ì¬ê³ 4)
            level_0 = ['ì…ê³ ì›”']  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
            level_1 = ['']
            
            # ì…ê³  4ê°œ í˜„ì¥ (ê°€ì´ë“œ ìˆœì„œ)
            sites = ['AGI', 'DAS', 'MIR', 'SHU']
            for site in sites:
                level_0.append('ì…ê³ ')
                level_1.append(site)
            
            # ì¬ê³  4ê°œ í˜„ì¥ (ë™ì¼ ìˆœì„œ)
            for site in sites:
                level_0.append('ì¬ê³ ')
                level_1.append(site)
            
            multi_columns = pd.MultiIndex.from_arrays([level_0, level_1], names=['Type', 'Location'])
        
        else:
            return df
        
        # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
        if len(df.columns) == len(multi_columns):
            df.columns = multi_columns
        
        return df
    
    def generate_final_excel_system(self):
        """ìµœì¢… Excel ì‹œìŠ¤í…œ ìƒì„± (ê°€ì´ë“œ í‘œì¤€ 5ì‹œíŠ¸)"""
        logger.info("ğŸ—ï¸ ìµœì¢… Excel ì‹œìŠ¤í…œ ìƒì„± ì‹œì‘ (ê°€ì´ë“œ í‘œì¤€)")
        
        # ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬
        self.load_real_hvdc_data()
        self.process_real_data()
        
        # ê° ì‹œíŠ¸ ë°ì´í„° ì¤€ë¹„
        logger.info("ğŸ“Š ì‹œíŠ¸ë³„ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        # ì‹œíŠ¸ 1: ì°½ê³ ë³„ ì›”ë³„ ì…ì¶œê³  (Multi-Level Header, 15ì—´)
        warehouse_monthly = self.calculate_warehouse_monthly_real()
        warehouse_monthly_with_headers = self.create_multi_level_headers(warehouse_monthly, 'warehouse')
        
        # ì‹œíŠ¸ 2: í˜„ì¥ë³„ ì›”ë³„ ì…ê³ ì¬ê³  (Multi-Level Header, 9ì—´)
        site_monthly = self.calculate_site_monthly_real()
        site_monthly_with_headers = self.create_multi_level_headers(site_monthly, 'site')
        
        # ì‹œíŠ¸ 3: Flow Code ë¶„ì„ (FLOW_CODE 0-4 ë¶„ì„)
        flow_analysis = self.create_flow_analysis_real()
        
        # ì‹œíŠ¸ 4: ì „ì²´ íŠ¸ëœì­ì…˜ ìš”ì•½
        transaction_summary = self.create_transaction_summary()
        
        # ì‹œíŠ¸ 5: ì›ë³¸ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 1000ê±´)
        sample_data = self.combined_data.head(1000)
        
        # Excel íŒŒì¼ ìƒì„±
        excel_filename = f"HVDC_ì…ê³ ë¡œì§_ì¢…í•©ë¦¬í¬íŠ¸_{self.timestamp}.xlsx"
        
        logger.info(f"ğŸ“ Excel íŒŒì¼ ìƒì„±: {excel_filename}")
        
        with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
            # ì‹œíŠ¸ 1: ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header)
            if isinstance(warehouse_monthly_with_headers.columns, pd.MultiIndex):
                warehouse_monthly_with_headers.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', index=True)
            else:
                warehouse_monthly_with_headers.to_excel(writer, sheet_name='ì°½ê³ _ì›”ë³„_ì…ì¶œê³ ', index=False)
            
            # ì‹œíŠ¸ 2: í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header)
            if isinstance(site_monthly_with_headers.columns, pd.MultiIndex):
                site_monthly_with_headers.to_excel(writer, sheet_name='í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', index=True)
            else:
                site_monthly_with_headers.to_excel(writer, sheet_name='í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³ ', index=False)
            
            # ì‹œíŠ¸ 3: Flow_Code_ë¶„ì„
            flow_analysis.to_excel(writer, sheet_name='Flow_Code_ë¶„ì„', index=False)
            
            # ì‹œíŠ¸ 4: ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½
            transaction_summary.to_excel(writer, sheet_name='ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½', index=False)
            
            # ì‹œíŠ¸ 5: ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ
            sample_data.to_excel(writer, sheet_name='ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ', index=False)
        
        logger.info(f"ğŸ‰ ìµœì¢… Excel ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ: {excel_filename}")
        
        # ê²°ê³¼ í†µê³„ ì¶œë ¥
        logger.info("ğŸ“Š ìµœì¢… ê²°ê³¼ í†µê³„:")
        logger.info(f"   - ì´ íŠ¸ëœì­ì…˜: {self.total_records:,}ê±´")
        logger.info(f"   - ìƒì„±ëœ ì‹œíŠ¸: 5ê°œ")
        logger.info(f"   - ì°½ê³ ë³„ ì›”ë³„ ë°ì´í„°: {len(warehouse_monthly)}í–‰ (15ì—´)")
        logger.info(f"   - í˜„ì¥ë³„ ì›”ë³„ ë°ì´í„°: {len(site_monthly)}í–‰ (9ì—´)")
        logger.info(f"   - Flow Code ë¶„ì„: {len(flow_analysis)}ê°œ ì½”ë“œ")
        logger.info(f"   - ì…ê³  ë¡œì§ 3ë‹¨ê³„: calculate_warehouse_inbound() â†’ create_monthly_inbound_pivot() â†’ calculate_final_location()")
        
        return excel_filename


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ—ï¸ HVDC ì…ê³  ë¡œì§ êµ¬í˜„ ë° ì§‘ê³„ ì‹œìŠ¤í…œ v2.0")
    print("ì…ê³  ë¡œì§ 3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ + Multi-Level Header êµ¬ì¡°")
    print("Samsung C&T Â· ADNOC Â· DSV Partnership")
    print("=" * 60)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì‹¤í–‰
        system = HVDCRealDataExcelSystemV2()
        excel_file = system.generate_final_excel_system()
        
        print(f"\nğŸ‰ HVDC ì…ê³  ë¡œì§ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼ëª…: {excel_file}")
        print(f"ğŸ“Š ì´ ë°ì´í„°: {system.total_records:,}ê±´")
        print(f"ğŸ“‹ ìƒì„±ëœ ì‹œíŠ¸:")
        print(f"   1. ì°½ê³ _ì›”ë³„_ì…ì¶œê³  (Multi-Level Header 15ì—´)")
        print(f"   2. í˜„ì¥_ì›”ë³„_ì…ê³ ì¬ê³  (Multi-Level Header 9ì—´)")
        print(f"   3. Flow_Code_ë¶„ì„ (FLOW_CODE 0-4)")
        print(f"   4. ì „ì²´_íŠ¸ëœì­ì…˜_ìš”ì•½")
        print(f"   5. ì›ë³¸_ë°ì´í„°_ìƒ˜í”Œ")
        print(f"\nğŸ“ˆ í•µì‹¬ ë¡œì§:")
        print(f"   - ì…ê³  ë¡œì§ 3ë‹¨ê³„: calculate_warehouse_inbound() â†’ create_monthly_inbound_pivot() â†’ calculate_final_location()")
        print(f"   - ì°½ê³  ìš°ì„ ìˆœìœ„: DSV Al Markaz > DSV Indoor > Status_Location")
        print(f"   - Multi-Level Header êµ¬ì¡° í‘œì¤€í™”")
        
    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise


if __name__ == "__main__":
    main() 